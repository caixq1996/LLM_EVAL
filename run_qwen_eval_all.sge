#!/bin/bash
#$ -S /bin/bash
#$ -cwd
#$ -jc gtn-container_g8.24h
#$ -ac d=nvcr-cuda-12.4.1-ubuntu22.04,d_shm=256g
#$ -j y
set -x
# set -e # 生产运行建议关闭，避免日志过多

PROJECT_NAME="OPRA"
EXP_NAMES="${EXP_NAMES:-OPRA-LoRA}"
BASE_ROOT="${BASE_ROOT:-/hss/giil/caixq/model}"
PROMPT_TYPE="${PROMPT_TYPE:-think-boxed}"
MAX_TOKENS="${MAX_TOKENS:-3072}"

# 1. 自动探测 GPU 数量
if [[ -z "${NUM_GPUS:-}" ]]; then
  if command -v nvidia-smi >/dev/null 2>&1; then
    NUM_GPUS=$(nvidia-smi --list-gpus | grep -c '^GPU')
    [[ "${NUM_GPUS}" -ge 1 ]] || NUM_GPUS=1
  else
    NUM_GPUS=1
  fi
fi

PYTHON_BIN="${PYTHON_BIN:-$HOME/miniconda3/envs/eval/bin/python3}"
OUT_ROOT="${OUT_ROOT:-$HOME/project/${PROJECT_NAME}/new_eval_${EXP_NAMES}_${PROMPT_TYPE}}"
MODEL_ROOT="${MODEL_ROOT:-$HOME/project/${PROJECT_NAME}/checkpoints/${EXP_NAMES}}"
MAX_SAMPLE_NUMS="${MAX_SAMPLE_NUMS:-128}"
SKIP_BASE_EVAL="${SKIP_BASE_EVAL:-false}"

export TZ='JST-9'
mkdir -p eval_log
TS="$(date +%Y%m%d_%H%M%S)"

# 注意：这里不再将所有输出重定向到同一个文件，而是让每个 GPU 进程写自己的日志
echo "[INFO] Job started at ${TS}. Detected ${NUM_GPUS} GPUs."

TEMP_G1="${TEMP_G1:-0.6}"
TEMP_G2="${TEMP_G2:-0.0}"
NSAMP_G1="${NSAMP_G1:-${MAX_SAMPLE_NUMS}}"
NSAMP_G2="${NSAMP_G2:-${MAX_SAMPLE_NUMS}}"

export EVAL_ONE_MODEL_TIMEOUT="${EVAL_ONE_MODEL_TIMEOUT:-21600}"
export PASS_AT_KS="${PASS_AT_KS:-1,${MAX_SAMPLE_NUMS}}"
export TORCH_CPP_LOG_LEVEL=ERROR
export VLLM_WORKER_MULTIPROC_METHOD=spawn
export PYTHONUNBUFFERED=1
export VLLM_USE_FLASHINFER_SAMPLER=1

# 基础参数数组
base_args=(
  --model_root "$MODEL_ROOT"
  --out_root "$OUT_ROOT"
  --prompt_type "$PROMPT_TYPE"
  --max_tokens_per_call "$MAX_TOKENS"
  --base_root "$BASE_ROOT"
  --use_vllm
  --pipeline_parallel_size 1
  --vllm_batch_size 0
  --temperature_g1 "$TEMP_G1"
  --temperature_g2 "$TEMP_G2"
  --n_sampling_g1 "$NSAMP_G1"
  --n_sampling_g2 "$NSAMP_G2"
  # 注意：单节点多进程并行时，建议去掉 --cleanup_exported
  # 因为进程A可能正在用模型，进程B评测完把它删了会导致报错
  # --cleanup_exported 
)

if [ "$SKIP_BASE_EVAL" = "true" ]; then
  base_args+=( --skip_base_eval )
fi

# =======================================================
# 2. 多进程启动逻辑 (Data Parallelism)
# =======================================================

pids=()

for ((i=0; i<NUM_GPUS; i++)); do
    # 为每个进程分配独立的日志文件
    LOG_FILE="eval_log/qwen-eval.${TS}.rank_${i}.log"
    
    echo "[INFO] Starting Worker $i/$NUM_GPUS on GPU $i... Log: $LOG_FILE"
    
    # 构造当前进程的命令
    # 关键修改：
    # 1. CUDA_VISIBLE_DEVICES=$i : 隔离显卡
    # 2. --nproc 1 : 本地进程只管理 1 张卡
    # 3. --shard_id $i --num_shards $NUM_GPUS : 开启数据切片
    
    CUDA_VISIBLE_DEVICES=$i "$PYTHON_BIN" -u tools/run_qwen_eval_all_shared.py \
      "${base_args[@]}" \
      --nproc 1 \
      --shard_id "$i" \
      --num_shards "$NUM_GPUS" \
      > "$LOG_FILE" 2>&1 &
      
    pids+=($!)
    
    # 稍微错开启动时间，避免多个进程同时尝试导出同一个 FSDP 模型导致文件竞争
    sleep 10 
done

# =======================================================
# 3. 等待所有任务完成
# =======================================================

echo "[INFO] All workers started. Waiting for completion..."
wait

echo "[INFO] Done at $(date). All workers finished."