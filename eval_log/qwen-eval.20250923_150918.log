+ TEMP_G1=0.6
+ TEMP_G2=0.0
+ NSAMP_G1=8
+ NSAMP_G2=8
+ export EVAL_ONE_MODEL_TIMEOUT=21600
+ EVAL_ONE_MODEL_TIMEOUT=21600
+ export PASS_AT_KS=1,8
+ PASS_AT_KS=1,8
+ export TORCH_CPP_LOG_LEVEL=ERROR
+ TORCH_CPP_LOG_LEVEL=ERROR
++ seq -s, 0 3
+ export CUDA_VISIBLE_DEVICES=0,1,2,3
+ CUDA_VISIBLE_DEVICES=0,1,2,3
+ export VLLM_WORKER_MULTIPROC_METHOD=spawn
+ VLLM_WORKER_MULTIPROC_METHOD=spawn
+ export PYTHONUNBUFFERED=1
+ PYTHONUNBUFFERED=1
+ export VLLM_USE_FLASHINFER_SAMPLER=1
+ VLLM_USE_FLASHINFER_SAMPLER=1
+ args=(--model_root "$MODEL_ROOT" --out_root "$OUT_ROOT" --prompt_type "$PROMPT_TYPE" --max_tokens_per_call "$MAX_TOKENS" --nproc "$NUM_GPUS" --base_root "$BASE_ROOT" --use_vllm --pipeline_parallel_size 1 --vllm_batch_size 0 --temperature_g1 "$TEMP_G1" --temperature_g2 "$TEMP_G2" --n_sampling_g1 "$NSAMP_G1" --n_sampling_g2 "$NSAMP_G2" --cleanup_exported)
+ echo '[INFO] Running: /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3 -u tools/run_qwen_eval_all_shared.py --model_root /data/giil/caixq/ckpts/noise_rlvr_1_5b_128batchsize_deepscaler_noise_robust --out_root /uge_mnt/home/caixq/project/noisy-RLVR/eval_noise_rlvr_1_5b_128batchsize_deepscaler_noise_robust_qwen25-math-cot --prompt_type qwen25-math-cot --max_tokens_per_call 3072 --nproc 4 --base_root /hss/giil/caixq/model --use_vllm --pipeline_parallel_size 1 --vllm_batch_size 0 --temperature_g1 0.6 --temperature_g2 0.0 --n_sampling_g1 8 --n_sampling_g2 8 --cleanup_exported'
[INFO] Running: /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3 -u tools/run_qwen_eval_all_shared.py --model_root /data/giil/caixq/ckpts/noise_rlvr_1_5b_128batchsize_deepscaler_noise_robust --out_root /uge_mnt/home/caixq/project/noisy-RLVR/eval_noise_rlvr_1_5b_128batchsize_deepscaler_noise_robust_qwen25-math-cot --prompt_type qwen25-math-cot --max_tokens_per_call 3072 --nproc 4 --base_root /hss/giil/caixq/model --use_vllm --pipeline_parallel_size 1 --vllm_batch_size 0 --temperature_g1 0.6 --temperature_g2 0.0 --n_sampling_g1 8 --n_sampling_g2 8 --cleanup_exported
+ /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3 -u tools/run_qwen_eval_all_shared.py --model_root /data/giil/caixq/ckpts/noise_rlvr_1_5b_128batchsize_deepscaler_noise_robust --out_root /uge_mnt/home/caixq/project/noisy-RLVR/eval_noise_rlvr_1_5b_128batchsize_deepscaler_noise_robust_qwen25-math-cot --prompt_type qwen25-math-cot --max_tokens_per_call 3072 --nproc 4 --base_root /hss/giil/caixq/model --use_vllm --pipeline_parallel_size 1 --vllm_batch_size 0 --temperature_g1 0.6 --temperature_g2 0.0 --n_sampling_g1 8 --n_sampling_g2 8 --cleanup_exported
INFO 09-23 15:10:23 [__init__.py:239] Automatically detected platform cuda.
[2025-09-23 15:11:01] [INFO] --cleanup_exported Â∑≤ÂøΩÁï•ÔºåÂØºÂá∫ÁõÆÂΩïÂ∞Ü‰øùÁïôÂú® /data/giil/caixq/export
[2025-09-23 15:11:01] ÂèëÁé∞ 28 ‰∏™ run„ÄÇÂÖàÊ£ÄÊü•Áº∫Â§±ÊåáÊ†áÔºåÂÜçÁ°Æ‰øùÂØºÂá∫Ê®°ÂûãÂ≠òÂú®Âπ∂Êèê‰∫§ËØÑÊµã‰ªªÂä°„ÄÇ
INFO 09-23 15:11:06 [__init__.py:239] Automatically detected platform cuda.
[2025-09-23 15:11:10] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/hss/giil/caixq/model/Qwen2.5-math-1.5B
INFO 09-23 15:11:28 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 15:11:28 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 15:11:28 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 15:11:28 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 15:11:37 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:11:42 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/hss/giil/caixq/model/Qwen2.5-math-1.5B', speculative_config=None, tokenizer='/hss/giil/caixq/model/Qwen2.5-math-1.5B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/hss/giil/caixq/model/Qwen2.5-math-1.5B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 15:11:42 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 15:11:42 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_41b90279'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/086fef90-e1d7-4035-89ca-6b553fc1d53b', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 15:11:47 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:11:47 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:11:47 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:11:47 [__init__.py:239] Automatically detected platform cuda.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
WARNING 09-23 15:12:02 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f4cd86e9090>
WARNING 09-23 15:12:02 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f0d42411000>
WARNING 09-23 15:12:02 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fe2877850c0>
WARNING 09-23 15:12:02 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f2170304fd0>
[1;36m(VllmWorker rank=3 pid=498)[0;0m INFO 09-23 15:12:02 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_fcff5cc2'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/7d15de66-44f0-4d97-9bb9-f750031fc074', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=497)[0;0m INFO 09-23 15:12:02 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_bf8f12a1'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/483d634e-f748-4915-a878-3af3906f143f', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=496)[0;0m INFO 09-23 15:12:02 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_230393bb'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/9db452b4-e11a-4031-a517-8fb3d78e6ea7', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=495)[0;0m INFO 09-23 15:12:02 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_43b0d213'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/d969c41f-ef5b-44d3-a44d-f088a3f196e9', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=497)[0;0m [1;36m(VllmWorker rank=1 pid=496)[0;0m INFO 09-23 15:12:38 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 15:12:38 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=495)[0;0m INFO 09-23 15:12:38 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=497)[0;0m INFO 09-23 15:12:38 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=496)[0;0m INFO 09-23 15:12:38 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=498)[0;0m INFO 09-23 15:12:38 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=495)[0;0m INFO 09-23 15:12:38 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=498)[0;0m INFO 09-23 15:12:38 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=495)[0;0m [1;36m(VllmWorker rank=2 pid=497)[0;0m [1;36m(VllmWorker rank=1 pid=496)[0;0m INFO 09-23 15:12:40 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 15:12:40 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 15:12:40 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=3 pid=498)[0;0m INFO 09-23 15:12:40 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=495)[0;0m INFO 09-23 15:12:40 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_3d7e750c'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/c6ca7063-e462-4fe2-a5a9-6ea34802e5b1', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=498)[0;0m INFO 09-23 15:12:40 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=497)[0;0m INFO 09-23 15:12:40 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=1 pid=496)[0;0m INFO 09-23 15:12:40 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=0 pid=495)[0;0m INFO 09-23 15:12:40 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=3 pid=498)[0;0m INFO 09-23 15:12:40 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=496)[0;0m INFO 09-23 15:12:40 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=497)[0;0m INFO 09-23 15:12:40 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=495)[0;0m INFO 09-23 15:12:40 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=498)[0;0m INFO 09-23 15:12:40 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=496)[0;0m INFO 09-23 15:12:40 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=497)[0;0m INFO 09-23 15:12:40 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=495)[0;0m INFO 09-23 15:12:40 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=498)[0;0m INFO 09-23 15:12:40 [gpu_model_runner.py:1329] Starting to load model /hss/giil/caixq/model/Qwen2.5-math-1.5B...
[1;36m(VllmWorker rank=1 pid=496)[0;0m [1;36m(VllmWorker rank=2 pid=497)[0;0m [1;36m(VllmWorker rank=0 pid=495)[0;0m INFO 09-23 15:12:40 [gpu_model_runner.py:1329] Starting to load model /hss/giil/caixq/model/Qwen2.5-math-1.5B...
INFO 09-23 15:12:40 [gpu_model_runner.py:1329] Starting to load model /hss/giil/caixq/model/Qwen2.5-math-1.5B...
INFO 09-23 15:12:40 [gpu_model_runner.py:1329] Starting to load model /hss/giil/caixq/model/Qwen2.5-math-1.5B...
[1;36m(VllmWorker rank=0 pid=495)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
[1;36m(VllmWorker rank=3 pid=498)[0;0m INFO 09-23 15:12:43 [loader.py:458] Loading weights took 0.37 seconds
[1;36m(VllmWorker rank=0 pid=495)[0;0m Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.60it/s]
[1;36m(VllmWorker rank=0 pid=495)[0;0m Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.60it/s]
[1;36m(VllmWorker rank=0 pid=495)[0;0m 
[1;36m(VllmWorker rank=1 pid=496)[0;0m INFO 09-23 15:12:43 [loader.py:458] Loading weights took 0.40 seconds
[1;36m(VllmWorker rank=0 pid=495)[0;0m INFO 09-23 15:12:43 [loader.py:458] Loading weights took 0.42 seconds
[1;36m(VllmWorker rank=2 pid=497)[0;0m INFO 09-23 15:12:43 [loader.py:458] Loading weights took 0.41 seconds
[1;36m(VllmWorker rank=3 pid=498)[0;0m INFO 09-23 15:12:43 [gpu_model_runner.py:1347] Model loading took 0.7655 GiB and 2.742932 seconds
[1;36m(VllmWorker rank=1 pid=496)[0;0m INFO 09-23 15:12:43 [gpu_model_runner.py:1347] Model loading took 0.7655 GiB and 2.773021 seconds
[1;36m(VllmWorker rank=0 pid=495)[0;0m INFO 09-23 15:12:43 [gpu_model_runner.py:1347] Model loading took 0.7655 GiB and 2.788838 seconds
[1;36m(VllmWorker rank=2 pid=497)[0;0m INFO 09-23 15:12:43 [gpu_model_runner.py:1347] Model loading took 0.7655 GiB and 2.792746 seconds
INFO 09-23 15:13:35 [kv_cache_utils.py:634] GPU KV cache size: 2,535,056 tokens
INFO 09-23 15:13:35 [kv_cache_utils.py:637] Maximum concurrency for 4,096 tokens per request: 618.91x
INFO 09-23 15:13:35 [kv_cache_utils.py:634] GPU KV cache size: 2,513,984 tokens
INFO 09-23 15:13:35 [kv_cache_utils.py:637] Maximum concurrency for 4,096 tokens per request: 613.77x
INFO 09-23 15:13:35 [kv_cache_utils.py:634] GPU KV cache size: 2,513,984 tokens
INFO 09-23 15:13:35 [kv_cache_utils.py:637] Maximum concurrency for 4,096 tokens per request: 613.77x
INFO 09-23 15:13:35 [kv_cache_utils.py:634] GPU KV cache size: 2,535,056 tokens
INFO 09-23 15:13:35 [kv_cache_utils.py:637] Maximum concurrency for 4,096 tokens per request: 618.91x
INFO 09-23 15:13:36 [core.py:159] init engine (profile, create kv cache, warmup model) took 52.51 seconds
INFO 09-23 15:13:36 [core_client.py:439] Core engine process 0 ready.
[2025-09-23 15:13:36] ‚úì Ê®°ÂûãÂ∞±Áª™ÔºåÂºÄÂßãËØÑÊµã base__Qwen2.5-math-1.5BÔºàÂÖ±‰∫´Âêå‰∏Ä LLMÔºå‰ªÖË°•Áº∫Êï∞ÊçÆÈõÜÔºâ
[2025-09-23 15:13:36] ‚ñ∂ base__Qwen2.5-math-1.5B/g1  ÂæÖËØÑÊµã=['aime25x8', 'amc23x8', 'aime24x8']  T=0.6  n=8
base__Qwen2.5-math-1.5B/g1:   0%|          | 0/3 [00:00<?, ?ds/s]==================================================
data: aime25x8  ,remain samples: 240
{'idx': 0, 'problem': 'Find the sum of all integer bases $b>9$ for which $17_{b}$ is a divisor of $97_{b}$.', 'answer': '70'}

  0%|          | 0/240 [00:00<?, ?it/s][A<|im_start|>system
Please reason step by step, and put your final answer within \boxed{{}}.<|im_end|>
<|im_start|>user
Find the sum of all integer bases $b>9$ for which $17_{b}$ is a divisor of $97_{b}$.<|im_end|>
<|im_start|>assistant


 12%|‚ñà‚ñé        | 30/240 [00:00<00:00, 299.11it/s][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 77/240 [00:00<00:00, 397.11it/s][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 124/240 [00:00<00:00, 427.21it/s][A
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 171/240 [00:00<00:00, 441.82it/s][A
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 218/240 [00:00<00:00, 449.82it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<00:00, 433.73it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/1920 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 1/1920 [00:06<3:41:53,  6.94s/it, est. speed input: 11.96 toks/s, output: 46.12 toks/s][A
Processed prompts:   0%|          | 2/1920 [00:07<1:38:45,  3.09s/it, est. speed input: 22.64 toks/s, output: 89.86 toks/s][A
Processed prompts:   0%|          | 4/1920 [00:08<44:06,  1.38s/it, est. speed input: 59.78 toks/s, output: 170.29 toks/s] [A
Processed prompts:   0%|          | 5/1920 [00:08<31:27,  1.01it/s, est. speed input: 70.66 toks/s, output: 214.56 toks/s][A
Processed prompts:   0%|          | 6/1920 [00:08<23:49,  1.34it/s, est. speed input: 78.84 toks/s, output: 255.74 toks/s][A
Processed prompts:   0%|          | 7/1920 [00:09<26:52,  1.19it/s, est. speed input: 78.76 toks/s, output: 273.58 toks/s][A
Processed prompts:   0%|          | 8/1920 [00:09<22:07,  1.44it/s, est. speed input: 82.77 toks/s, output: 310.44 toks/s][A
Processed prompts:   0%|          | 9/1920 [00:09<16:48,  1.89it/s, est. speed input: 91.14 toks/s, output: 352.67 toks/s][A
Processed prompts:   1%|          | 11/1920 [00:10<12:13,  2.60it/s, est. speed input: 108.82 toks/s, output: 429.49 toks/s][A
Processed prompts:   1%|          | 14/1920 [00:10<07:19,  4.34it/s, est. speed input: 137.64 toks/s, output: 558.79 toks/s][A
Processed prompts:   1%|          | 15/1920 [00:10<06:33,  4.84it/s, est. speed input: 145.16 toks/s, output: 600.08 toks/s][A
Processed prompts:   1%|          | 16/1920 [00:10<06:50,  4.64it/s, est. speed input: 151.64 toks/s, output: 633.34 toks/s][A
Processed prompts:   1%|          | 18/1920 [00:11<06:31,  4.86it/s, est. speed input: 171.29 toks/s, output: 704.51 toks/s][A
Processed prompts:   1%|          | 20/1920 [00:11<06:07,  5.17it/s, est. speed input: 183.51 toks/s, output: 776.30 toks/s][A
Processed prompts:   1%|          | 21/1920 [00:11<05:33,  5.69it/s, est. speed input: 194.52 toks/s, output: 816.22 toks/s][A
Processed prompts:   1%|          | 22/1920 [00:11<05:11,  6.09it/s, est. speed input: 216.28 toks/s, output: 854.62 toks/s][A
Processed prompts:   1%|‚ñè         | 24/1920 [00:12<04:33,  6.92it/s, est. speed input: 245.23 toks/s, output: 931.83 toks/s][A
Processed prompts:   1%|‚ñè         | 25/1920 [00:12<04:43,  6.69it/s, est. speed input: 246.85 toks/s, output: 966.16 toks/s][A
Processed prompts:   2%|‚ñè         | 29/1920 [00:12<02:38, 11.95it/s, est. speed input: 288.54 toks/s, output: 1143.19 toks/s][A
Processed prompts:   2%|‚ñè         | 31/1920 [00:12<03:16,  9.61it/s, est. speed input: 294.84 toks/s, output: 1208.04 toks/s][A
Processed prompts:   2%|‚ñè         | 33/1920 [00:12<02:58, 10.55it/s, est. speed input: 316.10 toks/s, output: 1288.49 toks/s][A
Processed prompts:   2%|‚ñè         | 35/1920 [00:13<02:58, 10.58it/s, est. speed input: 338.82 toks/s, output: 1363.38 toks/s][A
Processed prompts:   2%|‚ñè         | 39/1920 [00:13<01:58, 15.85it/s, est. speed input: 389.56 toks/s, output: 1540.52 toks/s][A
Processed prompts:   2%|‚ñè         | 42/1920 [00:13<02:15, 13.86it/s, est. speed input: 441.67 toks/s, output: 1650.00 toks/s][A
Processed prompts:   2%|‚ñè         | 44/1920 [00:13<02:38, 11.83it/s, est. speed input: 442.58 toks/s, output: 1713.79 toks/s][A
Processed prompts:   2%|‚ñè         | 46/1920 [00:14<03:21,  9.28it/s, est. speed input: 444.78 toks/s, output: 1764.53 toks/s][A
Processed prompts:   2%|‚ñé         | 48/1920 [00:14<02:54, 10.73it/s, est. speed input: 454.46 toks/s, output: 1845.48 toks/s][A
Processed prompts:   3%|‚ñé         | 50/1920 [00:14<02:54, 10.73it/s, est. speed input: 471.66 toks/s, output: 1915.68 toks/s][A
Processed prompts:   3%|‚ñé         | 54/1920 [00:14<02:59, 10.42it/s, est. speed input: 495.11 toks/s, output: 2049.06 toks/s][A
Processed prompts:   3%|‚ñé         | 56/1920 [00:14<02:39, 11.70it/s, est. speed input: 510.93 toks/s, output: 2128.85 toks/s][A
Processed prompts:   3%|‚ñé         | 58/1920 [00:15<03:07,  9.91it/s, est. speed input: 513.63 toks/s, output: 2181.45 toks/s][A
Processed prompts:   3%|‚ñé         | 60/1920 [00:15<04:44,  6.54it/s, est. speed input: 503.55 toks/s, output: 2193.51 toks/s][A
Processed prompts:   3%|‚ñé         | 62/1920 [00:15<04:03,  7.63it/s, est. speed input: 524.75 toks/s, output: 2247.05 toks/s][A
Processed prompts:   3%|‚ñé         | 64/1920 [00:16<03:43,  8.31it/s, est. speed input: 531.19 toks/s, output: 2315.24 toks/s][A
Processed prompts:   3%|‚ñé         | 66/1920 [00:16<04:14,  7.28it/s, est. speed input: 531.34 toks/s, output: 2358.99 toks/s][A
Processed prompts:   4%|‚ñé         | 71/1920 [00:16<02:35, 11.86it/s, est. speed input: 554.75 toks/s, output: 2570.19 toks/s][A
Processed prompts:   4%|‚ñç         | 73/1920 [00:16<02:40, 11.54it/s, est. speed input: 563.23 toks/s, output: 2635.49 toks/s][A
Processed prompts:   4%|‚ñç         | 75/1920 [00:16<02:29, 12.36it/s, est. speed input: 570.93 toks/s, output: 2687.72 toks/s][A
Processed prompts:   4%|‚ñç         | 78/1920 [00:17<02:30, 12.28it/s, est. speed input: 594.79 toks/s, output: 2747.61 toks/s][A
Processed prompts:   4%|‚ñç         | 80/1920 [00:17<02:58, 10.30it/s, est. speed input: 611.99 toks/s, output: 2796.21 toks/s][A
Processed prompts:   4%|‚ñç         | 82/1920 [00:17<03:36,  8.50it/s, est. speed input: 609.65 toks/s, output: 2834.47 toks/s][A
Processed prompts:   4%|‚ñç         | 84/1920 [00:18<03:49,  8.00it/s, est. speed input: 616.37 toks/s, output: 2882.88 toks/s][A
Processed prompts:   4%|‚ñç         | 86/1920 [00:18<03:11,  9.58it/s, est. speed input: 626.17 toks/s, output: 2961.21 toks/s][A
Processed prompts:   5%|‚ñç         | 89/1920 [00:18<03:06,  9.84it/s, est. speed input: 647.71 toks/s, output: 3054.96 toks/s][A
Processed prompts:   5%|‚ñç         | 93/1920 [00:18<02:23, 12.72it/s, est. speed input: 669.77 toks/s, output: 3213.01 toks/s][A
Processed prompts:   5%|‚ñç         | 95/1920 [00:18<02:46, 10.93it/s, est. speed input: 679.69 toks/s, output: 3261.54 toks/s][A
Processed prompts:   5%|‚ñå         | 97/1920 [00:19<02:28, 12.24it/s, est. speed input: 689.88 toks/s, output: 3315.05 toks/s][A
Processed prompts:   5%|‚ñå         | 102/1920 [00:19<01:36, 18.80it/s, est. speed input: 742.97 toks/s, output: 3533.07 toks/s][A
Processed prompts:   5%|‚ñå         | 105/1920 [00:19<02:35, 11.71it/s, est. speed input: 755.96 toks/s, output: 3584.38 toks/s][A
Processed prompts:   6%|‚ñå         | 107/1920 [00:19<02:29, 12.11it/s, est. speed input: 759.64 toks/s, output: 3652.74 toks/s][A
Processed prompts:   6%|‚ñå         | 109/1920 [00:19<02:20, 12.87it/s, est. speed input: 766.90 toks/s, output: 3724.58 toks/s][A
Processed prompts:   6%|‚ñå         | 111/1920 [00:20<02:41, 11.19it/s, est. speed input: 774.33 toks/s, output: 3773.38 toks/s][A
Processed prompts:   6%|‚ñå         | 116/1920 [00:20<02:00, 15.03it/s, est. speed input: 805.60 toks/s, output: 3970.91 toks/s][A
Processed prompts:   6%|‚ñå         | 118/1920 [00:20<02:50, 10.58it/s, est. speed input: 801.25 toks/s, output: 3989.57 toks/s][A
Processed prompts:   6%|‚ñã         | 120/1920 [00:20<02:31, 11.85it/s, est. speed input: 804.66 toks/s, output: 4064.63 toks/s][A
Processed prompts:   6%|‚ñã         | 122/1920 [00:20<02:28, 12.07it/s, est. speed input: 818.78 toks/s, output: 4129.22 toks/s][A
Processed prompts:   6%|‚ñã         | 124/1920 [00:21<02:33, 11.68it/s, est. speed input: 827.32 toks/s, output: 4187.27 toks/s][A
Processed prompts:   7%|‚ñã         | 126/1920 [00:21<02:37, 11.37it/s, est. speed input: 839.22 toks/s, output: 4229.00 toks/s][A
Processed prompts:   7%|‚ñã         | 128/1920 [00:21<02:55, 10.18it/s, est. speed input: 840.43 toks/s, output: 4274.69 toks/s][A
Processed prompts:   7%|‚ñã         | 131/1920 [00:21<02:17, 13.03it/s, est. speed input: 855.82 toks/s, output: 4392.49 toks/s][A
Processed prompts:   7%|‚ñã         | 134/1920 [00:22<02:32, 11.71it/s, est. speed input: 865.55 toks/s, output: 4473.06 toks/s][A
Processed prompts:   7%|‚ñã         | 139/1920 [00:22<01:39, 17.95it/s, est. speed input: 891.49 toks/s, output: 4689.84 toks/s][A
Processed prompts:   7%|‚ñã         | 142/1920 [00:23<04:39,  6.36it/s, est. speed input: 859.01 toks/s, output: 4560.79 toks/s][A
Processed prompts:   8%|‚ñä         | 144/1920 [00:23<04:50,  6.12it/s, est. speed input: 861.59 toks/s, output: 4582.92 toks/s][A
Processed prompts:   8%|‚ñä         | 146/1920 [00:24<04:33,  6.49it/s, est. speed input: 864.12 toks/s, output: 4604.61 toks/s][A
Processed prompts:   8%|‚ñä         | 148/1920 [00:24<04:37,  6.39it/s, est. speed input: 861.18 toks/s, output: 4615.19 toks/s][A
Processed prompts:   8%|‚ñä         | 150/1920 [00:24<05:38,  5.23it/s, est. speed input: 849.89 toks/s, output: 4579.49 toks/s][A
Processed prompts:   8%|‚ñä         | 153/1920 [00:25<04:11,  7.02it/s, est. speed input: 858.30 toks/s, output: 4671.41 toks/s][A
Processed prompts:   8%|‚ñä         | 155/1920 [00:25<03:48,  7.71it/s, est. speed input: 864.22 toks/s, output: 4731.30 toks/s][A
Processed prompts:   8%|‚ñä         | 157/1920 [00:25<05:17,  5.55it/s, est. speed input: 857.47 toks/s, output: 4684.48 toks/s][A
Processed prompts:   8%|‚ñä         | 160/1920 [00:26<04:25,  6.64it/s, est. speed input: 859.47 toks/s, output: 4732.89 toks/s][A
Processed prompts:   8%|‚ñä         | 161/1920 [00:26<04:56,  5.94it/s, est. speed input: 854.37 toks/s, output: 4731.06 toks/s][A
Processed prompts:   8%|‚ñä         | 163/1920 [00:26<04:16,  6.85it/s, est. speed input: 862.73 toks/s, output: 4791.20 toks/s][A
Processed prompts:   9%|‚ñä         | 164/1920 [00:26<04:47,  6.11it/s, est. speed input: 860.58 toks/s, output: 4761.09 toks/s][A
Processed prompts:   9%|‚ñä         | 166/1920 [00:27<03:53,  7.51it/s, est. speed input: 865.29 toks/s, output: 4828.99 toks/s][A
Processed prompts:   9%|‚ñä         | 167/1920 [00:27<03:56,  7.40it/s, est. speed input: 863.85 toks/s, output: 4832.30 toks/s][A
Processed prompts:   9%|‚ñâ         | 168/1920 [00:27<04:55,  5.93it/s, est. speed input: 863.85 toks/s, output: 4827.88 toks/s][A
Processed prompts:   9%|‚ñâ         | 171/1920 [00:27<03:07,  9.32it/s, est. speed input: 875.66 toks/s, output: 4927.01 toks/s][A
Processed prompts:   9%|‚ñâ         | 173/1920 [00:27<03:51,  7.55it/s, est. speed input: 872.95 toks/s, output: 4912.02 toks/s][A
Processed prompts:   9%|‚ñâ         | 176/1920 [00:28<03:06,  9.36it/s, est. speed input: 877.59 toks/s, output: 4969.18 toks/s][A
Processed prompts:   9%|‚ñâ         | 178/1920 [00:28<03:04,  9.45it/s, est. speed input: 886.06 toks/s, output: 5026.42 toks/s][A
Processed prompts:   9%|‚ñâ         | 181/1920 [00:28<02:17, 12.66it/s, est. speed input: 897.69 toks/s, output: 5127.05 toks/s][A
Processed prompts:  10%|‚ñâ         | 183/1920 [00:28<02:37, 11.04it/s, est. speed input: 905.33 toks/s, output: 5150.62 toks/s][A
Processed prompts:  10%|‚ñâ         | 185/1920 [00:28<02:52, 10.05it/s, est. speed input: 906.56 toks/s, output: 5180.81 toks/s][A
Processed prompts:  10%|‚ñâ         | 187/1920 [00:29<05:09,  5.60it/s, est. speed input: 894.63 toks/s, output: 5141.24 toks/s][A
Processed prompts:  10%|‚ñâ         | 188/1920 [00:29<04:47,  6.02it/s, est. speed input: 899.18 toks/s, output: 5170.32 toks/s][A
Processed prompts:  10%|‚ñâ         | 190/1920 [00:30<04:59,  5.77it/s, est. speed input: 893.41 toks/s, output: 5199.10 toks/s][A
Processed prompts:  10%|‚ñà         | 192/1920 [00:30<04:27,  6.47it/s, est. speed input: 900.08 toks/s, output: 5230.40 toks/s][A
Processed prompts:  10%|‚ñà         | 193/1920 [00:30<04:57,  5.80it/s, est. speed input: 897.56 toks/s, output: 5234.46 toks/s][A
Processed prompts:  10%|‚ñà         | 194/1920 [00:30<04:32,  6.33it/s, est. speed input: 901.68 toks/s, output: 5263.86 toks/s][A
Processed prompts:  10%|‚ñà         | 195/1920 [00:30<04:10,  6.89it/s, est. speed input: 902.01 toks/s, output: 5274.84 toks/s][A
Processed prompts:  10%|‚ñà         | 196/1920 [00:31<05:11,  5.54it/s, est. speed input: 896.40 toks/s, output: 5258.05 toks/s][A
Processed prompts:  10%|‚ñà         | 198/1920 [00:31<04:00,  7.15it/s, est. speed input: 899.40 toks/s, output: 5304.46 toks/s][A
Processed prompts:  10%|‚ñà         | 200/1920 [00:31<03:10,  9.03it/s, est. speed input: 908.55 toks/s, output: 5377.45 toks/s][A
Processed prompts:  11%|‚ñà         | 202/1920 [00:31<02:41, 10.66it/s, est. speed input: 922.07 toks/s, output: 5402.62 toks/s][A
Processed prompts:  11%|‚ñà         | 204/1920 [00:31<03:03,  9.34it/s, est. speed input: 922.70 toks/s, output: 5450.77 toks/s][A
Processed prompts:  11%|‚ñà         | 206/1920 [00:32<03:29,  8.18it/s, est. speed input: 922.39 toks/s, output: 5472.27 toks/s][A
Processed prompts:  11%|‚ñà         | 207/1920 [00:32<04:03,  7.05it/s, est. speed input: 919.59 toks/s, output: 5480.85 toks/s][A
Processed prompts:  11%|‚ñà         | 209/1920 [00:32<03:39,  7.79it/s, est. speed input: 920.42 toks/s, output: 5512.03 toks/s][A
Processed prompts:  11%|‚ñà         | 210/1920 [00:32<03:52,  7.35it/s, est. speed input: 919.59 toks/s, output: 5510.83 toks/s][A
Processed prompts:  11%|‚ñà         | 212/1920 [00:33<04:03,  7.00it/s, est. speed input: 918.72 toks/s, output: 5537.70 toks/s][A
Processed prompts:  11%|‚ñà         | 213/1920 [00:33<03:57,  7.20it/s, est. speed input: 923.43 toks/s, output: 5541.78 toks/s][A
Processed prompts:  11%|‚ñà         | 214/1920 [00:33<03:58,  7.14it/s, est. speed input: 924.19 toks/s, output: 5564.90 toks/s][A
Processed prompts:  11%|‚ñà         | 215/1920 [00:33<05:52,  4.83it/s, est. speed input: 915.61 toks/s, output: 5514.33 toks/s][A
Processed prompts:  11%|‚ñà‚ñè        | 219/1920 [00:33<03:01,  9.35it/s, est. speed input: 927.60 toks/s, output: 5595.80 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 221/1920 [00:34<02:49, 10.03it/s, est. speed input: 931.48 toks/s, output: 5662.77 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 223/1920 [00:34<02:40, 10.58it/s, est. speed input: 932.30 toks/s, output: 5684.00 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 225/1920 [00:34<03:32,  7.98it/s, est. speed input: 926.23 toks/s, output: 5684.35 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 227/1920 [00:35<04:31,  6.24it/s, est. speed input: 919.04 toks/s, output: 5672.64 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 228/1920 [00:35<04:39,  6.05it/s, est. speed input: 921.30 toks/s, output: 5657.82 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 229/1920 [00:35<04:26,  6.35it/s, est. speed input: 919.89 toks/s, output: 5657.59 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 230/1920 [00:35<04:06,  6.86it/s, est. speed input: 919.08 toks/s, output: 5660.93 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 231/1920 [00:35<05:04,  5.55it/s, est. speed input: 916.10 toks/s, output: 5621.29 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 234/1920 [00:36<03:16,  8.58it/s, est. speed input: 920.63 toks/s, output: 5657.42 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 236/1920 [00:36<04:11,  6.71it/s, est. speed input: 915.71 toks/s, output: 5626.84 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 237/1920 [00:36<03:56,  7.12it/s, est. speed input: 920.03 toks/s, output: 5629.23 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 242/1920 [00:36<02:16, 12.32it/s, est. speed input: 935.50 toks/s, output: 5719.13 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 244/1920 [00:37<03:13,  8.65it/s, est. speed input: 929.25 toks/s, output: 5707.80 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 246/1920 [00:37<02:45, 10.10it/s, est. speed input: 938.04 toks/s, output: 5756.65 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 249/1920 [00:37<02:36, 10.71it/s, est. speed input: 939.39 toks/s, output: 5772.95 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 251/1920 [00:38<03:36,  7.71it/s, est. speed input: 941.82 toks/s, output: 5734.09 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 253/1920 [00:38<03:17,  8.43it/s, est. speed input: 942.13 toks/s, output: 5730.12 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 255/1920 [00:38<02:46, 10.00it/s, est. speed input: 950.20 toks/s, output: 5788.92 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 257/1920 [00:38<02:59,  9.24it/s, est. speed input: 953.64 toks/s, output: 5776.41 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 259/1920 [00:38<02:47,  9.91it/s, est. speed input: 960.02 toks/s, output: 5822.38 toks/s][A
Processed prompts:  14%|‚ñà‚ñé        | 261/1920 [00:38<02:33, 10.80it/s, est. speed input: 961.33 toks/s, output: 5844.55 toks/s][A
Processed prompts:  14%|‚ñà‚ñé        | 263/1920 [00:38<02:23, 11.53it/s, est. speed input: 962.70 toks/s, output: 5875.00 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 265/1920 [00:39<02:11, 12.57it/s, est. speed input: 968.27 toks/s, output: 5923.82 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 267/1920 [00:39<02:03, 13.44it/s, est. speed input: 971.00 toks/s, output: 5968.76 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 269/1920 [00:39<02:01, 13.55it/s, est. speed input: 977.64 toks/s, output: 5976.18 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 271/1920 [00:39<02:06, 13.07it/s, est. speed input: 978.04 toks/s, output: 5975.01 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 273/1920 [00:39<02:15, 12.18it/s, est. speed input: 980.73 toks/s, output: 5994.53 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 277/1920 [00:40<02:11, 12.49it/s, est. speed input: 990.88 toks/s, output: 6059.38 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 279/1920 [00:40<01:59, 13.68it/s, est. speed input: 994.11 toks/s, output: 6095.25 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 281/1920 [00:40<02:30, 10.88it/s, est. speed input: 994.05 toks/s, output: 6123.06 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 283/1920 [00:40<02:17, 11.93it/s, est. speed input: 996.16 toks/s, output: 6148.14 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 285/1920 [00:40<02:40, 10.20it/s, est. speed input: 995.73 toks/s, output: 6164.36 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 288/1920 [00:41<02:14, 12.14it/s, est. speed input: 1000.76 toks/s, output: 6211.24 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 290/1920 [00:41<03:12,  8.47it/s, est. speed input: 996.35 toks/s, output: 6205.97 toks/s] [A
Processed prompts:  15%|‚ñà‚ñå        | 292/1920 [00:41<04:14,  6.39it/s, est. speed input: 987.50 toks/s, output: 6151.24 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 296/1920 [00:42<02:59,  9.03it/s, est. speed input: 993.84 toks/s, output: 6260.49 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 298/1920 [00:42<02:40, 10.08it/s, est. speed input: 995.84 toks/s, output: 6290.29 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 300/1920 [00:43<04:33,  5.92it/s, est. speed input: 988.18 toks/s, output: 6245.45 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 301/1920 [00:43<05:34,  4.84it/s, est. speed input: 981.55 toks/s, output: 6205.16 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 302/1920 [00:43<05:16,  5.12it/s, est. speed input: 981.85 toks/s, output: 6231.49 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 303/1920 [00:43<05:13,  5.16it/s, est. speed input: 980.43 toks/s, output: 6224.35 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 304/1920 [00:43<05:10,  5.20it/s, est. speed input: 982.68 toks/s, output: 6216.21 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 305/1920 [00:44<05:01,  5.36it/s, est. speed input: 981.68 toks/s, output: 6212.76 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 308/1920 [00:44<04:04,  6.59it/s, est. speed input: 985.30 toks/s, output: 6260.83 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 310/1920 [00:44<04:18,  6.23it/s, est. speed input: 983.16 toks/s, output: 6260.25 toks/s][A
Processed prompts:  16%|‚ñà‚ñã        | 312/1920 [00:44<03:28,  7.72it/s, est. speed input: 986.04 toks/s, output: 6336.73 toks/s][A
Processed prompts:  16%|‚ñà‚ñã        | 316/1920 [00:45<02:13, 12.04it/s, est. speed input: 993.30 toks/s, output: 6475.45 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 318/1920 [00:45<02:13, 12.03it/s, est. speed input: 997.97 toks/s, output: 6488.97 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 320/1920 [00:45<02:26, 10.93it/s, est. speed input: 999.23 toks/s, output: 6535.38 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 323/1920 [00:45<01:53, 14.09it/s, est. speed input: 1004.84 toks/s, output: 6602.59 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 325/1920 [00:46<03:27,  7.67it/s, est. speed input: 998.47 toks/s, output: 6548.58 toks/s] [A
Processed prompts:  17%|‚ñà‚ñã        | 329/1920 [00:46<02:27, 10.76it/s, est. speed input: 1006.98 toks/s, output: 6640.40 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 331/1920 [00:47<03:47,  6.98it/s, est. speed input: 998.39 toks/s, output: 6608.24 toks/s] [A
Processed prompts:  17%|‚ñà‚ñã        | 335/1920 [00:47<02:46,  9.52it/s, est. speed input: 1007.57 toks/s, output: 6699.97 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 339/1920 [00:47<02:09, 12.17it/s, est. speed input: 1022.56 toks/s, output: 6764.46 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 341/1920 [00:47<02:53,  9.12it/s, est. speed input: 1018.76 toks/s, output: 6732.76 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 343/1920 [00:48<03:24,  7.72it/s, est. speed input: 1019.19 toks/s, output: 6709.65 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 345/1920 [00:48<04:34,  5.74it/s, est. speed input: 1013.70 toks/s, output: 6655.91 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 347/1920 [00:48<03:57,  6.63it/s, est. speed input: 1017.74 toks/s, output: 6669.66 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 349/1920 [00:49<03:19,  7.87it/s, est. speed input: 1019.03 toks/s, output: 6713.05 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 351/1920 [00:49<02:51,  9.16it/s, est. speed input: 1022.30 toks/s, output: 6740.03 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 353/1920 [00:49<02:26, 10.73it/s, est. speed input: 1024.62 toks/s, output: 6807.40 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 355/1920 [00:49<02:44,  9.49it/s, est. speed input: 1024.01 toks/s, output: 6826.75 toks/s][A
Processed prompts:  19%|‚ñà‚ñä        | 357/1920 [00:49<02:44,  9.50it/s, est. speed input: 1029.30 toks/s, output: 6852.42 toks/s][A
Processed prompts:  19%|‚ñà‚ñä        | 359/1920 [00:50<03:02,  8.54it/s, est. speed input: 1030.71 toks/s, output: 6883.59 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 361/1920 [00:50<03:34,  7.25it/s, est. speed input: 1029.86 toks/s, output: 6905.96 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 363/1920 [00:50<03:09,  8.20it/s, est. speed input: 1031.66 toks/s, output: 6904.16 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 365/1920 [00:50<03:20,  7.74it/s, est. speed input: 1035.54 toks/s, output: 6906.67 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 366/1920 [00:51<03:59,  6.49it/s, est. speed input: 1035.60 toks/s, output: 6892.54 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 367/1920 [00:51<04:22,  5.92it/s, est. speed input: 1035.44 toks/s, output: 6867.76 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 368/1920 [00:51<04:08,  6.25it/s, est. speed input: 1037.72 toks/s, output: 6875.32 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 370/1920 [00:51<03:34,  7.21it/s, est. speed input: 1036.75 toks/s, output: 6866.46 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 371/1920 [00:51<03:30,  7.36it/s, est. speed input: 1036.84 toks/s, output: 6881.53 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 372/1920 [00:52<05:43,  4.51it/s, est. speed input: 1032.12 toks/s, output: 6848.69 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 375/1920 [00:52<03:18,  7.79it/s, est. speed input: 1037.23 toks/s, output: 6881.39 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 378/1920 [00:52<03:03,  8.41it/s, est. speed input: 1038.78 toks/s, output: 6896.04 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 381/1920 [00:52<02:22, 10.83it/s, est. speed input: 1044.06 toks/s, output: 6930.63 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 383/1920 [00:53<04:37,  5.54it/s, est. speed input: 1031.90 toks/s, output: 6862.04 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 386/1920 [00:55<09:00,  2.84it/s, est. speed input: 1001.84 toks/s, output: 6694.48 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 387/1920 [00:56<08:46,  2.91it/s, est. speed input: 999.27 toks/s, output: 6672.49 toks/s] [A
Processed prompts:  20%|‚ñà‚ñà        | 388/1920 [00:56<07:55,  3.22it/s, est. speed input: 998.10 toks/s, output: 6691.62 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 389/1920 [00:56<06:52,  3.71it/s, est. speed input: 998.88 toks/s, output: 6692.09 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 390/1920 [00:56<06:34,  3.88it/s, est. speed input: 999.50 toks/s, output: 6692.78 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 391/1920 [00:56<06:29,  3.92it/s, est. speed input: 997.32 toks/s, output: 6688.84 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 392/1920 [00:57<06:14,  4.08it/s, est. speed input: 995.95 toks/s, output: 6693.04 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 393/1920 [00:57<05:17,  4.81it/s, est. speed input: 997.08 toks/s, output: 6696.57 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 395/1920 [00:57<03:36,  7.06it/s, est. speed input: 999.54 toks/s, output: 6742.50 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 397/1920 [00:58<07:16,  3.49it/s, est. speed input: 986.27 toks/s, output: 6671.72 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 398/1920 [00:58<07:00,  3.62it/s, est. speed input: 983.71 toks/s, output: 6660.19 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 399/1920 [00:58<06:08,  4.13it/s, est. speed input: 986.13 toks/s, output: 6657.04 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 401/1920 [00:58<04:47,  5.28it/s, est. speed input: 987.64 toks/s, output: 6666.81 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 402/1920 [00:59<04:21,  5.81it/s, est. speed input: 988.05 toks/s, output: 6686.37 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 404/1920 [00:59<04:03,  6.23it/s, est. speed input: 987.63 toks/s, output: 6687.75 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 405/1920 [00:59<06:29,  3.89it/s, est. speed input: 979.93 toks/s, output: 6666.52 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 407/1920 [01:00<04:38,  5.43it/s, est. speed input: 982.62 toks/s, output: 6718.70 toks/s][A
Processed prompts:  21%|‚ñà‚ñà‚ñè       | 409/1920 [01:00<04:54,  5.13it/s, est. speed input: 979.30 toks/s, output: 6711.06 toks/s][A
Processed prompts:  21%|‚ñà‚ñà‚ñè       | 411/1920 [01:00<03:49,  6.59it/s, est. speed input: 981.65 toks/s, output: 6733.35 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 413/1920 [01:00<03:07,  8.03it/s, est. speed input: 983.38 toks/s, output: 6780.81 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 415/1920 [01:00<02:33,  9.78it/s, est. speed input: 987.52 toks/s, output: 6810.44 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 417/1920 [01:01<04:29,  5.57it/s, est. speed input: 979.71 toks/s, output: 6769.05 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 419/1920 [01:02<06:07,  4.09it/s, est. speed input: 970.73 toks/s, output: 6708.62 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 421/1920 [01:02<05:00,  5.00it/s, est. speed input: 976.28 toks/s, output: 6715.99 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 425/1920 [01:02<03:08,  7.94it/s, est. speed input: 984.48 toks/s, output: 6826.77 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 427/1920 [01:02<02:57,  8.41it/s, est. speed input: 985.37 toks/s, output: 6873.31 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 429/1920 [01:03<02:42,  9.19it/s, est. speed input: 985.55 toks/s, output: 6890.98 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 431/1920 [01:03<03:46,  6.57it/s, est. speed input: 981.16 toks/s, output: 6872.65 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 434/1920 [01:03<03:31,  7.03it/s, est. speed input: 983.20 toks/s, output: 6957.75 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 436/1920 [01:04<05:00,  4.93it/s, est. speed input: 976.05 toks/s, output: 6914.31 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 438/1920 [01:05<04:52,  5.07it/s, est. speed input: 973.73 toks/s, output: 6919.50 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 440/1920 [01:05<04:49,  5.11it/s, est. speed input: 970.80 toks/s, output: 6907.35 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 441/1920 [01:06<06:21,  3.88it/s, est. speed input: 963.79 toks/s, output: 6857.53 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 443/1920 [01:06<06:18,  3.90it/s, est. speed input: 960.75 toks/s, output: 6869.46 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñç       | 479/1920 [01:07<01:00, 23.93it/s, est. speed input: 1030.85 toks/s, output: 8424.89 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 482/1920 [01:07<01:04, 22.16it/s, est. speed input: 1033.62 toks/s, output: 8435.79 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 485/1920 [01:07<01:11, 20.11it/s, est. speed input: 1039.09 toks/s, output: 8429.99 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 487/1920 [01:07<01:11, 20.00it/s, est. speed input: 1043.97 toks/s, output: 8436.42 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 489/1920 [01:07<01:13, 19.38it/s, est. speed input: 1045.80 toks/s, output: 8448.05 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 491/1920 [01:08<01:58, 12.08it/s, est. speed input: 1043.00 toks/s, output: 8422.81 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 493/1920 [01:08<02:28,  9.64it/s, est. speed input: 1041.27 toks/s, output: 8401.71 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 495/1920 [01:08<02:15, 10.49it/s, est. speed input: 1044.01 toks/s, output: 8408.98 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 497/1920 [01:09<02:56,  8.06it/s, est. speed input: 1040.72 toks/s, output: 8381.77 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 499/1920 [01:09<02:57,  7.99it/s, est. speed input: 1044.83 toks/s, output: 8373.84 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 500/1920 [01:09<03:16,  7.23it/s, est. speed input: 1044.78 toks/s, output: 8359.74 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 501/1920 [01:10<04:47,  4.93it/s, est. speed input: 1039.38 toks/s, output: 8337.07 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñã       | 504/1920 [01:10<03:20,  7.06it/s, est. speed input: 1045.80 toks/s, output: 8348.82 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñã       | 506/1920 [01:10<03:26,  6.83it/s, est. speed input: 1047.11 toks/s, output: 8358.67 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 510/1920 [01:11<02:37,  8.96it/s, est. speed input: 1051.07 toks/s, output: 8365.93 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 512/1920 [01:11<03:15,  7.21it/s, est. speed input: 1047.35 toks/s, output: 8343.42 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 513/1920 [01:11<03:08,  7.47it/s, est. speed input: 1046.95 toks/s, output: 8336.64 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 515/1920 [01:11<02:34,  9.11it/s, est. speed input: 1050.69 toks/s, output: 8337.85 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 518/1920 [01:11<02:08, 10.87it/s, est. speed input: 1054.94 toks/s, output: 8348.20 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 520/1920 [01:11<01:57, 11.87it/s, est. speed input: 1058.11 toks/s, output: 8364.07 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 522/1920 [01:12<03:20,  6.97it/s, est. speed input: 1054.08 toks/s, output: 8313.28 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 524/1920 [01:12<02:44,  8.48it/s, est. speed input: 1058.05 toks/s, output: 8337.22 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 526/1920 [01:13<03:13,  7.20it/s, est. speed input: 1055.62 toks/s, output: 8337.38 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 528/1920 [01:13<02:42,  8.56it/s, est. speed input: 1058.33 toks/s, output: 8333.99 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 531/1920 [01:13<02:02, 11.31it/s, est. speed input: 1060.02 toks/s, output: 8338.73 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 533/1920 [01:13<02:11, 10.52it/s, est. speed input: 1061.97 toks/s, output: 8344.30 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 538/1920 [01:14<02:15, 10.20it/s, est. speed input: 1065.03 toks/s, output: 8364.21 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 540/1920 [01:14<02:01, 11.32it/s, est. speed input: 1066.74 toks/s, output: 8363.32 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 542/1920 [01:14<03:33,  6.45it/s, est. speed input: 1059.39 toks/s, output: 8312.08 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 544/1920 [01:15<02:59,  7.67it/s, est. speed input: 1060.67 toks/s, output: 8309.57 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 546/1920 [01:15<02:54,  7.87it/s, est. speed input: 1062.07 toks/s, output: 8312.19 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñä       | 549/1920 [01:15<02:32,  8.97it/s, est. speed input: 1066.43 toks/s, output: 8315.46 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñä       | 551/1920 [01:15<02:12, 10.35it/s, est. speed input: 1069.33 toks/s, output: 8322.75 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 553/1920 [01:16<02:54,  7.82it/s, est. speed input: 1066.73 toks/s, output: 8303.25 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 555/1920 [01:16<02:42,  8.41it/s, est. speed input: 1070.34 toks/s, output: 8312.68 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 557/1920 [01:16<03:50,  5.92it/s, est. speed input: 1066.19 toks/s, output: 8271.51 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 558/1920 [01:16<03:34,  6.35it/s, est. speed input: 1066.62 toks/s, output: 8266.42 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 559/1920 [01:17<03:26,  6.59it/s, est. speed input: 1067.70 toks/s, output: 8266.86 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 560/1920 [01:17<03:37,  6.25it/s, est. speed input: 1068.01 toks/s, output: 8282.50 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 561/1920 [01:17<03:50,  5.89it/s, est. speed input: 1067.01 toks/s, output: 8277.32 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 562/1920 [01:17<04:25,  5.11it/s, est. speed input: 1064.34 toks/s, output: 8257.13 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 563/1920 [01:17<04:21,  5.19it/s, est. speed input: 1063.73 toks/s, output: 8259.44 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 564/1920 [01:18<05:58,  3.78it/s, est. speed input: 1060.80 toks/s, output: 8226.05 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 566/1920 [01:18<04:08,  5.45it/s, est. speed input: 1061.78 toks/s, output: 8242.27 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 567/1920 [01:18<03:52,  5.81it/s, est. speed input: 1061.84 toks/s, output: 8250.26 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 569/1920 [01:18<03:43,  6.04it/s, est. speed input: 1060.95 toks/s, output: 8235.86 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 570/1920 [01:19<03:28,  6.47it/s, est. speed input: 1060.98 toks/s, output: 8245.63 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 571/1920 [01:19<04:19,  5.21it/s, est. speed input: 1058.38 toks/s, output: 8226.22 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 572/1920 [01:19<04:01,  5.59it/s, est. speed input: 1059.63 toks/s, output: 8239.04 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 574/1920 [01:19<03:18,  6.76it/s, est. speed input: 1061.40 toks/s, output: 8270.27 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 577/1920 [01:20<02:49,  7.91it/s, est. speed input: 1061.49 toks/s, output: 8279.12 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 578/1920 [01:20<03:17,  6.81it/s, est. speed input: 1060.20 toks/s, output: 8292.89 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 580/1920 [01:20<02:43,  8.21it/s, est. speed input: 1062.14 toks/s, output: 8320.46 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 583/1920 [01:20<01:55, 11.54it/s, est. speed input: 1065.30 toks/s, output: 8339.55 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 586/1920 [01:20<01:57, 11.31it/s, est. speed input: 1066.82 toks/s, output: 8378.62 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 588/1920 [01:21<02:22,  9.37it/s, est. speed input: 1064.18 toks/s, output: 8362.05 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 590/1920 [01:21<03:35,  6.18it/s, est. speed input: 1059.32 toks/s, output: 8374.38 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 592/1920 [01:21<03:05,  7.18it/s, est. speed input: 1060.49 toks/s, output: 8402.78 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 593/1920 [01:22<03:11,  6.94it/s, est. speed input: 1061.40 toks/s, output: 8418.58 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 594/1920 [01:22<03:04,  7.20it/s, est. speed input: 1061.59 toks/s, output: 8414.35 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 596/1920 [01:22<02:26,  9.05it/s, est. speed input: 1064.31 toks/s, output: 8455.43 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 598/1920 [01:22<03:28,  6.33it/s, est. speed input: 1060.48 toks/s, output: 8443.55 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 599/1920 [01:23<04:05,  5.37it/s, est. speed input: 1057.35 toks/s, output: 8421.46 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà‚ñè      | 601/1920 [01:23<03:17,  6.67it/s, est. speed input: 1057.17 toks/s, output: 8419.69 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà‚ñè      | 604/1920 [01:23<02:42,  8.11it/s, est. speed input: 1060.51 toks/s, output: 8434.18 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 605/1920 [01:23<03:39,  5.98it/s, est. speed input: 1056.80 toks/s, output: 8413.33 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 606/1920 [01:24<04:11,  5.23it/s, est. speed input: 1054.80 toks/s, output: 8402.57 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 608/1920 [01:24<03:24,  6.40it/s, est. speed input: 1056.16 toks/s, output: 8428.34 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 611/1920 [01:24<03:00,  7.25it/s, est. speed input: 1059.04 toks/s, output: 8473.19 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 612/1920 [01:25<03:32,  6.14it/s, est. speed input: 1057.10 toks/s, output: 8481.11 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 613/1920 [01:25<03:28,  6.27it/s, est. speed input: 1058.21 toks/s, output: 8476.84 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 615/1920 [01:25<02:58,  7.30it/s, est. speed input: 1059.14 toks/s, output: 8500.39 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 616/1920 [01:25<03:01,  7.19it/s, est. speed input: 1060.47 toks/s, output: 8507.03 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 618/1920 [01:25<03:09,  6.88it/s, est. speed input: 1059.27 toks/s, output: 8518.04 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 620/1920 [01:25<02:29,  8.67it/s, est. speed input: 1061.06 toks/s, output: 8551.96 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 622/1920 [01:26<02:40,  8.08it/s, est. speed input: 1060.11 toks/s, output: 8569.56 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 623/1920 [01:26<02:39,  8.14it/s, est. speed input: 1060.08 toks/s, output: 8567.63 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 629/1920 [01:26<01:16, 16.89it/s, est. speed input: 1066.10 toks/s, output: 8738.03 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 632/1920 [01:27<02:27,  8.72it/s, est. speed input: 1063.66 toks/s, output: 8699.88 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 635/1920 [01:27<02:22,  9.00it/s, est. speed input: 1064.09 toks/s, output: 8716.58 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 637/1920 [01:27<02:46,  7.71it/s, est. speed input: 1062.28 toks/s, output: 8733.22 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 639/1920 [01:28<02:50,  7.50it/s, est. speed input: 1060.98 toks/s, output: 8719.18 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 643/1920 [01:28<02:02, 10.40it/s, est. speed input: 1067.74 toks/s, output: 8745.56 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñé      | 646/1920 [01:28<01:41, 12.51it/s, est. speed input: 1070.27 toks/s, output: 8766.95 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 651/1920 [01:28<01:14, 16.95it/s, est. speed input: 1076.91 toks/s, output: 8870.39 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 654/1920 [01:28<01:27, 14.45it/s, est. speed input: 1076.76 toks/s, output: 8885.04 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 656/1920 [01:29<01:41, 12.41it/s, est. speed input: 1075.87 toks/s, output: 8905.41 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 658/1920 [01:29<02:24,  8.76it/s, est. speed input: 1072.67 toks/s, output: 8879.24 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 660/1920 [01:30<02:56,  7.16it/s, est. speed input: 1072.87 toks/s, output: 8877.07 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 665/1920 [01:30<01:51, 11.25it/s, est. speed input: 1079.31 toks/s, output: 8961.86 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 667/1920 [01:30<02:33,  8.16it/s, est. speed input: 1077.83 toks/s, output: 8942.54 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 669/1920 [01:30<02:22,  8.81it/s, est. speed input: 1079.09 toks/s, output: 8949.17 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 671/1920 [01:31<02:42,  7.70it/s, est. speed input: 1077.08 toks/s, output: 8939.38 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 674/1920 [01:31<02:00, 10.30it/s, est. speed input: 1079.69 toks/s, output: 8979.48 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 676/1920 [01:31<02:03, 10.10it/s, est. speed input: 1079.31 toks/s, output: 8995.21 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 679/1920 [01:32<02:53,  7.14it/s, est. speed input: 1080.08 toks/s, output: 9006.14 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 681/1920 [01:32<03:57,  5.21it/s, est. speed input: 1076.27 toks/s, output: 8973.90 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 683/1920 [01:33<03:42,  5.56it/s, est. speed input: 1075.33 toks/s, output: 8985.81 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 684/1920 [01:33<03:55,  5.24it/s, est. speed input: 1073.17 toks/s, output: 8967.05 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 685/1920 [01:33<03:40,  5.59it/s, est. speed input: 1072.84 toks/s, output: 8966.29 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 686/1920 [01:34<04:52,  4.22it/s, est. speed input: 1068.32 toks/s, output: 8927.95 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 687/1920 [01:34<06:47,  3.02it/s, est. speed input: 1062.46 toks/s, output: 8875.35 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 689/1920 [01:34<04:37,  4.44it/s, est. speed input: 1066.86 toks/s, output: 8876.06 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 690/1920 [01:35<04:44,  4.32it/s, est. speed input: 1065.20 toks/s, output: 8863.65 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 691/1920 [01:35<04:31,  4.52it/s, est. speed input: 1064.12 toks/s, output: 8852.99 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 692/1920 [01:35<04:08,  4.94it/s, est. speed input: 1064.12 toks/s, output: 8846.71 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 693/1920 [01:35<03:36,  5.66it/s, est. speed input: 1063.97 toks/s, output: 8844.04 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 695/1920 [01:35<03:04,  6.64it/s, est. speed input: 1063.32 toks/s, output: 8860.85 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñã      | 697/1920 [01:36<02:57,  6.88it/s, est. speed input: 1062.71 toks/s, output: 8878.82 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñã      | 699/1920 [01:36<03:02,  6.69it/s, est. speed input: 1062.30 toks/s, output: 8887.03 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 701/1920 [01:36<02:40,  7.62it/s, est. speed input: 1062.45 toks/s, output: 8893.12 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 704/1920 [01:36<02:12,  9.18it/s, est. speed input: 1063.48 toks/s, output: 8903.92 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 706/1920 [01:37<02:18,  8.79it/s, est. speed input: 1064.67 toks/s, output: 8903.20 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 707/1920 [01:37<03:11,  6.33it/s, est. speed input: 1061.75 toks/s, output: 8881.01 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 708/1920 [01:37<02:59,  6.75it/s, est. speed input: 1061.27 toks/s, output: 8878.34 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 711/1920 [01:37<02:49,  7.14it/s, est. speed input: 1061.86 toks/s, output: 8861.73 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 712/1920 [01:38<02:41,  7.46it/s, est. speed input: 1062.08 toks/s, output: 8875.93 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 713/1920 [01:38<02:55,  6.89it/s, est. speed input: 1061.25 toks/s, output: 8875.95 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 717/1920 [01:38<02:16,  8.83it/s, est. speed input: 1062.33 toks/s, output: 8882.10 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 718/1920 [01:38<02:22,  8.43it/s, est. speed input: 1063.61 toks/s, output: 8873.69 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 720/1920 [01:38<02:37,  7.63it/s, est. speed input: 1063.57 toks/s, output: 8907.40 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 724/1920 [01:39<01:38, 12.20it/s, est. speed input: 1068.74 toks/s, output: 8927.92 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 726/1920 [01:39<01:35, 12.46it/s, est. speed input: 1071.36 toks/s, output: 8973.74 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 728/1920 [01:39<01:30, 13.19it/s, est. speed input: 1071.65 toks/s, output: 8978.25 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 730/1920 [01:39<01:30, 13.18it/s, est. speed input: 1073.87 toks/s, output: 9005.75 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 732/1920 [01:39<01:32, 12.78it/s, est. speed input: 1075.22 toks/s, output: 9028.85 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 734/1920 [01:39<01:49, 10.88it/s, est. speed input: 1076.76 toks/s, output: 9027.34 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 736/1920 [01:40<01:57, 10.12it/s, est. speed input: 1075.88 toks/s, output: 9018.95 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 738/1920 [01:40<02:06,  9.36it/s, est. speed input: 1076.03 toks/s, output: 9031.68 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñä      | 740/1920 [01:40<02:38,  7.46it/s, est. speed input: 1073.81 toks/s, output: 9006.40 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñä      | 743/1920 [01:41<02:08,  9.13it/s, est. speed input: 1074.64 toks/s, output: 9008.83 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 745/1920 [01:41<02:14,  8.76it/s, est. speed input: 1074.17 toks/s, output: 9003.51 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 746/1920 [01:41<02:20,  8.37it/s, est. speed input: 1073.84 toks/s, output: 9020.73 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 748/1920 [01:41<02:49,  6.91it/s, est. speed input: 1073.13 toks/s, output: 9012.41 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 749/1920 [01:42<03:12,  6.09it/s, est. speed input: 1071.42 toks/s, output: 8995.72 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 753/1920 [01:42<02:05,  9.29it/s, est. speed input: 1075.43 toks/s, output: 9072.75 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 755/1920 [01:42<01:51, 10.43it/s, est. speed input: 1077.58 toks/s, output: 9108.32 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 758/1920 [01:42<01:37, 11.90it/s, est. speed input: 1081.24 toks/s, output: 9136.65 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 760/1920 [01:42<01:28, 13.13it/s, est. speed input: 1083.63 toks/s, output: 9177.47 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 764/1920 [01:42<01:11, 16.16it/s, est. speed input: 1088.29 toks/s, output: 9197.50 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 766/1920 [01:43<01:23, 13.90it/s, est. speed input: 1087.77 toks/s, output: 9193.01 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 768/1920 [01:43<02:04,  9.24it/s, est. speed input: 1084.58 toks/s, output: 9189.76 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 770/1920 [01:43<02:18,  8.28it/s, est. speed input: 1082.86 toks/s, output: 9201.85 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 772/1920 [01:43<01:59,  9.64it/s, est. speed input: 1083.73 toks/s, output: 9205.23 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 774/1920 [01:44<01:42, 11.17it/s, est. speed input: 1084.40 toks/s, output: 9216.05 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 776/1920 [01:44<01:57,  9.73it/s, est. speed input: 1083.78 toks/s, output: 9223.40 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 778/1920 [01:44<01:51, 10.26it/s, est. speed input: 1084.22 toks/s, output: 9227.45 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 780/1920 [01:45<02:38,  7.19it/s, est. speed input: 1082.38 toks/s, output: 9218.56 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 781/1920 [01:45<02:31,  7.50it/s, est. speed input: 1082.92 toks/s, output: 9238.56 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 783/1920 [01:45<02:44,  6.90it/s, est. speed input: 1081.71 toks/s, output: 9261.79 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 786/1920 [01:45<01:52, 10.04it/s, est. speed input: 1086.17 toks/s, output: 9304.74 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 788/1920 [01:45<02:02,  9.26it/s, est. speed input: 1088.27 toks/s, output: 9298.84 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 791/1920 [01:45<01:31, 12.37it/s, est. speed input: 1090.51 toks/s, output: 9333.08 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 796/1920 [01:46<01:06, 17.01it/s, est. speed input: 1099.16 toks/s, output: 9375.58 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 799/1920 [01:46<01:36, 11.62it/s, est. speed input: 1097.22 toks/s, output: 9381.72 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 801/1920 [01:46<01:38, 11.39it/s, est. speed input: 1098.40 toks/s, output: 9411.22 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 803/1920 [01:47<02:01,  9.18it/s, est. speed input: 1098.53 toks/s, output: 9396.27 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 805/1920 [01:47<01:51,  9.99it/s, est. speed input: 1100.62 toks/s, output: 9402.55 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 807/1920 [01:47<01:40, 11.06it/s, est. speed input: 1103.26 toks/s, output: 9403.32 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 809/1920 [01:47<01:29, 12.47it/s, est. speed input: 1104.70 toks/s, output: 9425.97 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 811/1920 [01:47<01:30, 12.30it/s, est. speed input: 1106.02 toks/s, output: 9437.89 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 814/1920 [01:47<01:11, 15.57it/s, est. speed input: 1108.25 toks/s, output: 9465.66 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 816/1920 [01:48<02:27,  7.46it/s, est. speed input: 1103.63 toks/s, output: 9464.95 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 818/1920 [01:48<02:28,  7.44it/s, est. speed input: 1103.42 toks/s, output: 9455.52 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 821/1920 [01:48<01:47, 10.21it/s, est. speed input: 1106.95 toks/s, output: 9490.04 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 823/1920 [01:49<01:46, 10.33it/s, est. speed input: 1108.74 toks/s, output: 9511.36 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 825/1920 [01:49<02:15,  8.06it/s, est. speed input: 1108.16 toks/s, output: 9511.91 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 827/1920 [01:49<01:53,  9.61it/s, est. speed input: 1111.19 toks/s, output: 9526.52 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 829/1920 [01:49<02:16,  8.00it/s, est. speed input: 1109.89 toks/s, output: 9538.76 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 831/1920 [01:50<02:29,  7.30it/s, est. speed input: 1109.63 toks/s, output: 9529.72 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 832/1920 [01:50<02:46,  6.53it/s, est. speed input: 1108.57 toks/s, output: 9514.30 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 836/1920 [01:50<01:40, 10.76it/s, est. speed input: 1113.23 toks/s, output: 9535.43 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 838/1920 [01:50<02:15,  7.96it/s, est. speed input: 1112.24 toks/s, output: 9521.09 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 840/1920 [01:51<02:57,  6.08it/s, est. speed input: 1109.27 toks/s, output: 9500.20 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 841/1920 [01:51<02:54,  6.19it/s, est. speed input: 1110.05 toks/s, output: 9495.62 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 843/1920 [01:51<02:59,  6.00it/s, est. speed input: 1109.90 toks/s, output: 9484.06 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 844/1920 [01:52<02:46,  6.45it/s, est. speed input: 1110.90 toks/s, output: 9489.72 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 846/1920 [01:52<02:16,  7.85it/s, est. speed input: 1112.75 toks/s, output: 9500.75 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 848/1920 [01:52<02:08,  8.35it/s, est. speed input: 1112.48 toks/s, output: 9494.05 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 849/1920 [01:52<02:05,  8.55it/s, est. speed input: 1112.66 toks/s, output: 9497.60 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 850/1920 [01:52<02:02,  8.75it/s, est. speed input: 1112.17 toks/s, output: 9494.70 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 852/1920 [01:52<02:02,  8.73it/s, est. speed input: 1111.68 toks/s, output: 9486.84 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 853/1920 [01:53<03:25,  5.20it/s, est. speed input: 1108.99 toks/s, output: 9473.84 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 854/1920 [01:53<03:19,  5.35it/s, est. speed input: 1107.94 toks/s, output: 9484.66 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 855/1920 [01:53<02:57,  6.01it/s, est. speed input: 1108.92 toks/s, output: 9502.91 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 856/1920 [01:54<03:49,  4.63it/s, est. speed input: 1107.47 toks/s, output: 9500.31 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 858/1920 [01:54<02:35,  6.85it/s, est. speed input: 1108.71 toks/s, output: 9523.16 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 860/1920 [01:54<02:05,  8.43it/s, est. speed input: 1109.64 toks/s, output: 9564.61 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 862/1920 [01:54<02:20,  7.51it/s, est. speed input: 1109.96 toks/s, output: 9566.72 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 864/1920 [01:54<01:59,  8.82it/s, est. speed input: 1110.66 toks/s, output: 9593.87 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 867/1920 [01:54<01:37, 10.79it/s, est. speed input: 1111.74 toks/s, output: 9650.01 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 869/1920 [01:55<01:25, 12.30it/s, est. speed input: 1112.55 toks/s, output: 9653.10 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 871/1920 [01:55<01:26, 12.19it/s, est. speed input: 1112.78 toks/s, output: 9662.37 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 873/1920 [01:55<01:39, 10.56it/s, est. speed input: 1112.22 toks/s, output: 9694.59 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 875/1920 [01:55<01:25, 12.15it/s, est. speed input: 1113.45 toks/s, output: 9718.06 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 877/1920 [01:55<01:32, 11.22it/s, est. speed input: 1114.05 toks/s, output: 9731.92 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 879/1920 [01:55<01:27, 11.85it/s, est. speed input: 1114.73 toks/s, output: 9752.41 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 883/1920 [01:56<01:14, 13.88it/s, est. speed input: 1117.41 toks/s, output: 9821.15 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 885/1920 [01:57<02:56,  5.87it/s, est. speed input: 1110.55 toks/s, output: 9773.93 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 888/1920 [01:57<02:51,  6.00it/s, est. speed input: 1110.22 toks/s, output: 9759.39 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 889/1920 [01:57<03:27,  4.96it/s, est. speed input: 1107.58 toks/s, output: 9730.99 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 891/1920 [01:58<02:55,  5.86it/s, est. speed input: 1107.85 toks/s, output: 9740.86 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 892/1920 [01:58<03:01,  5.65it/s, est. speed input: 1107.16 toks/s, output: 9729.86 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 895/1920 [01:58<02:38,  6.46it/s, est. speed input: 1106.22 toks/s, output: 9732.02 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 896/1920 [01:58<02:37,  6.51it/s, est. speed input: 1105.89 toks/s, output: 9728.88 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 897/1920 [01:59<02:43,  6.26it/s, est. speed input: 1105.22 toks/s, output: 9722.59 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 898/1920 [01:59<02:31,  6.77it/s, est. speed input: 1105.30 toks/s, output: 9731.39 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 899/1920 [01:59<02:20,  7.27it/s, est. speed input: 1105.77 toks/s, output: 9730.75 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 900/1920 [01:59<02:28,  6.85it/s, est. speed input: 1106.27 toks/s, output: 9737.26 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 902/1920 [01:59<01:53,  9.01it/s, est. speed input: 1107.25 toks/s, output: 9740.69 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 907/1920 [01:59<01:12, 13.88it/s, est. speed input: 1110.28 toks/s, output: 9768.08 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 909/1920 [02:00<01:26, 11.70it/s, est. speed input: 1110.91 toks/s, output: 9773.25 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 911/1920 [02:00<01:31, 11.04it/s, est. speed input: 1112.64 toks/s, output: 9782.15 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 913/1920 [02:00<01:52,  8.98it/s, est. speed input: 1111.46 toks/s, output: 9782.68 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 914/1920 [02:00<01:54,  8.80it/s, est. speed input: 1111.39 toks/s, output: 9790.14 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 915/1920 [02:00<02:12,  7.60it/s, est. speed input: 1110.51 toks/s, output: 9793.54 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 917/1920 [02:01<02:24,  6.96it/s, est. speed input: 1109.26 toks/s, output: 9796.13 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 918/1920 [02:01<02:37,  6.38it/s, est. speed input: 1108.05 toks/s, output: 9787.56 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 919/1920 [02:01<02:29,  6.68it/s, est. speed input: 1108.21 toks/s, output: 9788.30 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 920/1920 [02:01<02:18,  7.21it/s, est. speed input: 1107.96 toks/s, output: 9788.22 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 921/1920 [02:01<02:43,  6.10it/s, est. speed input: 1107.03 toks/s, output: 9776.50 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 922/1920 [02:02<02:44,  6.07it/s, est. speed input: 1106.22 toks/s, output: 9771.35 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 923/1920 [02:02<05:37,  2.95it/s, est. speed input: 1100.09 toks/s, output: 9718.69 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 924/1920 [02:03<04:42,  3.52it/s, est. speed input: 1099.99 toks/s, output: 9714.76 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 925/1920 [02:03<04:27,  3.73it/s, est. speed input: 1098.87 toks/s, output: 9704.68 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 926/1920 [02:03<05:33,  2.98it/s, est. speed input: 1094.98 toks/s, output: 9670.50 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 927/1920 [02:04<05:09,  3.21it/s, est. speed input: 1094.76 toks/s, output: 9675.48 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 928/1920 [02:04<04:44,  3.48it/s, est. speed input: 1093.70 toks/s, output: 9670.77 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 929/1920 [02:04<04:21,  3.78it/s, est. speed input: 1093.87 toks/s, output: 9679.15 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 930/1920 [02:04<03:40,  4.49it/s, est. speed input: 1093.31 toks/s, output: 9674.44 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 931/1920 [02:04<03:42,  4.44it/s, est. speed input: 1092.24 toks/s, output: 9669.86 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 932/1920 [02:04<03:25,  4.81it/s, est. speed input: 1092.14 toks/s, output: 9666.68 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 933/1920 [02:05<03:19,  4.94it/s, est. speed input: 1091.57 toks/s, output: 9669.61 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 934/1920 [02:05<03:22,  4.86it/s, est. speed input: 1090.44 toks/s, output: 9658.10 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 936/1920 [02:05<03:47,  4.33it/s, est. speed input: 1088.41 toks/s, output: 9631.20 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 937/1920 [02:06<03:21,  4.88it/s, est. speed input: 1088.67 toks/s, output: 9631.68 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 938/1920 [02:06<03:11,  5.12it/s, est. speed input: 1089.47 toks/s, output: 9622.70 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 940/1920 [02:06<03:04,  5.31it/s, est. speed input: 1089.37 toks/s, output: 9611.26 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 942/1920 [02:06<02:14,  7.30it/s, est. speed input: 1091.12 toks/s, output: 9616.86 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 943/1920 [02:06<02:07,  7.67it/s, est. speed input: 1091.19 toks/s, output: 9620.26 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 944/1920 [02:07<03:12,  5.08it/s, est. speed input: 1088.68 toks/s, output: 9606.88 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 945/1920 [02:07<03:20,  4.87it/s, est. speed input: 1088.70 toks/s, output: 9594.44 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 946/1920 [02:07<03:32,  4.59it/s, est. speed input: 1088.76 toks/s, output: 9579.17 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 947/1920 [02:07<03:07,  5.18it/s, est. speed input: 1088.70 toks/s, output: 9578.16 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 949/1920 [02:07<02:16,  7.10it/s, est. speed input: 1091.51 toks/s, output: 9579.82 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 951/1920 [02:08<02:34,  6.28it/s, est. speed input: 1090.26 toks/s, output: 9562.19 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 953/1920 [02:08<02:29,  6.46it/s, est. speed input: 1089.86 toks/s, output: 9558.21 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 954/1920 [02:08<02:20,  6.90it/s, est. speed input: 1089.48 toks/s, output: 9556.91 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 956/1920 [02:08<02:13,  7.24it/s, est. speed input: 1089.20 toks/s, output: 9558.87 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 957/1920 [02:09<02:19,  6.92it/s, est. speed input: 1088.66 toks/s, output: 9555.96 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 961/1920 [02:09<01:28, 10.82it/s, est. speed input: 1091.18 toks/s, output: 9562.52 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 963/1920 [02:09<01:34, 10.10it/s, est. speed input: 1090.52 toks/s, output: 9559.56 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 965/1920 [02:09<01:36,  9.93it/s, est. speed input: 1091.66 toks/s, output: 9572.58 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 967/1920 [02:09<01:34, 10.09it/s, est. speed input: 1091.43 toks/s, output: 9565.61 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 969/1920 [02:10<01:38,  9.61it/s, est. speed input: 1092.39 toks/s, output: 9557.12 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 970/1920 [02:10<01:45,  8.97it/s, est. speed input: 1093.10 toks/s, output: 9552.04 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 975/1920 [02:10<01:07, 13.94it/s, est. speed input: 1097.61 toks/s, output: 9584.70 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 977/1920 [02:10<01:15, 12.52it/s, est. speed input: 1098.60 toks/s, output: 9584.85 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 979/1920 [02:10<01:13, 12.74it/s, est. speed input: 1099.13 toks/s, output: 9590.55 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 981/1920 [02:11<01:38,  9.51it/s, est. speed input: 1098.74 toks/s, output: 9576.66 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 983/1920 [02:11<01:52,  8.34it/s, est. speed input: 1098.84 toks/s, output: 9581.82 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 984/1920 [02:11<02:09,  7.24it/s, est. speed input: 1098.12 toks/s, output: 9567.97 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 986/1920 [02:11<01:43,  8.99it/s, est. speed input: 1101.02 toks/s, output: 9589.71 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 988/1920 [02:12<01:30, 10.35it/s, est. speed input: 1101.71 toks/s, output: 9601.16 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 990/1920 [02:12<01:17, 12.04it/s, est. speed input: 1102.80 toks/s, output: 9612.99 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 992/1920 [02:12<01:29, 10.37it/s, est. speed input: 1102.50 toks/s, output: 9625.51 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 994/1920 [02:12<02:01,  7.64it/s, est. speed input: 1101.61 toks/s, output: 9622.93 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 996/1920 [02:12<01:42,  9.04it/s, est. speed input: 1101.98 toks/s, output: 9623.13 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 998/1920 [02:13<01:46,  8.68it/s, est. speed input: 1101.53 toks/s, output: 9622.56 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1000/1920 [02:13<02:17,  6.67it/s, est. speed input: 1100.23 toks/s, output: 9607.64 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1001/1920 [02:13<02:13,  6.86it/s, est. speed input: 1101.08 toks/s, output: 9605.43 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1004/1920 [02:13<01:38,  9.27it/s, est. speed input: 1102.95 toks/s, output: 9628.89 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1006/1920 [02:14<01:43,  8.82it/s, est. speed input: 1103.66 toks/s, output: 9624.14 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1008/1920 [02:14<01:36,  9.49it/s, est. speed input: 1104.32 toks/s, output: 9641.10 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1014/1920 [02:14<00:56, 16.07it/s, est. speed input: 1107.99 toks/s, output: 9749.73 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1017/1920 [02:15<01:21, 11.08it/s, est. speed input: 1106.11 toks/s, output: 9736.27 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1020/1920 [02:15<01:18, 11.54it/s, est. speed input: 1107.12 toks/s, output: 9766.34 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1022/1920 [02:15<01:19, 11.30it/s, est. speed input: 1107.45 toks/s, output: 9766.57 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1024/1920 [02:15<01:16, 11.75it/s, est. speed input: 1108.28 toks/s, output: 9787.56 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1026/1920 [02:16<02:00,  7.45it/s, est. speed input: 1105.50 toks/s, output: 9761.12 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1028/1920 [02:16<01:59,  7.47it/s, est. speed input: 1106.19 toks/s, output: 9758.61 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1030/1920 [02:16<01:57,  7.58it/s, est. speed input: 1106.73 toks/s, output: 9759.00 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1031/1920 [02:16<02:05,  7.08it/s, est. speed input: 1107.03 toks/s, output: 9762.48 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1033/1920 [02:16<01:40,  8.85it/s, est. speed input: 1109.20 toks/s, output: 9773.13 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1035/1920 [02:17<01:43,  8.54it/s, est. speed input: 1110.94 toks/s, output: 9771.39 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1037/1920 [02:17<02:33,  5.74it/s, est. speed input: 1108.01 toks/s, output: 9747.41 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1039/1920 [02:17<02:03,  7.12it/s, est. speed input: 1108.56 toks/s, output: 9755.04 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1041/1920 [02:18<02:36,  5.63it/s, est. speed input: 1105.57 toks/s, output: 9741.99 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1043/1920 [02:18<02:19,  6.30it/s, est. speed input: 1105.66 toks/s, output: 9746.79 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1044/1920 [02:19<02:45,  5.29it/s, est. speed input: 1103.87 toks/s, output: 9735.93 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1045/1920 [02:19<02:41,  5.42it/s, est. speed input: 1103.25 toks/s, output: 9734.32 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1047/1920 [02:19<02:29,  5.85it/s, est. speed input: 1102.74 toks/s, output: 9731.74 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1048/1920 [02:19<02:17,  6.35it/s, est. speed input: 1102.77 toks/s, output: 9732.33 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1049/1920 [02:19<02:10,  6.65it/s, est. speed input: 1103.55 toks/s, output: 9739.32 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1052/1920 [02:20<01:51,  7.80it/s, est. speed input: 1103.78 toks/s, output: 9754.93 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1055/1920 [02:20<01:22, 10.44it/s, est. speed input: 1105.53 toks/s, output: 9783.63 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1057/1920 [02:20<01:30,  9.56it/s, est. speed input: 1105.33 toks/s, output: 9800.08 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1060/1920 [02:20<01:09, 12.31it/s, est. speed input: 1106.90 toks/s, output: 9818.20 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1062/1920 [02:20<01:12, 11.80it/s, est. speed input: 1107.40 toks/s, output: 9812.05 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1064/1920 [02:21<01:17, 11.07it/s, est. speed input: 1108.74 toks/s, output: 9828.79 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1066/1920 [02:21<01:33,  9.12it/s, est. speed input: 1108.20 toks/s, output: 9820.60 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1068/1920 [02:21<01:24, 10.04it/s, est. speed input: 1109.86 toks/s, output: 9843.58 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1070/1920 [02:21<01:21, 10.49it/s, est. speed input: 1111.05 toks/s, output: 9851.42 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1072/1920 [02:21<01:10, 12.04it/s, est. speed input: 1111.79 toks/s, output: 9869.17 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1074/1920 [02:22<01:51,  7.56it/s, est. speed input: 1109.59 toks/s, output: 9851.86 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1076/1920 [02:22<01:39,  8.47it/s, est. speed input: 1111.38 toks/s, output: 9866.06 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1078/1920 [02:22<02:02,  6.89it/s, est. speed input: 1110.06 toks/s, output: 9852.01 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1079/1920 [02:23<02:05,  6.71it/s, est. speed input: 1109.19 toks/s, output: 9845.42 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1081/1920 [02:23<01:55,  7.25it/s, est. speed input: 1110.58 toks/s, output: 9872.37 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1083/1920 [02:23<01:32,  9.03it/s, est. speed input: 1111.00 toks/s, output: 9887.56 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1085/1920 [02:23<01:33,  8.91it/s, est. speed input: 1110.54 toks/s, output: 9893.21 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1087/1920 [02:23<01:48,  7.71it/s, est. speed input: 1110.12 toks/s, output: 9895.69 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1089/1920 [02:24<01:41,  8.16it/s, est. speed input: 1110.63 toks/s, output: 9893.81 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1091/1920 [02:24<01:55,  7.17it/s, est. speed input: 1110.03 toks/s, output: 9894.81 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1093/1920 [02:24<01:44,  7.93it/s, est. speed input: 1111.05 toks/s, output: 9906.02 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1095/1920 [02:24<01:30,  9.08it/s, est. speed input: 1112.03 toks/s, output: 9922.28 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1097/1920 [02:25<01:34,  8.70it/s, est. speed input: 1112.21 toks/s, output: 9931.27 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1099/1920 [02:25<01:21, 10.07it/s, est. speed input: 1112.72 toks/s, output: 9945.71 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1101/1920 [02:25<01:09, 11.70it/s, est. speed input: 1113.35 toks/s, output: 9947.76 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1103/1920 [02:25<01:37,  8.37it/s, est. speed input: 1112.77 toks/s, output: 9960.19 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1105/1920 [02:26<01:46,  7.65it/s, est. speed input: 1112.69 toks/s, output: 9958.13 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1108/1920 [02:26<01:22,  9.82it/s, est. speed input: 1113.59 toks/s, output: 10009.55 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1110/1920 [02:26<01:23,  9.74it/s, est. speed input: 1113.54 toks/s, output: 10025.20 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1112/1920 [02:26<01:23,  9.68it/s, est. speed input: 1114.70 toks/s, output: 10030.07 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1115/1920 [02:27<01:53,  7.11it/s, est. speed input: 1112.56 toks/s, output: 10021.65 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1116/1920 [02:27<01:53,  7.07it/s, est. speed input: 1112.52 toks/s, output: 10032.55 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1117/1920 [02:27<02:03,  6.50it/s, est. speed input: 1111.98 toks/s, output: 10039.01 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1118/1920 [02:27<02:08,  6.22it/s, est. speed input: 1111.58 toks/s, output: 10030.92 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1119/1920 [02:27<01:58,  6.75it/s, est. speed input: 1111.87 toks/s, output: 10031.26 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1121/1920 [02:28<02:07,  6.27it/s, est. speed input: 1110.78 toks/s, output: 10017.20 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1122/1920 [02:28<02:15,  5.87it/s, est. speed input: 1109.63 toks/s, output: 10009.43 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1124/1920 [02:28<01:58,  6.70it/s, est. speed input: 1109.21 toks/s, output: 10010.42 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1128/1920 [02:28<01:24,  9.34it/s, est. speed input: 1111.54 toks/s, output: 10033.45 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1130/1920 [02:29<01:15, 10.52it/s, est. speed input: 1113.35 toks/s, output: 10035.03 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1132/1920 [02:29<01:19,  9.93it/s, est. speed input: 1113.24 toks/s, output: 10045.62 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1134/1920 [02:29<01:13, 10.76it/s, est. speed input: 1113.86 toks/s, output: 10044.09 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1136/1920 [02:29<01:44,  7.53it/s, est. speed input: 1111.41 toks/s, output: 10025.80 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1138/1920 [02:30<01:56,  6.71it/s, est. speed input: 1110.01 toks/s, output: 10014.56 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1139/1920 [02:30<02:10,  6.00it/s, est. speed input: 1108.98 toks/s, output: 10005.65 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1140/1920 [02:30<02:00,  6.47it/s, est. speed input: 1108.82 toks/s, output: 10010.52 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1142/1920 [02:30<01:52,  6.93it/s, est. speed input: 1109.32 toks/s, output: 10004.58 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1143/1920 [02:31<02:06,  6.16it/s, est. speed input: 1108.30 toks/s, output: 9995.36 toks/s] [A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1145/1920 [02:31<01:46,  7.27it/s, est. speed input: 1109.29 toks/s, output: 10007.84 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1147/1920 [02:31<02:13,  5.78it/s, est. speed input: 1107.41 toks/s, output: 9986.43 toks/s] [A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1148/1920 [02:31<02:06,  6.10it/s, est. speed input: 1108.35 toks/s, output: 9997.41 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1149/1920 [02:32<02:14,  5.74it/s, est. speed input: 1108.47 toks/s, output: 9985.68 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1150/1920 [02:32<02:51,  4.50it/s, est. speed input: 1107.38 toks/s, output: 9970.48 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1152/1920 [02:32<02:01,  6.33it/s, est. speed input: 1108.08 toks/s, output: 9996.08 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1153/1920 [02:32<01:59,  6.43it/s, est. speed input: 1107.76 toks/s, output: 9992.75 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1154/1920 [02:32<02:00,  6.35it/s, est. speed input: 1107.14 toks/s, output: 9988.90 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1155/1920 [02:33<01:49,  7.01it/s, est. speed input: 1108.06 toks/s, output: 10002.42 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1157/1920 [02:33<01:32,  8.22it/s, est. speed input: 1108.07 toks/s, output: 10001.99 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1159/1920 [02:33<02:07,  5.95it/s, est. speed input: 1107.93 toks/s, output: 9995.62 toks/s] [A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1162/1920 [02:34<01:45,  7.17it/s, est. speed input: 1108.81 toks/s, output: 9996.78 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1164/1920 [02:34<01:54,  6.63it/s, est. speed input: 1107.58 toks/s, output: 9991.54 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1165/1920 [02:34<02:06,  5.98it/s, est. speed input: 1107.44 toks/s, output: 9994.42 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1166/1920 [02:34<02:22,  5.28it/s, est. speed input: 1106.20 toks/s, output: 9983.24 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1167/1920 [02:35<02:36,  4.81it/s, est. speed input: 1105.07 toks/s, output: 9971.92 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1168/1920 [02:35<03:11,  3.93it/s, est. speed input: 1102.77 toks/s, output: 9953.47 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1169/1920 [02:35<02:51,  4.38it/s, est. speed input: 1102.28 toks/s, output: 9947.35 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1171/1920 [02:35<02:11,  5.72it/s, est. speed input: 1102.19 toks/s, output: 9957.39 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1172/1920 [02:36<02:01,  6.16it/s, est. speed input: 1102.10 toks/s, output: 9969.40 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1174/1920 [02:36<01:44,  7.17it/s, est. speed input: 1101.48 toks/s, output: 9963.65 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1175/1920 [02:36<02:43,  4.56it/s, est. speed input: 1099.58 toks/s, output: 9935.21 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1176/1920 [02:36<02:37,  4.72it/s, est. speed input: 1099.85 toks/s, output: 9933.90 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1177/1920 [02:37<02:57,  4.20it/s, est. speed input: 1098.30 toks/s, output: 9930.26 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1179/1920 [02:37<01:59,  6.20it/s, est. speed input: 1099.11 toks/s, output: 9944.51 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1180/1920 [02:37<01:49,  6.73it/s, est. speed input: 1099.06 toks/s, output: 9955.44 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1182/1920 [02:37<01:34,  7.83it/s, est. speed input: 1099.86 toks/s, output: 9967.43 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1184/1920 [02:38<02:01,  6.05it/s, est. speed input: 1099.02 toks/s, output: 9945.04 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1188/1920 [02:38<01:19,  9.17it/s, est. speed input: 1101.30 toks/s, output: 9947.95 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1194/1920 [02:38<00:47, 15.21it/s, est. speed input: 1107.84 toks/s, output: 10009.91 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1196/1920 [02:38<00:45, 15.78it/s, est. speed input: 1109.59 toks/s, output: 10029.58 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1198/1920 [02:39<01:09, 10.44it/s, est. speed input: 1108.06 toks/s, output: 10022.85 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1201/1920 [02:39<01:19,  9.03it/s, est. speed input: 1107.76 toks/s, output: 10008.51 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1203/1920 [02:39<01:20,  8.89it/s, est. speed input: 1107.94 toks/s, output: 10005.72 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1205/1920 [02:39<01:17,  9.21it/s, est. speed input: 1109.43 toks/s, output: 10005.58 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1207/1920 [02:40<01:09, 10.32it/s, est. speed input: 1110.33 toks/s, output: 10010.50 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1209/1920 [02:40<01:00, 11.74it/s, est. speed input: 1112.14 toks/s, output: 10023.33 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1211/1920 [02:40<00:53, 13.16it/s, est. speed input: 1113.58 toks/s, output: 10023.55 toks/s][A[2025-09-23 15:16:18] ‚è≠ Ë∑≥ËøáÔºöB_rb_manual_algo1_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B__global_step_313Ôºàg1/g2 ÂÖ®ÈÉ®Â∑≤Êúâ metricsÔºâ

Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1213/1920 [02:40<01:54,  6.18it/s, est. speed input: 1111.37 toks/s, output: 9996.79 toks/s] [A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1215/1920 [02:41<01:55,  6.11it/s, est. speed input: 1110.16 toks/s, output: 9981.86 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1217/1920 [02:41<01:51,  6.29it/s, est. speed input: 1110.81 toks/s, output: 9975.36 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1218/1920 [02:41<01:58,  5.95it/s, est. speed input: 1110.10 toks/s, output: 9966.49 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1219/1920 [02:41<01:57,  5.95it/s, est. speed input: 1109.46 toks/s, output: 9959.02 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1220/1920 [02:42<02:04,  5.64it/s, est. speed input: 1109.69 toks/s, output: 9953.56 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1221/1920 [02:42<02:41,  4.34it/s, est. speed input: 1107.38 toks/s, output: 9934.78 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1222/1920 [02:42<02:44,  4.24it/s, est. speed input: 1106.18 toks/s, output: 9922.32 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1224/1920 [02:43<01:57,  5.95it/s, est. speed input: 1106.43 toks/s, output: 9935.05 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1226/1920 [02:43<01:26,  7.98it/s, est. speed input: 1106.79 toks/s, output: 9935.20 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1229/1920 [02:43<01:20,  8.56it/s, est. speed input: 1107.57 toks/s, output: 9952.88 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1233/1920 [02:43<00:53, 12.75it/s, est. speed input: 1110.39 toks/s, output: 9982.62 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1236/1920 [02:43<00:48, 14.02it/s, est. speed input: 1112.22 toks/s, output: 10009.23 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1239/1920 [02:43<00:40, 16.61it/s, est. speed input: 1113.93 toks/s, output: 10020.58 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1241/1920 [02:44<00:58, 11.63it/s, est. speed input: 1112.96 toks/s, output: 10009.23 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1243/1920 [02:44<01:26,  7.84it/s, est. speed input: 1110.67 toks/s, output: 10007.90 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1245/1920 [02:44<01:26,  7.85it/s, est. speed input: 1109.70 toks/s, output: 10029.74 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1249/1920 [02:45<01:05, 10.22it/s, est. speed input: 1110.84 toks/s, output: 10050.10 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1251/1920 [02:45<01:03, 10.55it/s, est. speed input: 1111.09 toks/s, output: 10055.53 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1253/1920 [02:45<00:56, 11.83it/s, est. speed input: 1113.07 toks/s, output: 10071.26 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1255/1920 [02:46<01:47,  6.19it/s, est. speed input: 1109.62 toks/s, output: 10043.58 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1258/1920 [02:46<01:18,  8.41it/s, est. speed input: 1111.62 toks/s, output: 10062.00 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1260/1920 [02:46<01:23,  7.93it/s, est. speed input: 1110.89 toks/s, output: 10067.42 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1262/1920 [02:47<02:34,  4.27it/s, est. speed input: 1105.75 toks/s, output: 10014.25 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1264/1920 [02:48<02:27,  4.44it/s, est. speed input: 1105.40 toks/s, output: 10013.60 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1265/1920 [02:48<02:26,  4.48it/s, est. speed input: 1104.55 toks/s, output: 10007.76 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1266/1920 [02:48<02:11,  4.98it/s, est. speed input: 1105.20 toks/s, output: 10010.12 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1269/1920 [02:48<01:42,  6.32it/s, est. speed input: 1106.45 toks/s, output: 10024.56 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1270/1920 [02:49<01:58,  5.50it/s, est. speed input: 1105.24 toks/s, output: 10012.48 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1273/1920 [02:49<01:19,  8.18it/s, est. speed input: 1106.36 toks/s, output: 10036.44 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1275/1920 [02:49<01:15,  8.49it/s, est. speed input: 1106.79 toks/s, output: 10037.35 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1277/1920 [02:49<01:39,  6.45it/s, est. speed input: 1105.58 toks/s, output: 10017.19 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1279/1920 [02:50<01:25,  7.47it/s, est. speed input: 1105.53 toks/s, output: 10020.58 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1282/1920 [02:50<01:03, 10.00it/s, est. speed input: 1107.46 toks/s, output: 10044.79 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1285/1920 [02:50<00:49, 12.90it/s, est. speed input: 1110.11 toks/s, output: 10062.18 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1287/1920 [02:50<00:53, 11.80it/s, est. speed input: 1110.39 toks/s, output: 10071.66 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1289/1920 [02:50<01:00, 10.41it/s, est. speed input: 1110.37 toks/s, output: 10067.05 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1291/1920 [02:51<01:23,  7.50it/s, est. speed input: 1108.99 toks/s, output: 10050.61 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1293/1920 [02:51<01:18,  7.96it/s, est. speed input: 1109.84 toks/s, output: 10052.20 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1295/1920 [02:51<01:17,  8.08it/s, est. speed input: 1110.11 toks/s, output: 10048.37 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1297/1920 [02:51<01:08,  9.11it/s, est. speed input: 1111.28 toks/s, output: 10058.89 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1299/1920 [02:51<00:58, 10.70it/s, est. speed input: 1112.08 toks/s, output: 10070.03 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1301/1920 [02:52<01:46,  5.79it/s, est. speed input: 1109.15 toks/s, output: 10039.82 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1303/1920 [02:52<01:36,  6.41it/s, est. speed input: 1109.73 toks/s, output: 10036.87 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1304/1920 [02:53<01:35,  6.47it/s, est. speed input: 1109.40 toks/s, output: 10029.01 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1305/1920 [02:53<01:49,  5.61it/s, est. speed input: 1108.97 toks/s, output: 10030.96 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1307/1920 [02:53<01:21,  7.52it/s, est. speed input: 1110.22 toks/s, output: 10046.57 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1309/1920 [02:53<01:13,  8.31it/s, est. speed input: 1110.55 toks/s, output: 10070.85 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1311/1920 [02:54<01:33,  6.53it/s, est. speed input: 1109.10 toks/s, output: 10074.06 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1314/1920 [02:54<01:10,  8.60it/s, est. speed input: 1110.18 toks/s, output: 10103.42 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1316/1920 [02:54<01:01,  9.82it/s, est. speed input: 1111.39 toks/s, output: 10119.03 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1319/1920 [02:54<00:55, 10.77it/s, est. speed input: 1111.99 toks/s, output: 10138.54 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1324/1920 [02:54<00:35, 16.86it/s, est. speed input: 1114.52 toks/s, output: 10177.09 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1327/1920 [02:54<00:32, 18.18it/s, est. speed input: 1115.70 toks/s, output: 10216.25 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1330/1920 [02:55<00:41, 14.26it/s, est. speed input: 1115.96 toks/s, output: 10236.49 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1334/1920 [02:55<00:34, 17.13it/s, est. speed input: 1118.27 toks/s, output: 10260.33 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1337/1920 [02:56<01:05,  8.86it/s, est. speed input: 1116.97 toks/s, output: 10236.25 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1339/1920 [02:56<01:25,  6.79it/s, est. speed input: 1115.43 toks/s, output: 10237.31 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1341/1920 [02:56<01:19,  7.25it/s, est. speed input: 1115.70 toks/s, output: 10241.07 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1343/1920 [02:57<01:20,  7.14it/s, est. speed input: 1115.23 toks/s, output: 10236.82 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1345/1920 [02:57<01:13,  7.85it/s, est. speed input: 1115.99 toks/s, output: 10238.66 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1347/1920 [02:57<01:30,  6.35it/s, est. speed input: 1114.21 toks/s, output: 10226.33 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1349/1920 [02:58<01:25,  6.71it/s, est. speed input: 1113.84 toks/s, output: 10232.55 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1351/1920 [02:58<01:29,  6.35it/s, est. speed input: 1112.85 toks/s, output: 10238.81 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1353/1920 [02:58<01:27,  6.48it/s, est. speed input: 1112.11 toks/s, output: 10242.54 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1359/1920 [02:58<00:46, 12.07it/s, est. speed input: 1116.89 toks/s, output: 10280.36 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1361/1920 [02:59<00:56,  9.85it/s, est. speed input: 1116.05 toks/s, output: 10268.77 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1364/1920 [02:59<00:52, 10.67it/s, est. speed input: 1117.17 toks/s, output: 10281.57 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1366/1920 [02:59<00:48, 11.35it/s, est. speed input: 1118.19 toks/s, output: 10289.85 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1368/1920 [02:59<01:06,  8.30it/s, est. speed input: 1116.69 toks/s, output: 10284.93 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1370/1920 [03:00<01:19,  6.96it/s, est. speed input: 1116.41 toks/s, output: 10268.36 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1371/1920 [03:00<01:20,  6.82it/s, est. speed input: 1116.15 toks/s, output: 10269.51 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1373/1920 [03:00<01:07,  8.10it/s, est. speed input: 1117.33 toks/s, output: 10269.24 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1375/1920 [03:00<01:04,  8.42it/s, est. speed input: 1117.69 toks/s, output: 10267.36 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1376/1920 [03:01<01:23,  6.54it/s, est. speed input: 1117.00 toks/s, output: 10266.85 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1377/1920 [03:01<01:50,  4.91it/s, est. speed input: 1115.74 toks/s, output: 10261.08 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1378/1920 [03:01<02:07,  4.27it/s, est. speed input: 1115.04 toks/s, output: 10258.75 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1379/1920 [03:02<01:56,  4.65it/s, est. speed input: 1114.68 toks/s, output: 10252.81 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1381/1920 [03:02<01:28,  6.09it/s, est. speed input: 1115.20 toks/s, output: 10260.17 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1383/1920 [03:02<01:09,  7.74it/s, est. speed input: 1116.66 toks/s, output: 10282.28 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1384/1920 [03:02<01:17,  6.88it/s, est. speed input: 1116.77 toks/s, output: 10287.49 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1385/1920 [03:02<01:38,  5.43it/s, est. speed input: 1116.23 toks/s, output: 10286.62 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1386/1920 [03:03<01:38,  5.45it/s, est. speed input: 1115.48 toks/s, output: 10286.12 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1387/1920 [03:03<01:35,  5.58it/s, est. speed input: 1115.83 toks/s, output: 10284.06 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1388/1920 [03:03<01:30,  5.86it/s, est. speed input: 1115.69 toks/s, output: 10281.43 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1390/1920 [03:03<01:12,  7.31it/s, est. speed input: 1115.80 toks/s, output: 10285.66 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1391/1920 [03:03<01:09,  7.58it/s, est. speed input: 1116.56 toks/s, output: 10282.87 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1393/1920 [03:04<01:11,  7.36it/s, est. speed input: 1117.14 toks/s, output: 10289.44 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1394/1920 [03:04<02:05,  4.20it/s, est. speed input: 1114.02 toks/s, output: 10261.95 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1396/1920 [03:05<02:20,  3.74it/s, est. speed input: 1112.38 toks/s, output: 10250.51 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1397/1920 [03:05<02:20,  3.72it/s, est. speed input: 1111.41 toks/s, output: 10240.10 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1398/1920 [03:05<02:30,  3.47it/s, est. speed input: 1110.02 toks/s, output: 10233.13 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1399/1920 [03:06<02:05,  4.15it/s, est. speed input: 1109.87 toks/s, output: 10233.62 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1400/1920 [03:06<02:11,  3.95it/s, est. speed input: 1108.79 toks/s, output: 10226.67 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1401/1920 [03:06<01:57,  4.43it/s, est. speed input: 1109.40 toks/s, output: 10219.82 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1402/1920 [03:07<02:50,  3.04it/s, est. speed input: 1106.53 toks/s, output: 10203.91 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1403/1920 [03:07<03:10,  2.71it/s, est. speed input: 1104.46 toks/s, output: 10183.32 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1404/1920 [03:07<02:44,  3.15it/s, est. speed input: 1103.85 toks/s, output: 10176.31 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1406/1920 [03:08<02:08,  4.01it/s, est. speed input: 1102.98 toks/s, output: 10182.17 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1407/1920 [03:08<02:08,  3.98it/s, est. speed input: 1101.93 toks/s, output: 10184.64 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1408/1920 [03:08<01:50,  4.61it/s, est. speed input: 1101.84 toks/s, output: 10184.08 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1411/1920 [03:08<01:03,  7.97it/s, est. speed input: 1104.46 toks/s, output: 10190.98 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1413/1920 [03:09<01:34,  5.36it/s, est. speed input: 1103.50 toks/s, output: 10190.24 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1416/1920 [03:09<01:02,  8.08it/s, est. speed input: 1104.43 toks/s, output: 10199.99 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1418/1920 [03:09<01:20,  6.25it/s, est. speed input: 1102.47 toks/s, output: 10187.17 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1421/1920 [03:10<01:13,  6.79it/s, est. speed input: 1102.41 toks/s, output: 10190.00 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1423/1920 [03:10<01:03,  7.81it/s, est. speed input: 1102.77 toks/s, output: 10187.74 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1425/1920 [03:10<01:08,  7.19it/s, est. speed input: 1103.46 toks/s, output: 10175.90 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1426/1920 [03:10<01:16,  6.49it/s, est. speed input: 1103.43 toks/s, output: 10172.38 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1427/1920 [03:11<01:17,  6.37it/s, est. speed input: 1103.78 toks/s, output: 10166.80 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1428/1920 [03:11<01:18,  6.27it/s, est. speed input: 1103.42 toks/s, output: 10167.67 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1430/1920 [03:11<01:21,  5.98it/s, est. speed input: 1103.02 toks/s, output: 10155.82 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1432/1920 [03:11<01:05,  7.43it/s, est. speed input: 1103.36 toks/s, output: 10160.94 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1434/1920 [03:11<00:52,  9.29it/s, est. speed input: 1103.89 toks/s, output: 10163.73 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1437/1920 [03:11<00:41, 11.59it/s, est. speed input: 1105.22 toks/s, output: 10169.96 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1439/1920 [03:12<00:38, 12.43it/s, est. speed input: 1105.35 toks/s, output: 10174.01 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1441/1920 [03:12<01:12,  6.64it/s, est. speed input: 1102.90 toks/s, output: 10165.62 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1445/1920 [03:12<00:45, 10.55it/s, est. speed input: 1106.25 toks/s, output: 10180.40 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1447/1920 [03:13<00:49,  9.53it/s, est. speed input: 1105.81 toks/s, output: 10173.67 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1451/1920 [03:13<00:34, 13.67it/s, est. speed input: 1107.00 toks/s, output: 10183.77 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1454/1920 [03:13<00:39, 11.74it/s, est. speed input: 1106.70 toks/s, output: 10187.33 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1458/1920 [03:14<00:42, 10.82it/s, est. speed input: 1107.76 toks/s, output: 10187.24 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1460/1920 [03:14<00:41, 10.98it/s, est. speed input: 1109.54 toks/s, output: 10185.61 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1463/1920 [03:14<00:34, 13.08it/s, est. speed input: 1110.97 toks/s, output: 10201.72 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1465/1920 [03:14<00:33, 13.58it/s, est. speed input: 1111.53 toks/s, output: 10203.04 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1467/1920 [03:14<00:40, 11.23it/s, est. speed input: 1111.67 toks/s, output: 10209.25 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1469/1920 [03:15<00:49,  9.15it/s, est. speed input: 1111.29 toks/s, output: 10201.86 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1471/1920 [03:15<00:51,  8.77it/s, est. speed input: 1110.75 toks/s, output: 10201.92 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1473/1920 [03:15<00:53,  8.31it/s, est. speed input: 1110.54 toks/s, output: 10200.87 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1475/1920 [03:15<00:55,  8.01it/s, est. speed input: 1111.16 toks/s, output: 10199.56 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1476/1920 [03:16<01:13,  6.02it/s, est. speed input: 1110.36 toks/s, output: 10184.77 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1477/1920 [03:16<01:17,  5.74it/s, est. speed input: 1109.65 toks/s, output: 10178.82 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1480/1920 [03:16<00:50,  8.72it/s, est. speed input: 1110.08 toks/s, output: 10193.73 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1482/1920 [03:16<01:01,  7.14it/s, est. speed input: 1109.02 toks/s, output: 10204.40 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1484/1920 [03:17<00:51,  8.54it/s, est. speed input: 1110.27 toks/s, output: 10218.20 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1486/1920 [03:17<00:58,  7.38it/s, est. speed input: 1110.42 toks/s, output: 10219.86 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1487/1920 [03:17<01:27,  4.97it/s, est. speed input: 1108.00 toks/s, output: 10197.05 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1488/1920 [03:18<01:49,  3.96it/s, est. speed input: 1106.07 toks/s, output: 10183.06 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1490/1920 [03:18<01:22,  5.22it/s, est. speed input: 1106.44 toks/s, output: 10187.25 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1491/1920 [03:18<01:25,  5.00it/s, est. speed input: 1106.30 toks/s, output: 10189.38 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1493/1920 [03:19<01:13,  5.79it/s, est. speed input: 1107.24 toks/s, output: 10191.88 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1495/1920 [03:19<01:00,  7.02it/s, est. speed input: 1107.50 toks/s, output: 10197.84 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1497/1920 [03:19<01:19,  5.30it/s, est. speed input: 1105.99 toks/s, output: 10189.83 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1498/1920 [03:20<01:54,  3.68it/s, est. speed input: 1103.98 toks/s, output: 10162.79 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1501/1920 [03:20<01:13,  5.66it/s, est. speed input: 1105.35 toks/s, output: 10182.64 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1503/1920 [03:20<00:58,  7.15it/s, est. speed input: 1106.45 toks/s, output: 10199.36 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1505/1920 [03:20<00:49,  8.30it/s, est. speed input: 1107.68 toks/s, output: 10204.35 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1507/1920 [03:20<00:41,  9.94it/s, est. speed input: 1108.99 toks/s, output: 10221.64 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1509/1920 [03:21<00:43,  9.44it/s, est. speed input: 1109.02 toks/s, output: 10223.60 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1511/1920 [03:21<00:53,  7.65it/s, est. speed input: 1108.19 toks/s, output: 10228.23 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1513/1920 [03:21<00:51,  7.92it/s, est. speed input: 1108.60 toks/s, output: 10227.39 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1516/1920 [03:21<00:39, 10.34it/s, est. speed input: 1110.48 toks/s, output: 10238.97 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1518/1920 [03:22<00:35, 11.37it/s, est. speed input: 1111.14 toks/s, output: 10240.80 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1520/1920 [03:22<00:31, 12.73it/s, est. speed input: 1111.88 toks/s, output: 10255.68 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1522/1920 [03:22<00:36, 10.84it/s, est. speed input: 1111.80 toks/s, output: 10260.15 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1524/1920 [03:22<00:49,  7.94it/s, est. speed input: 1110.80 toks/s, output: 10269.34 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1528/1920 [03:23<00:34, 11.32it/s, est. speed input: 1112.78 toks/s, output: 10288.60 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1530/1920 [03:23<00:34, 11.42it/s, est. speed input: 1113.25 toks/s, output: 10295.07 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1532/1920 [03:23<00:39,  9.73it/s, est. speed input: 1113.31 toks/s, output: 10291.32 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1534/1920 [03:23<00:43,  8.92it/s, est. speed input: 1113.79 toks/s, output: 10288.34 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1536/1920 [03:23<00:42,  9.06it/s, est. speed input: 1113.74 toks/s, output: 10292.40 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1538/1920 [03:24<00:38,  9.98it/s, est. speed input: 1114.84 toks/s, output: 10305.46 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1541/1920 [03:24<00:29, 12.93it/s, est. speed input: 1116.40 toks/s, output: 10337.15 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1543/1920 [03:24<00:31, 11.94it/s, est. speed input: 1116.26 toks/s, output: 10336.53 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1545/1920 [03:24<00:29, 12.57it/s, est. speed input: 1117.41 toks/s, output: 10336.34 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1547/1920 [03:24<00:38,  9.59it/s, est. speed input: 1117.92 toks/s, output: 10340.18 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1549/1920 [03:25<01:07,  5.50it/s, est. speed input: 1115.17 toks/s, output: 10325.39 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1550/1920 [03:25<01:06,  5.57it/s, est. speed input: 1114.92 toks/s, output: 10331.88 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1552/1920 [03:25<00:52,  7.07it/s, est. speed input: 1115.54 toks/s, output: 10336.87 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1554/1920 [03:26<00:46,  7.90it/s, est. speed input: 1116.05 toks/s, output: 10340.31 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1556/1920 [03:26<00:40,  9.09it/s, est. speed input: 1116.36 toks/s, output: 10354.70 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1558/1920 [03:26<00:33, 10.81it/s, est. speed input: 1116.76 toks/s, output: 10371.13 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1560/1920 [03:26<00:47,  7.62it/s, est. speed input: 1115.55 toks/s, output: 10366.75 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1562/1920 [03:26<00:38,  9.30it/s, est. speed input: 1116.06 toks/s, output: 10381.87 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1564/1920 [03:27<00:32, 11.00it/s, est. speed input: 1116.99 toks/s, output: 10384.70 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1566/1920 [03:27<00:29, 12.10it/s, est. speed input: 1117.23 toks/s, output: 10396.16 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1568/1920 [03:27<00:29, 12.02it/s, est. speed input: 1117.67 toks/s, output: 10405.93 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1570/1920 [03:27<00:43,  8.08it/s, est. speed input: 1116.76 toks/s, output: 10389.17 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1573/1920 [03:27<00:31, 10.86it/s, est. speed input: 1117.75 toks/s, output: 10403.90 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1577/1920 [03:28<00:25, 13.27it/s, est. speed input: 1119.62 toks/s, output: 10429.34 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1579/1920 [03:28<00:34,  9.84it/s, est. speed input: 1119.00 toks/s, output: 10432.81 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1581/1920 [03:28<00:32, 10.57it/s, est. speed input: 1119.43 toks/s, output: 10454.89 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1583/1920 [03:28<00:29, 11.59it/s, est. speed input: 1119.87 toks/s, output: 10471.60 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1585/1920 [03:28<00:29, 11.34it/s, est. speed input: 1120.30 toks/s, output: 10467.83 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1588/1920 [03:29<00:22, 14.54it/s, est. speed input: 1121.00 toks/s, output: 10472.77 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1590/1920 [03:29<00:28, 11.60it/s, est. speed input: 1120.70 toks/s, output: 10470.68 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1592/1920 [03:29<00:28, 11.31it/s, est. speed input: 1121.00 toks/s, output: 10490.58 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1594/1920 [03:29<00:34,  9.55it/s, est. speed input: 1120.59 toks/s, output: 10485.99 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1597/1920 [03:30<00:37,  8.53it/s, est. speed input: 1119.97 toks/s, output: 10489.03 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1599/1920 [03:30<00:41,  7.68it/s, est. speed input: 1118.84 toks/s, output: 10501.64 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1603/1920 [03:30<00:27, 11.68it/s, est. speed input: 1120.93 toks/s, output: 10515.88 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1605/1920 [03:31<00:32,  9.80it/s, est. speed input: 1120.53 toks/s, output: 10506.75 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1607/1920 [03:31<00:57,  5.46it/s, est. speed input: 1117.14 toks/s, output: 10478.20 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1609/1920 [03:32<00:59,  5.20it/s, est. speed input: 1116.73 toks/s, output: 10467.44 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1611/1920 [03:32<00:58,  5.24it/s, est. speed input: 1116.65 toks/s, output: 10461.66 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1612/1920 [03:33<01:06,  4.60it/s, est. speed input: 1115.30 toks/s, output: 10446.72 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1614/1920 [03:33<00:55,  5.50it/s, est. speed input: 1116.01 toks/s, output: 10451.17 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1616/1920 [03:33<00:46,  6.60it/s, est. speed input: 1115.80 toks/s, output: 10451.96 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1619/1920 [03:33<00:34,  8.81it/s, est. speed input: 1116.89 toks/s, output: 10467.82 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1621/1920 [03:33<00:33,  8.99it/s, est. speed input: 1116.93 toks/s, output: 10467.60 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1624/1920 [03:34<00:40,  7.27it/s, est. speed input: 1116.45 toks/s, output: 10469.80 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1625/1920 [03:34<00:41,  7.04it/s, est. speed input: 1115.97 toks/s, output: 10466.17 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1627/1920 [03:34<00:33,  8.67it/s, est. speed input: 1117.16 toks/s, output: 10468.37 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1629/1920 [03:34<00:29,  9.72it/s, est. speed input: 1118.25 toks/s, output: 10479.43 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1631/1920 [03:35<00:40,  7.08it/s, est. speed input: 1117.24 toks/s, output: 10467.44 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1632/1920 [03:35<00:43,  6.68it/s, est. speed input: 1117.43 toks/s, output: 10466.28 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1634/1920 [03:35<00:36,  7.83it/s, est. speed input: 1117.85 toks/s, output: 10466.47 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1635/1920 [03:36<01:11,  3.97it/s, est. speed input: 1115.12 toks/s, output: 10432.63 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1636/1920 [03:36<01:10,  4.04it/s, est. speed input: 1114.62 toks/s, output: 10425.83 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1637/1920 [03:36<01:06,  4.28it/s, est. speed input: 1114.28 toks/s, output: 10425.76 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1638/1920 [03:37<01:22,  3.44it/s, est. speed input: 1112.55 toks/s, output: 10412.68 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1640/1920 [03:37<01:08,  4.11it/s, est. speed input: 1111.57 toks/s, output: 10403.55 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1641/1920 [03:37<01:07,  4.15it/s, est. speed input: 1111.52 toks/s, output: 10399.21 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1644/1920 [03:38<00:54,  5.05it/s, est. speed input: 1110.60 toks/s, output: 10392.08 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1645/1920 [03:38<00:55,  4.96it/s, est. speed input: 1109.95 toks/s, output: 10384.90 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1646/1920 [03:38<00:49,  5.52it/s, est. speed input: 1109.97 toks/s, output: 10386.26 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1648/1920 [03:38<00:38,  7.10it/s, est. speed input: 1110.63 toks/s, output: 10390.65 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1649/1920 [03:38<00:37,  7.24it/s, est. speed input: 1110.55 toks/s, output: 10397.43 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1650/1920 [03:39<00:37,  7.12it/s, est. speed input: 1110.23 toks/s, output: 10404.40 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1651/1920 [03:39<00:43,  6.12it/s, est. speed input: 1110.19 toks/s, output: 10400.74 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1653/1920 [03:39<00:44,  6.04it/s, est. speed input: 1110.09 toks/s, output: 10395.05 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1655/1920 [03:39<00:40,  6.59it/s, est. speed input: 1110.00 toks/s, output: 10392.62 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1656/1920 [03:40<00:42,  6.25it/s, est. speed input: 1109.41 toks/s, output: 10397.59 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1657/1920 [03:40<00:52,  4.99it/s, est. speed input: 1108.95 toks/s, output: 10385.98 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1659/1920 [03:40<00:45,  5.69it/s, est. speed input: 1108.24 toks/s, output: 10389.95 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1660/1920 [03:40<00:45,  5.74it/s, est. speed input: 1107.91 toks/s, output: 10387.34 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1662/1920 [03:40<00:32,  7.82it/s, est. speed input: 1109.77 toks/s, output: 10398.25 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1663/1920 [03:41<00:32,  7.82it/s, est. speed input: 1109.62 toks/s, output: 10398.81 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1665/1920 [03:41<00:45,  5.57it/s, est. speed input: 1108.81 toks/s, output: 10391.75 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1667/1920 [03:41<00:39,  6.38it/s, est. speed input: 1108.68 toks/s, output: 10398.18 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1668/1920 [03:42<00:57,  4.38it/s, est. speed input: 1106.54 toks/s, output: 10377.49 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1671/1920 [03:42<00:35,  7.05it/s, est. speed input: 1107.31 toks/s, output: 10387.29 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1673/1920 [03:42<00:36,  6.85it/s, est. speed input: 1108.24 toks/s, output: 10379.93 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1674/1920 [03:42<00:34,  7.03it/s, est. speed input: 1108.17 toks/s, output: 10383.18 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1676/1920 [03:43<00:30,  7.96it/s, est. speed input: 1108.71 toks/s, output: 10394.73 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1677/1920 [03:43<00:30,  7.98it/s, est. speed input: 1108.40 toks/s, output: 10392.49 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1679/1920 [03:43<00:27,  8.80it/s, est. speed input: 1109.35 toks/s, output: 10397.25 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1681/1920 [03:43<00:22, 10.79it/s, est. speed input: 1110.16 toks/s, output: 10419.25 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1684/1920 [03:43<00:16, 14.07it/s, est. speed input: 1110.98 toks/s, output: 10441.66 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1687/1920 [03:43<00:13, 17.47it/s, est. speed input: 1113.57 toks/s, output: 10446.83 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1690/1920 [03:44<00:20, 11.18it/s, est. speed input: 1113.40 toks/s, output: 10432.37 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1692/1920 [03:44<00:25,  9.09it/s, est. speed input: 1112.59 toks/s, output: 10427.34 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1694/1920 [03:44<00:21, 10.58it/s, est. speed input: 1113.12 toks/s, output: 10443.38 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1696/1920 [03:44<00:18, 12.11it/s, est. speed input: 1114.36 toks/s, output: 10448.58 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1698/1920 [03:44<00:18, 11.77it/s, est. speed input: 1114.18 toks/s, output: 10446.31 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1700/1920 [03:45<00:26,  8.24it/s, est. speed input: 1112.99 toks/s, output: 10442.69 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1703/1920 [03:45<00:20, 10.74it/s, est. speed input: 1113.89 toks/s, output: 10460.10 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1707/1920 [03:45<00:14, 14.53it/s, est. speed input: 1114.96 toks/s, output: 10493.52 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1712/1920 [03:45<00:12, 17.23it/s, est. speed input: 1116.65 toks/s, output: 10499.98 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1714/1920 [03:45<00:13, 15.59it/s, est. speed input: 1117.15 toks/s, output: 10508.83 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1716/1920 [03:46<00:12, 15.83it/s, est. speed input: 1117.94 toks/s, output: 10526.49 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1721/1920 [03:46<00:10, 19.61it/s, est. speed input: 1119.47 toks/s, output: 10557.61 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1724/1920 [03:46<00:14, 13.68it/s, est. speed input: 1119.89 toks/s, output: 10558.15 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1727/1920 [03:46<00:12, 15.75it/s, est. speed input: 1120.67 toks/s, output: 10567.19 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1729/1920 [03:47<00:14, 12.97it/s, est. speed input: 1121.14 toks/s, output: 10568.42 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1731/1920 [03:47<00:15, 12.58it/s, est. speed input: 1121.33 toks/s, output: 10572.85 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1733/1920 [03:47<00:15, 11.94it/s, est. speed input: 1121.51 toks/s, output: 10571.84 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1736/1920 [03:47<00:13, 13.39it/s, est. speed input: 1122.60 toks/s, output: 10575.55 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1738/1920 [03:47<00:14, 12.88it/s, est. speed input: 1122.97 toks/s, output: 10573.15 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1740/1920 [03:48<00:16, 11.13it/s, est. speed input: 1123.86 toks/s, output: 10571.08 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1742/1920 [03:48<00:20,  8.50it/s, est. speed input: 1123.46 toks/s, output: 10561.31 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1744/1920 [03:48<00:19,  9.20it/s, est. speed input: 1124.31 toks/s, output: 10563.00 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1746/1920 [03:48<00:16, 10.64it/s, est. speed input: 1124.57 toks/s, output: 10566.20 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1748/1920 [03:49<00:22,  7.70it/s, est. speed input: 1123.49 toks/s, output: 10564.72 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1750/1920 [03:49<00:18,  8.98it/s, est. speed input: 1124.89 toks/s, output: 10567.28 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1752/1920 [03:49<00:27,  6.13it/s, est. speed input: 1124.27 toks/s, output: 10547.71 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1753/1920 [03:49<00:25,  6.47it/s, est. speed input: 1124.39 toks/s, output: 10554.04 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1755/1920 [03:50<00:22,  7.42it/s, est. speed input: 1124.91 toks/s, output: 10557.05 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1756/1920 [03:50<00:22,  7.25it/s, est. speed input: 1124.69 toks/s, output: 10554.33 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1758/1920 [03:50<00:19,  8.11it/s, est. speed input: 1125.17 toks/s, output: 10565.02 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1762/1920 [03:50<00:12, 12.45it/s, est. speed input: 1128.31 toks/s, output: 10579.48 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1764/1920 [03:50<00:12, 12.24it/s, est. speed input: 1128.46 toks/s, output: 10598.27 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1766/1920 [03:51<00:13, 11.44it/s, est. speed input: 1128.53 toks/s, output: 10599.96 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1769/1920 [03:51<00:10, 14.01it/s, est. speed input: 1130.16 toks/s, output: 10626.64 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1771/1920 [03:51<00:12, 11.85it/s, est. speed input: 1130.69 toks/s, output: 10635.24 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1773/1920 [03:51<00:13, 11.20it/s, est. speed input: 1131.35 toks/s, output: 10636.55 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1775/1920 [03:51<00:12, 11.75it/s, est. speed input: 1132.00 toks/s, output: 10646.55 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1777/1920 [03:52<00:15,  9.47it/s, est. speed input: 1131.54 toks/s, output: 10654.03 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1779/1920 [03:52<00:18,  7.48it/s, est. speed input: 1130.81 toks/s, output: 10651.47 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1781/1920 [03:52<00:22,  6.17it/s, est. speed input: 1129.74 toks/s, output: 10642.25 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1782/1920 [03:53<00:30,  4.49it/s, est. speed input: 1128.33 toks/s, output: 10623.82 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1784/1920 [03:53<00:23,  5.87it/s, est. speed input: 1128.82 toks/s, output: 10631.78 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1785/1920 [03:53<00:22,  6.03it/s, est. speed input: 1128.63 toks/s, output: 10629.58 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1787/1920 [03:53<00:17,  7.51it/s, est. speed input: 1130.20 toks/s, output: 10638.85 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1788/1920 [03:54<00:22,  5.81it/s, est. speed input: 1129.13 toks/s, output: 10634.69 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1790/1920 [03:54<00:22,  5.80it/s, est. speed input: 1128.92 toks/s, output: 10634.76 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1792/1920 [03:54<00:19,  6.64it/s, est. speed input: 1129.52 toks/s, output: 10641.43 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1794/1920 [03:54<00:15,  8.40it/s, est. speed input: 1130.64 toks/s, output: 10652.96 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1796/1920 [03:55<00:15,  8.21it/s, est. speed input: 1131.35 toks/s, output: 10667.53 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1798/1920 [03:55<00:18,  6.44it/s, est. speed input: 1130.17 toks/s, output: 10662.47 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1800/1920 [03:55<00:18,  6.36it/s, est. speed input: 1129.72 toks/s, output: 10664.41 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1801/1920 [03:56<00:18,  6.60it/s, est. speed input: 1129.67 toks/s, output: 10666.36 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1803/1920 [03:56<00:15,  7.67it/s, est. speed input: 1129.72 toks/s, output: 10684.28 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1807/1920 [03:56<00:08, 12.59it/s, est. speed input: 1131.14 toks/s, output: 10724.64 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1809/1920 [03:56<00:09, 11.54it/s, est. speed input: 1131.07 toks/s, output: 10733.30 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1811/1920 [03:56<00:08, 12.46it/s, est. speed input: 1131.55 toks/s, output: 10738.82 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1813/1920 [03:56<00:10,  9.75it/s, est. speed input: 1131.14 toks/s, output: 10740.66 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1815/1920 [03:57<00:12,  8.44it/s, est. speed input: 1130.68 toks/s, output: 10742.72 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1817/1920 [03:57<00:15,  6.67it/s, est. speed input: 1129.53 toks/s, output: 10739.67 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1820/1920 [03:58<00:15,  6.65it/s, est. speed input: 1129.39 toks/s, output: 10742.24 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1822/1920 [03:58<00:13,  7.12it/s, est. speed input: 1129.27 toks/s, output: 10752.88 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1823/1920 [03:58<00:13,  6.99it/s, est. speed input: 1129.08 toks/s, output: 10754.01 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1824/1920 [03:58<00:17,  5.43it/s, est. speed input: 1128.02 toks/s, output: 10747.89 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1825/1920 [03:59<00:25,  3.71it/s, est. speed input: 1125.74 toks/s, output: 10726.89 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1826/1920 [03:59<00:21,  4.33it/s, est. speed input: 1125.77 toks/s, output: 10726.56 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1827/1920 [04:00<00:36,  2.53it/s, est. speed input: 1122.05 toks/s, output: 10690.96 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1828/1920 [04:00<00:31,  2.89it/s, est. speed input: 1121.65 toks/s, output: 10689.17 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1830/1920 [04:00<00:21,  4.26it/s, est. speed input: 1121.99 toks/s, output: 10694.94 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1832/1920 [04:01<00:18,  4.68it/s, est. speed input: 1121.40 toks/s, output: 10695.97 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1833/1920 [04:01<00:18,  4.64it/s, est. speed input: 1121.32 toks/s, output: 10694.45 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1834/1920 [04:01<00:20,  4.22it/s, est. speed input: 1120.93 toks/s, output: 10693.59 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1835/1920 [04:01<00:19,  4.38it/s, est. speed input: 1120.64 toks/s, output: 10689.69 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1836/1920 [04:02<00:22,  3.82it/s, est. speed input: 1120.03 toks/s, output: 10686.66 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1837/1920 [04:02<00:23,  3.59it/s, est. speed input: 1119.25 toks/s, output: 10682.64 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1839/1920 [04:02<00:15,  5.37it/s, est. speed input: 1119.65 toks/s, output: 10691.74 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1840/1920 [04:03<00:17,  4.67it/s, est. speed input: 1119.19 toks/s, output: 10687.03 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1841/1920 [04:03<00:20,  3.87it/s, est. speed input: 1117.92 toks/s, output: 10680.89 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1842/1920 [04:03<00:21,  3.70it/s, est. speed input: 1117.18 toks/s, output: 10672.97 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1843/1920 [04:03<00:19,  4.05it/s, est. speed input: 1116.82 toks/s, output: 10677.45 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1844/1920 [04:04<00:27,  2.76it/s, est. speed input: 1114.75 toks/s, output: 10657.64 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1845/1920 [04:05<00:32,  2.34it/s, est. speed input: 1112.59 toks/s, output: 10637.51 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1846/1920 [04:05<00:34,  2.13it/s, est. speed input: 1110.32 toks/s, output: 10625.12 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1848/1920 [04:06<00:23,  3.01it/s, est. speed input: 1110.41 toks/s, output: 10629.13 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1850/1920 [04:06<00:17,  4.04it/s, est. speed input: 1110.03 toks/s, output: 10643.99 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1853/1920 [04:06<00:10,  6.57it/s, est. speed input: 1110.76 toks/s, output: 10663.91 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1855/1920 [04:06<00:11,  5.45it/s, est. speed input: 1110.11 toks/s, output: 10660.36 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1857/1920 [04:07<00:12,  5.13it/s, est. speed input: 1109.66 toks/s, output: 10663.50 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1858/1920 [04:07<00:11,  5.17it/s, est. speed input: 1109.83 toks/s, output: 10667.75 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1859/1920 [04:08<00:21,  2.87it/s, est. speed input: 1106.56 toks/s, output: 10634.78 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1860/1920 [04:08<00:20,  2.90it/s, est. speed input: 1105.57 toks/s, output: 10632.39 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1861/1920 [04:09<00:22,  2.63it/s, est. speed input: 1103.93 toks/s, output: 10622.03 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1862/1920 [04:09<00:19,  3.00it/s, est. speed input: 1103.54 toks/s, output: 10625.70 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1863/1920 [04:10<00:31,  1.84it/s, est. speed input: 1099.10 toks/s, output: 10586.31 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1864/1920 [04:10<00:26,  2.14it/s, est. speed input: 1098.37 toks/s, output: 10581.67 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1867/1920 [04:11<00:14,  3.65it/s, est. speed input: 1098.83 toks/s, output: 10594.01 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1868/1920 [04:12<00:23,  2.21it/s, est. speed input: 1094.34 toks/s, output: 10552.94 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1869/1920 [04:12<00:20,  2.46it/s, est. speed input: 1093.51 toks/s, output: 10554.84 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1870/1920 [04:12<00:17,  2.81it/s, est. speed input: 1093.32 toks/s, output: 10558.58 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1871/1920 [04:13<00:17,  2.79it/s, est. speed input: 1092.42 toks/s, output: 10555.46 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1872/1920 [04:14<00:22,  2.14it/s, est. speed input: 1089.70 toks/s, output: 10535.94 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1873/1920 [04:14<00:17,  2.64it/s, est. speed input: 1089.38 toks/s, output: 10541.72 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1874/1920 [04:15<00:26,  1.70it/s, est. speed input: 1085.07 toks/s, output: 10506.51 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1875/1920 [04:16<00:28,  1.59it/s, est. speed input: 1082.43 toks/s, output: 10488.64 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1876/1920 [04:16<00:21,  2.03it/s, est. speed input: 1082.17 toks/s, output: 10493.74 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1877/1920 [04:16<00:21,  2.02it/s, est. speed input: 1080.54 toks/s, output: 10481.01 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1878/1920 [04:17<00:20,  2.06it/s, est. speed input: 1079.08 toks/s, output: 10474.05 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1879/1920 [04:17<00:16,  2.43it/s, est. speed input: 1078.59 toks/s, output: 10472.51 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1881/1920 [04:17<00:09,  4.00it/s, est. speed input: 1079.06 toks/s, output: 10491.43 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1882/1920 [04:19<00:21,  1.78it/s, est. speed input: 1073.13 toks/s, output: 10440.97 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1883/1920 [04:19<00:17,  2.17it/s, est. speed input: 1072.76 toks/s, output: 10444.46 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1884/1920 [04:19<00:14,  2.42it/s, est. speed input: 1072.61 toks/s, output: 10444.72 toks/s][A[2025-09-23 15:17:57] ‚è≠ Ë∑≥ËøáÔºöB_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B__global_step_200Ôºàg1/g2 ÂÖ®ÈÉ®Â∑≤Êúâ metricsÔºâ
[2025-09-23 15:17:57] ‚è≠ Ë∑≥ËøáÔºöB_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B__global_step_313Ôºàg1/g2 ÂÖ®ÈÉ®Â∑≤Êúâ metricsÔºâ
[2025-09-23 15:17:57] ‚è≠ Ë∑≥ËøáÔºöB_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B__global_step_100Ôºàg1/g2 ÂÖ®ÈÉ®Â∑≤Êúâ metricsÔºâ

Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1885/1920 [04:20<00:16,  2.18it/s, est. speed input: 1070.63 toks/s, output: 10432.98 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1886/1920 [04:20<00:15,  2.18it/s, est. speed input: 1069.24 toks/s, output: 10426.25 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1887/1920 [04:20<00:12,  2.71it/s, est. speed input: 1069.16 toks/s, output: 10432.22 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1888/1920 [04:21<00:13,  2.31it/s, est. speed input: 1067.16 toks/s, output: 10420.45 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1892/1920 [04:21<00:05,  5.27it/s, est. speed input: 1068.62 toks/s, output: 10457.84 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1894/1920 [04:22<00:06,  3.93it/s, est. speed input: 1066.34 toks/s, output: 10449.45 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1897/1920 [04:22<00:04,  5.35it/s, est. speed input: 1066.57 toks/s, output: 10474.38 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1898/1920 [04:22<00:03,  5.72it/s, est. speed input: 1066.64 toks/s, output: 10481.66 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1899/1920 [04:23<00:06,  3.38it/s, est. speed input: 1063.81 toks/s, output: 10460.38 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1900/1920 [04:23<00:06,  3.29it/s, est. speed input: 1062.71 toks/s, output: 10458.80 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1901/1920 [04:24<00:06,  2.88it/s, est. speed input: 1061.07 toks/s, output: 10450.86 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1903/1920 [04:24<00:05,  3.36it/s, est. speed input: 1060.47 toks/s, output: 10456.54 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1904/1920 [04:24<00:04,  3.60it/s, est. speed input: 1060.47 toks/s, output: 10460.01 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1906/1920 [04:25<00:04,  2.83it/s, est. speed input: 1058.47 toks/s, output: 10445.96 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1907/1920 [04:26<00:04,  3.12it/s, est. speed input: 1058.61 toks/s, output: 10449.56 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1908/1920 [04:28<00:09,  1.32it/s, est. speed input: 1050.38 toks/s, output: 10376.02 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1910/1920 [04:29<00:06,  1.55it/s, est. speed input: 1047.43 toks/s, output: 10361.80 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1911/1920 [04:30<00:07,  1.19it/s, est. speed input: 1041.83 toks/s, output: 10314.74 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1913/1920 [04:30<00:03,  1.86it/s, est. speed input: 1043.19 toks/s, output: 10332.72 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1914/1920 [04:31<00:03,  1.84it/s, est. speed input: 1041.93 toks/s, output: 10322.49 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1915/1920 [04:31<00:02,  2.20it/s, est. speed input: 1042.20 toks/s, output: 10327.37 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1916/1920 [04:32<00:01,  2.17it/s, est. speed input: 1041.30 toks/s, output: 10320.69 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1917/1920 [04:34<00:02,  1.04it/s, est. speed input: 1032.84 toks/s, output: 10244.10 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1918/1920 [04:34<00:01,  1.34it/s, est. speed input: 1032.50 toks/s, output: 10247.96 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1919/1920 [04:34<00:00,  1.74it/s, est. speed input: 1032.40 toks/s, output: 10254.17 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1920/1920 [04:36<00:00,  1.27it/s, est. speed input: 1027.87 toks/s, output: 10216.37 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1920/1920 [04:36<00:00,  6.96it/s, est. speed input: 1027.87 toks/s, output: 10216.37 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/1920 [00:00<?, ?it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1920/1920 [00:00<00:00, 30970.70it/s]
{'num_samples': 240, 'num_scores': 1920, 'timeout_samples': 0, 'empty_samples': 0, 'acc': 4.6, 'total_acc': 4.479166666666667, 'pass_at_k_percent': {'1': 4.5, '8': 18.3}, 'pass_at_k_valid_counts': {'1': 240, '8': 240}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_noise_rlvr_1_5b_128batchsize_deepscaler_noise_robust_qwen25-math-cot/base__Qwen2.5-math-1.5B/g1/aime25x8/test_qwen25-math-cot_-1_seed0_t0.6_s0_e-1.jsonl
[2025-09-23 15:18:20] ‚úì base__Qwen2.5-math-1.5B/g1/aime25x8  acc=4.6 pass_at_k={'1': 4.5, '8': 18.3}
base__Qwen2.5-math-1.5B/g1:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [04:44<09:28, 284.26s/ds]==================================================
data: amc23x8  ,remain samples: 320
{'idx': 0, 'id': 0, 'problem': 'Cities $A$ and $B$ are $45$ miles apart. Alicia lives in $A$ and Beth lives in $B$. Alicia bikes towards $B$ at 18 miles per hour. Leaving at the same time, Beth bikes toward $A$ at 12 miles per hour. How many miles from City $A$ will they be when they meet?', 'answer': 27.0, 'url': 'https://artofproblemsolving.com/wiki/index.php/2023_AMC_12A_Problems/Problem_1', 'question': 'Cities $A$ and $B$ are $45$ miles apart. Alicia lives in $A$ and Beth lives in $B$. Alicia bikes towards $B$ at 18 miles per hour. Leaving at the same time, Beth bikes toward $A$ at 12 miles per hour. How many miles from City $A$ will they be when they meet?'}

  0%|          | 0/320 [00:00<?, ?it/s][A<|im_start|>system
Please reason step by step, and put your final answer within \boxed{{}}.<|im_end|>
<|im_start|>user
Cities $A$ and $B$ are $45$ miles apart. Alicia lives in $A$ and Beth lives in $B$. Alicia bikes towards $B$ at 18 miles per hour. Leaving at the same time, Beth bikes toward $A$ at 12 miles per hour. How many miles from City $A$ will they be when they meet?<|im_end|>
<|im_start|>assistant


 12%|‚ñà‚ñè        | 37/320 [00:00<00:00, 362.49it/s][A
 24%|‚ñà‚ñà‚ñç       | 76/320 [00:00<00:00, 373.17it/s][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 114/320 [00:00<00:00, 371.01it/s][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 152/320 [00:00<00:00, 372.49it/s][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 191/320 [00:00<00:00, 375.34it/s][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 229/320 [00:00<00:00, 374.57it/s][A
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 267/320 [00:00<00:00, 376.23it/s][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 306/320 [00:00<00:00, 378.29it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 320/320 [00:00<00:00, 375.44it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/2560 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 3/2560 [00:02<34:11,  1.25it/s, est. speed input: 95.55 toks/s, output: 70.63 toks/s][A
Processed prompts:   0%|          | 4/2560 [00:02<29:30,  1.44it/s, est. speed input: 165.51 toks/s, output: 66.90 toks/s][A
Processed prompts:   0%|          | 5/2560 [00:03<33:36,  1.27it/s, est. speed input: 148.90 toks/s, output: 101.08 toks/s][A
Processed prompts:   0%|          | 6/2560 [00:04<34:26,  1.24it/s, est. speed input: 135.78 toks/s, output: 133.44 toks/s][A
Processed prompts:   0%|          | 7/2560 [00:05<39:11,  1.09it/s, est. speed input: 128.08 toks/s, output: 156.92 toks/s][A
Processed prompts:   0%|          | 8/2560 [00:06<30:43,  1.38it/s, est. speed input: 135.79 toks/s, output: 200.84 toks/s][A
Processed prompts:   0%|          | 9/2560 [00:06<23:30,  1.81it/s, est. speed input: 140.15 toks/s, output: 245.85 toks/s][A
Processed prompts:   0%|          | 10/2560 [00:06<21:11,  2.00it/s, est. speed input: 139.80 toks/s, output: 282.27 toks/s][A
Processed prompts:   0%|          | 11/2560 [00:06<16:56,  2.51it/s, est. speed input: 154.89 toks/s, output: 325.49 toks/s][A
Processed prompts:   0%|          | 12/2560 [00:07<14:28,  2.93it/s, est. speed input: 166.46 toks/s, output: 365.70 toks/s][A
Processed prompts:   1%|          | 13/2560 [00:07<11:57,  3.55it/s, est. speed input: 188.48 toks/s, output: 408.54 toks/s][A
Processed prompts:   1%|          | 14/2560 [00:07<09:40,  4.39it/s, est. speed input: 194.72 toks/s, output: 452.51 toks/s][A
Processed prompts:   1%|          | 18/2560 [00:07<04:21,  9.70it/s, est. speed input: 253.46 toks/s, output: 643.25 toks/s][A
Processed prompts:   1%|          | 20/2560 [00:07<04:05, 10.34it/s, est. speed input: 269.50 toks/s, output: 728.88 toks/s][A
Processed prompts:   1%|          | 22/2560 [00:07<04:26,  9.52it/s, est. speed input: 291.17 toks/s, output: 804.65 toks/s][A
Processed prompts:   1%|          | 24/2560 [00:07<03:53, 10.86it/s, est. speed input: 324.19 toks/s, output: 891.90 toks/s][A
Processed prompts:   1%|          | 26/2560 [00:08<03:46, 11.20it/s, est. speed input: 341.65 toks/s, output: 973.28 toks/s][A
Processed prompts:   1%|          | 28/2560 [00:08<03:32, 11.89it/s, est. speed input: 367.65 toks/s, output: 1055.68 toks/s][A
Processed prompts:   1%|          | 30/2560 [00:08<03:31, 11.95it/s, est. speed input: 388.24 toks/s, output: 1134.09 toks/s][A
Processed prompts:   1%|‚ñè         | 32/2560 [00:08<05:21,  7.87it/s, est. speed input: 395.02 toks/s, output: 1174.61 toks/s][A
Processed prompts:   1%|‚ñè         | 34/2560 [00:09<04:39,  9.04it/s, est. speed input: 413.20 toks/s, output: 1254.82 toks/s][A
Processed prompts:   1%|‚ñè         | 36/2560 [00:09<03:54, 10.79it/s, est. speed input: 431.62 toks/s, output: 1340.27 toks/s][A
Processed prompts:   1%|‚ñè         | 38/2560 [00:09<03:39, 11.49it/s, est. speed input: 455.51 toks/s, output: 1418.53 toks/s][A
Processed prompts:   2%|‚ñè         | 40/2560 [00:09<04:47,  8.76it/s, est. speed input: 458.86 toks/s, output: 1463.59 toks/s][A
Processed prompts:   2%|‚ñè         | 42/2560 [00:09<04:47,  8.76it/s, est. speed input: 470.93 toks/s, output: 1529.36 toks/s][A
Processed prompts:   2%|‚ñè         | 45/2560 [00:10<03:55, 10.68it/s, est. speed input: 493.13 toks/s, output: 1648.48 toks/s][A
Processed prompts:   2%|‚ñè         | 48/2560 [00:10<03:01, 13.86it/s, est. speed input: 526.95 toks/s, output: 1780.10 toks/s][A
Processed prompts:   2%|‚ñè         | 53/2560 [00:10<02:15, 18.50it/s, est. speed input: 567.30 toks/s, output: 1996.62 toks/s][A
Processed prompts:   2%|‚ñè         | 56/2560 [00:10<02:21, 17.75it/s, est. speed input: 591.27 toks/s, output: 2108.91 toks/s][A
Processed prompts:   2%|‚ñè         | 58/2560 [00:10<02:18, 18.10it/s, est. speed input: 607.21 toks/s, output: 2187.54 toks/s][A
Processed prompts:   2%|‚ñè         | 60/2560 [00:10<02:33, 16.24it/s, est. speed input: 629.15 toks/s, output: 2252.70 toks/s][A
Processed prompts:   2%|‚ñè         | 63/2560 [00:10<02:22, 17.53it/s, est. speed input: 642.27 toks/s, output: 2370.42 toks/s][A
Processed prompts:   3%|‚ñé         | 65/2560 [00:11<02:37, 15.83it/s, est. speed input: 648.03 toks/s, output: 2399.23 toks/s][A
Processed prompts:   3%|‚ñé         | 67/2560 [00:11<02:36, 15.95it/s, est. speed input: 658.14 toks/s, output: 2471.51 toks/s][A
Processed prompts:   3%|‚ñé         | 69/2560 [00:11<02:57, 14.01it/s, est. speed input: 669.08 toks/s, output: 2528.90 toks/s][A
Processed prompts:   3%|‚ñé         | 71/2560 [00:11<03:49, 10.86it/s, est. speed input: 666.70 toks/s, output: 2564.16 toks/s][A
Processed prompts:   3%|‚ñé         | 73/2560 [00:11<03:42, 11.15it/s, est. speed input: 675.69 toks/s, output: 2626.72 toks/s][A
Processed prompts:   3%|‚ñé         | 75/2560 [00:12<04:10,  9.91it/s, est. speed input: 672.87 toks/s, output: 2638.84 toks/s][A
Processed prompts:   3%|‚ñé         | 77/2560 [00:12<03:57, 10.47it/s, est. speed input: 686.88 toks/s, output: 2701.42 toks/s][A
Processed prompts:   3%|‚ñé         | 79/2560 [00:12<03:56, 10.50it/s, est. speed input: 691.91 toks/s, output: 2758.85 toks/s][A
Processed prompts:   3%|‚ñé         | 81/2560 [00:12<03:31, 11.72it/s, est. speed input: 696.49 toks/s, output: 2830.19 toks/s][A
Processed prompts:   3%|‚ñé         | 83/2560 [00:12<04:39,  8.87it/s, est. speed input: 688.15 toks/s, output: 2849.93 toks/s][A
Processed prompts:   3%|‚ñé         | 85/2560 [00:13<05:27,  7.56it/s, est. speed input: 688.50 toks/s, output: 2871.77 toks/s][A
Processed prompts:   3%|‚ñé         | 88/2560 [00:13<03:52, 10.63it/s, est. speed input: 731.26 toks/s, output: 2996.92 toks/s][A
Processed prompts:   4%|‚ñé         | 91/2560 [00:13<03:05, 13.33it/s, est. speed input: 753.44 toks/s, output: 3116.71 toks/s][A
Processed prompts:   4%|‚ñé         | 93/2560 [00:13<02:50, 14.50it/s, est. speed input: 765.74 toks/s, output: 3191.54 toks/s][A
Processed prompts:   4%|‚ñé         | 95/2560 [00:13<03:54, 10.50it/s, est. speed input: 757.61 toks/s, output: 3183.89 toks/s][A
Processed prompts:   4%|‚ñç         | 97/2560 [00:14<03:38, 11.25it/s, est. speed input: 768.98 toks/s, output: 3249.37 toks/s][A
Processed prompts:   4%|‚ñç         | 99/2560 [00:14<03:20, 12.28it/s, est. speed input: 784.67 toks/s, output: 3318.75 toks/s][A
Processed prompts:   4%|‚ñç         | 102/2560 [00:14<03:21, 12.22it/s, est. speed input: 791.69 toks/s, output: 3380.97 toks/s][A
Processed prompts:   4%|‚ñç         | 104/2560 [00:14<03:14, 12.61it/s, est. speed input: 806.15 toks/s, output: 3445.73 toks/s][A
Processed prompts:   4%|‚ñç         | 106/2560 [00:14<03:24, 11.99it/s, est. speed input: 815.46 toks/s, output: 3499.64 toks/s][A
Processed prompts:   4%|‚ñç         | 108/2560 [00:15<03:53, 10.52it/s, est. speed input: 811.64 toks/s, output: 3514.77 toks/s][A
Processed prompts:   4%|‚ñç         | 111/2560 [00:15<02:56, 13.89it/s, est. speed input: 829.87 toks/s, output: 3638.12 toks/s][A
Processed prompts:   4%|‚ñç         | 113/2560 [00:15<05:21,  7.60it/s, est. speed input: 823.22 toks/s, output: 3596.44 toks/s][A
Processed prompts:   4%|‚ñç         | 115/2560 [00:15<04:56,  8.25it/s, est. speed input: 831.26 toks/s, output: 3650.09 toks/s][A
Processed prompts:   5%|‚ñç         | 118/2560 [00:16<04:09,  9.78it/s, est. speed input: 842.19 toks/s, output: 3673.76 toks/s][A
Processed prompts:   5%|‚ñç         | 120/2560 [00:16<04:03, 10.01it/s, est. speed input: 851.84 toks/s, output: 3728.39 toks/s][A
Processed prompts:   5%|‚ñç         | 122/2560 [00:16<03:46, 10.77it/s, est. speed input: 858.18 toks/s, output: 3791.28 toks/s][A
Processed prompts:   5%|‚ñç         | 124/2560 [00:16<04:00, 10.12it/s, est. speed input: 870.49 toks/s, output: 3836.05 toks/s][A
Processed prompts:   5%|‚ñç         | 126/2560 [00:16<04:18,  9.42it/s, est. speed input: 867.74 toks/s, output: 3853.50 toks/s][A
Processed prompts:   5%|‚ñå         | 129/2560 [00:17<03:24, 11.88it/s, est. speed input: 887.13 toks/s, output: 3965.07 toks/s][A
Processed prompts:   5%|‚ñå         | 131/2560 [00:17<03:10, 12.75it/s, est. speed input: 893.74 toks/s, output: 3985.30 toks/s][A
Processed prompts:   5%|‚ñå         | 134/2560 [00:17<03:02, 13.27it/s, est. speed input: 902.24 toks/s, output: 4081.07 toks/s][A
Processed prompts:   5%|‚ñå         | 136/2560 [00:17<03:14, 12.47it/s, est. speed input: 906.10 toks/s, output: 4133.76 toks/s][A
Processed prompts:   5%|‚ñå         | 138/2560 [00:17<03:29, 11.54it/s, est. speed input: 906.27 toks/s, output: 4181.33 toks/s][A
Processed prompts:   6%|‚ñå         | 141/2560 [00:18<03:23, 11.89it/s, est. speed input: 913.07 toks/s, output: 4250.62 toks/s][A
Processed prompts:   6%|‚ñå         | 143/2560 [00:18<03:27, 11.64it/s, est. speed input: 915.47 toks/s, output: 4303.67 toks/s][A
Processed prompts:   6%|‚ñå         | 145/2560 [00:18<04:37,  8.71it/s, est. speed input: 915.36 toks/s, output: 4310.03 toks/s][A
Processed prompts:   6%|‚ñå         | 147/2560 [00:18<04:30,  8.91it/s, est. speed input: 916.47 toks/s, output: 4297.17 toks/s][A
Processed prompts:   6%|‚ñå         | 150/2560 [00:19<03:26, 11.68it/s, est. speed input: 930.29 toks/s, output: 4412.18 toks/s][A
Processed prompts:   6%|‚ñå         | 152/2560 [00:19<03:37, 11.08it/s, est. speed input: 934.92 toks/s, output: 4459.96 toks/s][A
Processed prompts:   6%|‚ñå         | 155/2560 [00:19<03:01, 13.28it/s, est. speed input: 952.17 toks/s, output: 4569.23 toks/s][A
Processed prompts:   6%|‚ñå         | 158/2560 [00:19<02:44, 14.64it/s, est. speed input: 960.41 toks/s, output: 4673.90 toks/s][A
Processed prompts:   6%|‚ñã         | 160/2560 [00:19<02:52, 13.93it/s, est. speed input: 965.20 toks/s, output: 4711.30 toks/s][A
Processed prompts:   6%|‚ñã         | 164/2560 [00:19<02:32, 15.73it/s, est. speed input: 985.71 toks/s, output: 4826.77 toks/s][A
Processed prompts:   7%|‚ñã         | 168/2560 [00:20<02:16, 17.53it/s, est. speed input: 999.74 toks/s, output: 4871.83 toks/s][A
Processed prompts:   7%|‚ñã         | 171/2560 [00:20<02:00, 19.77it/s, est. speed input: 1010.50 toks/s, output: 4934.05 toks/s][A
Processed prompts:   7%|‚ñã         | 174/2560 [00:20<02:50, 13.98it/s, est. speed input: 1010.57 toks/s, output: 4939.63 toks/s][A
Processed prompts:   7%|‚ñã         | 177/2560 [00:20<02:24, 16.47it/s, est. speed input: 1019.79 toks/s, output: 5031.29 toks/s][A
Processed prompts:   7%|‚ñã         | 180/2560 [00:20<02:30, 15.85it/s, est. speed input: 1027.07 toks/s, output: 5090.51 toks/s][A
Processed prompts:   7%|‚ñã         | 182/2560 [00:20<02:24, 16.50it/s, est. speed input: 1031.86 toks/s, output: 5142.28 toks/s][A
Processed prompts:   7%|‚ñã         | 184/2560 [00:21<02:25, 16.33it/s, est. speed input: 1035.30 toks/s, output: 5205.65 toks/s][A
Processed prompts:   7%|‚ñã         | 187/2560 [00:21<02:36, 15.13it/s, est. speed input: 1043.56 toks/s, output: 5245.70 toks/s][A
Processed prompts:   7%|‚ñã         | 189/2560 [00:21<03:23, 11.67it/s, est. speed input: 1036.16 toks/s, output: 5268.48 toks/s][A
Processed prompts:   8%|‚ñä         | 192/2560 [00:21<03:09, 12.48it/s, est. speed input: 1048.12 toks/s, output: 5358.96 toks/s][A
Processed prompts:   8%|‚ñä         | 194/2560 [00:22<04:48,  8.21it/s, est. speed input: 1034.26 toks/s, output: 5285.03 toks/s][A
Processed prompts:   8%|‚ñä         | 197/2560 [00:22<04:10,  9.45it/s, est. speed input: 1036.31 toks/s, output: 5299.11 toks/s][A
Processed prompts:   8%|‚ñä         | 199/2560 [00:22<04:32,  8.65it/s, est. speed input: 1032.41 toks/s, output: 5308.02 toks/s][A
Processed prompts:   8%|‚ñä         | 201/2560 [00:22<04:05,  9.60it/s, est. speed input: 1034.69 toks/s, output: 5304.22 toks/s][A
Processed prompts:   8%|‚ñä         | 204/2560 [00:23<03:18, 11.89it/s, est. speed input: 1041.01 toks/s, output: 5373.72 toks/s][A
Processed prompts:   8%|‚ñä         | 206/2560 [00:23<02:58, 13.17it/s, est. speed input: 1046.39 toks/s, output: 5444.19 toks/s][A
Processed prompts:   8%|‚ñä         | 208/2560 [00:23<02:49, 13.86it/s, est. speed input: 1047.36 toks/s, output: 5488.29 toks/s][A
Processed prompts:   8%|‚ñä         | 210/2560 [00:23<02:36, 15.00it/s, est. speed input: 1049.93 toks/s, output: 5515.72 toks/s][A
Processed prompts:   8%|‚ñä         | 214/2560 [00:23<02:10, 17.91it/s, est. speed input: 1067.17 toks/s, output: 5630.12 toks/s][A
Processed prompts:   8%|‚ñä         | 216/2560 [00:24<03:25, 11.41it/s, est. speed input: 1057.63 toks/s, output: 5615.54 toks/s][A
Processed prompts:   9%|‚ñä         | 219/2560 [00:24<02:59, 13.04it/s, est. speed input: 1061.71 toks/s, output: 5718.27 toks/s][A
Processed prompts:   9%|‚ñä         | 221/2560 [00:24<04:02,  9.65it/s, est. speed input: 1057.39 toks/s, output: 5725.43 toks/s][A
Processed prompts:   9%|‚ñä         | 223/2560 [00:24<03:43, 10.48it/s, est. speed input: 1063.95 toks/s, output: 5774.05 toks/s][A
Processed prompts:   9%|‚ñâ         | 225/2560 [00:24<03:34, 10.87it/s, est. speed input: 1066.43 toks/s, output: 5803.09 toks/s][A
Processed prompts:   9%|‚ñâ         | 228/2560 [00:25<03:03, 12.69it/s, est. speed input: 1070.64 toks/s, output: 5885.14 toks/s][A
Processed prompts:   9%|‚ñâ         | 230/2560 [00:25<02:54, 13.38it/s, est. speed input: 1072.30 toks/s, output: 5931.09 toks/s][A
Processed prompts:   9%|‚ñâ         | 232/2560 [00:25<04:05,  9.47it/s, est. speed input: 1063.98 toks/s, output: 5918.63 toks/s][A
Processed prompts:   9%|‚ñâ         | 234/2560 [00:25<04:24,  8.79it/s, est. speed input: 1061.70 toks/s, output: 5950.83 toks/s][A
Processed prompts:   9%|‚ñâ         | 236/2560 [00:25<03:57,  9.80it/s, est. speed input: 1061.71 toks/s, output: 5993.36 toks/s][A
Processed prompts:   9%|‚ñâ         | 238/2560 [00:26<03:22, 11.44it/s, est. speed input: 1065.39 toks/s, output: 6034.65 toks/s][A
Processed prompts:   9%|‚ñâ         | 240/2560 [00:26<03:06, 12.47it/s, est. speed input: 1067.16 toks/s, output: 6059.92 toks/s][A
Processed prompts:   9%|‚ñâ         | 242/2560 [00:26<03:01, 12.76it/s, est. speed input: 1068.50 toks/s, output: 6102.97 toks/s][A
Processed prompts:  10%|‚ñâ         | 245/2560 [00:26<02:53, 13.32it/s, est. speed input: 1071.64 toks/s, output: 6113.40 toks/s][A
Processed prompts:  10%|‚ñâ         | 247/2560 [00:26<03:31, 10.94it/s, est. speed input: 1074.36 toks/s, output: 6115.45 toks/s][A
Processed prompts:  10%|‚ñâ         | 251/2560 [00:27<03:28, 11.10it/s, est. speed input: 1076.60 toks/s, output: 6168.30 toks/s][A
Processed prompts:  10%|‚ñâ         | 253/2560 [00:27<04:10,  9.20it/s, est. speed input: 1068.82 toks/s, output: 6135.05 toks/s][A
Processed prompts:  10%|‚ñâ         | 255/2560 [00:27<04:32,  8.45it/s, est. speed input: 1064.30 toks/s, output: 6135.38 toks/s][A
Processed prompts:  10%|‚ñà         | 257/2560 [00:28<06:06,  6.29it/s, est. speed input: 1054.95 toks/s, output: 6080.12 toks/s][A
Processed prompts:  10%|‚ñà         | 260/2560 [00:28<04:27,  8.60it/s, est. speed input: 1059.98 toks/s, output: 6158.96 toks/s][A
Processed prompts:  10%|‚ñà         | 262/2560 [00:29<06:12,  6.18it/s, est. speed input: 1044.76 toks/s, output: 6072.88 toks/s][A
Processed prompts:  10%|‚ñà         | 264/2560 [00:29<05:42,  6.71it/s, est. speed input: 1044.64 toks/s, output: 6095.62 toks/s][A
Processed prompts:  10%|‚ñà         | 265/2560 [00:29<07:05,  5.39it/s, est. speed input: 1035.43 toks/s, output: 6038.36 toks/s][A
Processed prompts:  10%|‚ñà         | 266/2560 [00:29<06:40,  5.72it/s, est. speed input: 1034.74 toks/s, output: 6044.60 toks/s][A
Processed prompts:  10%|‚ñà         | 268/2560 [00:29<05:35,  6.83it/s, est. speed input: 1039.17 toks/s, output: 6045.30 toks/s][A
Processed prompts:  11%|‚ñà         | 271/2560 [00:30<03:45, 10.17it/s, est. speed input: 1045.91 toks/s, output: 6060.59 toks/s][A
Processed prompts:  11%|‚ñà         | 273/2560 [00:30<03:49,  9.96it/s, est. speed input: 1042.48 toks/s, output: 6052.87 toks/s][A
Processed prompts:  11%|‚ñà         | 275/2560 [00:30<04:26,  8.57it/s, est. speed input: 1042.28 toks/s, output: 6053.50 toks/s][A
Processed prompts:  11%|‚ñà         | 277/2560 [00:31<05:29,  6.93it/s, est. speed input: 1035.52 toks/s, output: 6031.18 toks/s][A
Processed prompts:  11%|‚ñà         | 279/2560 [00:31<04:33,  8.33it/s, est. speed input: 1039.97 toks/s, output: 6036.42 toks/s][A
Processed prompts:  11%|‚ñà         | 281/2560 [00:31<04:08,  9.16it/s, est. speed input: 1041.62 toks/s, output: 6047.81 toks/s][A
Processed prompts:  11%|‚ñà         | 283/2560 [00:31<03:37, 10.45it/s, est. speed input: 1045.84 toks/s, output: 6095.64 toks/s][A
Processed prompts:  11%|‚ñà         | 286/2560 [00:31<03:27, 10.96it/s, est. speed input: 1048.71 toks/s, output: 6137.97 toks/s][A
Processed prompts:  11%|‚ñà‚ñè        | 288/2560 [00:31<03:22, 11.20it/s, est. speed input: 1053.03 toks/s, output: 6199.59 toks/s][A
Processed prompts:  11%|‚ñà‚ñè        | 291/2560 [00:32<03:42, 10.21it/s, est. speed input: 1052.20 toks/s, output: 6194.99 toks/s][A
Processed prompts:  11%|‚ñà‚ñè        | 293/2560 [00:32<03:15, 11.62it/s, est. speed input: 1059.56 toks/s, output: 6202.66 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 295/2560 [00:32<03:33, 10.61it/s, est. speed input: 1058.73 toks/s, output: 6228.15 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 298/2560 [00:32<03:35, 10.49it/s, est. speed input: 1057.55 toks/s, output: 6235.89 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 300/2560 [00:33<03:57,  9.52it/s, est. speed input: 1060.32 toks/s, output: 6216.91 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 302/2560 [00:33<03:43, 10.09it/s, est. speed input: 1064.63 toks/s, output: 6253.26 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 305/2560 [00:33<03:13, 11.68it/s, est. speed input: 1067.41 toks/s, output: 6360.17 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 307/2560 [00:33<03:05, 12.16it/s, est. speed input: 1066.49 toks/s, output: 6362.03 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 311/2560 [00:33<02:16, 16.49it/s, est. speed input: 1076.01 toks/s, output: 6429.17 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 314/2560 [00:33<02:41, 13.88it/s, est. speed input: 1075.89 toks/s, output: 6468.81 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 316/2560 [00:34<02:58, 12.58it/s, est. speed input: 1073.93 toks/s, output: 6471.71 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 319/2560 [00:34<03:16, 11.39it/s, est. speed input: 1074.00 toks/s, output: 6468.86 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 321/2560 [00:34<03:32, 10.56it/s, est. speed input: 1071.66 toks/s, output: 6480.93 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 324/2560 [00:34<02:56, 12.66it/s, est. speed input: 1073.51 toks/s, output: 6514.06 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 326/2560 [00:35<02:58, 12.51it/s, est. speed input: 1075.63 toks/s, output: 6549.65 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 328/2560 [00:35<02:53, 12.83it/s, est. speed input: 1076.22 toks/s, output: 6541.76 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 331/2560 [00:35<02:30, 14.82it/s, est. speed input: 1083.74 toks/s, output: 6586.65 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 333/2560 [00:35<02:32, 14.56it/s, est. speed input: 1085.82 toks/s, output: 6586.56 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 335/2560 [00:35<03:30, 10.56it/s, est. speed input: 1081.22 toks/s, output: 6572.18 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 337/2560 [00:36<03:29, 10.59it/s, est. speed input: 1082.79 toks/s, output: 6573.72 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 340/2560 [00:36<03:14, 11.43it/s, est. speed input: 1087.20 toks/s, output: 6622.95 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 342/2560 [00:36<04:17,  8.60it/s, est. speed input: 1084.42 toks/s, output: 6580.45 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 344/2560 [00:37<05:37,  6.56it/s, est. speed input: 1076.86 toks/s, output: 6525.41 toks/s][A
Processed prompts:  14%|‚ñà‚ñé        | 346/2560 [00:37<06:37,  5.56it/s, est. speed input: 1069.79 toks/s, output: 6480.94 toks/s][A
Processed prompts:  14%|‚ñà‚ñé        | 349/2560 [00:37<04:54,  7.51it/s, est. speed input: 1070.25 toks/s, output: 6524.10 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 353/2560 [00:37<03:15, 11.30it/s, est. speed input: 1079.64 toks/s, output: 6606.40 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 355/2560 [00:38<03:12, 11.46it/s, est. speed input: 1080.56 toks/s, output: 6623.36 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 357/2560 [00:38<03:40,  9.99it/s, est. speed input: 1081.34 toks/s, output: 6614.90 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 359/2560 [00:38<04:37,  7.94it/s, est. speed input: 1077.63 toks/s, output: 6588.51 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 361/2560 [00:39<06:35,  5.56it/s, est. speed input: 1065.65 toks/s, output: 6527.82 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 362/2560 [00:39<06:15,  5.85it/s, est. speed input: 1065.00 toks/s, output: 6536.96 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 363/2560 [00:40<09:38,  3.80it/s, est. speed input: 1050.66 toks/s, output: 6446.89 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 365/2560 [00:40<07:04,  5.18it/s, est. speed input: 1054.06 toks/s, output: 6461.94 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 367/2560 [00:40<05:36,  6.52it/s, est. speed input: 1056.82 toks/s, output: 6468.85 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 369/2560 [00:40<04:39,  7.85it/s, est. speed input: 1061.84 toks/s, output: 6504.99 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 371/2560 [00:41<05:49,  6.26it/s, est. speed input: 1056.56 toks/s, output: 6468.23 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 372/2560 [00:41<05:28,  6.66it/s, est. speed input: 1056.58 toks/s, output: 6459.96 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 374/2560 [00:41<04:30,  8.09it/s, est. speed input: 1056.56 toks/s, output: 6494.70 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 376/2560 [00:41<03:46,  9.63it/s, est. speed input: 1061.24 toks/s, output: 6514.33 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 378/2560 [00:41<03:39,  9.93it/s, est. speed input: 1062.67 toks/s, output: 6510.77 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 380/2560 [00:41<04:10,  8.69it/s, est. speed input: 1061.42 toks/s, output: 6491.65 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 382/2560 [00:42<04:10,  8.69it/s, est. speed input: 1060.64 toks/s, output: 6511.52 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 384/2560 [00:42<03:35, 10.09it/s, est. speed input: 1063.92 toks/s, output: 6529.27 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 386/2560 [00:42<03:11, 11.36it/s, est. speed input: 1068.43 toks/s, output: 6562.21 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 388/2560 [00:42<02:47, 12.93it/s, est. speed input: 1070.09 toks/s, output: 6580.24 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 391/2560 [00:42<02:17, 15.75it/s, est. speed input: 1072.52 toks/s, output: 6603.11 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 393/2560 [00:42<02:48, 12.83it/s, est. speed input: 1071.66 toks/s, output: 6620.17 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 395/2560 [00:43<03:11, 11.31it/s, est. speed input: 1070.79 toks/s, output: 6659.72 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 397/2560 [00:43<03:21, 10.73it/s, est. speed input: 1069.78 toks/s, output: 6664.78 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 400/2560 [00:43<02:56, 12.21it/s, est. speed input: 1071.60 toks/s, output: 6671.19 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 402/2560 [00:43<02:39, 13.49it/s, est. speed input: 1073.74 toks/s, output: 6677.96 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 404/2560 [00:44<05:01,  7.14it/s, est. speed input: 1066.58 toks/s, output: 6629.77 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 406/2560 [00:44<04:34,  7.84it/s, est. speed input: 1065.80 toks/s, output: 6622.30 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 408/2560 [00:44<03:54,  9.17it/s, est. speed input: 1066.86 toks/s, output: 6628.56 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 410/2560 [00:44<04:05,  8.77it/s, est. speed input: 1064.92 toks/s, output: 6616.27 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 412/2560 [00:44<03:26, 10.41it/s, est. speed input: 1067.44 toks/s, output: 6649.52 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 414/2560 [00:45<03:58,  8.99it/s, est. speed input: 1066.57 toks/s, output: 6643.76 toks/s][A
Processed prompts:  16%|‚ñà‚ñã        | 416/2560 [00:45<03:27, 10.32it/s, est. speed input: 1066.52 toks/s, output: 6667.53 toks/s][A
Processed prompts:  16%|‚ñà‚ñã        | 418/2560 [00:45<03:12, 11.11it/s, est. speed input: 1069.04 toks/s, output: 6687.27 toks/s][A
Processed prompts:  16%|‚ñà‚ñã        | 420/2560 [00:45<04:49,  7.38it/s, est. speed input: 1061.66 toks/s, output: 6643.56 toks/s][A
Processed prompts:  16%|‚ñà‚ñã        | 422/2560 [00:46<04:10,  8.55it/s, est. speed input: 1064.04 toks/s, output: 6655.50 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 424/2560 [00:46<03:55,  9.05it/s, est. speed input: 1064.37 toks/s, output: 6646.03 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 426/2560 [00:46<03:32, 10.06it/s, est. speed input: 1065.45 toks/s, output: 6665.40 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 428/2560 [00:46<04:09,  8.56it/s, est. speed input: 1062.17 toks/s, output: 6648.85 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 430/2560 [00:47<04:28,  7.93it/s, est. speed input: 1058.92 toks/s, output: 6648.60 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 433/2560 [00:47<03:24, 10.40it/s, est. speed input: 1062.91 toks/s, output: 6673.16 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 435/2560 [00:47<04:11,  8.43it/s, est. speed input: 1058.50 toks/s, output: 6680.22 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 437/2560 [00:48<06:38,  5.33it/s, est. speed input: 1048.04 toks/s, output: 6612.86 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 439/2560 [00:48<05:31,  6.40it/s, est. speed input: 1050.53 toks/s, output: 6623.85 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 442/2560 [00:48<04:16,  8.25it/s, est. speed input: 1053.33 toks/s, output: 6633.44 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 444/2560 [00:48<04:13,  8.35it/s, est. speed input: 1053.49 toks/s, output: 6627.25 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 446/2560 [00:49<04:36,  7.66it/s, est. speed input: 1054.62 toks/s, output: 6622.76 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 447/2560 [00:50<08:33,  4.11it/s, est. speed input: 1039.52 toks/s, output: 6523.44 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 449/2560 [00:50<06:25,  5.47it/s, est. speed input: 1041.99 toks/s, output: 6541.09 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 451/2560 [00:50<05:55,  5.93it/s, est. speed input: 1040.09 toks/s, output: 6554.35 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 452/2560 [00:51<09:08,  3.85it/s, est. speed input: 1031.25 toks/s, output: 6497.33 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 453/2560 [00:51<08:45,  4.01it/s, est. speed input: 1030.08 toks/s, output: 6492.39 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 456/2560 [00:51<05:47,  6.05it/s, est. speed input: 1031.61 toks/s, output: 6536.85 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 460/2560 [00:51<03:43,  9.40it/s, est. speed input: 1036.63 toks/s, output: 6611.82 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 462/2560 [00:51<04:03,  8.61it/s, est. speed input: 1034.94 toks/s, output: 6592.54 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 465/2560 [00:52<03:06, 11.21it/s, est. speed input: 1037.93 toks/s, output: 6610.87 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 467/2560 [00:52<02:56, 11.84it/s, est. speed input: 1038.79 toks/s, output: 6625.97 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 469/2560 [00:52<03:08, 11.07it/s, est. speed input: 1037.43 toks/s, output: 6628.33 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 472/2560 [00:52<03:10, 10.97it/s, est. speed input: 1038.52 toks/s, output: 6630.24 toks/s][A
Processed prompts:  19%|‚ñà‚ñä        | 476/2560 [00:52<02:25, 14.36it/s, est. speed input: 1044.57 toks/s, output: 6669.64 toks/s][A
Processed prompts:  19%|‚ñà‚ñä        | 479/2560 [00:52<02:13, 15.62it/s, est. speed input: 1047.82 toks/s, output: 6696.23 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 481/2560 [00:53<02:08, 16.16it/s, est. speed input: 1051.77 toks/s, output: 6720.73 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 483/2560 [00:53<02:15, 15.35it/s, est. speed input: 1052.12 toks/s, output: 6739.44 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 485/2560 [00:53<03:12, 10.80it/s, est. speed input: 1049.60 toks/s, output: 6727.25 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 487/2560 [00:53<02:56, 11.76it/s, est. speed input: 1052.19 toks/s, output: 6762.12 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 489/2560 [00:54<03:51,  8.94it/s, est. speed input: 1048.38 toks/s, output: 6772.33 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 492/2560 [00:54<03:14, 10.61it/s, est. speed input: 1050.03 toks/s, output: 6797.16 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 494/2560 [00:54<04:29,  7.66it/s, est. speed input: 1045.04 toks/s, output: 6771.50 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 496/2560 [00:54<04:21,  7.88it/s, est. speed input: 1044.78 toks/s, output: 6790.54 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 497/2560 [00:55<04:22,  7.87it/s, est. speed input: 1044.27 toks/s, output: 6786.37 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 498/2560 [00:55<06:09,  5.58it/s, est. speed input: 1037.91 toks/s, output: 6748.67 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 499/2560 [00:55<06:14,  5.51it/s, est. speed input: 1035.95 toks/s, output: 6755.45 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 500/2560 [00:55<05:47,  5.92it/s, est. speed input: 1034.76 toks/s, output: 6760.15 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 503/2560 [00:56<04:22,  7.84it/s, est. speed input: 1034.58 toks/s, output: 6804.57 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 505/2560 [00:56<04:15,  8.05it/s, est. speed input: 1032.90 toks/s, output: 6830.68 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 507/2560 [00:56<04:10,  8.19it/s, est. speed input: 1032.80 toks/s, output: 6858.57 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 509/2560 [00:56<03:40,  9.30it/s, est. speed input: 1035.40 toks/s, output: 6879.69 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 511/2560 [00:56<03:53,  8.79it/s, est. speed input: 1033.91 toks/s, output: 6875.30 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 512/2560 [00:57<05:30,  6.19it/s, est. speed input: 1029.62 toks/s, output: 6854.62 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 513/2560 [00:57<06:08,  5.55it/s, est. speed input: 1026.85 toks/s, output: 6831.79 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 515/2560 [00:57<04:49,  7.06it/s, est. speed input: 1028.12 toks/s, output: 6843.99 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 517/2560 [00:57<04:02,  8.42it/s, est. speed input: 1028.58 toks/s, output: 6858.01 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 518/2560 [00:58<03:57,  8.59it/s, est. speed input: 1028.62 toks/s, output: 6860.80 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 519/2560 [00:58<07:10,  4.74it/s, est. speed input: 1021.07 toks/s, output: 6804.55 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 521/2560 [00:58<06:13,  5.47it/s, est. speed input: 1019.61 toks/s, output: 6811.03 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 522/2560 [00:58<05:58,  5.69it/s, est. speed input: 1018.18 toks/s, output: 6806.29 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 524/2560 [00:59<04:56,  6.87it/s, est. speed input: 1020.92 toks/s, output: 6823.41 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 525/2560 [00:59<05:35,  6.06it/s, est. speed input: 1018.29 toks/s, output: 6811.11 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 527/2560 [00:59<07:01,  4.83it/s, est. speed input: 1014.97 toks/s, output: 6786.88 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 528/2560 [01:00<06:18,  5.38it/s, est. speed input: 1014.94 toks/s, output: 6785.25 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 529/2560 [01:00<05:50,  5.79it/s, est. speed input: 1014.73 toks/s, output: 6779.12 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 530/2560 [01:00<07:02,  4.81it/s, est. speed input: 1012.07 toks/s, output: 6750.24 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 532/2560 [01:01<08:40,  3.90it/s, est. speed input: 1004.20 toks/s, output: 6703.78 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 535/2560 [01:01<05:48,  5.81it/s, est. speed input: 1006.17 toks/s, output: 6718.28 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 537/2560 [01:01<04:53,  6.90it/s, est. speed input: 1006.22 toks/s, output: 6734.11 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 538/2560 [01:01<04:39,  7.22it/s, est. speed input: 1005.83 toks/s, output: 6738.37 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 539/2560 [01:01<05:01,  6.69it/s, est. speed input: 1003.79 toks/s, output: 6728.34 toks/s][A
Processed prompts:  21%|‚ñà‚ñà‚ñè       | 544/2560 [01:02<03:00, 11.15it/s, est. speed input: 1009.00 toks/s, output: 6790.18 toks/s][A
Processed prompts:  21%|‚ñà‚ñà‚ñè       | 546/2560 [01:02<04:33,  7.37it/s, est. speed input: 1004.64 toks/s, output: 6783.04 toks/s][A
Processed prompts:  21%|‚ñà‚ñà‚ñè       | 547/2560 [01:02<05:02,  6.65it/s, est. speed input: 1004.85 toks/s, output: 6778.43 toks/s][A
Processed prompts:  21%|‚ñà‚ñà‚ñè       | 548/2560 [01:02<04:46,  7.03it/s, est. speed input: 1004.20 toks/s, output: 6790.35 toks/s][A
Processed prompts:  21%|‚ñà‚ñà‚ñè       | 549/2560 [01:03<04:48,  6.98it/s, est. speed input: 1004.34 toks/s, output: 6782.68 toks/s][A
Processed prompts:  21%|‚ñà‚ñà‚ñè       | 550/2560 [01:03<08:47,  3.81it/s, est. speed input: 997.64 toks/s, output: 6732.50 toks/s] [A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 551/2560 [01:04<08:41,  3.85it/s, est. speed input: 995.35 toks/s, output: 6722.38 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 553/2560 [01:04<05:50,  5.73it/s, est. speed input: 998.51 toks/s, output: 6724.89 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 554/2560 [01:04<05:50,  5.73it/s, est. speed input: 996.58 toks/s, output: 6711.59 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 556/2560 [01:05<09:52,  3.38it/s, est. speed input: 984.00 toks/s, output: 6625.41 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 558/2560 [01:05<07:22,  4.53it/s, est. speed input: 984.23 toks/s, output: 6655.24 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 561/2560 [01:05<05:13,  6.39it/s, est. speed input: 990.76 toks/s, output: 6721.39 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 579/2560 [01:05<01:15, 26.07it/s, est. speed input: 1007.79 toks/s, output: 7508.02 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 597/2560 [01:05<00:41, 47.59it/s, est. speed input: 1033.71 toks/s, output: 8335.45 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñé       | 606/2560 [01:06<00:51, 37.67it/s, est. speed input: 1041.99 toks/s, output: 8563.72 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 614/2560 [01:07<01:57, 16.56it/s, est. speed input: 1039.07 toks/s, output: 8478.21 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 620/2560 [01:09<03:43,  8.69it/s, est. speed input: 1021.70 toks/s, output: 8319.57 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 624/2560 [01:10<03:55,  8.22it/s, est. speed input: 1020.51 toks/s, output: 8321.90 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 627/2560 [01:10<03:41,  8.74it/s, est. speed input: 1022.63 toks/s, output: 8324.85 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñç       | 630/2560 [01:10<03:47,  8.47it/s, est. speed input: 1023.23 toks/s, output: 8310.64 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñç       | 632/2560 [01:10<03:28,  9.23it/s, est. speed input: 1024.83 toks/s, output: 8316.99 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñç       | 635/2560 [01:10<02:57, 10.82it/s, est. speed input: 1029.54 toks/s, output: 8387.23 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñç       | 638/2560 [01:11<03:19,  9.64it/s, est. speed input: 1028.11 toks/s, output: 8361.17 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 640/2560 [01:11<03:31,  9.06it/s, est. speed input: 1027.95 toks/s, output: 8349.58 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 643/2560 [01:11<02:50, 11.22it/s, est. speed input: 1031.99 toks/s, output: 8415.70 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 645/2560 [01:11<02:41, 11.88it/s, est. speed input: 1036.14 toks/s, output: 8420.24 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 647/2560 [01:12<03:34,  8.91it/s, est. speed input: 1033.38 toks/s, output: 8390.54 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 649/2560 [01:12<03:07, 10.22it/s, est. speed input: 1034.56 toks/s, output: 8410.46 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 651/2560 [01:12<03:23,  9.39it/s, est. speed input: 1032.82 toks/s, output: 8401.35 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 653/2560 [01:12<02:56, 10.82it/s, est. speed input: 1034.53 toks/s, output: 8414.66 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 655/2560 [01:12<02:41, 11.78it/s, est. speed input: 1035.29 toks/s, output: 8413.90 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 657/2560 [01:13<02:48, 11.29it/s, est. speed input: 1036.40 toks/s, output: 8406.14 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 659/2560 [01:13<03:22,  9.38it/s, est. speed input: 1035.50 toks/s, output: 8396.56 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 662/2560 [01:13<02:51, 11.07it/s, est. speed input: 1037.16 toks/s, output: 8415.58 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 665/2560 [01:13<02:57, 10.69it/s, est. speed input: 1039.71 toks/s, output: 8409.99 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 667/2560 [01:13<02:48, 11.26it/s, est. speed input: 1040.71 toks/s, output: 8404.34 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 669/2560 [01:14<03:07, 10.08it/s, est. speed input: 1039.66 toks/s, output: 8402.97 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 671/2560 [01:14<02:54, 10.80it/s, est. speed input: 1041.89 toks/s, output: 8399.69 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñã       | 673/2560 [01:14<03:30,  8.97it/s, est. speed input: 1040.68 toks/s, output: 8398.15 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñã       | 675/2560 [01:14<03:22,  9.30it/s, est. speed input: 1039.76 toks/s, output: 8391.07 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñã       | 677/2560 [01:15<03:10,  9.87it/s, est. speed input: 1040.01 toks/s, output: 8400.49 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 679/2560 [01:15<02:50, 11.04it/s, est. speed input: 1041.01 toks/s, output: 8406.92 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 682/2560 [01:15<02:46, 11.25it/s, est. speed input: 1041.40 toks/s, output: 8445.17 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 684/2560 [01:15<03:23,  9.23it/s, est. speed input: 1039.55 toks/s, output: 8432.85 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 686/2560 [01:16<03:33,  8.79it/s, est. speed input: 1040.10 toks/s, output: 8471.64 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 688/2560 [01:17<07:29,  4.16it/s, est. speed input: 1028.71 toks/s, output: 8378.10 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 689/2560 [01:17<07:48,  3.99it/s, est. speed input: 1026.18 toks/s, output: 8354.64 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 690/2560 [01:17<08:22,  3.72it/s, est. speed input: 1023.11 toks/s, output: 8322.12 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 691/2560 [01:17<07:25,  4.20it/s, est. speed input: 1022.83 toks/s, output: 8315.10 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 695/2560 [01:18<04:20,  7.16it/s, est. speed input: 1024.32 toks/s, output: 8382.15 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 699/2560 [01:18<02:56, 10.54it/s, est. speed input: 1026.96 toks/s, output: 8453.67 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 701/2560 [01:18<02:52, 10.78it/s, est. speed input: 1027.08 toks/s, output: 8476.98 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 703/2560 [01:18<02:49, 10.95it/s, est. speed input: 1027.71 toks/s, output: 8467.44 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 705/2560 [01:18<03:07,  9.87it/s, est. speed input: 1028.74 toks/s, output: 8501.39 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 708/2560 [01:19<02:33, 12.07it/s, est. speed input: 1032.49 toks/s, output: 8509.71 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 711/2560 [01:19<02:03, 14.93it/s, est. speed input: 1035.30 toks/s, output: 8528.18 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 714/2560 [01:19<01:45, 17.52it/s, est. speed input: 1037.77 toks/s, output: 8574.62 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 717/2560 [01:19<02:06, 14.56it/s, est. speed input: 1037.75 toks/s, output: 8598.82 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 719/2560 [01:19<02:00, 15.34it/s, est. speed input: 1039.81 toks/s, output: 8606.72 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 721/2560 [01:19<01:55, 15.95it/s, est. speed input: 1041.51 toks/s, output: 8645.99 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 723/2560 [01:19<01:50, 16.58it/s, est. speed input: 1041.83 toks/s, output: 8686.83 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 725/2560 [01:20<01:58, 15.46it/s, est. speed input: 1041.89 toks/s, output: 8727.58 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 729/2560 [01:20<02:07, 14.39it/s, est. speed input: 1042.72 toks/s, output: 8751.44 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñä       | 731/2560 [01:20<02:18, 13.17it/s, est. speed input: 1043.98 toks/s, output: 8762.39 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñä       | 733/2560 [01:20<02:23, 12.75it/s, est. speed input: 1044.06 toks/s, output: 8790.78 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñä       | 735/2560 [01:20<02:11, 13.83it/s, est. speed input: 1044.01 toks/s, output: 8854.74 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 740/2560 [01:20<01:26, 20.99it/s, est. speed input: 1047.05 toks/s, output: 8934.72 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 743/2560 [01:21<02:20, 12.93it/s, est. speed input: 1046.60 toks/s, output: 8947.48 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 745/2560 [01:21<03:01, 10.02it/s, est. speed input: 1045.09 toks/s, output: 8954.16 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 747/2560 [01:21<02:49, 10.67it/s, est. speed input: 1045.96 toks/s, output: 8955.00 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 749/2560 [01:22<02:31, 11.99it/s, est. speed input: 1047.33 toks/s, output: 8957.03 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 751/2560 [01:22<03:13,  9.36it/s, est. speed input: 1045.01 toks/s, output: 8993.63 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 753/2560 [01:22<03:12,  9.36it/s, est. speed input: 1045.35 toks/s, output: 8984.03 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 756/2560 [01:22<02:34, 11.68it/s, est. speed input: 1045.87 toks/s, output: 9050.91 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 760/2560 [01:22<01:50, 16.29it/s, est. speed input: 1051.44 toks/s, output: 9090.62 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 763/2560 [01:23<03:01,  9.90it/s, est. speed input: 1048.61 toks/s, output: 9057.17 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 765/2560 [01:23<03:25,  8.73it/s, est. speed input: 1047.41 toks/s, output: 9043.23 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 767/2560 [01:23<03:11,  9.34it/s, est. speed input: 1047.60 toks/s, output: 9045.99 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 769/2560 [01:24<03:12,  9.32it/s, est. speed input: 1047.41 toks/s, output: 9042.07 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 771/2560 [01:24<02:55, 10.19it/s, est. speed input: 1048.54 toks/s, output: 9045.66 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 773/2560 [01:24<04:28,  6.65it/s, est. speed input: 1044.67 toks/s, output: 9001.32 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 774/2560 [01:25<05:56,  5.01it/s, est. speed input: 1041.10 toks/s, output: 8964.27 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 777/2560 [01:25<04:37,  6.42it/s, est. speed input: 1041.17 toks/s, output: 8964.40 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 778/2560 [01:25<04:23,  6.77it/s, est. speed input: 1041.33 toks/s, output: 8959.99 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 780/2560 [01:25<04:28,  6.63it/s, est. speed input: 1040.66 toks/s, output: 8944.46 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 783/2560 [01:26<03:51,  7.69it/s, est. speed input: 1041.99 toks/s, output: 8965.12 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 788/2560 [01:26<02:53, 10.23it/s, est. speed input: 1046.59 toks/s, output: 9034.94 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 790/2560 [01:26<02:36, 11.33it/s, est. speed input: 1049.55 toks/s, output: 9071.69 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 792/2560 [01:26<02:39, 11.09it/s, est. speed input: 1049.37 toks/s, output: 9062.62 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 794/2560 [01:27<02:27, 11.96it/s, est. speed input: 1049.74 toks/s, output: 9059.18 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 796/2560 [01:27<02:13, 13.18it/s, est. speed input: 1050.63 toks/s, output: 9069.18 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 798/2560 [01:27<02:19, 12.67it/s, est. speed input: 1050.86 toks/s, output: 9095.46 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà‚ñè      | 800/2560 [01:27<02:22, 12.34it/s, est. speed input: 1051.02 toks/s, output: 9120.18 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà‚ñè      | 803/2560 [01:27<01:57, 15.01it/s, est. speed input: 1053.14 toks/s, output: 9156.93 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà‚ñè      | 805/2560 [01:27<02:15, 12.93it/s, est. speed input: 1053.64 toks/s, output: 9150.17 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 807/2560 [01:28<02:27, 11.88it/s, est. speed input: 1053.82 toks/s, output: 9153.34 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 809/2560 [01:28<03:16,  8.90it/s, est. speed input: 1053.37 toks/s, output: 9153.64 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 811/2560 [01:28<03:28,  8.38it/s, est. speed input: 1052.32 toks/s, output: 9148.79 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 813/2560 [01:28<03:08,  9.28it/s, est. speed input: 1053.17 toks/s, output: 9148.01 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 815/2560 [01:29<03:23,  8.57it/s, est. speed input: 1052.69 toks/s, output: 9165.25 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 818/2560 [01:29<03:06,  9.36it/s, est. speed input: 1053.54 toks/s, output: 9155.31 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 819/2560 [01:29<03:08,  9.25it/s, est. speed input: 1053.60 toks/s, output: 9157.28 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 820/2560 [01:29<04:30,  6.44it/s, est. speed input: 1050.40 toks/s, output: 9131.69 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 822/2560 [01:30<03:55,  7.37it/s, est. speed input: 1050.88 toks/s, output: 9123.41 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 823/2560 [01:30<03:58,  7.27it/s, est. speed input: 1049.93 toks/s, output: 9130.40 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 825/2560 [01:30<04:27,  6.47it/s, est. speed input: 1048.12 toks/s, output: 9111.13 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 827/2560 [01:30<04:27,  6.47it/s, est. speed input: 1045.79 toks/s, output: 9147.73 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 828/2560 [01:31<05:03,  5.72it/s, est. speed input: 1043.49 toks/s, output: 9155.40 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 830/2560 [01:31<04:07,  6.99it/s, est. speed input: 1043.38 toks/s, output: 9177.31 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 833/2560 [01:31<03:15,  8.83it/s, est. speed input: 1045.06 toks/s, output: 9189.85 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 835/2560 [01:31<03:33,  8.07it/s, est. speed input: 1043.54 toks/s, output: 9172.60 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 838/2560 [01:31<02:47, 10.27it/s, est. speed input: 1044.93 toks/s, output: 9211.85 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 840/2560 [01:32<03:53,  7.36it/s, est. speed input: 1040.93 toks/s, output: 9179.79 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 842/2560 [01:32<03:19,  8.60it/s, est. speed input: 1041.34 toks/s, output: 9191.60 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 844/2560 [01:32<03:37,  7.89it/s, est. speed input: 1040.17 toks/s, output: 9175.08 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 845/2560 [01:33<03:35,  7.96it/s, est. speed input: 1040.19 toks/s, output: 9196.18 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 846/2560 [01:33<03:57,  7.22it/s, est. speed input: 1038.74 toks/s, output: 9205.31 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 849/2560 [01:33<04:33,  6.26it/s, est. speed input: 1037.51 toks/s, output: 9185.47 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 850/2560 [01:33<04:34,  6.23it/s, est. speed input: 1036.88 toks/s, output: 9178.15 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 852/2560 [01:34<04:03,  7.02it/s, est. speed input: 1036.32 toks/s, output: 9196.39 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 855/2560 [01:34<02:49, 10.07it/s, est. speed input: 1038.50 toks/s, output: 9236.65 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 857/2560 [01:34<03:01,  9.39it/s, est. speed input: 1038.04 toks/s, output: 9256.21 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñé      | 859/2560 [01:35<04:07,  6.86it/s, est. speed input: 1034.73 toks/s, output: 9232.43 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñé      | 861/2560 [01:35<04:25,  6.41it/s, est. speed input: 1033.19 toks/s, output: 9208.56 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñé      | 863/2560 [01:35<04:33,  6.20it/s, est. speed input: 1030.99 toks/s, output: 9194.59 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 864/2560 [01:35<04:27,  6.35it/s, est. speed input: 1031.12 toks/s, output: 9194.76 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 865/2560 [01:36<07:17,  3.88it/s, est. speed input: 1024.74 toks/s, output: 9137.72 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 866/2560 [01:36<08:00,  3.53it/s, est. speed input: 1021.67 toks/s, output: 9111.95 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 869/2560 [01:37<04:38,  6.08it/s, est. speed input: 1023.54 toks/s, output: 9124.52 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 872/2560 [01:37<03:51,  7.28it/s, est. speed input: 1024.74 toks/s, output: 9130.47 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 874/2560 [01:37<04:33,  6.18it/s, est. speed input: 1021.90 toks/s, output: 9109.18 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 875/2560 [01:38<04:58,  5.64it/s, est. speed input: 1020.33 toks/s, output: 9094.40 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 876/2560 [01:38<04:42,  5.96it/s, est. speed input: 1020.06 toks/s, output: 9113.85 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 877/2560 [01:38<04:56,  5.68it/s, est. speed input: 1018.98 toks/s, output: 9103.60 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 879/2560 [01:38<04:24,  6.35it/s, est. speed input: 1018.58 toks/s, output: 9125.47 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 880/2560 [01:38<04:13,  6.63it/s, est. speed input: 1018.41 toks/s, output: 9140.45 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 881/2560 [01:39<05:29,  5.10it/s, est. speed input: 1016.46 toks/s, output: 9113.82 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 882/2560 [01:39<05:22,  5.20it/s, est. speed input: 1015.62 toks/s, output: 9104.16 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 884/2560 [01:39<04:29,  6.21it/s, est. speed input: 1016.24 toks/s, output: 9094.47 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 885/2560 [01:39<05:52,  4.75it/s, est. speed input: 1013.26 toks/s, output: 9070.63 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 886/2560 [01:39<05:21,  5.20it/s, est. speed input: 1012.69 toks/s, output: 9080.11 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 890/2560 [01:40<03:09,  8.80it/s, est. speed input: 1013.66 toks/s, output: 9090.56 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 891/2560 [01:40<03:36,  7.70it/s, est. speed input: 1012.60 toks/s, output: 9086.49 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 892/2560 [01:40<03:57,  7.02it/s, est. speed input: 1011.78 toks/s, output: 9082.14 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 895/2560 [01:40<03:33,  7.78it/s, est. speed input: 1011.72 toks/s, output: 9090.43 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 896/2560 [01:41<03:39,  7.59it/s, est. speed input: 1010.75 toks/s, output: 9081.02 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 899/2560 [01:41<02:36, 10.62it/s, est. speed input: 1014.76 toks/s, output: 9087.22 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 901/2560 [01:41<03:05,  8.93it/s, est. speed input: 1012.99 toks/s, output: 9074.34 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 904/2560 [01:41<02:29, 11.09it/s, est. speed input: 1014.38 toks/s, output: 9075.67 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 908/2560 [01:41<02:10, 12.65it/s, est. speed input: 1014.93 toks/s, output: 9082.23 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 910/2560 [01:42<02:11, 12.52it/s, est. speed input: 1015.52 toks/s, output: 9127.71 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 914/2560 [01:42<01:43, 15.88it/s, est. speed input: 1018.80 toks/s, output: 9132.87 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 916/2560 [01:42<02:24, 11.41it/s, est. speed input: 1017.53 toks/s, output: 9118.60 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 918/2560 [01:42<02:23, 11.44it/s, est. speed input: 1017.83 toks/s, output: 9114.69 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 920/2560 [01:43<03:28,  7.86it/s, est. speed input: 1014.29 toks/s, output: 9131.14 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 922/2560 [01:43<03:04,  8.89it/s, est. speed input: 1016.82 toks/s, output: 9163.68 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 924/2560 [01:43<03:24,  7.99it/s, est. speed input: 1015.69 toks/s, output: 9155.50 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 925/2560 [01:43<03:21,  8.10it/s, est. speed input: 1015.60 toks/s, output: 9154.89 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 927/2560 [01:44<03:33,  7.65it/s, est. speed input: 1015.95 toks/s, output: 9165.52 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñã      | 929/2560 [01:44<03:04,  8.84it/s, est. speed input: 1016.12 toks/s, output: 9186.88 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñã      | 931/2560 [01:44<03:54,  6.95it/s, est. speed input: 1015.56 toks/s, output: 9159.99 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 935/2560 [01:44<02:28, 10.97it/s, est. speed input: 1020.38 toks/s, output: 9173.07 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 938/2560 [01:45<02:30, 10.74it/s, est. speed input: 1020.85 toks/s, output: 9195.05 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 942/2560 [01:45<02:49,  9.54it/s, est. speed input: 1020.97 toks/s, output: 9179.26 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 944/2560 [01:45<02:32, 10.61it/s, est. speed input: 1022.33 toks/s, output: 9177.23 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 946/2560 [01:46<03:04,  8.77it/s, est. speed input: 1022.17 toks/s, output: 9156.67 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 949/2560 [01:46<02:43,  9.85it/s, est. speed input: 1023.50 toks/s, output: 9172.80 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 951/2560 [01:46<02:40, 10.01it/s, est. speed input: 1025.21 toks/s, output: 9171.56 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 954/2560 [01:46<02:06, 12.66it/s, est. speed input: 1028.35 toks/s, output: 9191.57 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 956/2560 [01:46<02:03, 13.03it/s, est. speed input: 1029.76 toks/s, output: 9198.92 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 958/2560 [01:47<03:54,  6.82it/s, est. speed input: 1025.08 toks/s, output: 9154.24 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 960/2560 [01:47<03:13,  8.25it/s, est. speed input: 1027.82 toks/s, output: 9168.09 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 962/2560 [01:47<03:13,  8.24it/s, est. speed input: 1028.16 toks/s, output: 9160.51 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 965/2560 [01:47<02:27, 10.81it/s, est. speed input: 1030.26 toks/s, output: 9182.77 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 967/2560 [01:48<02:54,  9.11it/s, est. speed input: 1030.41 toks/s, output: 9172.01 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 969/2560 [01:48<02:48,  9.45it/s, est. speed input: 1030.82 toks/s, output: 9166.65 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 971/2560 [01:48<02:52,  9.19it/s, est. speed input: 1030.06 toks/s, output: 9167.16 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 973/2560 [01:48<02:36, 10.11it/s, est. speed input: 1031.03 toks/s, output: 9174.13 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 978/2560 [01:48<01:35, 16.60it/s, est. speed input: 1035.41 toks/s, output: 9209.63 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 981/2560 [01:49<01:53, 13.90it/s, est. speed input: 1035.25 toks/s, output: 9239.54 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 983/2560 [01:49<03:04,  8.55it/s, est. speed input: 1031.49 toks/s, output: 9234.03 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 985/2560 [01:50<03:12,  8.19it/s, est. speed input: 1030.74 toks/s, output: 9226.31 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñä      | 987/2560 [01:50<03:47,  6.91it/s, est. speed input: 1028.16 toks/s, output: 9229.24 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñä      | 990/2560 [01:50<02:54,  8.99it/s, est. speed input: 1028.90 toks/s, output: 9275.96 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 992/2560 [01:50<02:47,  9.34it/s, est. speed input: 1029.13 toks/s, output: 9277.08 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 995/2560 [01:50<02:08, 12.15it/s, est. speed input: 1030.29 toks/s, output: 9317.23 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 997/2560 [01:51<02:05, 12.43it/s, est. speed input: 1030.12 toks/s, output: 9359.94 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 999/2560 [01:51<02:16, 11.45it/s, est. speed input: 1029.58 toks/s, output: 9353.22 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1001/2560 [01:51<02:15, 11.51it/s, est. speed input: 1029.52 toks/s, output: 9373.98 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1003/2560 [01:51<02:46,  9.35it/s, est. speed input: 1028.54 toks/s, output: 9387.85 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1005/2560 [01:52<03:27,  7.49it/s, est. speed input: 1026.79 toks/s, output: 9396.69 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1008/2560 [01:52<02:29, 10.36it/s, est. speed input: 1028.15 toks/s, output: 9431.30 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1010/2560 [01:52<02:25, 10.68it/s, est. speed input: 1028.10 toks/s, output: 9446.89 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 1013/2560 [01:52<02:27, 10.48it/s, est. speed input: 1028.19 toks/s, output: 9457.59 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 1015/2560 [01:52<02:19, 11.11it/s, est. speed input: 1029.98 toks/s, output: 9465.82 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 1017/2560 [01:53<02:08, 12.05it/s, est. speed input: 1030.29 toks/s, output: 9486.82 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 1021/2560 [01:53<01:30, 17.01it/s, est. speed input: 1032.81 toks/s, output: 9532.85 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 1026/2560 [01:53<01:10, 21.61it/s, est. speed input: 1036.06 toks/s, output: 9575.81 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 1029/2560 [01:53<01:12, 21.23it/s, est. speed input: 1036.69 toks/s, output: 9625.26 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 1032/2560 [01:53<01:24, 18.00it/s, est. speed input: 1038.34 toks/s, output: 9649.18 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 1035/2560 [01:53<01:33, 16.23it/s, est. speed input: 1038.87 toks/s, output: 9652.11 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 1037/2560 [01:54<01:54, 13.27it/s, est. speed input: 1039.44 toks/s, output: 9674.08 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 1040/2560 [01:54<01:38, 15.39it/s, est. speed input: 1043.28 toks/s, output: 9711.08 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 1042/2560 [01:54<01:37, 15.52it/s, est. speed input: 1044.35 toks/s, output: 9715.82 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 1044/2560 [01:54<01:57, 12.94it/s, est. speed input: 1045.36 toks/s, output: 9723.60 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 1046/2560 [01:54<02:07, 11.86it/s, est. speed input: 1045.39 toks/s, output: 9736.13 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 1050/2560 [01:55<01:46, 14.14it/s, est. speed input: 1048.22 toks/s, output: 9753.35 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 1052/2560 [01:55<01:43, 14.52it/s, est. speed input: 1048.69 toks/s, output: 9771.90 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 1055/2560 [01:55<01:57, 12.76it/s, est. speed input: 1049.29 toks/s, output: 9781.53 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1057/2560 [01:55<02:18, 10.84it/s, est. speed input: 1048.49 toks/s, output: 9789.10 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1059/2560 [01:56<03:05,  8.11it/s, est. speed input: 1046.46 toks/s, output: 9786.00 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1060/2560 [01:56<03:49,  6.55it/s, est. speed input: 1045.75 toks/s, output: 9776.74 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1061/2560 [01:56<04:09,  6.00it/s, est. speed input: 1045.03 toks/s, output: 9764.01 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1064/2560 [01:56<02:52,  8.69it/s, est. speed input: 1047.97 toks/s, output: 9783.38 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1066/2560 [01:57<02:24, 10.34it/s, est. speed input: 1048.67 toks/s, output: 9805.56 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1068/2560 [01:57<02:09, 11.55it/s, est. speed input: 1049.28 toks/s, output: 9805.84 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1070/2560 [01:57<02:12, 11.27it/s, est. speed input: 1049.33 toks/s, output: 9842.53 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1072/2560 [01:57<02:37,  9.46it/s, est. speed input: 1048.17 toks/s, output: 9826.46 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1074/2560 [01:57<02:17, 10.77it/s, est. speed input: 1048.95 toks/s, output: 9848.36 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1080/2560 [01:58<01:49, 13.54it/s, est. speed input: 1050.56 toks/s, output: 9856.40 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1082/2560 [01:58<01:48, 13.57it/s, est. speed input: 1051.07 toks/s, output: 9862.42 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1084/2560 [01:58<01:59, 12.37it/s, est. speed input: 1050.42 toks/s, output: 9854.27 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1086/2560 [01:58<02:23, 10.31it/s, est. speed input: 1049.34 toks/s, output: 9840.55 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1088/2560 [01:59<02:54,  8.44it/s, est. speed input: 1048.16 toks/s, output: 9821.98 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1089/2560 [01:59<04:03,  6.05it/s, est. speed input: 1045.46 toks/s, output: 9792.98 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1091/2560 [01:59<03:18,  7.40it/s, est. speed input: 1047.62 toks/s, output: 9814.08 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1093/2560 [01:59<03:19,  7.37it/s, est. speed input: 1047.85 toks/s, output: 9807.55 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1097/2560 [02:00<02:35,  9.39it/s, est. speed input: 1049.65 toks/s, output: 9805.69 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1099/2560 [02:00<03:47,  6.43it/s, est. speed input: 1046.68 toks/s, output: 9769.12 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1102/2560 [02:01<02:59,  8.11it/s, est. speed input: 1047.91 toks/s, output: 9782.32 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1104/2560 [02:01<03:30,  6.91it/s, est. speed input: 1045.50 toks/s, output: 9757.27 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1106/2560 [02:01<03:19,  7.29it/s, est. speed input: 1046.80 toks/s, output: 9772.03 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1107/2560 [02:02<04:33,  5.32it/s, est. speed input: 1043.89 toks/s, output: 9740.31 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1110/2560 [02:02<03:15,  7.40it/s, est. speed input: 1044.57 toks/s, output: 9748.32 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1112/2560 [02:02<03:12,  7.54it/s, est. speed input: 1044.34 toks/s, output: 9741.14 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1113/2560 [02:02<03:50,  6.28it/s, est. speed input: 1042.52 toks/s, output: 9720.73 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1118/2560 [02:02<02:11, 10.94it/s, est. speed input: 1045.58 toks/s, output: 9753.96 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1120/2560 [02:03<02:26,  9.80it/s, est. speed input: 1045.09 toks/s, output: 9737.99 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1122/2560 [02:03<02:20, 10.25it/s, est. speed input: 1045.85 toks/s, output: 9736.24 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1124/2560 [02:03<02:11, 10.95it/s, est. speed input: 1046.72 toks/s, output: 9746.85 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1126/2560 [02:03<02:12, 10.85it/s, est. speed input: 1046.52 toks/s, output: 9742.16 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1128/2560 [02:03<02:00, 11.89it/s, est. speed input: 1047.31 toks/s, output: 9743.98 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1131/2560 [02:04<01:37, 14.61it/s, est. speed input: 1048.84 toks/s, output: 9751.36 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1133/2560 [02:04<01:51, 12.81it/s, est. speed input: 1049.22 toks/s, output: 9747.24 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1137/2560 [02:04<01:26, 16.51it/s, est. speed input: 1052.88 toks/s, output: 9779.73 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1140/2560 [02:04<01:17, 18.26it/s, est. speed input: 1054.52 toks/s, output: 9784.64 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1143/2560 [02:04<01:15, 18.81it/s, est. speed input: 1056.23 toks/s, output: 9784.72 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1145/2560 [02:05<02:05, 11.26it/s, est. speed input: 1055.83 toks/s, output: 9776.31 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1147/2560 [02:05<02:22,  9.94it/s, est. speed input: 1054.95 toks/s, output: 9769.27 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1150/2560 [02:05<02:10, 10.81it/s, est. speed input: 1055.51 toks/s, output: 9774.52 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1152/2560 [02:05<02:33,  9.19it/s, est. speed input: 1054.36 toks/s, output: 9759.96 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1155/2560 [02:06<02:14, 10.46it/s, est. speed input: 1055.72 toks/s, output: 9774.85 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1158/2560 [02:06<01:49, 12.80it/s, est. speed input: 1057.34 toks/s, output: 9785.30 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1160/2560 [02:06<02:05, 11.15it/s, est. speed input: 1056.62 toks/s, output: 9779.45 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1163/2560 [02:06<01:43, 13.54it/s, est. speed input: 1057.45 toks/s, output: 9787.66 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1165/2560 [02:06<01:58, 11.82it/s, est. speed input: 1057.30 toks/s, output: 9785.48 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1167/2560 [02:07<01:54, 12.20it/s, est. speed input: 1057.11 toks/s, output: 9786.30 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1169/2560 [02:07<02:26,  9.48it/s, est. speed input: 1055.51 toks/s, output: 9793.79 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1171/2560 [02:07<02:54,  7.95it/s, est. speed input: 1053.91 toks/s, output: 9776.71 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1173/2560 [02:07<02:25,  9.53it/s, est. speed input: 1054.80 toks/s, output: 9783.69 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1175/2560 [02:07<02:12, 10.41it/s, est. speed input: 1054.97 toks/s, output: 9798.97 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1179/2560 [02:08<02:08, 10.74it/s, est. speed input: 1055.44 toks/s, output: 9795.96 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1181/2560 [02:08<02:12, 10.39it/s, est. speed input: 1055.50 toks/s, output: 9789.67 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1184/2560 [02:08<01:53, 12.10it/s, est. speed input: 1056.26 toks/s, output: 9812.81 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1186/2560 [02:08<02:04, 11.00it/s, est. speed input: 1056.04 toks/s, output: 9824.67 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1188/2560 [02:09<02:28,  9.23it/s, est. speed input: 1054.84 toks/s, output: 9833.67 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1190/2560 [02:09<03:14,  7.03it/s, est. speed input: 1052.82 toks/s, output: 9815.30 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1193/2560 [02:09<02:34,  8.83it/s, est. speed input: 1053.44 toks/s, output: 9848.39 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1196/2560 [02:10<01:58, 11.54it/s, est. speed input: 1055.43 toks/s, output: 9894.38 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1198/2560 [02:10<02:08, 10.60it/s, est. speed input: 1055.51 toks/s, output: 9896.10 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1200/2560 [02:10<01:57, 11.58it/s, est. speed input: 1055.61 toks/s, output: 9894.94 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1203/2560 [02:10<01:35, 14.16it/s, est. speed input: 1058.19 toks/s, output: 9921.11 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1205/2560 [02:10<02:09, 10.47it/s, est. speed input: 1057.29 toks/s, output: 9926.05 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1207/2560 [02:11<02:58,  7.59it/s, est. speed input: 1055.00 toks/s, output: 9909.91 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1209/2560 [02:11<03:15,  6.91it/s, est. speed input: 1053.51 toks/s, output: 9898.71 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1210/2560 [02:11<03:20,  6.73it/s, est. speed input: 1052.81 toks/s, output: 9893.05 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1211/2560 [02:11<03:25,  6.56it/s, est. speed input: 1052.65 toks/s, output: 9891.67 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1213/2560 [02:12<02:43,  8.25it/s, est. speed input: 1052.63 toks/s, output: 9897.07 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1215/2560 [02:12<02:45,  8.13it/s, est. speed input: 1052.32 toks/s, output: 9888.07 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1216/2560 [02:12<02:41,  8.34it/s, est. speed input: 1051.84 toks/s, output: 9882.36 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1217/2560 [02:12<02:54,  7.68it/s, est. speed input: 1051.37 toks/s, output: 9879.42 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1219/2560 [02:12<02:20,  9.53it/s, est. speed input: 1052.79 toks/s, output: 9884.11 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1221/2560 [02:13<03:30,  6.37it/s, est. speed input: 1049.95 toks/s, output: 9868.87 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1222/2560 [02:13<05:39,  3.94it/s, est. speed input: 1045.34 toks/s, output: 9824.72 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1225/2560 [02:14<03:28,  6.41it/s, est. speed input: 1046.28 toks/s, output: 9852.05 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1227/2560 [02:14<03:11,  6.95it/s, est. speed input: 1047.72 toks/s, output: 9841.62 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1229/2560 [02:14<03:00,  7.38it/s, est. speed input: 1047.09 toks/s, output: 9850.18 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1232/2560 [02:14<02:30,  8.85it/s, est. speed input: 1047.31 toks/s, output: 9884.36 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1234/2560 [02:14<02:19,  9.52it/s, est. speed input: 1047.26 toks/s, output: 9880.41 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1237/2560 [02:15<02:02, 10.81it/s, est. speed input: 1049.18 toks/s, output: 9879.31 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1239/2560 [02:15<02:32,  8.69it/s, est. speed input: 1048.76 toks/s, output: 9868.61 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1241/2560 [02:15<02:43,  8.07it/s, est. speed input: 1047.91 toks/s, output: 9855.90 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1243/2560 [02:15<02:24,  9.09it/s, est. speed input: 1047.81 toks/s, output: 9870.90 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1245/2560 [02:16<02:38,  8.30it/s, est. speed input: 1047.82 toks/s, output: 9876.20 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1246/2560 [02:16<03:26,  6.37it/s, est. speed input: 1046.84 toks/s, output: 9855.88 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1249/2560 [02:16<02:26,  8.95it/s, est. speed input: 1048.39 toks/s, output: 9859.64 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1251/2560 [02:16<02:20,  9.34it/s, est. speed input: 1048.28 toks/s, output: 9860.71 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1253/2560 [02:17<02:27,  8.86it/s, est. speed input: 1048.13 toks/s, output: 9849.93 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1255/2560 [02:17<02:20,  9.28it/s, est. speed input: 1048.55 toks/s, output: 9844.19 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1257/2560 [02:17<02:07, 10.21it/s, est. speed input: 1049.35 toks/s, output: 9845.69 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1259/2560 [02:17<02:18,  9.39it/s, est. speed input: 1048.69 toks/s, output: 9853.59 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1261/2560 [02:17<02:05, 10.32it/s, est. speed input: 1048.75 toks/s, output: 9849.10 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1263/2560 [02:18<02:09, 10.03it/s, est. speed input: 1048.17 toks/s, output: 9845.02 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1265/2560 [02:18<02:31,  8.54it/s, est. speed input: 1047.05 toks/s, output: 9829.81 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1267/2560 [02:18<02:23,  9.04it/s, est. speed input: 1046.87 toks/s, output: 9843.36 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1268/2560 [02:18<02:31,  8.53it/s, est. speed input: 1046.22 toks/s, output: 9854.98 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1270/2560 [02:19<02:40,  8.06it/s, est. speed input: 1046.20 toks/s, output: 9842.97 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1274/2560 [02:19<01:38, 13.04it/s, est. speed input: 1050.50 toks/s, output: 9879.25 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1276/2560 [02:19<01:37, 13.19it/s, est. speed input: 1051.88 toks/s, output: 9877.09 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1278/2560 [02:19<01:32, 13.81it/s, est. speed input: 1052.88 toks/s, output: 9878.08 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1280/2560 [02:19<01:40, 12.72it/s, est. speed input: 1052.57 toks/s, output: 9898.12 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1282/2560 [02:19<01:42, 12.44it/s, est. speed input: 1052.40 toks/s, output: 9900.74 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1284/2560 [02:20<02:34,  8.26it/s, est. speed input: 1051.74 toks/s, output: 9883.74 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1286/2560 [02:20<02:24,  8.79it/s, est. speed input: 1053.18 toks/s, output: 9898.58 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1288/2560 [02:20<03:12,  6.61it/s, est. speed input: 1051.18 toks/s, output: 9873.22 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1289/2560 [02:21<03:06,  6.81it/s, est. speed input: 1051.04 toks/s, output: 9868.79 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1291/2560 [02:21<02:58,  7.12it/s, est. speed input: 1050.97 toks/s, output: 9858.63 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1292/2560 [02:21<03:09,  6.67it/s, est. speed input: 1050.36 toks/s, output: 9849.85 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1294/2560 [02:21<02:36,  8.11it/s, est. speed input: 1050.82 toks/s, output: 9864.36 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1295/2560 [02:21<02:53,  7.31it/s, est. speed input: 1050.44 toks/s, output: 9854.63 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1297/2560 [02:21<02:14,  9.40it/s, est. speed input: 1051.86 toks/s, output: 9860.26 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1299/2560 [02:22<02:59,  7.02it/s, est. speed input: 1050.88 toks/s, output: 9859.56 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1301/2560 [02:22<02:39,  7.87it/s, est. speed input: 1051.79 toks/s, output: 9873.39 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1303/2560 [02:22<02:14,  9.34it/s, est. speed input: 1052.68 toks/s, output: 9877.50 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1306/2560 [02:23<02:27,  8.48it/s, est. speed input: 1052.41 toks/s, output: 9866.60 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1308/2560 [02:23<02:16,  9.18it/s, est. speed input: 1052.54 toks/s, output: 9865.25 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1310/2560 [02:23<03:11,  6.54it/s, est. speed input: 1050.27 toks/s, output: 9835.65 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1312/2560 [02:23<02:57,  7.01it/s, est. speed input: 1050.72 toks/s, output: 9836.22 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1315/2560 [02:24<02:20,  8.86it/s, est. speed input: 1051.15 toks/s, output: 9871.38 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1317/2560 [02:24<02:32,  8.17it/s, est. speed input: 1051.00 toks/s, output: 9859.90 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1319/2560 [02:24<02:22,  8.68it/s, est. speed input: 1051.19 toks/s, output: 9861.42 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1320/2560 [02:25<04:34,  4.51it/s, est. speed input: 1046.15 toks/s, output: 9818.88 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1321/2560 [02:25<04:42,  4.39it/s, est. speed input: 1044.94 toks/s, output: 9808.72 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1323/2560 [02:25<03:48,  5.41it/s, est. speed input: 1044.67 toks/s, output: 9807.05 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1326/2560 [02:26<02:29,  8.25it/s, est. speed input: 1046.31 toks/s, output: 9817.49 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1331/2560 [02:26<01:32, 13.24it/s, est. speed input: 1048.61 toks/s, output: 9848.02 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1335/2560 [02:26<01:27, 14.00it/s, est. speed input: 1049.70 toks/s, output: 9862.58 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1337/2560 [02:26<01:55, 10.61it/s, est. speed input: 1048.89 toks/s, output: 9841.86 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1339/2560 [02:27<02:01, 10.05it/s, est. speed input: 1048.57 toks/s, output: 9838.85 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1342/2560 [02:27<01:41, 11.96it/s, est. speed input: 1049.41 toks/s, output: 9891.21 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1345/2560 [02:27<01:28, 13.66it/s, est. speed input: 1050.56 toks/s, output: 9896.86 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1347/2560 [02:27<01:41, 11.99it/s, est. speed input: 1049.79 toks/s, output: 9905.62 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1351/2560 [02:27<01:16, 15.85it/s, est. speed input: 1051.95 toks/s, output: 9926.26 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1353/2560 [02:27<01:16, 15.79it/s, est. speed input: 1051.79 toks/s, output: 9959.21 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1355/2560 [02:27<01:16, 15.75it/s, est. speed input: 1052.31 toks/s, output: 9976.24 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1358/2560 [02:28<01:05, 18.43it/s, est. speed input: 1052.67 toks/s, output: 10031.12 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1363/2560 [02:28<01:18, 15.21it/s, est. speed input: 1053.48 toks/s, output: 10041.86 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1366/2560 [02:28<01:10, 16.87it/s, est. speed input: 1054.85 toks/s, output: 10063.80 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1369/2560 [02:28<01:07, 17.68it/s, est. speed input: 1055.46 toks/s, output: 10082.98 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1372/2560 [02:28<00:59, 19.81it/s, est. speed input: 1057.26 toks/s, output: 10094.52 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1375/2560 [02:29<01:06, 17.79it/s, est. speed input: 1058.02 toks/s, output: 10093.49 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1377/2560 [02:29<01:13, 16.02it/s, est. speed input: 1058.03 toks/s, output: 10093.63 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1379/2560 [02:29<01:40, 11.78it/s, est. speed input: 1056.88 toks/s, output: 10083.86 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1381/2560 [02:29<01:30, 13.01it/s, est. speed input: 1058.22 toks/s, output: 10090.29 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1385/2560 [02:29<01:21, 14.47it/s, est. speed input: 1060.76 toks/s, output: 10104.81 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1389/2560 [02:30<01:25, 13.72it/s, est. speed input: 1060.78 toks/s, output: 10133.39 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1392/2560 [02:30<01:17, 15.14it/s, est. speed input: 1061.40 toks/s, output: 10151.32 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1394/2560 [02:30<01:37, 11.99it/s, est. speed input: 1060.51 toks/s, output: 10154.43 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1398/2560 [02:30<01:16, 15.20it/s, est. speed input: 1062.40 toks/s, output: 10192.48 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1401/2560 [02:31<01:40, 11.48it/s, est. speed input: 1062.28 toks/s, output: 10194.91 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1403/2560 [02:31<01:39, 11.57it/s, est. speed input: 1062.64 toks/s, output: 10207.66 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1405/2560 [02:31<01:44, 11.02it/s, est. speed input: 1062.39 toks/s, output: 10218.55 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1407/2560 [02:31<01:48, 10.61it/s, est. speed input: 1062.42 toks/s, output: 10214.40 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1409/2560 [02:31<01:48, 10.59it/s, est. speed input: 1062.05 toks/s, output: 10226.69 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1411/2560 [02:32<01:45, 10.92it/s, est. speed input: 1062.13 toks/s, output: 10223.47 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1414/2560 [02:32<01:23, 13.66it/s, est. speed input: 1063.49 toks/s, output: 10227.26 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1416/2560 [02:32<01:17, 14.77it/s, est. speed input: 1063.86 toks/s, output: 10227.81 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1418/2560 [02:32<01:58,  9.67it/s, est. speed input: 1062.31 toks/s, output: 10206.06 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1422/2560 [02:32<01:19, 14.31it/s, est. speed input: 1064.91 toks/s, output: 10218.40 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1425/2560 [02:33<01:24, 13.48it/s, est. speed input: 1064.77 toks/s, output: 10216.56 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1428/2560 [02:33<01:12, 15.59it/s, est. speed input: 1065.89 toks/s, output: 10236.03 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1430/2560 [02:33<01:53,  9.99it/s, est. speed input: 1064.47 toks/s, output: 10214.21 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1432/2560 [02:34<02:14,  8.41it/s, est. speed input: 1063.76 toks/s, output: 10202.54 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1434/2560 [02:34<02:58,  6.32it/s, est. speed input: 1061.21 toks/s, output: 10177.32 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1436/2560 [02:34<02:38,  7.09it/s, est. speed input: 1061.40 toks/s, output: 10175.22 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1438/2560 [02:34<02:10,  8.59it/s, est. speed input: 1061.85 toks/s, output: 10182.36 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1441/2560 [02:35<01:48, 10.36it/s, est. speed input: 1064.40 toks/s, output: 10211.66 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1443/2560 [02:35<01:50, 10.13it/s, est. speed input: 1063.81 toks/s, output: 10205.04 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1445/2560 [02:35<02:59,  6.21it/s, est. speed input: 1060.62 toks/s, output: 10184.55 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1446/2560 [02:36<02:52,  6.44it/s, est. speed input: 1060.76 toks/s, output: 10183.41 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1449/2560 [02:36<02:00,  9.20it/s, est. speed input: 1062.05 toks/s, output: 10199.21 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1451/2560 [02:36<02:25,  7.61it/s, est. speed input: 1060.60 toks/s, output: 10179.14 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1453/2560 [02:36<02:30,  7.36it/s, est. speed input: 1059.99 toks/s, output: 10183.50 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1457/2560 [02:36<01:35, 11.55it/s, est. speed input: 1062.02 toks/s, output: 10193.80 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1459/2560 [02:37<02:08,  8.58it/s, est. speed input: 1060.27 toks/s, output: 10175.16 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1463/2560 [02:37<01:27, 12.56it/s, est. speed input: 1063.19 toks/s, output: 10193.35 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1466/2560 [02:37<01:24, 13.02it/s, est. speed input: 1063.79 toks/s, output: 10204.15 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1468/2560 [02:38<01:51,  9.81it/s, est. speed input: 1062.71 toks/s, output: 10188.17 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1470/2560 [02:38<02:50,  6.39it/s, est. speed input: 1060.00 toks/s, output: 10157.51 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1472/2560 [02:39<02:53,  6.27it/s, est. speed input: 1059.18 toks/s, output: 10148.82 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1474/2560 [02:39<02:28,  7.33it/s, est. speed input: 1059.17 toks/s, output: 10162.45 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1476/2560 [02:39<02:18,  7.82it/s, est. speed input: 1059.20 toks/s, output: 10154.68 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1478/2560 [02:39<02:11,  8.24it/s, est. speed input: 1059.57 toks/s, output: 10154.48 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1480/2560 [02:39<02:06,  8.56it/s, est. speed input: 1059.23 toks/s, output: 10163.87 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1482/2560 [02:39<01:46, 10.17it/s, est. speed input: 1059.42 toks/s, output: 10179.52 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1484/2560 [02:40<02:14,  7.99it/s, est. speed input: 1058.28 toks/s, output: 10182.75 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1486/2560 [02:40<02:41,  6.65it/s, est. speed input: 1056.92 toks/s, output: 10167.50 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1489/2560 [02:40<01:56,  9.21it/s, est. speed input: 1058.11 toks/s, output: 10200.48 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1494/2560 [02:40<01:11, 15.01it/s, est. speed input: 1061.10 toks/s, output: 10238.05 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1497/2560 [02:41<01:56,  9.16it/s, est. speed input: 1059.09 toks/s, output: 10210.27 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1499/2560 [02:41<01:59,  8.86it/s, est. speed input: 1058.93 toks/s, output: 10220.19 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1502/2560 [02:42<01:35, 11.04it/s, est. speed input: 1060.26 toks/s, output: 10224.89 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1504/2560 [02:42<01:31, 11.54it/s, est. speed input: 1060.65 toks/s, output: 10226.93 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1506/2560 [02:42<01:55,  9.14it/s, est. speed input: 1059.39 toks/s, output: 10212.45 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1508/2560 [02:42<01:42, 10.28it/s, est. speed input: 1059.94 toks/s, output: 10224.06 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1512/2560 [02:43<02:05,  8.35it/s, est. speed input: 1058.51 toks/s, output: 10203.47 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1514/2560 [02:43<02:30,  6.93it/s, est. speed input: 1057.29 toks/s, output: 10199.84 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1515/2560 [02:44<03:09,  5.51it/s, est. speed input: 1055.20 toks/s, output: 10179.10 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1517/2560 [02:44<02:47,  6.24it/s, est. speed input: 1054.88 toks/s, output: 10174.56 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1518/2560 [02:44<03:03,  5.69it/s, est. speed input: 1053.77 toks/s, output: 10163.41 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1519/2560 [02:44<03:01,  5.74it/s, est. speed input: 1053.31 toks/s, output: 10171.71 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1520/2560 [02:45<03:41,  4.70it/s, est. speed input: 1051.69 toks/s, output: 10168.81 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1521/2560 [02:45<03:49,  4.54it/s, est. speed input: 1050.85 toks/s, output: 10157.48 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1523/2560 [02:45<03:26,  5.02it/s, est. speed input: 1050.11 toks/s, output: 10148.36 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1524/2560 [02:45<03:14,  5.32it/s, est. speed input: 1050.12 toks/s, output: 10142.45 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1527/2560 [02:46<02:38,  6.52it/s, est. speed input: 1049.76 toks/s, output: 10135.61 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1528/2560 [02:46<02:28,  6.93it/s, est. speed input: 1049.49 toks/s, output: 10134.32 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1529/2560 [02:46<02:29,  6.89it/s, est. speed input: 1048.97 toks/s, output: 10130.20 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1530/2560 [02:46<02:25,  7.09it/s, est. speed input: 1048.57 toks/s, output: 10127.43 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1532/2560 [02:46<02:15,  7.60it/s, est. speed input: 1047.91 toks/s, output: 10129.24 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1533/2560 [02:46<02:19,  7.36it/s, est. speed input: 1047.90 toks/s, output: 10123.65 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1535/2560 [02:47<03:04,  5.56it/s, est. speed input: 1045.97 toks/s, output: 10110.13 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1538/2560 [02:47<02:11,  7.76it/s, est. speed input: 1046.53 toks/s, output: 10114.69 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1540/2560 [02:47<01:49,  9.35it/s, est. speed input: 1047.43 toks/s, output: 10117.77 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1542/2560 [02:48<02:35,  6.54it/s, est. speed input: 1044.91 toks/s, output: 10094.11 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1544/2560 [02:48<02:08,  7.88it/s, est. speed input: 1045.40 toks/s, output: 10108.82 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1546/2560 [02:48<01:50,  9.21it/s, est. speed input: 1046.18 toks/s, output: 10106.01 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1548/2560 [02:48<01:43,  9.78it/s, est. speed input: 1046.64 toks/s, output: 10117.78 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1550/2560 [02:48<01:28, 11.37it/s, est. speed input: 1047.55 toks/s, output: 10116.52 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1552/2560 [02:48<01:18, 12.86it/s, est. speed input: 1047.57 toks/s, output: 10118.01 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1554/2560 [02:49<01:24, 11.97it/s, est. speed input: 1047.69 toks/s, output: 10131.09 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1556/2560 [02:49<01:14, 13.40it/s, est. speed input: 1048.25 toks/s, output: 10131.28 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1560/2560 [02:49<00:57, 17.38it/s, est. speed input: 1050.22 toks/s, output: 10132.60 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1562/2560 [02:49<01:14, 13.35it/s, est. speed input: 1049.82 toks/s, output: 10135.35 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1564/2560 [02:50<01:50,  9.03it/s, est. speed input: 1048.09 toks/s, output: 10126.64 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1566/2560 [02:50<02:37,  6.31it/s, est. speed input: 1046.92 toks/s, output: 10099.19 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1569/2560 [02:50<02:10,  7.61it/s, est. speed input: 1046.91 toks/s, output: 10095.58 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1571/2560 [02:51<02:38,  6.24it/s, est. speed input: 1045.16 toks/s, output: 10074.49 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1572/2560 [02:51<02:43,  6.05it/s, est. speed input: 1044.91 toks/s, output: 10068.05 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1574/2560 [02:51<02:09,  7.63it/s, est. speed input: 1045.49 toks/s, output: 10070.32 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1576/2560 [02:51<02:08,  7.68it/s, est. speed input: 1045.06 toks/s, output: 10063.30 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1580/2560 [02:52<01:23, 11.76it/s, est. speed input: 1048.39 toks/s, output: 10090.51 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1583/2560 [02:52<01:09, 14.06it/s, est. speed input: 1050.12 toks/s, output: 10098.37 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1585/2560 [02:52<01:08, 14.31it/s, est. speed input: 1050.54 toks/s, output: 10098.22 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1589/2560 [02:52<00:51, 18.98it/s, est. speed input: 1052.80 toks/s, output: 10107.35 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1592/2560 [02:52<01:05, 14.80it/s, est. speed input: 1052.57 toks/s, output: 10100.99 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1594/2560 [02:52<01:02, 15.45it/s, est. speed input: 1054.58 toks/s, output: 10106.98 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1596/2560 [02:52<01:05, 14.78it/s, est. speed input: 1055.05 toks/s, output: 10118.33 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1598/2560 [02:53<01:23, 11.58it/s, est. speed input: 1055.34 toks/s, output: 10108.61 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1600/2560 [02:53<01:14, 12.88it/s, est. speed input: 1056.26 toks/s, output: 10125.31 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1603/2560 [02:53<00:59, 16.01it/s, est. speed input: 1058.35 toks/s, output: 10150.97 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1605/2560 [02:53<01:00, 15.84it/s, est. speed input: 1059.12 toks/s, output: 10151.73 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1607/2560 [02:53<01:06, 14.35it/s, est. speed input: 1059.48 toks/s, output: 10163.08 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1610/2560 [02:53<00:56, 16.67it/s, est. speed input: 1060.46 toks/s, output: 10179.05 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1612/2560 [02:54<01:13, 12.88it/s, est. speed input: 1060.67 toks/s, output: 10190.39 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1616/2560 [02:54<01:03, 14.78it/s, est. speed input: 1063.58 toks/s, output: 10230.55 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1618/2560 [02:54<01:32, 10.14it/s, est. speed input: 1063.12 toks/s, output: 10230.73 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1620/2560 [02:55<01:51,  8.41it/s, est. speed input: 1062.47 toks/s, output: 10225.97 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1622/2560 [02:55<01:38,  9.56it/s, est. speed input: 1062.64 toks/s, output: 10241.69 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1625/2560 [02:55<01:22, 11.39it/s, est. speed input: 1064.69 toks/s, output: 10252.16 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1627/2560 [02:55<01:26, 10.81it/s, est. speed input: 1064.66 toks/s, output: 10249.96 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1629/2560 [02:56<01:58,  7.85it/s, est. speed input: 1063.31 toks/s, output: 10235.75 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1633/2560 [02:56<01:45,  8.75it/s, est. speed input: 1064.57 toks/s, output: 10232.90 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1635/2560 [02:56<01:46,  8.70it/s, est. speed input: 1065.18 toks/s, output: 10228.73 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1636/2560 [02:56<01:50,  8.34it/s, est. speed input: 1064.93 toks/s, output: 10230.18 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1637/2560 [02:57<01:52,  8.22it/s, est. speed input: 1064.78 toks/s, output: 10226.67 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1638/2560 [02:57<01:49,  8.42it/s, est. speed input: 1064.60 toks/s, output: 10226.87 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1639/2560 [02:57<01:55,  7.97it/s, est. speed input: 1064.43 toks/s, output: 10221.94 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1640/2560 [02:57<02:14,  6.83it/s, est. speed input: 1063.61 toks/s, output: 10216.09 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1641/2560 [02:57<02:20,  6.56it/s, est. speed input: 1063.41 toks/s, output: 10223.59 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1643/2560 [02:57<01:42,  8.99it/s, est. speed input: 1064.96 toks/s, output: 10240.42 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1645/2560 [02:58<02:53,  5.28it/s, est. speed input: 1062.69 toks/s, output: 10225.10 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1648/2560 [02:58<02:02,  7.46it/s, est. speed input: 1063.58 toks/s, output: 10224.97 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1650/2560 [02:58<02:06,  7.19it/s, est. speed input: 1062.92 toks/s, output: 10215.05 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1651/2560 [02:59<02:33,  5.93it/s, est. speed input: 1062.46 toks/s, output: 10203.72 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1652/2560 [02:59<02:45,  5.49it/s, est. speed input: 1061.69 toks/s, output: 10192.08 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1653/2560 [02:59<02:43,  5.55it/s, est. speed input: 1061.16 toks/s, output: 10188.17 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1656/2560 [02:59<01:52,  8.05it/s, est. speed input: 1061.69 toks/s, output: 10192.09 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1659/2560 [02:59<01:19, 11.33it/s, est. speed input: 1062.84 toks/s, output: 10194.59 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1661/2560 [03:00<01:32,  9.72it/s, est. speed input: 1062.02 toks/s, output: 10202.76 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1663/2560 [03:00<01:25, 10.49it/s, est. speed input: 1062.13 toks/s, output: 10213.19 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1665/2560 [03:00<01:25, 10.48it/s, est. speed input: 1062.61 toks/s, output: 10224.96 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1667/2560 [03:00<01:23, 10.75it/s, est. speed input: 1062.84 toks/s, output: 10239.45 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1671/2560 [03:00<00:56, 15.83it/s, est. speed input: 1064.70 toks/s, output: 10261.38 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1673/2560 [03:00<00:56, 15.72it/s, est. speed input: 1065.25 toks/s, output: 10260.41 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1676/2560 [03:01<01:07, 13.06it/s, est. speed input: 1065.02 toks/s, output: 10269.95 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1679/2560 [03:01<00:55, 15.76it/s, est. speed input: 1066.13 toks/s, output: 10285.98 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1683/2560 [03:01<00:47, 18.52it/s, est. speed input: 1067.39 toks/s, output: 10307.40 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1687/2560 [03:01<00:38, 22.49it/s, est. speed input: 1068.58 toks/s, output: 10342.40 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1690/2560 [03:01<00:45, 19.13it/s, est. speed input: 1068.73 toks/s, output: 10353.55 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1693/2560 [03:02<00:48, 17.93it/s, est. speed input: 1069.94 toks/s, output: 10379.21 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1696/2560 [03:02<00:43, 19.97it/s, est. speed input: 1070.22 toks/s, output: 10423.65 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1699/2560 [03:02<01:11, 12.03it/s, est. speed input: 1068.92 toks/s, output: 10416.61 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1704/2560 [03:02<00:49, 17.12it/s, est. speed input: 1071.52 toks/s, output: 10443.67 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1707/2560 [03:03<00:54, 15.75it/s, est. speed input: 1071.45 toks/s, output: 10441.56 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1710/2560 [03:03<00:56, 15.08it/s, est. speed input: 1071.72 toks/s, output: 10452.34 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1712/2560 [03:03<01:16, 11.08it/s, est. speed input: 1070.82 toks/s, output: 10443.54 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1714/2560 [03:03<01:14, 11.37it/s, est. speed input: 1071.81 toks/s, output: 10445.34 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1716/2560 [03:03<01:13, 11.47it/s, est. speed input: 1071.81 toks/s, output: 10445.73 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1718/2560 [03:04<01:09, 12.10it/s, est. speed input: 1072.18 toks/s, output: 10458.44 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1720/2560 [03:04<01:09, 12.01it/s, est. speed input: 1071.98 toks/s, output: 10467.70 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1723/2560 [03:04<00:55, 15.00it/s, est. speed input: 1073.15 toks/s, output: 10484.93 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1725/2560 [03:04<01:20, 10.32it/s, est. speed input: 1072.16 toks/s, output: 10476.99 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1728/2560 [03:04<01:10, 11.77it/s, est. speed input: 1072.48 toks/s, output: 10492.91 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1730/2560 [03:05<01:07, 12.36it/s, est. speed input: 1072.82 toks/s, output: 10505.72 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1732/2560 [03:05<01:22, 10.08it/s, est. speed input: 1072.46 toks/s, output: 10496.12 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1734/2560 [03:05<01:29,  9.25it/s, est. speed input: 1072.17 toks/s, output: 10501.97 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1737/2560 [03:06<01:36,  8.52it/s, est. speed input: 1071.54 toks/s, output: 10505.64 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1739/2560 [03:06<01:28,  9.23it/s, est. speed input: 1071.68 toks/s, output: 10501.86 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1741/2560 [03:06<01:20, 10.14it/s, est. speed input: 1072.40 toks/s, output: 10503.69 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1743/2560 [03:06<02:03,  6.64it/s, est. speed input: 1070.83 toks/s, output: 10480.67 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1745/2560 [03:07<01:52,  7.22it/s, est. speed input: 1070.29 toks/s, output: 10477.01 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1746/2560 [03:07<01:53,  7.19it/s, est. speed input: 1070.15 toks/s, output: 10472.14 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1748/2560 [03:07<01:44,  7.75it/s, est. speed input: 1069.82 toks/s, output: 10484.16 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1750/2560 [03:07<01:50,  7.35it/s, est. speed input: 1069.04 toks/s, output: 10474.02 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1751/2560 [03:07<01:51,  7.28it/s, est. speed input: 1069.53 toks/s, output: 10477.59 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1753/2560 [03:08<03:07,  4.30it/s, est. speed input: 1065.89 toks/s, output: 10437.02 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1754/2560 [03:09<03:15,  4.13it/s, est. speed input: 1064.73 toks/s, output: 10423.00 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1756/2560 [03:09<02:19,  5.77it/s, est. speed input: 1065.28 toks/s, output: 10427.17 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1759/2560 [03:09<01:37,  8.21it/s, est. speed input: 1066.08 toks/s, output: 10426.89 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1762/2560 [03:09<01:28,  9.05it/s, est. speed input: 1066.87 toks/s, output: 10436.22 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1764/2560 [03:10<01:59,  6.68it/s, est. speed input: 1065.59 toks/s, output: 10427.32 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1765/2560 [03:10<02:06,  6.29it/s, est. speed input: 1065.02 toks/s, output: 10419.02 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1768/2560 [03:10<01:39,  7.99it/s, est. speed input: 1065.98 toks/s, output: 10432.57 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1770/2560 [03:10<01:34,  8.35it/s, est. speed input: 1066.65 toks/s, output: 10439.29 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1771/2560 [03:11<02:05,  6.30it/s, est. speed input: 1065.49 toks/s, output: 10425.57 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1772/2560 [03:11<02:07,  6.20it/s, est. speed input: 1065.08 toks/s, output: 10418.73 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1774/2560 [03:11<01:50,  7.13it/s, est. speed input: 1065.10 toks/s, output: 10414.28 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1776/2560 [03:11<01:31,  8.52it/s, est. speed input: 1065.18 toks/s, output: 10416.71 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1777/2560 [03:11<02:12,  5.90it/s, est. speed input: 1063.59 toks/s, output: 10398.45 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1778/2560 [03:12<02:02,  6.36it/s, est. speed input: 1063.42 toks/s, output: 10408.32 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1782/2560 [03:12<01:12, 10.79it/s, est. speed input: 1064.58 toks/s, output: 10437.38 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1784/2560 [03:12<01:33,  8.30it/s, est. speed input: 1063.37 toks/s, output: 10424.31 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1787/2560 [03:12<01:15, 10.26it/s, est. speed input: 1063.65 toks/s, output: 10434.98 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1790/2560 [03:13<01:05, 11.68it/s, est. speed input: 1064.45 toks/s, output: 10450.12 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1792/2560 [03:13<01:02, 12.20it/s, est. speed input: 1064.80 toks/s, output: 10450.12 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1794/2560 [03:13<01:06, 11.48it/s, est. speed input: 1065.14 toks/s, output: 10459.45 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1796/2560 [03:13<01:40,  7.60it/s, est. speed input: 1063.26 toks/s, output: 10446.66 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1797/2560 [03:14<01:47,  7.09it/s, est. speed input: 1062.77 toks/s, output: 10439.18 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1799/2560 [03:14<01:27,  8.68it/s, est. speed input: 1063.24 toks/s, output: 10440.90 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1801/2560 [03:14<01:45,  7.19it/s, est. speed input: 1062.20 toks/s, output: 10436.13 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1806/2560 [03:14<01:10, 10.72it/s, est. speed input: 1064.08 toks/s, output: 10454.18 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1808/2560 [03:14<01:03, 11.82it/s, est. speed input: 1064.15 toks/s, output: 10466.59 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1810/2560 [03:15<01:15,  9.91it/s, est. speed input: 1063.62 toks/s, output: 10457.46 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1812/2560 [03:15<01:20,  9.35it/s, est. speed input: 1063.02 toks/s, output: 10463.57 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1814/2560 [03:15<01:32,  8.03it/s, est. speed input: 1061.85 toks/s, output: 10456.92 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1817/2560 [03:16<01:38,  7.53it/s, est. speed input: 1060.91 toks/s, output: 10461.35 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1819/2560 [03:16<01:26,  8.59it/s, est. speed input: 1061.32 toks/s, output: 10464.56 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1821/2560 [03:16<01:51,  6.65it/s, est. speed input: 1059.93 toks/s, output: 10459.73 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1822/2560 [03:17<02:12,  5.56it/s, est. speed input: 1058.94 toks/s, output: 10448.70 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1824/2560 [03:18<03:52,  3.16it/s, est. speed input: 1053.53 toks/s, output: 10391.80 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1827/2560 [03:18<02:38,  4.61it/s, est. speed input: 1053.99 toks/s, output: 10405.32 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1828/2560 [03:18<02:27,  4.96it/s, est. speed input: 1053.93 toks/s, output: 10401.61 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1829/2560 [03:19<02:34,  4.72it/s, est. speed input: 1053.14 toks/s, output: 10393.00 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1830/2560 [03:19<02:17,  5.31it/s, est. speed input: 1053.18 toks/s, output: 10393.51 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1831/2560 [03:19<03:14,  3.74it/s, est. speed input: 1050.99 toks/s, output: 10369.11 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1833/2560 [03:19<02:11,  5.54it/s, est. speed input: 1051.40 toks/s, output: 10383.66 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1835/2560 [03:19<01:38,  7.39it/s, est. speed input: 1051.67 toks/s, output: 10388.40 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1837/2560 [03:20<01:45,  6.83it/s, est. speed input: 1050.60 toks/s, output: 10374.37 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1839/2560 [03:20<01:24,  8.50it/s, est. speed input: 1051.48 toks/s, output: 10373.86 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1841/2560 [03:20<01:22,  8.74it/s, est. speed input: 1051.89 toks/s, output: 10366.53 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1844/2560 [03:21<01:42,  6.99it/s, est. speed input: 1050.21 toks/s, output: 10352.99 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1845/2560 [03:21<01:45,  6.79it/s, est. speed input: 1049.74 toks/s, output: 10348.26 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1846/2560 [03:21<02:19,  5.13it/s, est. speed input: 1048.45 toks/s, output: 10334.56 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1848/2560 [03:21<01:53,  6.30it/s, est. speed input: 1048.82 toks/s, output: 10332.08 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1849/2560 [03:22<01:54,  6.20it/s, est. speed input: 1048.44 toks/s, output: 10338.48 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1851/2560 [03:22<01:37,  7.26it/s, est. speed input: 1048.20 toks/s, output: 10345.59 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1853/2560 [03:22<01:27,  8.10it/s, est. speed input: 1048.50 toks/s, output: 10353.90 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1856/2560 [03:22<01:03, 11.06it/s, est. speed input: 1049.92 toks/s, output: 10358.77 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1858/2560 [03:22<01:02, 11.23it/s, est. speed input: 1050.45 toks/s, output: 10356.91 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1860/2560 [03:23<01:31,  7.62it/s, est. speed input: 1049.78 toks/s, output: 10348.93 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1862/2560 [03:23<01:19,  8.78it/s, est. speed input: 1049.77 toks/s, output: 10350.53 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1866/2560 [03:23<01:00, 11.46it/s, est. speed input: 1051.10 toks/s, output: 10378.19 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1870/2560 [03:23<00:48, 14.32it/s, est. speed input: 1053.34 toks/s, output: 10407.01 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1872/2560 [03:23<00:48, 14.07it/s, est. speed input: 1054.25 toks/s, output: 10416.78 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1874/2560 [03:24<00:52, 13.07it/s, est. speed input: 1054.03 toks/s, output: 10417.37 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1877/2560 [03:24<00:46, 14.71it/s, est. speed input: 1054.87 toks/s, output: 10422.34 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1880/2560 [03:24<00:45, 14.98it/s, est. speed input: 1056.02 toks/s, output: 10420.71 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1883/2560 [03:24<00:41, 16.34it/s, est. speed input: 1056.92 toks/s, output: 10427.82 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1885/2560 [03:24<00:46, 14.40it/s, est. speed input: 1056.64 toks/s, output: 10429.35 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1888/2560 [03:25<00:51, 13.03it/s, est. speed input: 1057.11 toks/s, output: 10424.65 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1890/2560 [03:25<01:02, 10.68it/s, est. speed input: 1056.43 toks/s, output: 10432.30 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1892/2560 [03:25<01:34,  7.04it/s, est. speed input: 1055.48 toks/s, output: 10410.77 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1895/2560 [03:26<01:19,  8.40it/s, est. speed input: 1056.25 toks/s, output: 10410.00 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1898/2560 [03:26<01:08,  9.72it/s, est. speed input: 1056.20 toks/s, output: 10412.24 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1900/2560 [03:26<01:16,  8.61it/s, est. speed input: 1055.45 toks/s, output: 10400.89 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1901/2560 [03:26<01:32,  7.15it/s, est. speed input: 1054.81 toks/s, output: 10391.28 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1905/2560 [03:27<01:02, 10.51it/s, est. speed input: 1056.15 toks/s, output: 10397.30 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1907/2560 [03:27<00:58, 11.10it/s, est. speed input: 1056.91 toks/s, output: 10398.21 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1909/2560 [03:27<01:13,  8.82it/s, est. speed input: 1056.00 toks/s, output: 10385.07 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1911/2560 [03:27<01:14,  8.76it/s, est. speed input: 1055.96 toks/s, output: 10380.68 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1913/2560 [03:27<01:03, 10.24it/s, est. speed input: 1056.43 toks/s, output: 10383.35 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1915/2560 [03:28<01:13,  8.73it/s, est. speed input: 1055.49 toks/s, output: 10376.91 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1917/2560 [03:28<01:21,  7.88it/s, est. speed input: 1055.27 toks/s, output: 10367.81 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1919/2560 [03:28<01:15,  8.52it/s, est. speed input: 1055.34 toks/s, output: 10363.30 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1920/2560 [03:28<01:27,  7.30it/s, est. speed input: 1055.35 toks/s, output: 10359.21 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1921/2560 [03:29<01:23,  7.63it/s, est. speed input: 1055.42 toks/s, output: 10356.69 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1922/2560 [03:29<01:37,  6.53it/s, est. speed input: 1054.73 toks/s, output: 10350.42 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1924/2560 [03:29<01:25,  7.41it/s, est. speed input: 1055.15 toks/s, output: 10360.03 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1927/2560 [03:29<01:10,  8.92it/s, est. speed input: 1056.41 toks/s, output: 10358.74 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1928/2560 [03:30<01:33,  6.77it/s, est. speed input: 1055.32 toks/s, output: 10348.67 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1930/2560 [03:30<01:15,  8.36it/s, est. speed input: 1055.50 toks/s, output: 10359.69 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1931/2560 [03:30<01:28,  7.07it/s, est. speed input: 1055.50 toks/s, output: 10355.99 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1933/2560 [03:30<01:21,  7.69it/s, est. speed input: 1055.54 toks/s, output: 10362.38 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1936/2560 [03:30<01:13,  8.45it/s, est. speed input: 1056.17 toks/s, output: 10360.45 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1937/2560 [03:31<01:14,  8.35it/s, est. speed input: 1056.70 toks/s, output: 10362.02 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1938/2560 [03:31<01:15,  8.25it/s, est. speed input: 1056.43 toks/s, output: 10370.31 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1941/2560 [03:31<00:51, 12.11it/s, est. speed input: 1058.32 toks/s, output: 10373.92 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1943/2560 [03:31<00:55, 11.14it/s, est. speed input: 1058.09 toks/s, output: 10373.71 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1945/2560 [03:31<01:15,  8.12it/s, est. speed input: 1057.65 toks/s, output: 10372.66 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1947/2560 [03:32<01:28,  6.95it/s, est. speed input: 1056.57 toks/s, output: 10366.16 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1949/2560 [03:32<01:16,  7.95it/s, est. speed input: 1056.97 toks/s, output: 10367.67 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1950/2560 [03:32<01:41,  5.99it/s, est. speed input: 1055.52 toks/s, output: 10354.74 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1951/2560 [03:33<01:46,  5.70it/s, est. speed input: 1055.34 toks/s, output: 10355.76 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1952/2560 [03:33<02:00,  5.06it/s, est. speed input: 1054.58 toks/s, output: 10346.12 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1954/2560 [03:33<01:46,  5.70it/s, est. speed input: 1054.86 toks/s, output: 10338.77 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1955/2560 [03:33<01:39,  6.05it/s, est. speed input: 1054.65 toks/s, output: 10337.54 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1957/2560 [03:33<01:16,  7.91it/s, est. speed input: 1055.53 toks/s, output: 10342.24 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1958/2560 [03:34<01:29,  6.72it/s, est. speed input: 1055.07 toks/s, output: 10334.07 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1959/2560 [03:34<01:32,  6.47it/s, est. speed input: 1054.75 toks/s, output: 10329.68 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1961/2560 [03:34<01:30,  6.63it/s, est. speed input: 1054.86 toks/s, output: 10320.78 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1962/2560 [03:34<01:32,  6.43it/s, est. speed input: 1054.55 toks/s, output: 10314.23 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1963/2560 [03:34<01:34,  6.29it/s, est. speed input: 1054.24 toks/s, output: 10307.67 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1965/2560 [03:35<01:24,  7.07it/s, est. speed input: 1054.16 toks/s, output: 10299.76 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1966/2560 [03:35<01:27,  6.77it/s, est. speed input: 1053.86 toks/s, output: 10293.38 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1967/2560 [03:35<02:04,  4.76it/s, est. speed input: 1052.56 toks/s, output: 10277.46 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1969/2560 [03:35<01:34,  6.27it/s, est. speed input: 1052.46 toks/s, output: 10285.68 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1970/2560 [03:36<01:27,  6.77it/s, est. speed input: 1052.25 toks/s, output: 10294.76 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1972/2560 [03:36<01:07,  8.68it/s, est. speed input: 1052.46 toks/s, output: 10298.37 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1974/2560 [03:36<01:01,  9.54it/s, est. speed input: 1052.57 toks/s, output: 10294.38 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1976/2560 [03:36<00:51, 11.39it/s, est. speed input: 1053.13 toks/s, output: 10307.29 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1978/2560 [03:36<00:50, 11.51it/s, est. speed input: 1053.48 toks/s, output: 10307.04 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1982/2560 [03:36<00:46, 12.31it/s, est. speed input: 1053.63 toks/s, output: 10338.51 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1987/2560 [03:37<00:43, 13.24it/s, est. speed input: 1054.15 toks/s, output: 10360.41 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1990/2560 [03:37<00:41, 13.80it/s, est. speed input: 1054.48 toks/s, output: 10358.34 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1992/2560 [03:37<00:40, 14.14it/s, est. speed input: 1054.69 toks/s, output: 10370.74 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1996/2560 [03:37<00:31, 17.74it/s, est. speed input: 1055.20 toks/s, output: 10413.25 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1999/2560 [03:37<00:36, 15.47it/s, est. speed input: 1055.15 toks/s, output: 10432.81 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2001/2560 [03:38<00:39, 14.05it/s, est. speed input: 1055.14 toks/s, output: 10433.37 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2004/2560 [03:38<00:37, 15.01it/s, est. speed input: 1055.55 toks/s, output: 10456.68 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2006/2560 [03:38<00:47, 11.68it/s, est. speed input: 1055.13 toks/s, output: 10447.49 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2011/2560 [03:38<00:32, 17.03it/s, est. speed input: 1056.39 toks/s, output: 10454.64 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2014/2560 [03:38<00:34, 15.61it/s, est. speed input: 1056.60 toks/s, output: 10467.56 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2016/2560 [03:39<00:46, 11.65it/s, est. speed input: 1055.59 toks/s, output: 10468.65 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2020/2560 [03:39<00:38, 13.96it/s, est. speed input: 1056.32 toks/s, output: 10492.67 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2023/2560 [03:39<00:37, 14.41it/s, est. speed input: 1056.61 toks/s, output: 10490.30 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2025/2560 [03:40<00:54,  9.82it/s, est. speed input: 1055.31 toks/s, output: 10484.96 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2028/2560 [03:40<01:16,  6.93it/s, est. speed input: 1053.19 toks/s, output: 10478.20 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2030/2560 [03:41<01:20,  6.57it/s, est. speed input: 1052.64 toks/s, output: 10466.33 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2032/2560 [03:41<01:07,  7.84it/s, est. speed input: 1052.88 toks/s, output: 10469.38 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2035/2560 [03:41<00:54,  9.69it/s, est. speed input: 1053.51 toks/s, output: 10473.93 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2037/2560 [03:41<00:58,  8.94it/s, est. speed input: 1053.06 toks/s, output: 10471.72 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2039/2560 [03:41<00:57,  9.09it/s, est. speed input: 1052.98 toks/s, output: 10466.17 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2041/2560 [03:42<00:54,  9.44it/s, est. speed input: 1052.69 toks/s, output: 10467.00 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2045/2560 [03:42<00:41, 12.42it/s, est. speed input: 1053.69 toks/s, output: 10479.01 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2047/2560 [03:42<00:48, 10.64it/s, est. speed input: 1052.97 toks/s, output: 10472.65 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2049/2560 [03:42<00:49, 10.30it/s, est. speed input: 1052.94 toks/s, output: 10478.16 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2051/2560 [03:43<01:13,  6.96it/s, est. speed input: 1051.39 toks/s, output: 10464.51 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2052/2560 [03:43<01:13,  6.93it/s, est. speed input: 1051.22 toks/s, output: 10457.83 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2053/2560 [03:43<01:17,  6.57it/s, est. speed input: 1050.91 toks/s, output: 10451.69 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2056/2560 [03:43<01:03,  7.99it/s, est. speed input: 1051.28 toks/s, output: 10452.01 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2057/2560 [03:44<01:01,  8.21it/s, est. speed input: 1051.51 toks/s, output: 10451.13 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2058/2560 [03:44<00:59,  8.42it/s, est. speed input: 1051.70 toks/s, output: 10450.70 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2060/2560 [03:44<00:51,  9.76it/s, est. speed input: 1052.39 toks/s, output: 10461.45 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2062/2560 [03:44<00:51,  9.66it/s, est. speed input: 1052.32 toks/s, output: 10462.12 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2064/2560 [03:44<00:44, 11.06it/s, est. speed input: 1052.98 toks/s, output: 10463.52 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2066/2560 [03:45<01:05,  7.58it/s, est. speed input: 1051.70 toks/s, output: 10451.48 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2067/2560 [03:45<01:08,  7.22it/s, est. speed input: 1051.48 toks/s, output: 10456.07 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2068/2560 [03:45<01:26,  5.69it/s, est. speed input: 1050.31 toks/s, output: 10455.05 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2069/2560 [03:45<01:18,  6.27it/s, est. speed input: 1050.18 toks/s, output: 10451.50 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2070/2560 [03:45<01:11,  6.84it/s, est. speed input: 1050.41 toks/s, output: 10451.00 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2073/2560 [03:46<00:53,  9.02it/s, est. speed input: 1050.84 toks/s, output: 10448.10 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2074/2560 [03:46<00:55,  8.73it/s, est. speed input: 1050.54 toks/s, output: 10455.68 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2076/2560 [03:46<00:45, 10.75it/s, est. speed input: 1050.80 toks/s, output: 10468.98 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2078/2560 [03:46<00:50,  9.58it/s, est. speed input: 1050.48 toks/s, output: 10461.42 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2080/2560 [03:46<00:43, 10.98it/s, est. speed input: 1050.55 toks/s, output: 10458.86 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2082/2560 [03:46<00:42, 11.19it/s, est. speed input: 1051.33 toks/s, output: 10471.00 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2084/2560 [03:47<00:49,  9.58it/s, est. speed input: 1050.84 toks/s, output: 10467.28 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2086/2560 [03:47<00:55,  8.51it/s, est. speed input: 1050.25 toks/s, output: 10459.76 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2087/2560 [03:47<00:54,  8.67it/s, est. speed input: 1050.57 toks/s, output: 10468.42 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2089/2560 [03:47<00:46, 10.23it/s, est. speed input: 1051.19 toks/s, output: 10469.97 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2091/2560 [03:47<00:50,  9.32it/s, est. speed input: 1050.97 toks/s, output: 10462.47 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2093/2560 [03:48<00:45, 10.31it/s, est. speed input: 1051.41 toks/s, output: 10461.50 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2095/2560 [03:48<00:41, 11.13it/s, est. speed input: 1051.48 toks/s, output: 10461.31 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2097/2560 [03:48<00:39, 11.76it/s, est. speed input: 1051.75 toks/s, output: 10461.08 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2099/2560 [03:48<00:48,  9.53it/s, est. speed input: 1051.30 toks/s, output: 10451.97 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2102/2560 [03:48<00:35, 12.84it/s, est. speed input: 1052.20 toks/s, output: 10454.70 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2104/2560 [03:49<00:52,  8.74it/s, est. speed input: 1051.31 toks/s, output: 10443.57 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2107/2560 [03:49<00:44, 10.14it/s, est. speed input: 1052.04 toks/s, output: 10446.66 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2109/2560 [03:49<00:40, 11.15it/s, est. speed input: 1051.96 toks/s, output: 10456.42 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2112/2560 [03:49<00:40, 11.01it/s, est. speed input: 1051.90 toks/s, output: 10462.74 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2114/2560 [03:50<00:50,  8.78it/s, est. speed input: 1050.80 toks/s, output: 10463.83 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2117/2560 [03:50<00:39, 11.24it/s, est. speed input: 1051.04 toks/s, output: 10492.16 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2122/2560 [03:50<00:25, 17.12it/s, est. speed input: 1053.17 toks/s, output: 10535.05 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2125/2560 [03:50<00:30, 14.29it/s, est. speed input: 1053.30 toks/s, output: 10538.06 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2127/2560 [03:50<00:36, 11.84it/s, est. speed input: 1053.04 toks/s, output: 10532.15 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2129/2560 [03:51<00:41, 10.35it/s, est. speed input: 1052.61 toks/s, output: 10540.14 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2131/2560 [03:51<00:36, 11.67it/s, est. speed input: 1053.12 toks/s, output: 10545.11 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2133/2560 [03:51<00:34, 12.54it/s, est. speed input: 1053.18 toks/s, output: 10546.19 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2135/2560 [03:51<00:54,  7.74it/s, est. speed input: 1051.75 toks/s, output: 10530.44 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2137/2560 [03:52<01:04,  6.60it/s, est. speed input: 1050.98 toks/s, output: 10520.48 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2138/2560 [03:52<01:14,  5.70it/s, est. speed input: 1049.95 toks/s, output: 10510.10 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2140/2560 [03:53<01:24,  4.99it/s, est. speed input: 1048.78 toks/s, output: 10502.24 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2142/2560 [03:53<01:20,  5.16it/s, est. speed input: 1048.08 toks/s, output: 10503.07 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2144/2560 [03:53<01:09,  6.01it/s, est. speed input: 1048.01 toks/s, output: 10499.37 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2146/2560 [03:53<00:55,  7.41it/s, est. speed input: 1048.40 toks/s, output: 10501.55 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2147/2560 [03:54<00:53,  7.73it/s, est. speed input: 1048.23 toks/s, output: 10505.08 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2148/2560 [03:54<00:53,  7.72it/s, est. speed input: 1048.31 toks/s, output: 10500.91 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2150/2560 [03:54<00:55,  7.38it/s, est. speed input: 1047.73 toks/s, output: 10497.86 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2153/2560 [03:54<00:47,  8.64it/s, est. speed input: 1048.08 toks/s, output: 10497.74 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2154/2560 [03:55<01:02,  6.49it/s, est. speed input: 1047.24 toks/s, output: 10495.77 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2156/2560 [03:55<01:16,  5.25it/s, est. speed input: 1045.96 toks/s, output: 10484.08 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2157/2560 [03:55<01:23,  4.85it/s, est. speed input: 1045.11 toks/s, output: 10475.98 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2158/2560 [03:56<01:19,  5.05it/s, est. speed input: 1044.74 toks/s, output: 10470.21 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2159/2560 [03:56<01:18,  5.08it/s, est. speed input: 1044.33 toks/s, output: 10474.71 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2160/2560 [03:56<01:13,  5.42it/s, est. speed input: 1043.96 toks/s, output: 10471.88 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2163/2560 [03:56<00:55,  7.15it/s, est. speed input: 1043.63 toks/s, output: 10467.96 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2164/2560 [03:56<00:54,  7.30it/s, est. speed input: 1043.29 toks/s, output: 10463.71 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2166/2560 [03:56<00:45,  8.75it/s, est. speed input: 1043.29 toks/s, output: 10471.47 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2168/2560 [03:57<00:36, 10.73it/s, est. speed input: 1043.50 toks/s, output: 10471.59 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2171/2560 [03:57<00:28, 13.74it/s, est. speed input: 1044.75 toks/s, output: 10493.23 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2173/2560 [03:57<00:30, 12.68it/s, est. speed input: 1044.75 toks/s, output: 10502.20 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2175/2560 [03:57<00:28, 13.43it/s, est. speed input: 1045.13 toks/s, output: 10502.28 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2177/2560 [03:58<00:54,  7.04it/s, est. speed input: 1043.38 toks/s, output: 10485.03 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2179/2560 [03:58<01:10,  5.42it/s, est. speed input: 1042.57 toks/s, output: 10468.10 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2181/2560 [03:58<00:58,  6.45it/s, est. speed input: 1043.06 toks/s, output: 10468.02 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2182/2560 [03:58<00:58,  6.50it/s, est. speed input: 1043.07 toks/s, output: 10464.38 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2184/2560 [03:59<00:53,  7.05it/s, est. speed input: 1043.19 toks/s, output: 10464.42 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2186/2560 [03:59<01:09,  5.42it/s, est. speed input: 1041.29 toks/s, output: 10445.95 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2187/2560 [03:59<01:07,  5.51it/s, est. speed input: 1041.47 toks/s, output: 10440.86 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2188/2560 [04:00<01:10,  5.31it/s, est. speed input: 1041.21 toks/s, output: 10434.64 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2190/2560 [04:00<00:50,  7.26it/s, est. speed input: 1041.27 toks/s, output: 10435.50 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2191/2560 [04:00<00:56,  6.52it/s, est. speed input: 1040.73 toks/s, output: 10429.00 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2192/2560 [04:00<01:10,  5.24it/s, est. speed input: 1040.27 toks/s, output: 10417.64 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2193/2560 [04:01<01:13,  4.98it/s, est. speed input: 1039.56 toks/s, output: 10412.31 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2196/2560 [04:01<00:52,  6.87it/s, est. speed input: 1040.45 toks/s, output: 10417.75 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2198/2560 [04:01<00:44,  8.15it/s, est. speed input: 1040.32 toks/s, output: 10426.01 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2200/2560 [04:01<00:36,  9.92it/s, est. speed input: 1041.12 toks/s, output: 10429.62 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2202/2560 [04:02<00:55,  6.44it/s, est. speed input: 1040.78 toks/s, output: 10424.83 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2205/2560 [04:02<00:38,  9.11it/s, est. speed input: 1042.18 toks/s, output: 10439.59 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2207/2560 [04:02<00:36,  9.72it/s, est. speed input: 1042.80 toks/s, output: 10448.53 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2209/2560 [04:02<00:33, 10.59it/s, est. speed input: 1043.19 toks/s, output: 10447.60 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2211/2560 [04:02<00:34, 10.24it/s, est. speed input: 1043.19 toks/s, output: 10445.08 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2213/2560 [04:02<00:36,  9.54it/s, est. speed input: 1043.31 toks/s, output: 10450.77 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2216/2560 [04:03<00:27, 12.30it/s, est. speed input: 1044.23 toks/s, output: 10450.16 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2219/2560 [04:03<00:24, 13.86it/s, est. speed input: 1045.64 toks/s, output: 10451.99 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2222/2560 [04:03<00:20, 16.57it/s, est. speed input: 1047.03 toks/s, output: 10456.29 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2224/2560 [04:03<00:21, 15.66it/s, est. speed input: 1047.60 toks/s, output: 10454.88 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2226/2560 [04:03<00:23, 14.39it/s, est. speed input: 1047.71 toks/s, output: 10457.96 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2229/2560 [04:03<00:25, 13.23it/s, est. speed input: 1048.36 toks/s, output: 10456.77 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2233/2560 [04:04<00:19, 17.02it/s, est. speed input: 1049.91 toks/s, output: 10489.76 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2236/2560 [04:04<00:18, 17.23it/s, est. speed input: 1050.87 toks/s, output: 10503.24 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2238/2560 [04:04<00:25, 12.78it/s, est. speed input: 1050.65 toks/s, output: 10494.39 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2240/2560 [04:04<00:24, 12.95it/s, est. speed input: 1051.37 toks/s, output: 10503.54 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2244/2560 [04:05<00:26, 11.81it/s, est. speed input: 1052.55 toks/s, output: 10509.91 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2246/2560 [04:05<00:25, 12.48it/s, est. speed input: 1053.01 toks/s, output: 10512.69 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2248/2560 [04:05<00:29, 10.62it/s, est. speed input: 1052.51 toks/s, output: 10509.69 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2250/2560 [04:05<00:30, 10.27it/s, est. speed input: 1052.53 toks/s, output: 10504.51 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2252/2560 [04:05<00:32,  9.49it/s, est. speed input: 1052.90 toks/s, output: 10499.98 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2254/2560 [04:06<00:37,  8.12it/s, est. speed input: 1052.27 toks/s, output: 10491.94 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2255/2560 [04:06<00:36,  8.31it/s, est. speed input: 1052.23 toks/s, output: 10492.15 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2257/2560 [04:06<00:31,  9.74it/s, est. speed input: 1052.67 toks/s, output: 10494.14 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2259/2560 [04:06<00:32,  9.34it/s, est. speed input: 1052.75 toks/s, output: 10493.33 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2261/2560 [04:07<00:32,  9.32it/s, est. speed input: 1052.66 toks/s, output: 10494.46 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2264/2560 [04:07<00:29,  9.87it/s, est. speed input: 1052.48 toks/s, output: 10504.08 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2266/2560 [04:08<00:52,  5.63it/s, est. speed input: 1050.59 toks/s, output: 10477.54 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2268/2560 [04:08<00:52,  5.61it/s, est. speed input: 1050.79 toks/s, output: 10469.83 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2270/2560 [04:08<00:46,  6.22it/s, est. speed input: 1050.78 toks/s, output: 10466.78 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2271/2560 [04:08<00:43,  6.59it/s, est. speed input: 1050.60 toks/s, output: 10474.56 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2273/2560 [04:09<00:43,  6.61it/s, est. speed input: 1049.88 toks/s, output: 10486.62 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2274/2560 [04:09<00:42,  6.80it/s, est. speed input: 1050.21 toks/s, output: 10484.96 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2277/2560 [04:09<00:40,  7.06it/s, est. speed input: 1049.48 toks/s, output: 10504.88 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2280/2560 [04:09<00:30,  9.15it/s, est. speed input: 1050.01 toks/s, output: 10524.73 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2282/2560 [04:10<00:40,  6.87it/s, est. speed input: 1048.47 toks/s, output: 10528.87 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2285/2560 [04:10<00:29,  9.48it/s, est. speed input: 1049.04 toks/s, output: 10551.22 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2288/2560 [04:10<00:22, 12.23it/s, est. speed input: 1049.25 toks/s, output: 10583.39 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2291/2560 [04:10<00:26, 10.11it/s, est. speed input: 1048.69 toks/s, output: 10593.39 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2293/2560 [04:10<00:23, 11.37it/s, est. speed input: 1049.56 toks/s, output: 10608.60 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2295/2560 [04:11<00:30,  8.59it/s, est. speed input: 1048.78 toks/s, output: 10595.02 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2299/2560 [04:11<00:24, 10.61it/s, est. speed input: 1049.44 toks/s, output: 10597.68 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2301/2560 [04:11<00:23, 10.83it/s, est. speed input: 1049.44 toks/s, output: 10604.06 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2304/2560 [04:11<00:19, 12.81it/s, est. speed input: 1050.05 toks/s, output: 10615.05 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2306/2560 [04:12<00:21, 11.81it/s, est. speed input: 1050.05 toks/s, output: 10620.98 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2308/2560 [04:12<00:23, 10.80it/s, est. speed input: 1049.76 toks/s, output: 10635.58 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2310/2560 [04:12<00:22, 11.10it/s, est. speed input: 1049.87 toks/s, output: 10652.89 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2312/2560 [04:12<00:19, 12.55it/s, est. speed input: 1050.41 toks/s, output: 10661.43 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2314/2560 [04:12<00:24, 10.15it/s, est. speed input: 1050.18 toks/s, output: 10662.09 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2316/2560 [04:13<00:26,  9.19it/s, est. speed input: 1049.93 toks/s, output: 10656.09 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2319/2560 [04:13<00:21, 11.28it/s, est. speed input: 1050.67 toks/s, output: 10676.99 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2324/2560 [04:13<00:13, 17.76it/s, est. speed input: 1052.28 toks/s, output: 10694.77 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2327/2560 [04:13<00:16, 14.28it/s, est. speed input: 1052.11 toks/s, output: 10686.70 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2329/2560 [04:14<00:30,  7.57it/s, est. speed input: 1049.99 toks/s, output: 10664.60 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2332/2560 [04:14<00:25,  9.05it/s, est. speed input: 1050.70 toks/s, output: 10670.51 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2334/2560 [04:15<00:31,  7.19it/s, est. speed input: 1049.57 toks/s, output: 10655.74 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2336/2560 [04:15<00:30,  7.43it/s, est. speed input: 1049.27 toks/s, output: 10653.32 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2338/2560 [04:15<00:31,  7.05it/s, est. speed input: 1048.64 toks/s, output: 10644.38 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2340/2560 [04:15<00:29,  7.34it/s, est. speed input: 1048.20 toks/s, output: 10638.32 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2341/2560 [04:16<00:30,  7.13it/s, est. speed input: 1048.16 toks/s, output: 10637.42 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2343/2560 [04:16<00:24,  8.95it/s, est. speed input: 1048.47 toks/s, output: 10638.01 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2347/2560 [04:16<00:22,  9.57it/s, est. speed input: 1048.43 toks/s, output: 10636.56 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2349/2560 [04:17<00:30,  6.97it/s, est. speed input: 1047.70 toks/s, output: 10630.07 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2351/2560 [04:17<00:27,  7.74it/s, est. speed input: 1048.26 toks/s, output: 10646.53 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2352/2560 [04:17<00:27,  7.65it/s, est. speed input: 1048.10 toks/s, output: 10644.18 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2353/2560 [04:17<00:26,  7.78it/s, est. speed input: 1048.18 toks/s, output: 10643.02 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2357/2560 [04:17<00:16, 12.48it/s, est. speed input: 1049.22 toks/s, output: 10651.54 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2359/2560 [04:17<00:16, 12.13it/s, est. speed input: 1049.42 toks/s, output: 10649.51 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2361/2560 [04:18<00:15, 13.18it/s, est. speed input: 1049.65 toks/s, output: 10652.63 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2363/2560 [04:18<00:14, 13.49it/s, est. speed input: 1049.82 toks/s, output: 10665.39 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2365/2560 [04:18<00:21,  9.13it/s, est. speed input: 1049.34 toks/s, output: 10656.68 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2369/2560 [04:18<00:16, 11.58it/s, est. speed input: 1049.88 toks/s, output: 10656.99 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2371/2560 [04:18<00:15, 12.22it/s, est. speed input: 1050.71 toks/s, output: 10661.93 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2373/2560 [04:19<00:16, 11.66it/s, est. speed input: 1050.81 toks/s, output: 10659.80 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2376/2560 [04:19<00:13, 13.32it/s, est. speed input: 1051.68 toks/s, output: 10660.18 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2378/2560 [04:19<00:18, 10.04it/s, est. speed input: 1050.95 toks/s, output: 10655.32 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2380/2560 [04:19<00:18,  9.77it/s, est. speed input: 1051.25 toks/s, output: 10662.78 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2382/2560 [04:20<00:19,  9.07it/s, est. speed input: 1051.52 toks/s, output: 10667.16 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2383/2560 [04:20<00:21,  8.12it/s, est. speed input: 1050.95 toks/s, output: 10671.24 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2386/2560 [04:20<00:16, 10.65it/s, est. speed input: 1051.45 toks/s, output: 10672.29 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2388/2560 [04:20<00:16, 10.29it/s, est. speed input: 1051.40 toks/s, output: 10673.13 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2390/2560 [04:20<00:17, 10.00it/s, est. speed input: 1051.38 toks/s, output: 10678.40 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2392/2560 [04:21<00:14, 11.28it/s, est. speed input: 1051.56 toks/s, output: 10680.87 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2394/2560 [04:21<00:16, 10.16it/s, est. speed input: 1051.57 toks/s, output: 10676.83 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2396/2560 [04:21<00:28,  5.83it/s, est. speed input: 1049.43 toks/s, output: 10662.17 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2397/2560 [04:22<00:28,  5.77it/s, est. speed input: 1048.94 toks/s, output: 10666.48 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2399/2560 [04:22<00:25,  6.30it/s, est. speed input: 1048.92 toks/s, output: 10661.45 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2400/2560 [04:22<00:27,  5.81it/s, est. speed input: 1048.44 toks/s, output: 10663.85 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2404/2560 [04:22<00:18,  8.59it/s, est. speed input: 1049.04 toks/s, output: 10686.28 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2405/2560 [04:23<00:19,  8.03it/s, est. speed input: 1048.71 toks/s, output: 10685.59 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2406/2560 [04:23<00:19,  7.87it/s, est. speed input: 1048.48 toks/s, output: 10682.18 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2409/2560 [04:23<00:14, 10.70it/s, est. speed input: 1049.35 toks/s, output: 10703.13 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2411/2560 [04:23<00:13, 10.68it/s, est. speed input: 1049.71 toks/s, output: 10702.79 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2415/2560 [04:23<00:09, 15.20it/s, est. speed input: 1051.32 toks/s, output: 10713.45 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2418/2560 [04:23<00:08, 17.70it/s, est. speed input: 1052.35 toks/s, output: 10727.30 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2421/2560 [04:24<00:14,  9.80it/s, est. speed input: 1051.11 toks/s, output: 10714.35 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2423/2560 [04:24<00:16,  8.23it/s, est. speed input: 1050.34 toks/s, output: 10708.68 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2425/2560 [04:25<00:17,  7.78it/s, est. speed input: 1049.83 toks/s, output: 10703.89 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2428/2560 [04:25<00:14,  9.33it/s, est. speed input: 1049.96 toks/s, output: 10712.28 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2430/2560 [04:25<00:13,  9.90it/s, est. speed input: 1050.38 toks/s, output: 10722.06 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2432/2560 [04:25<00:14,  9.06it/s, est. speed input: 1050.13 toks/s, output: 10719.92 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2434/2560 [04:25<00:14,  8.89it/s, est. speed input: 1049.94 toks/s, output: 10716.09 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2435/2560 [04:26<00:15,  7.90it/s, est. speed input: 1049.48 toks/s, output: 10710.82 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2436/2560 [04:26<00:15,  8.11it/s, est. speed input: 1049.44 toks/s, output: 10709.12 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2439/2560 [04:26<00:10, 11.46it/s, est. speed input: 1050.07 toks/s, output: 10738.56 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2441/2560 [04:26<00:11, 10.70it/s, est. speed input: 1050.08 toks/s, output: 10737.89 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2443/2560 [04:27<00:17,  6.81it/s, est. speed input: 1048.79 toks/s, output: 10724.79 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2444/2560 [04:27<00:18,  6.41it/s, est. speed input: 1048.33 toks/s, output: 10719.81 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2445/2560 [04:27<00:17,  6.66it/s, est. speed input: 1048.22 toks/s, output: 10719.61 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2447/2560 [04:28<00:31,  3.60it/s, est. speed input: 1044.97 toks/s, output: 10687.01 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2449/2560 [04:28<00:23,  4.74it/s, est. speed input: 1045.23 toks/s, output: 10695.14 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2450/2560 [04:28<00:22,  5.00it/s, est. speed input: 1044.92 toks/s, output: 10696.92 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2452/2560 [04:29<00:27,  3.91it/s, est. speed input: 1042.84 toks/s, output: 10679.34 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2454/2560 [04:29<00:21,  4.85it/s, est. speed input: 1042.81 toks/s, output: 10693.49 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2457/2560 [04:29<00:15,  6.60it/s, est. speed input: 1043.19 toks/s, output: 10714.39 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2459/2560 [04:30<00:19,  5.31it/s, est. speed input: 1042.34 toks/s, output: 10700.35 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2461/2560 [04:30<00:16,  6.09it/s, est. speed input: 1042.48 toks/s, output: 10701.37 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2462/2560 [04:30<00:15,  6.49it/s, est. speed input: 1042.98 toks/s, output: 10704.99 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2464/2560 [04:31<00:17,  5.43it/s, est. speed input: 1042.10 toks/s, output: 10694.76 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2465/2560 [04:31<00:22,  4.20it/s, est. speed input: 1040.56 toks/s, output: 10680.04 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2466/2560 [04:32<00:27,  3.41it/s, est. speed input: 1038.99 toks/s, output: 10668.40 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2468/2560 [04:33<00:31,  2.92it/s, est. speed input: 1036.42 toks/s, output: 10651.68 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2470/2560 [04:33<00:22,  4.09it/s, est. speed input: 1036.49 toks/s, output: 10662.15 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2471/2560 [04:33<00:19,  4.46it/s, est. speed input: 1036.18 toks/s, output: 10667.82 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2473/2560 [04:33<00:17,  5.03it/s, est. speed input: 1035.57 toks/s, output: 10665.15 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2475/2560 [04:33<00:12,  6.76it/s, est. speed input: 1035.66 toks/s, output: 10683.66 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2477/2560 [04:34<00:17,  4.68it/s, est. speed input: 1034.16 toks/s, output: 10672.95 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2479/2560 [04:34<00:13,  5.80it/s, est. speed input: 1035.31 toks/s, output: 10676.87 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2480/2560 [04:35<00:21,  3.80it/s, est. speed input: 1033.05 toks/s, output: 10657.10 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2481/2560 [04:36<00:33,  2.33it/s, est. speed input: 1029.63 toks/s, output: 10627.47 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2482/2560 [04:37<00:45,  1.71it/s, est. speed input: 1026.05 toks/s, output: 10596.10 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2483/2560 [04:37<00:37,  2.07it/s, est. speed input: 1026.31 toks/s, output: 10595.49 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2484/2560 [04:38<00:43,  1.73it/s, est. speed input: 1023.77 toks/s, output: 10569.91 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2485/2560 [04:39<00:54,  1.39it/s, est. speed input: 1020.11 toks/s, output: 10539.21 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2486/2560 [04:39<00:45,  1.64it/s, est. speed input: 1019.18 toks/s, output: 10538.12 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2487/2560 [04:40<00:39,  1.85it/s, est. speed input: 1018.08 toks/s, output: 10530.77 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2492/2560 [04:40<00:14,  4.78it/s, est. speed input: 1019.35 toks/s, output: 10572.22 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2494/2560 [04:40<00:12,  5.50it/s, est. speed input: 1019.03 toks/s, output: 10585.78 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2495/2560 [04:40<00:12,  5.26it/s, est. speed input: 1018.44 toks/s, output: 10588.02 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2498/2560 [04:41<00:08,  7.08it/s, est. speed input: 1018.25 toks/s, output: 10612.58 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2501/2560 [04:41<00:06,  8.44it/s, est. speed input: 1018.65 toks/s, output: 10631.99 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2506/2560 [04:41<00:04, 12.95it/s, est. speed input: 1019.37 toks/s, output: 10680.76 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2508/2560 [04:41<00:04, 10.98it/s, est. speed input: 1019.56 toks/s, output: 10690.19 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2510/2560 [04:42<00:05,  9.54it/s, est. speed input: 1019.14 toks/s, output: 10700.58 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2512/2560 [04:42<00:06,  7.31it/s, est. speed input: 1018.57 toks/s, output: 10703.69 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2514/2560 [04:43<00:08,  5.49it/s, est. speed input: 1017.56 toks/s, output: 10697.92 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2515/2560 [04:43<00:09,  4.75it/s, est. speed input: 1016.62 toks/s, output: 10695.10 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2516/2560 [04:43<00:09,  4.88it/s, est. speed input: 1016.32 toks/s, output: 10699.10 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2518/2560 [04:43<00:07,  5.94it/s, est. speed input: 1016.39 toks/s, output: 10713.29 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2520/2560 [04:44<00:05,  7.34it/s, est. speed input: 1016.72 toks/s, output: 10729.57 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2521/2560 [04:45<00:10,  3.55it/s, est. speed input: 1013.88 toks/s, output: 10704.05 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2522/2560 [04:46<00:20,  1.86it/s, est. speed input: 1009.18 toks/s, output: 10659.36 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2523/2560 [04:46<00:17,  2.13it/s, est. speed input: 1008.68 toks/s, output: 10659.28 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2524/2560 [04:47<00:15,  2.39it/s, est. speed input: 1008.59 toks/s, output: 10659.94 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2526/2560 [04:48<00:21,  1.60it/s, est. speed input: 1003.16 toks/s, output: 10611.46 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2527/2560 [04:48<00:17,  1.93it/s, est. speed input: 1002.86 toks/s, output: 10616.30 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2528/2560 [04:49<00:13,  2.33it/s, est. speed input: 1002.53 toks/s, output: 10620.99 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2529/2560 [04:49<00:10,  2.90it/s, est. speed input: 1002.41 toks/s, output: 10627.76 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2530/2560 [04:49<00:08,  3.41it/s, est. speed input: 1002.63 toks/s, output: 10632.71 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2531/2560 [04:49<00:06,  4.18it/s, est. speed input: 1002.52 toks/s, output: 10635.92 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2532/2560 [04:50<00:09,  2.90it/s, est. speed input: 1001.15 toks/s, output: 10624.09 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2533/2560 [04:50<00:09,  2.97it/s, est. speed input: 1000.70 toks/s, output: 10623.18 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2534/2560 [04:51<00:11,  2.27it/s, est. speed input: 998.50 toks/s, output: 10608.50 toks/s] [A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2537/2560 [04:51<00:07,  2.94it/s, est. speed input: 996.63 toks/s, output: 10611.65 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2539/2560 [04:55<00:19,  1.10it/s, est. speed input: 983.98 toks/s, output: 10490.02 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2540/2560 [04:57<00:21,  1.10s/it, est. speed input: 978.22 toks/s, output: 10435.17 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2541/2560 [04:57<00:16,  1.12it/s, est. speed input: 978.05 toks/s, output: 10439.94 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2542/2560 [04:58<00:12,  1.40it/s, est. speed input: 977.90 toks/s, output: 10444.73 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2543/2560 [04:59<00:13,  1.22it/s, est. speed input: 974.54 toks/s, output: 10415.19 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2544/2560 [05:00<00:14,  1.10it/s, est. speed input: 971.18 toks/s, output: 10386.18 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2545/2560 [05:00<00:11,  1.29it/s, est. speed input: 970.13 toks/s, output: 10381.17 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2547/2560 [05:00<00:05,  2.18it/s, est. speed input: 970.53 toks/s, output: 10397.77 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2549/2560 [05:01<00:04,  2.56it/s, est. speed input: 969.48 toks/s, output: 10398.78 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2551/2560 [05:01<00:02,  3.02it/s, est. speed input: 968.46 toks/s, output: 10403.59 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2553/2560 [05:01<00:01,  4.20it/s, est. speed input: 969.15 toks/s, output: 10419.12 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2555/2560 [05:03<00:01,  2.98it/s, est. speed input: 966.41 toks/s, output: 10400.97 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2556/2560 [05:03<00:01,  3.00it/s, est. speed input: 965.65 toks/s, output: 10400.08 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2557/2560 [05:04<00:01,  1.90it/s, est. speed input: 962.19 toks/s, output: 10367.79 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2558/2560 [05:06<00:01,  1.18it/s, est. speed input: 956.41 toks/s, output: 10313.07 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2560/2560 [05:06<00:00,  1.83it/s, est. speed input: 956.27 toks/s, output: 10326.88 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2560/2560 [05:06<00:00,  8.35it/s, est. speed input: 956.27 toks/s, output: 10326.88 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/2560 [00:00<?, ?it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2560/2560 [00:00<00:00, 52951.85it/s]
{'num_samples': 320, 'num_scores': 2560, 'timeout_samples': 0, 'empty_samples': 3, 'acc': 33.1, 'total_acc': 33.828125, 'pass_at_k_percent': {'1': 33.8, '8': 72.8}, 'pass_at_k_valid_counts': {'1': 320, '8': 320}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_noise_rlvr_1_5b_128batchsize_deepscaler_noise_robust_qwen25-math-cot/base__Qwen2.5-math-1.5B/g1/amc23x8/test_qwen25-math-cot_-1_seed0_t0.6_s0_e-1.jsonl
[2025-09-23 15:23:36] ‚úì base__Qwen2.5-math-1.5B/g1/amc23x8  acc=33.1 pass_at_k={'1': 33.8, '8': 72.8}
base__Qwen2.5-math-1.5B/g1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [09:59<05:02, 302.77s/ds]==================================================
data: aime24x8  ,remain samples: 240
{'idx': 0, 'id': 60, 'problem': 'Every morning Aya goes for a $9$-kilometer-long walk and stops at a coffee shop afterwards. When she walks at a constant speed of $s$ kilometers per hour, the walk takes her 4 hours, including $t$ minutes spent in the coffee shop. When she walks $s+2$ kilometers per hour, the walk takes her 2 hours and 24 minutes, including $t$ minutes spent in the coffee shop. Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find the number of minutes the walk takes her, including the $t$ minutes spent in the coffee shop.', 'solution': '$\\frac{9}{s} + t = 4$ in hours and $\\frac{9}{s+2} + t = 2.4$ in hours.\nSubtracting the second equation from the first, we get, \n$\\frac{9}{s} - \\frac{9}{s+2} = 1.6$\nMultiplying by $(s)(s+2)$, we get \n$9s+18-9s=18=1.6s^{2} + 3.2s$\nMultiplying by 5/2 on both sides, we get\n$0 = 4s^{2} + 8s - 45$\nFactoring gives us \n$(2s-5)(2s+9) = 0$, of which the solution we want is $s=2.5$.\nSubstituting this back to the first equation, we can find that $t = 0.4$ hours.\nLastly, $s + \\frac{1}{2} = 3$ kilometers per hour, so\n$\\frac{9}{3} + 0.4 = 3.4$ hours, or $\\framebox{204}$ minutes\n-Failure.net\nThe amount of hours spent while walking on the first travel is $\\frac{240-t}{6}$. Thus, we have the equation $(240-t)(s) = 540$, and by the same logic, the second equation yields $(144-t)(s+2) = 540$. We have $240s-st = 540$, and $288+144s-2t-st = 540$. We subtract the two equations to get $96s+2t-288 = 0$, so we have $48s+t = 144$, so $t = 144-48s$, and now we have $(96+48s)(s) = 540$. The numerator of $s$ must evenly divide 540, however, $s$ must be less than 3. We can guess that $s = 2.5$. Now, $2.5+0.5 = 3$. Taking $\\frac{9}{3} = 3$, we find that it will take three hours for the 9 kilometers to be traveled. The t minutes spent at the coffeeshop can be written as $144-48(2.5)$, so t = 24. $180 + 24 = 204$. -sepehr2010', 'answer': '204', 'url': 'https://artofproblemsolving.com/wiki/index.php/2024_AIME_I_Problems/Problem_1', 'question': 'Every morning Aya goes for a $9$-kilometer-long walk and stops at a coffee shop afterwards. When she walks at a constant speed of $s$ kilometers per hour, the walk takes her 4 hours, including $t$ minutes spent in the coffee shop. When she walks $s+2$ kilometers per hour, the walk takes her 2 hours and 24 minutes, including $t$ minutes spent in the coffee shop. Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find the number of minutes the walk takes her, including the $t$ minutes spent in the coffee shop.'}

  0%|          | 0/240 [00:00<?, ?it/s][A<|im_start|>system
Please reason step by step, and put your final answer within \boxed{{}}.<|im_end|>
<|im_start|>user
Every morning Aya goes for a $9$-kilometer-long walk and stops at a coffee shop afterwards. When she walks at a constant speed of $s$ kilometers per hour, the walk takes her 4 hours, including $t$ minutes spent in the coffee shop. When she walks $s+2$ kilometers per hour, the walk takes her 2 hours and 24 minutes, including $t$ minutes spent in the coffee shop. Suppose Aya walks at $s+\frac{1}{2}$ kilometers per hour. Find the number of minutes the walk takes her, including the $t$ minutes spent in the coffee shop.<|im_end|>
<|im_start|>assistant


 19%|‚ñà‚ñâ        | 46/240 [00:00<00:00, 459.48it/s][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 92/240 [00:00<00:00, 459.28it/s][A
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 138/240 [00:00<00:00, 459.47it/s][A
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 185/240 [00:00<00:00, 459.85it/s][A
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 232/240 [00:00<00:00, 461.87it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<00:00, 460.98it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/1920 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 1/1920 [00:02<1:24:20,  2.64s/it, est. speed input: 40.58 toks/s, output: 56.51 toks/s][A
Processed prompts:   0%|          | 2/1920 [00:03<47:08,  1.47s/it, est. speed input: 160.70 toks/s, output: 100.06 toks/s][A
Processed prompts:   0%|          | 4/1920 [00:03<18:58,  1.68it/s, est. speed input: 301.57 toks/s, output: 208.51 toks/s][A
Processed prompts:   0%|          | 5/1920 [00:04<23:50,  1.34it/s, est. speed input: 275.28 toks/s, output: 213.20 toks/s][A
Processed prompts:   0%|          | 6/1920 [00:04<19:50,  1.61it/s, est. speed input: 299.05 toks/s, output: 252.60 toks/s][A
Processed prompts:   0%|          | 7/1920 [00:05<24:44,  1.29it/s, est. speed input: 258.08 toks/s, output: 255.91 toks/s][A
Processed prompts:   0%|          | 8/1920 [00:06<22:54,  1.39it/s, est. speed input: 254.98 toks/s, output: 283.70 toks/s][A
Processed prompts:   0%|          | 9/1920 [00:06<19:34,  1.63it/s, est. speed input: 260.09 toks/s, output: 318.89 toks/s][A
Processed prompts:   1%|          | 10/1920 [00:07<18:06,  1.76it/s, est. speed input: 262.18 toks/s, output: 348.99 toks/s][A
Processed prompts:   1%|          | 11/1920 [00:08<21:01,  1.51it/s, est. speed input: 255.90 toks/s, output: 361.17 toks/s][A
Processed prompts:   1%|          | 12/1920 [00:08<17:16,  1.84it/s, est. speed input: 260.22 toks/s, output: 398.85 toks/s][A
Processed prompts:   1%|          | 14/1920 [00:08<12:01,  2.64it/s, est. speed input: 282.14 toks/s, output: 477.99 toks/s][A
Processed prompts:   1%|          | 15/1920 [00:09<13:27,  2.36it/s, est. speed input: 273.59 toks/s, output: 498.63 toks/s][A
Processed prompts:   1%|          | 18/1920 [00:09<07:57,  3.98it/s, est. speed input: 303.49 toks/s, output: 629.71 toks/s][A
Processed prompts:   1%|          | 20/1920 [00:09<05:52,  5.40it/s, est. speed input: 330.84 toks/s, output: 720.48 toks/s][A
Processed prompts:   1%|          | 22/1920 [00:09<04:30,  7.02it/s, est. speed input: 357.22 toks/s, output: 810.54 toks/s][A
Processed prompts:   1%|‚ñè         | 24/1920 [00:10<03:55,  8.07it/s, est. speed input: 376.60 toks/s, output: 894.20 toks/s][A
Processed prompts:   1%|‚ñè         | 26/1920 [00:10<03:42,  8.51it/s, est. speed input: 391.44 toks/s, output: 973.39 toks/s][A
Processed prompts:   1%|‚ñè         | 28/1920 [00:10<03:03, 10.30it/s, est. speed input: 406.49 toks/s, output: 1047.20 toks/s][A
Processed prompts:   2%|‚ñè         | 30/1920 [00:10<03:07, 10.10it/s, est. speed input: 422.63 toks/s, output: 1124.23 toks/s][A
Processed prompts:   2%|‚ñè         | 32/1920 [00:10<02:45, 11.41it/s, est. speed input: 434.14 toks/s, output: 1208.56 toks/s][A
Processed prompts:   2%|‚ñè         | 36/1920 [00:10<01:55, 16.34it/s, est. speed input: 471.20 toks/s, output: 1389.28 toks/s][A
Processed prompts:   2%|‚ñè         | 39/1920 [00:10<01:37, 19.20it/s, est. speed input: 506.96 toks/s, output: 1522.60 toks/s][A
Processed prompts:   2%|‚ñè         | 42/1920 [00:11<01:35, 19.73it/s, est. speed input: 536.62 toks/s, output: 1648.99 toks/s][A
Processed prompts:   2%|‚ñè         | 45/1920 [00:11<01:49, 17.08it/s, est. speed input: 567.51 toks/s, output: 1761.46 toks/s][A
Processed prompts:   2%|‚ñè         | 47/1920 [00:11<02:13, 14.04it/s, est. speed input: 571.40 toks/s, output: 1824.35 toks/s][A
Processed prompts:   3%|‚ñé         | 49/1920 [00:11<02:52, 10.86it/s, est. speed input: 575.91 toks/s, output: 1873.82 toks/s][A
Processed prompts:   3%|‚ñé         | 51/1920 [00:12<02:57, 10.53it/s, est. speed input: 582.60 toks/s, output: 1938.86 toks/s][A
Processed prompts:   3%|‚ñé         | 54/1920 [00:12<02:35, 12.03it/s, est. speed input: 606.31 toks/s, output: 2054.68 toks/s][A
Processed prompts:   3%|‚ñé         | 56/1920 [00:12<02:44, 11.32it/s, est. speed input: 615.08 toks/s, output: 2117.71 toks/s][A
Processed prompts:   3%|‚ñé         | 58/1920 [00:12<02:41, 11.51it/s, est. speed input: 623.20 toks/s, output: 2187.50 toks/s][A
Processed prompts:   3%|‚ñé         | 60/1920 [00:12<02:23, 12.99it/s, est. speed input: 632.23 toks/s, output: 2267.43 toks/s][A
Processed prompts:   3%|‚ñé         | 62/1920 [00:12<02:20, 13.23it/s, est. speed input: 642.44 toks/s, output: 2339.44 toks/s][A
Processed prompts:   3%|‚ñé         | 64/1920 [00:13<02:51, 10.82it/s, est. speed input: 645.07 toks/s, output: 2388.52 toks/s][A
Processed prompts:   3%|‚ñé         | 66/1920 [00:13<02:45, 11.17it/s, est. speed input: 652.16 toks/s, output: 2456.20 toks/s][A
Processed prompts:   4%|‚ñé         | 70/1920 [00:13<01:51, 16.56it/s, est. speed input: 684.70 toks/s, output: 2631.97 toks/s][A
Processed prompts:   4%|‚ñç         | 73/1920 [00:14<03:07,  9.84it/s, est. speed input: 682.73 toks/s, output: 2657.67 toks/s][A
Processed prompts:   4%|‚ñç         | 75/1920 [00:14<03:12,  9.57it/s, est. speed input: 688.06 toks/s, output: 2712.71 toks/s][A
Processed prompts:   4%|‚ñç         | 77/1920 [00:14<04:24,  6.98it/s, est. speed input: 676.57 toks/s, output: 2713.75 toks/s][A
Processed prompts:   4%|‚ñç         | 79/1920 [00:14<03:38,  8.41it/s, est. speed input: 684.78 toks/s, output: 2790.22 toks/s][A
Processed prompts:   4%|‚ñç         | 81/1920 [00:15<03:20,  9.17it/s, est. speed input: 693.44 toks/s, output: 2854.58 toks/s][A
Processed prompts:   4%|‚ñç         | 83/1920 [00:15<04:00,  7.63it/s, est. speed input: 696.61 toks/s, output: 2880.02 toks/s][A
Processed prompts:   4%|‚ñç         | 85/1920 [00:15<05:14,  5.83it/s, est. speed input: 684.48 toks/s, output: 2860.75 toks/s][A
Processed prompts:   5%|‚ñç         | 87/1920 [00:16<05:00,  6.11it/s, est. speed input: 686.36 toks/s, output: 2904.77 toks/s][A
Processed prompts:   5%|‚ñç         | 89/1920 [00:16<05:18,  5.75it/s, est. speed input: 684.05 toks/s, output: 2902.22 toks/s][A
Processed prompts:   5%|‚ñç         | 90/1920 [00:17<07:21,  4.15it/s, est. speed input: 666.21 toks/s, output: 2855.39 toks/s][A
Processed prompts:   5%|‚ñç         | 91/1920 [00:17<06:30,  4.68it/s, est. speed input: 667.59 toks/s, output: 2886.39 toks/s][A
Processed prompts:   5%|‚ñç         | 92/1920 [00:17<07:09,  4.25it/s, est. speed input: 665.38 toks/s, output: 2883.21 toks/s][A
Processed prompts:   5%|‚ñç         | 94/1920 [00:17<05:14,  5.81it/s, est. speed input: 674.86 toks/s, output: 2955.45 toks/s][A
Processed prompts:   5%|‚ñç         | 95/1920 [00:18<07:55,  3.84it/s, est. speed input: 659.32 toks/s, output: 2909.74 toks/s][A
Processed prompts:   5%|‚ñå         | 96/1920 [00:18<07:14,  4.20it/s, est. speed input: 662.97 toks/s, output: 2931.51 toks/s][A
Processed prompts:   5%|‚ñå         | 97/1920 [00:18<07:28,  4.07it/s, est. speed input: 659.12 toks/s, output: 2921.17 toks/s][A
Processed prompts:   5%|‚ñå         | 99/1920 [00:18<05:38,  5.38it/s, est. speed input: 664.40 toks/s, output: 2985.04 toks/s][A
Processed prompts:   5%|‚ñå         | 102/1920 [00:19<04:20,  6.97it/s, est. speed input: 682.70 toks/s, output: 3082.80 toks/s][A
Processed prompts:   5%|‚ñå         | 104/1920 [00:19<03:34,  8.47it/s, est. speed input: 688.17 toks/s, output: 3130.34 toks/s][A
Processed prompts:   6%|‚ñå         | 106/1920 [00:19<03:08,  9.62it/s, est. speed input: 695.08 toks/s, output: 3185.96 toks/s][A
Processed prompts:   6%|‚ñå         | 108/1920 [00:19<03:48,  7.94it/s, est. speed input: 693.18 toks/s, output: 3224.68 toks/s][A
Processed prompts:   6%|‚ñå         | 110/1920 [00:20<04:09,  7.25it/s, est. speed input: 691.57 toks/s, output: 3254.75 toks/s][A
Processed prompts:   6%|‚ñå         | 112/1920 [00:20<03:27,  8.70it/s, est. speed input: 698.87 toks/s, output: 3302.06 toks/s][A
Processed prompts:   6%|‚ñå         | 114/1920 [00:20<05:20,  5.63it/s, est. speed input: 687.68 toks/s, output: 3296.39 toks/s][A
Processed prompts:   6%|‚ñå         | 115/1920 [00:21<07:04,  4.25it/s, est. speed input: 675.42 toks/s, output: 3267.29 toks/s][A
Processed prompts:   6%|‚ñå         | 117/1920 [00:21<05:12,  5.77it/s, est. speed input: 687.33 toks/s, output: 3347.78 toks/s][A
Processed prompts:   6%|‚ñå         | 119/1920 [00:21<05:01,  5.97it/s, est. speed input: 692.96 toks/s, output: 3368.22 toks/s][A
Processed prompts:   6%|‚ñã         | 122/1920 [00:22<03:27,  8.65it/s, est. speed input: 705.30 toks/s, output: 3492.86 toks/s][A
Processed prompts:   7%|‚ñã         | 126/1920 [00:22<02:21, 12.64it/s, est. speed input: 724.61 toks/s, output: 3636.56 toks/s][A
Processed prompts:   7%|‚ñã         | 128/1920 [00:22<02:09, 13.79it/s, est. speed input: 735.73 toks/s, output: 3694.03 toks/s][A
Processed prompts:   7%|‚ñã         | 130/1920 [00:22<02:47, 10.66it/s, est. speed input: 737.24 toks/s, output: 3716.94 toks/s][A
Processed prompts:   7%|‚ñã         | 132/1920 [00:22<02:37, 11.35it/s, est. speed input: 744.03 toks/s, output: 3788.87 toks/s][A
Processed prompts:   7%|‚ñã         | 135/1920 [00:22<02:38, 11.27it/s, est. speed input: 766.96 toks/s, output: 3887.49 toks/s][A
Processed prompts:   7%|‚ñã         | 137/1920 [00:23<02:25, 12.22it/s, est. speed input: 770.99 toks/s, output: 3954.10 toks/s][A
Processed prompts:   7%|‚ñã         | 139/1920 [00:23<03:25,  8.69it/s, est. speed input: 769.28 toks/s, output: 3980.30 toks/s][A
Processed prompts:   7%|‚ñã         | 141/1920 [00:23<03:49,  7.74it/s, est. speed input: 766.54 toks/s, output: 3980.04 toks/s][A
Processed prompts:   7%|‚ñã         | 143/1920 [00:24<03:57,  7.47it/s, est. speed input: 765.16 toks/s, output: 3987.51 toks/s][A
Processed prompts:   8%|‚ñä         | 145/1920 [00:24<03:21,  8.81it/s, est. speed input: 774.62 toks/s, output: 4062.53 toks/s][A
Processed prompts:   8%|‚ñä         | 147/1920 [00:24<02:55, 10.12it/s, est. speed input: 784.70 toks/s, output: 4137.09 toks/s][A
Processed prompts:   8%|‚ñä         | 149/1920 [00:24<02:47, 10.60it/s, est. speed input: 789.66 toks/s, output: 4204.55 toks/s][A
Processed prompts:   8%|‚ñä         | 151/1920 [00:24<02:36, 11.33it/s, est. speed input: 791.45 toks/s, output: 4216.37 toks/s][A
Processed prompts:   8%|‚ñä         | 153/1920 [00:25<03:12,  9.19it/s, est. speed input: 792.65 toks/s, output: 4258.95 toks/s][A
Processed prompts:   8%|‚ñä         | 155/1920 [00:25<03:04,  9.57it/s, est. speed input: 796.24 toks/s, output: 4322.74 toks/s][A
Processed prompts:   8%|‚ñä         | 158/1920 [00:25<02:36, 11.29it/s, est. speed input: 809.52 toks/s, output: 4433.55 toks/s][A
Processed prompts:   8%|‚ñä         | 160/1920 [00:25<02:49, 10.40it/s, est. speed input: 810.59 toks/s, output: 4488.92 toks/s][A
Processed prompts:   8%|‚ñä         | 162/1920 [00:25<03:03,  9.58it/s, est. speed input: 810.09 toks/s, output: 4513.02 toks/s][A
Processed prompts:   9%|‚ñä         | 164/1920 [00:25<02:37, 11.18it/s, est. speed input: 814.08 toks/s, output: 4576.42 toks/s][A
Processed prompts:   9%|‚ñä         | 166/1920 [00:26<02:54, 10.03it/s, est. speed input: 817.96 toks/s, output: 4628.65 toks/s][A
Processed prompts:   9%|‚ñâ         | 168/1920 [00:26<05:11,  5.62it/s, est. speed input: 803.95 toks/s, output: 4573.37 toks/s][A
Processed prompts:   9%|‚ñâ         | 169/1920 [00:27<04:50,  6.02it/s, est. speed input: 804.62 toks/s, output: 4602.79 toks/s][A
Processed prompts:   9%|‚ñâ         | 171/1920 [00:27<04:09,  7.02it/s, est. speed input: 806.00 toks/s, output: 4640.45 toks/s][A
Processed prompts:   9%|‚ñâ         | 172/1920 [00:27<03:56,  7.40it/s, est. speed input: 806.21 toks/s, output: 4670.63 toks/s][A
Processed prompts:   9%|‚ñâ         | 174/1920 [00:27<03:31,  8.25it/s, est. speed input: 810.19 toks/s, output: 4712.12 toks/s][A
Processed prompts:   9%|‚ñâ         | 176/1920 [00:28<05:04,  5.72it/s, est. speed input: 803.40 toks/s, output: 4692.08 toks/s][A
Processed prompts:   9%|‚ñâ         | 179/1920 [00:28<03:37,  8.01it/s, est. speed input: 811.70 toks/s, output: 4807.92 toks/s][A
Processed prompts:   9%|‚ñâ         | 181/1920 [00:28<03:05,  9.35it/s, est. speed input: 815.82 toks/s, output: 4870.27 toks/s][A
Processed prompts:  10%|‚ñâ         | 183/1920 [00:28<02:58,  9.71it/s, est. speed input: 817.42 toks/s, output: 4909.88 toks/s][A
Processed prompts:  10%|‚ñâ         | 185/1920 [00:28<03:09,  9.15it/s, est. speed input: 824.23 toks/s, output: 4962.97 toks/s][A
Processed prompts:  10%|‚ñâ         | 187/1920 [00:28<02:50, 10.16it/s, est. speed input: 829.57 toks/s, output: 5018.73 toks/s][A
Processed prompts:  10%|‚ñâ         | 189/1920 [00:29<02:26, 11.83it/s, est. speed input: 833.41 toks/s, output: 5096.61 toks/s][A
Processed prompts:  10%|‚ñâ         | 191/1920 [00:29<02:19, 12.38it/s, est. speed input: 836.00 toks/s, output: 5167.08 toks/s][A
Processed prompts:  10%|‚ñà         | 193/1920 [00:29<03:09,  9.10it/s, est. speed input: 837.23 toks/s, output: 5141.43 toks/s][A
Processed prompts:  10%|‚ñà         | 195/1920 [00:30<04:52,  5.89it/s, est. speed input: 836.68 toks/s, output: 5112.05 toks/s][A
Processed prompts:  10%|‚ñà         | 199/1920 [00:30<03:10,  9.04it/s, est. speed input: 851.56 toks/s, output: 5196.22 toks/s][A
Processed prompts:  10%|‚ñà         | 201/1920 [00:30<03:42,  7.72it/s, est. speed input: 847.19 toks/s, output: 5181.46 toks/s][A
Processed prompts:  11%|‚ñà         | 203/1920 [00:30<03:12,  8.94it/s, est. speed input: 852.76 toks/s, output: 5207.39 toks/s][A
Processed prompts:  11%|‚ñà         | 205/1920 [00:31<03:37,  7.89it/s, est. speed input: 852.63 toks/s, output: 5246.63 toks/s][A
Processed prompts:  11%|‚ñà         | 207/1920 [00:31<03:01,  9.45it/s, est. speed input: 856.99 toks/s, output: 5324.23 toks/s][A
Processed prompts:  11%|‚ñà         | 209/1920 [00:31<03:35,  7.93it/s, est. speed input: 854.94 toks/s, output: 5317.72 toks/s][A
Processed prompts:  11%|‚ñà         | 211/1920 [00:32<04:31,  6.29it/s, est. speed input: 850.96 toks/s, output: 5313.82 toks/s][A
Processed prompts:  11%|‚ñà         | 214/1920 [00:32<03:10,  8.97it/s, est. speed input: 859.96 toks/s, output: 5424.66 toks/s][A
Processed prompts:  11%|‚ñà‚ñè        | 216/1920 [00:32<04:41,  6.05it/s, est. speed input: 853.84 toks/s, output: 5361.03 toks/s][A
Processed prompts:  11%|‚ñà‚ñè        | 219/1920 [00:33<03:46,  7.52it/s, est. speed input: 861.01 toks/s, output: 5449.54 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 221/1920 [00:33<03:28,  8.14it/s, est. speed input: 861.86 toks/s, output: 5484.76 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 223/1920 [00:33<03:29,  8.10it/s, est. speed input: 872.63 toks/s, output: 5474.40 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 225/1920 [00:34<05:57,  4.74it/s, est. speed input: 858.02 toks/s, output: 5429.56 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 226/1920 [00:34<05:27,  5.17it/s, est. speed input: 857.70 toks/s, output: 5443.99 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 227/1920 [00:34<05:27,  5.17it/s, est. speed input: 858.95 toks/s, output: 5425.97 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 229/1920 [00:34<04:09,  6.79it/s, est. speed input: 864.56 toks/s, output: 5478.48 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 233/1920 [00:34<02:34, 10.90it/s, est. speed input: 878.59 toks/s, output: 5613.77 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 235/1920 [00:35<03:22,  8.31it/s, est. speed input: 876.13 toks/s, output: 5631.46 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 237/1920 [00:35<03:58,  7.05it/s, est. speed input: 873.06 toks/s, output: 5609.04 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 238/1920 [00:35<03:48,  7.36it/s, est. speed input: 872.71 toks/s, output: 5624.47 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 241/1920 [00:36<02:47, 10.00it/s, est. speed input: 882.00 toks/s, output: 5677.30 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 243/1920 [00:36<02:44, 10.16it/s, est. speed input: 883.02 toks/s, output: 5707.27 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 245/1920 [00:36<03:22,  8.26it/s, est. speed input: 890.84 toks/s, output: 5671.94 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 247/1920 [00:36<03:45,  7.43it/s, est. speed input: 888.19 toks/s, output: 5671.23 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 249/1920 [00:37<03:09,  8.81it/s, est. speed input: 890.97 toks/s, output: 5709.19 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 251/1920 [00:37<05:39,  4.91it/s, est. speed input: 881.05 toks/s, output: 5652.44 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 252/1920 [00:38<06:17,  4.42it/s, est. speed input: 878.08 toks/s, output: 5636.98 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 255/1920 [00:38<04:26,  6.26it/s, est. speed input: 884.93 toks/s, output: 5668.41 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 257/1920 [00:38<03:39,  7.58it/s, est. speed input: 887.82 toks/s, output: 5744.69 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 259/1920 [00:39<05:28,  5.06it/s, est. speed input: 879.41 toks/s, output: 5704.86 toks/s][A
Processed prompts:  14%|‚ñà‚ñé        | 261/1920 [00:39<04:42,  5.87it/s, est. speed input: 882.42 toks/s, output: 5723.03 toks/s][A
Processed prompts:  14%|‚ñà‚ñé        | 263/1920 [00:39<03:45,  7.36it/s, est. speed input: 888.75 toks/s, output: 5739.95 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 266/1920 [00:39<02:49,  9.75it/s, est. speed input: 894.59 toks/s, output: 5778.73 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 268/1920 [00:40<03:50,  7.18it/s, est. speed input: 891.52 toks/s, output: 5784.30 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 271/1920 [00:40<03:21,  8.18it/s, est. speed input: 896.95 toks/s, output: 5795.94 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 274/1920 [00:40<02:36, 10.51it/s, est. speed input: 901.33 toks/s, output: 5849.43 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 277/1920 [00:40<02:19, 11.75it/s, est. speed input: 904.56 toks/s, output: 5904.76 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 281/1920 [00:41<02:02, 13.38it/s, est. speed input: 911.37 toks/s, output: 5976.70 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 283/1920 [00:41<02:05, 13.01it/s, est. speed input: 912.23 toks/s, output: 5984.24 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 285/1920 [00:41<02:12, 12.32it/s, est. speed input: 916.40 toks/s, output: 5991.28 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 287/1920 [00:41<03:19,  8.20it/s, est. speed input: 910.26 toks/s, output: 5986.35 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 289/1920 [00:42<03:50,  7.06it/s, est. speed input: 914.91 toks/s, output: 5950.61 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 293/1920 [00:42<02:34, 10.54it/s, est. speed input: 922.30 toks/s, output: 6039.18 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 295/1920 [00:42<03:38,  7.43it/s, est. speed input: 915.75 toks/s, output: 6014.77 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 297/1920 [00:43<03:48,  7.10it/s, est. speed input: 914.99 toks/s, output: 6007.49 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 299/1920 [00:43<03:19,  8.11it/s, est. speed input: 916.73 toks/s, output: 6052.14 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 301/1920 [00:43<03:25,  7.86it/s, est. speed input: 918.81 toks/s, output: 6059.19 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 302/1920 [00:44<04:21,  6.19it/s, est. speed input: 916.93 toks/s, output: 6034.73 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 304/1920 [00:44<03:38,  7.38it/s, est. speed input: 920.35 toks/s, output: 6095.10 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 305/1920 [00:44<05:10,  5.21it/s, est. speed input: 914.20 toks/s, output: 6046.81 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 306/1920 [00:45<06:31,  4.13it/s, est. speed input: 907.95 toks/s, output: 6015.00 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 308/1920 [00:45<04:53,  5.50it/s, est. speed input: 908.73 toks/s, output: 6023.90 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 309/1920 [00:45<05:13,  5.14it/s, est. speed input: 906.79 toks/s, output: 6003.65 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 311/1920 [00:46<06:16,  4.28it/s, est. speed input: 907.29 toks/s, output: 5998.44 toks/s][A
Processed prompts:  16%|‚ñà‚ñã        | 313/1920 [00:46<07:22,  3.63it/s, est. speed input: 898.31 toks/s, output: 5941.52 toks/s][A
Processed prompts:  16%|‚ñà‚ñã        | 315/1920 [00:46<05:22,  4.98it/s, est. speed input: 901.01 toks/s, output: 5980.96 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 318/1920 [00:47<03:37,  7.37it/s, est. speed input: 915.05 toks/s, output: 6014.34 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 320/1920 [00:47<03:49,  6.97it/s, est. speed input: 915.90 toks/s, output: 6066.00 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 322/1920 [00:47<04:21,  6.12it/s, est. speed input: 913.21 toks/s, output: 6038.72 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 323/1920 [00:48<04:48,  5.54it/s, est. speed input: 910.45 toks/s, output: 6038.44 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 324/1920 [00:48<04:38,  5.74it/s, est. speed input: 911.39 toks/s, output: 6055.51 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 325/1920 [00:48<06:54,  3.85it/s, est. speed input: 902.71 toks/s, output: 6002.30 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 326/1920 [00:49<06:56,  3.82it/s, est. speed input: 899.96 toks/s, output: 6002.51 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 329/1920 [00:49<05:13,  5.07it/s, est. speed input: 899.76 toks/s, output: 6007.12 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 331/1920 [00:49<04:07,  6.42it/s, est. speed input: 900.70 toks/s, output: 6039.69 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 334/1920 [00:49<03:48,  6.94it/s, est. speed input: 901.87 toks/s, output: 6097.22 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 335/1920 [00:50<04:05,  6.45it/s, est. speed input: 899.88 toks/s, output: 6089.36 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 336/1920 [00:50<04:34,  5.76it/s, est. speed input: 897.63 toks/s, output: 6087.22 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 337/1920 [00:50<05:22,  4.91it/s, est. speed input: 894.14 toks/s, output: 6061.93 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 340/1920 [00:50<03:37,  7.26it/s, est. speed input: 897.13 toks/s, output: 6097.69 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 342/1920 [00:51<03:37,  7.25it/s, est. speed input: 895.58 toks/s, output: 6097.28 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 343/1920 [00:51<05:10,  5.07it/s, est. speed input: 889.62 toks/s, output: 6055.15 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 344/1920 [00:52<06:23,  4.11it/s, est. speed input: 884.49 toks/s, output: 6019.77 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 345/1920 [00:52<07:19,  3.58it/s, est. speed input: 879.75 toks/s, output: 5996.63 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 346/1920 [00:52<06:45,  3.88it/s, est. speed input: 878.05 toks/s, output: 5984.38 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 347/1920 [00:53<08:43,  3.00it/s, est. speed input: 871.67 toks/s, output: 5950.92 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 348/1920 [00:53<08:10,  3.21it/s, est. speed input: 869.20 toks/s, output: 5947.33 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 350/1920 [00:53<05:21,  4.88it/s, est. speed input: 871.47 toks/s, output: 5972.97 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 351/1920 [00:53<05:00,  5.21it/s, est. speed input: 870.81 toks/s, output: 5968.46 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 352/1920 [00:54<05:34,  4.69it/s, est. speed input: 868.72 toks/s, output: 5947.55 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 353/1920 [00:54<05:16,  4.95it/s, est. speed input: 868.49 toks/s, output: 5975.29 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 355/1920 [00:54<04:32,  5.73it/s, est. speed input: 869.39 toks/s, output: 5971.97 toks/s][A
Processed prompts:  19%|‚ñà‚ñä        | 358/1920 [00:55<07:10,  3.63it/s, est. speed input: 858.02 toks/s, output: 5900.93 toks/s][A
Processed prompts:  19%|‚ñà‚ñä        | 359/1920 [00:55<07:41,  3.39it/s, est. speed input: 854.47 toks/s, output: 5871.57 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 360/1920 [00:56<06:39,  3.90it/s, est. speed input: 854.85 toks/s, output: 5890.48 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 361/1920 [00:56<06:38,  3.91it/s, est. speed input: 852.39 toks/s, output: 5874.95 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 363/1920 [00:56<04:54,  5.29it/s, est. speed input: 853.19 toks/s, output: 5910.57 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 364/1920 [00:56<04:40,  5.54it/s, est. speed input: 853.79 toks/s, output: 5911.85 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 365/1920 [00:56<04:30,  5.75it/s, est. speed input: 852.90 toks/s, output: 5907.33 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 367/1920 [00:57<04:54,  5.27it/s, est. speed input: 850.21 toks/s, output: 5908.18 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 368/1920 [00:57<04:48,  5.39it/s, est. speed input: 850.36 toks/s, output: 5926.08 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 369/1920 [00:57<05:54,  4.38it/s, est. speed input: 846.70 toks/s, output: 5902.92 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 370/1920 [00:57<05:14,  4.93it/s, est. speed input: 846.44 toks/s, output: 5903.50 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 371/1920 [00:58<05:27,  4.73it/s, est. speed input: 844.47 toks/s, output: 5888.33 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 373/1920 [00:58<04:56,  5.22it/s, est. speed input: 842.97 toks/s, output: 5897.97 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 374/1920 [00:58<04:50,  5.32it/s, est. speed input: 842.14 toks/s, output: 5901.29 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 375/1920 [00:58<04:46,  5.39it/s, est. speed input: 841.22 toks/s, output: 5929.80 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 376/1920 [00:59<05:51,  4.39it/s, est. speed input: 837.64 toks/s, output: 5908.23 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 378/1920 [00:59<04:18,  5.96it/s, est. speed input: 844.42 toks/s, output: 5949.60 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 379/1920 [00:59<03:57,  6.49it/s, est. speed input: 845.61 toks/s, output: 5957.06 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 380/1920 [00:59<04:37,  5.54it/s, est. speed input: 843.73 toks/s, output: 5942.46 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 381/1920 [00:59<05:08,  4.99it/s, est. speed input: 843.03 toks/s, output: 5940.96 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 383/1920 [01:00<04:07,  6.21it/s, est. speed input: 843.65 toks/s, output: 5982.62 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 385/1920 [01:00<03:55,  6.51it/s, est. speed input: 843.06 toks/s, output: 6005.56 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 387/1920 [01:00<03:17,  7.74it/s, est. speed input: 845.00 toks/s, output: 6018.99 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 389/1920 [01:00<02:38,  9.66it/s, est. speed input: 847.76 toks/s, output: 6042.84 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 391/1920 [01:01<03:11,  7.98it/s, est. speed input: 848.36 toks/s, output: 6047.74 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 392/1920 [01:01<04:22,  5.81it/s, est. speed input: 845.27 toks/s, output: 6024.08 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 393/1920 [01:01<04:39,  5.46it/s, est. speed input: 844.00 toks/s, output: 6018.80 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 395/1920 [01:02<05:18,  4.78it/s, est. speed input: 840.54 toks/s, output: 5989.36 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 396/1920 [01:02<08:10,  3.11it/s, est. speed input: 832.66 toks/s, output: 5934.21 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 397/1920 [01:03<07:46,  3.26it/s, est. speed input: 830.98 toks/s, output: 5922.05 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 399/1920 [01:03<07:51,  3.22it/s, est. speed input: 827.53 toks/s, output: 5914.11 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 400/1920 [01:04<08:13,  3.08it/s, est. speed input: 825.38 toks/s, output: 5903.73 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 401/1920 [01:04<08:20,  3.04it/s, est. speed input: 823.37 toks/s, output: 5886.34 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 403/1920 [01:04<06:41,  3.78it/s, est. speed input: 823.06 toks/s, output: 5881.77 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 404/1920 [01:05<06:02,  4.18it/s, est. speed input: 822.37 toks/s, output: 5883.54 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 405/1920 [01:05<07:35,  3.33it/s, est. speed input: 818.84 toks/s, output: 5864.08 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 406/1920 [01:05<06:23,  3.95it/s, est. speed input: 819.24 toks/s, output: 5863.87 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 407/1920 [01:05<05:51,  4.30it/s, est. speed input: 818.50 toks/s, output: 5865.15 toks/s][A
Processed prompts:  21%|‚ñà‚ñà‚ñè       | 409/1920 [01:06<04:31,  5.56it/s, est. speed input: 819.24 toks/s, output: 5870.59 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 423/1920 [01:06<00:59, 25.28it/s, est. speed input: 843.87 toks/s, output: 6136.24 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 430/1920 [01:06<00:48, 30.45it/s, est. speed input: 855.37 toks/s, output: 6238.83 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 441/1920 [01:06<00:33, 44.43it/s, est. speed input: 875.98 toks/s, output: 6714.88 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 487/1920 [01:06<00:11, 122.36it/s, est. speed input: 968.25 toks/s, output: 8778.80 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 502/1920 [01:12<02:36,  9.08it/s, est. speed input: 920.36 toks/s, output: 8279.00 toks/s] [A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 513/1920 [01:15<03:04,  7.63it/s, est. speed input: 910.98 toks/s, output: 8164.50 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 521/1920 [01:16<03:01,  7.71it/s, est. speed input: 911.96 toks/s, output: 8155.12 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 527/1920 [01:16<02:53,  8.02it/s, est. speed input: 916.55 toks/s, output: 8196.70 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 532/1920 [01:17<02:59,  7.75it/s, est. speed input: 914.44 toks/s, output: 8178.02 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 536/1920 [01:17<02:48,  8.21it/s, est. speed input: 919.19 toks/s, output: 8221.47 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 539/1920 [01:17<02:44,  8.37it/s, est. speed input: 925.25 toks/s, output: 8227.75 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 542/1920 [01:18<02:34,  8.94it/s, est. speed input: 929.59 toks/s, output: 8225.93 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 544/1920 [01:19<03:40,  6.25it/s, est. speed input: 922.39 toks/s, output: 8175.61 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 547/1920 [01:19<03:50,  5.96it/s, est. speed input: 919.20 toks/s, output: 8134.88 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñä       | 550/1920 [01:19<03:20,  6.82it/s, est. speed input: 922.03 toks/s, output: 8196.77 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 552/1920 [01:20<03:16,  6.96it/s, est. speed input: 922.42 toks/s, output: 8215.00 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 554/1920 [01:20<02:49,  8.05it/s, est. speed input: 924.47 toks/s, output: 8248.99 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 558/1920 [01:20<02:01, 11.21it/s, est. speed input: 929.03 toks/s, output: 8298.73 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 561/1920 [01:20<02:05, 10.80it/s, est. speed input: 929.60 toks/s, output: 8304.79 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 563/1920 [01:21<02:19,  9.70it/s, est. speed input: 929.72 toks/s, output: 8297.35 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 565/1920 [01:21<02:07, 10.64it/s, est. speed input: 931.94 toks/s, output: 8304.89 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 568/1920 [01:21<01:41, 13.38it/s, est. speed input: 935.46 toks/s, output: 8347.00 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 570/1920 [01:21<01:37, 13.89it/s, est. speed input: 936.47 toks/s, output: 8363.23 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 572/1920 [01:21<01:45, 12.77it/s, est. speed input: 937.60 toks/s, output: 8384.18 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 574/1920 [01:21<02:06, 10.62it/s, est. speed input: 937.84 toks/s, output: 8428.25 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 576/1920 [01:22<04:29,  4.98it/s, est. speed input: 930.38 toks/s, output: 8396.33 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 577/1920 [01:23<04:36,  4.86it/s, est. speed input: 929.08 toks/s, output: 8409.91 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 579/1920 [01:23<04:15,  5.24it/s, est. speed input: 927.92 toks/s, output: 8422.81 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 580/1920 [01:23<04:37,  4.83it/s, est. speed input: 926.78 toks/s, output: 8419.94 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 581/1920 [01:23<05:02,  4.43it/s, est. speed input: 924.51 toks/s, output: 8426.83 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 582/1920 [01:24<04:25,  5.04it/s, est. speed input: 924.34 toks/s, output: 8452.68 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 584/1920 [01:24<03:42,  6.01it/s, est. speed input: 923.66 toks/s, output: 8501.92 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 585/1920 [01:24<03:36,  6.17it/s, est. speed input: 923.17 toks/s, output: 8492.63 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 586/1920 [01:24<04:05,  5.43it/s, est. speed input: 922.41 toks/s, output: 8476.91 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 587/1920 [01:25<04:49,  4.60it/s, est. speed input: 920.11 toks/s, output: 8451.74 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 588/1920 [01:25<04:17,  5.17it/s, est. speed input: 920.32 toks/s, output: 8447.97 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 590/1920 [01:25<03:20,  6.62it/s, est. speed input: 921.78 toks/s, output: 8447.99 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 592/1920 [01:25<02:31,  8.77it/s, est. speed input: 922.80 toks/s, output: 8453.01 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 594/1920 [01:25<02:35,  8.54it/s, est. speed input: 922.86 toks/s, output: 8443.82 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 595/1920 [01:25<02:32,  8.70it/s, est. speed input: 923.30 toks/s, output: 8442.54 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 597/1920 [01:26<02:37,  8.37it/s, est. speed input: 922.96 toks/s, output: 8444.01 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà‚ñè      | 600/1920 [01:26<02:46,  7.93it/s, est. speed input: 923.58 toks/s, output: 8457.81 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà‚ñè      | 604/1920 [01:26<02:37,  8.37it/s, est. speed input: 926.00 toks/s, output: 8454.96 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 605/1920 [01:27<02:50,  7.73it/s, est. speed input: 925.85 toks/s, output: 8446.29 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 607/1920 [01:27<03:01,  7.24it/s, est. speed input: 928.40 toks/s, output: 8432.27 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 608/1920 [01:27<02:58,  7.34it/s, est. speed input: 928.45 toks/s, output: 8438.33 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 610/1920 [01:27<02:27,  8.85it/s, est. speed input: 929.59 toks/s, output: 8453.92 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 611/1920 [01:27<03:02,  7.17it/s, est. speed input: 927.84 toks/s, output: 8445.78 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 613/1920 [01:28<02:47,  7.81it/s, est. speed input: 928.64 toks/s, output: 8445.64 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 614/1920 [01:28<02:58,  7.34it/s, est. speed input: 927.89 toks/s, output: 8439.75 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 616/1920 [01:28<03:08,  6.91it/s, est. speed input: 926.88 toks/s, output: 8454.54 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 617/1920 [01:29<04:51,  4.47it/s, est. speed input: 922.28 toks/s, output: 8410.61 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 619/1920 [01:29<04:05,  5.31it/s, est. speed input: 922.16 toks/s, output: 8425.62 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 620/1920 [01:29<03:54,  5.55it/s, est. speed input: 922.21 toks/s, output: 8445.91 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 622/1920 [01:29<03:38,  5.94it/s, est. speed input: 921.60 toks/s, output: 8447.55 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 626/1920 [01:30<02:25,  8.92it/s, est. speed input: 924.72 toks/s, output: 8464.46 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 629/1920 [01:30<01:55, 11.15it/s, est. speed input: 927.75 toks/s, output: 8497.67 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 631/1920 [01:30<01:43, 12.44it/s, est. speed input: 929.48 toks/s, output: 8533.21 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 633/1920 [01:30<02:02, 10.49it/s, est. speed input: 929.10 toks/s, output: 8525.07 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 635/1920 [01:30<02:17,  9.37it/s, est. speed input: 929.27 toks/s, output: 8523.40 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 637/1920 [01:31<02:05, 10.26it/s, est. speed input: 929.55 toks/s, output: 8577.00 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 639/1920 [01:31<01:56, 11.03it/s, est. speed input: 934.07 toks/s, output: 8598.62 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 642/1920 [01:31<01:50, 11.57it/s, est. speed input: 935.49 toks/s, output: 8665.97 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñé      | 644/1920 [01:31<01:39, 12.88it/s, est. speed input: 936.92 toks/s, output: 8722.95 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñé      | 646/1920 [01:31<01:56, 10.92it/s, est. speed input: 936.34 toks/s, output: 8712.05 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 648/1920 [01:31<01:54, 11.10it/s, est. speed input: 939.51 toks/s, output: 8762.50 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 651/1920 [01:32<01:35, 13.33it/s, est. speed input: 944.38 toks/s, output: 8809.29 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 653/1920 [01:32<01:42, 12.41it/s, est. speed input: 944.19 toks/s, output: 8804.73 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 656/1920 [01:32<01:21, 15.46it/s, est. speed input: 947.83 toks/s, output: 8860.05 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 661/1920 [01:32<01:01, 20.39it/s, est. speed input: 950.65 toks/s, output: 8892.34 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 664/1920 [01:32<01:34, 13.34it/s, est. speed input: 949.59 toks/s, output: 8881.33 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 666/1920 [01:33<02:30,  8.33it/s, est. speed input: 947.14 toks/s, output: 8841.45 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 668/1920 [01:34<03:15,  6.41it/s, est. speed input: 944.86 toks/s, output: 8830.33 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 670/1920 [01:34<03:02,  6.83it/s, est. speed input: 944.50 toks/s, output: 8839.64 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 673/1920 [01:34<02:29,  8.32it/s, est. speed input: 946.02 toks/s, output: 8843.77 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 675/1920 [01:34<02:32,  8.19it/s, est. speed input: 947.88 toks/s, output: 8884.74 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 678/1920 [01:34<02:04, 10.02it/s, est. speed input: 949.44 toks/s, output: 8908.78 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 680/1920 [01:35<02:32,  8.16it/s, est. speed input: 948.96 toks/s, output: 8894.18 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 682/1920 [01:35<02:26,  8.46it/s, est. speed input: 948.97 toks/s, output: 8889.74 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 684/1920 [01:36<03:05,  6.68it/s, est. speed input: 946.55 toks/s, output: 8910.41 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 686/1920 [01:36<03:15,  6.32it/s, est. speed input: 946.34 toks/s, output: 8890.88 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 687/1920 [01:36<03:08,  6.54it/s, est. speed input: 946.69 toks/s, output: 8887.46 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 689/1920 [01:36<02:41,  7.62it/s, est. speed input: 947.56 toks/s, output: 8910.83 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 690/1920 [01:36<02:40,  7.66it/s, est. speed input: 947.13 toks/s, output: 8908.55 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 692/1920 [01:37<03:01,  6.77it/s, est. speed input: 945.89 toks/s, output: 8898.58 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 693/1920 [01:37<02:51,  7.16it/s, est. speed input: 945.99 toks/s, output: 8915.39 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 694/1920 [01:37<03:39,  5.60it/s, est. speed input: 944.02 toks/s, output: 8895.18 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñã      | 697/1920 [01:38<03:20,  6.09it/s, est. speed input: 944.39 toks/s, output: 8909.50 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñã      | 699/1920 [01:38<02:49,  7.19it/s, est. speed input: 945.70 toks/s, output: 8913.54 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñã      | 700/1920 [01:38<02:42,  7.51it/s, est. speed input: 945.60 toks/s, output: 8935.08 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 701/1920 [01:38<03:07,  6.49it/s, est. speed input: 944.30 toks/s, output: 8945.12 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 704/1920 [01:38<02:16,  8.93it/s, est. speed input: 946.52 toks/s, output: 8972.97 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 707/1920 [01:38<01:48, 11.14it/s, est. speed input: 948.26 toks/s, output: 9004.41 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 709/1920 [01:39<02:36,  7.73it/s, est. speed input: 947.38 toks/s, output: 8970.91 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 711/1920 [01:39<02:14,  8.97it/s, est. speed input: 948.27 toks/s, output: 8998.23 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 713/1920 [01:39<02:05,  9.61it/s, est. speed input: 949.64 toks/s, output: 9008.54 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 715/1920 [01:40<02:58,  6.76it/s, est. speed input: 947.09 toks/s, output: 9003.66 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 717/1920 [01:40<02:28,  8.09it/s, est. speed input: 947.65 toks/s, output: 9033.23 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 720/1920 [01:40<02:03,  9.68it/s, est. speed input: 948.98 toks/s, output: 9034.18 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 722/1920 [01:41<02:57,  6.73it/s, est. speed input: 947.92 toks/s, output: 9015.75 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 723/1920 [01:41<02:49,  7.05it/s, est. speed input: 951.09 toks/s, output: 9036.57 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 725/1920 [01:41<02:24,  8.28it/s, est. speed input: 952.68 toks/s, output: 9039.66 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 727/1920 [01:41<02:22,  8.36it/s, est. speed input: 953.03 toks/s, output: 9031.18 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 729/1920 [01:41<02:02,  9.73it/s, est. speed input: 953.51 toks/s, output: 9044.86 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 733/1920 [01:41<01:28, 13.34it/s, est. speed input: 962.99 toks/s, output: 9101.38 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 735/1920 [01:42<01:22, 14.36it/s, est. speed input: 967.26 toks/s, output: 9100.24 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 737/1920 [01:42<01:37, 12.19it/s, est. speed input: 967.55 toks/s, output: 9096.07 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 739/1920 [01:42<01:44, 11.27it/s, est. speed input: 967.88 toks/s, output: 9112.11 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñä      | 741/1920 [01:42<01:36, 12.22it/s, est. speed input: 969.28 toks/s, output: 9120.47 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñä      | 743/1920 [01:42<01:51, 10.54it/s, est. speed input: 969.31 toks/s, output: 9122.99 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 745/1920 [01:43<02:41,  7.27it/s, est. speed input: 968.28 toks/s, output: 9096.64 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 746/1920 [01:43<02:43,  7.17it/s, est. speed input: 968.47 toks/s, output: 9099.15 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 747/1920 [01:43<03:29,  5.61it/s, est. speed input: 967.03 toks/s, output: 9075.51 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 748/1920 [01:43<03:22,  5.79it/s, est. speed input: 966.49 toks/s, output: 9066.18 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 750/1920 [01:44<03:30,  5.57it/s, est. speed input: 965.12 toks/s, output: 9057.38 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 751/1920 [01:44<03:16,  5.94it/s, est. speed input: 965.02 toks/s, output: 9068.98 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 752/1920 [01:44<03:23,  5.75it/s, est. speed input: 964.55 toks/s, output: 9081.70 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 753/1920 [01:44<03:09,  6.16it/s, est. speed input: 965.37 toks/s, output: 9076.65 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 754/1920 [01:44<03:18,  5.89it/s, est. speed input: 964.82 toks/s, output: 9072.86 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 756/1920 [01:45<02:51,  6.79it/s, est. speed input: 965.01 toks/s, output: 9109.69 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 758/1920 [01:45<02:28,  7.82it/s, est. speed input: 965.55 toks/s, output: 9139.42 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 760/1920 [01:45<01:58,  9.80it/s, est. speed input: 967.81 toks/s, output: 9165.48 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 762/1920 [01:45<02:24,  8.03it/s, est. speed input: 966.82 toks/s, output: 9173.28 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 763/1920 [01:46<02:38,  7.29it/s, est. speed input: 967.23 toks/s, output: 9164.59 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 764/1920 [01:46<02:41,  7.16it/s, est. speed input: 967.46 toks/s, output: 9157.90 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 765/1920 [01:46<02:38,  7.30it/s, est. speed input: 967.34 toks/s, output: 9161.56 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 767/1920 [01:46<02:28,  7.75it/s, est. speed input: 967.83 toks/s, output: 9164.60 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 769/1920 [01:46<01:57,  9.82it/s, est. speed input: 969.36 toks/s, output: 9200.54 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 771/1920 [01:47<03:51,  4.96it/s, est. speed input: 967.20 toks/s, output: 9167.59 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 772/1920 [01:47<04:04,  4.69it/s, est. speed input: 965.84 toks/s, output: 9152.21 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 775/1920 [01:47<02:36,  7.30it/s, est. speed input: 968.30 toks/s, output: 9157.63 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 778/1920 [01:48<02:19,  8.17it/s, est. speed input: 969.16 toks/s, output: 9180.29 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 782/1920 [01:48<01:40, 11.30it/s, est. speed input: 972.44 toks/s, output: 9223.55 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 784/1920 [01:48<01:51, 10.21it/s, est. speed input: 972.40 toks/s, output: 9220.09 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 786/1920 [01:48<01:56,  9.73it/s, est. speed input: 972.35 toks/s, output: 9210.17 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 788/1920 [01:48<01:48, 10.46it/s, est. speed input: 973.05 toks/s, output: 9216.87 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 790/1920 [01:49<01:35, 11.89it/s, est. speed input: 973.72 toks/s, output: 9224.72 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 792/1920 [01:49<01:52, 10.07it/s, est. speed input: 973.75 toks/s, output: 9221.75 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 794/1920 [01:49<01:50, 10.17it/s, est. speed input: 974.38 toks/s, output: 9238.74 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 796/1920 [01:49<01:43, 10.91it/s, est. speed input: 975.27 toks/s, output: 9241.52 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 799/1920 [01:49<01:25, 13.17it/s, est. speed input: 978.41 toks/s, output: 9289.13 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 801/1920 [01:50<01:56,  9.63it/s, est. speed input: 978.46 toks/s, output: 9294.84 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 803/1920 [01:50<01:59,  9.32it/s, est. speed input: 979.68 toks/s, output: 9330.86 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 805/1920 [01:50<02:25,  7.65it/s, est. speed input: 978.35 toks/s, output: 9344.01 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 807/1920 [01:50<02:10,  8.50it/s, est. speed input: 978.85 toks/s, output: 9354.78 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 808/1920 [01:51<02:28,  7.49it/s, est. speed input: 978.04 toks/s, output: 9347.16 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 810/1920 [01:51<01:59,  9.31it/s, est. speed input: 979.55 toks/s, output: 9362.26 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 812/1920 [01:51<02:28,  7.48it/s, est. speed input: 978.02 toks/s, output: 9355.70 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 814/1920 [01:51<02:10,  8.44it/s, est. speed input: 978.66 toks/s, output: 9359.83 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 816/1920 [01:52<03:21,  5.48it/s, est. speed input: 975.29 toks/s, output: 9338.50 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 817/1920 [01:52<03:18,  5.54it/s, est. speed input: 974.98 toks/s, output: 9330.20 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 818/1920 [01:52<03:11,  5.76it/s, est. speed input: 974.71 toks/s, output: 9329.63 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 820/1920 [01:53<03:45,  4.89it/s, est. speed input: 972.58 toks/s, output: 9302.95 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 823/1920 [01:53<02:22,  7.68it/s, est. speed input: 975.46 toks/s, output: 9319.68 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 825/1920 [01:53<02:25,  7.55it/s, est. speed input: 975.24 toks/s, output: 9333.92 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 827/1920 [01:54<03:58,  4.58it/s, est. speed input: 970.20 toks/s, output: 9297.51 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 828/1920 [01:54<03:37,  5.03it/s, est. speed input: 972.98 toks/s, output: 9307.31 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 829/1920 [01:54<03:40,  4.95it/s, est. speed input: 972.10 toks/s, output: 9316.68 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 832/1920 [01:55<02:24,  7.55it/s, est. speed input: 976.11 toks/s, output: 9349.47 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 834/1920 [01:55<02:18,  7.82it/s, est. speed input: 975.75 toks/s, output: 9344.03 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 836/1920 [01:55<02:46,  6.51it/s, est. speed input: 974.94 toks/s, output: 9336.58 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 838/1920 [01:55<02:31,  7.16it/s, est. speed input: 974.83 toks/s, output: 9333.22 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 841/1920 [01:56<02:02,  8.84it/s, est. speed input: 976.51 toks/s, output: 9358.87 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 843/1920 [01:56<01:57,  9.20it/s, est. speed input: 977.54 toks/s, output: 9368.90 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 845/1920 [01:56<01:50,  9.77it/s, est. speed input: 977.98 toks/s, output: 9373.70 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 848/1920 [01:56<01:26, 12.46it/s, est. speed input: 979.59 toks/s, output: 9401.59 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 850/1920 [01:56<01:18, 13.61it/s, est. speed input: 980.66 toks/s, output: 9415.68 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 852/1920 [01:57<02:05,  8.52it/s, est. speed input: 978.71 toks/s, output: 9390.09 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 854/1920 [01:57<01:49,  9.74it/s, est. speed input: 979.11 toks/s, output: 9389.62 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 856/1920 [01:57<01:57,  9.07it/s, est. speed input: 979.07 toks/s, output: 9391.66 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 858/1920 [01:57<01:39, 10.63it/s, est. speed input: 980.13 toks/s, output: 9407.17 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 860/1920 [01:58<02:10,  8.15it/s, est. speed input: 978.69 toks/s, output: 9404.55 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 863/1920 [01:58<01:51,  9.44it/s, est. speed input: 982.35 toks/s, output: 9411.97 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 865/1920 [01:58<02:04,  8.50it/s, est. speed input: 982.82 toks/s, output: 9425.98 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 867/1920 [01:59<02:40,  6.55it/s, est. speed input: 980.62 toks/s, output: 9419.52 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 871/1920 [01:59<01:44, 10.05it/s, est. speed input: 984.96 toks/s, output: 9462.76 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 874/1920 [01:59<01:32, 11.37it/s, est. speed input: 986.29 toks/s, output: 9468.72 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 876/1920 [01:59<01:41, 10.28it/s, est. speed input: 985.69 toks/s, output: 9462.82 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 878/1920 [01:59<01:35, 10.92it/s, est. speed input: 986.68 toks/s, output: 9466.31 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 880/1920 [02:00<02:25,  7.14it/s, est. speed input: 984.32 toks/s, output: 9443.84 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 882/1920 [02:00<02:40,  6.49it/s, est. speed input: 983.06 toks/s, output: 9428.64 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 884/1920 [02:01<02:29,  6.95it/s, est. speed input: 982.79 toks/s, output: 9424.47 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 886/1920 [02:01<02:46,  6.21it/s, est. speed input: 982.12 toks/s, output: 9439.67 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 890/1920 [02:02<03:02,  5.64it/s, est. speed input: 980.35 toks/s, output: 9411.09 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 891/1920 [02:02<03:04,  5.57it/s, est. speed input: 979.56 toks/s, output: 9407.11 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 892/1920 [02:02<02:59,  5.73it/s, est. speed input: 979.52 toks/s, output: 9420.68 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 894/1920 [02:02<02:19,  7.34it/s, est. speed input: 980.71 toks/s, output: 9445.05 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 896/1920 [02:02<01:56,  8.78it/s, est. speed input: 981.72 toks/s, output: 9452.55 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 898/1920 [02:03<03:18,  5.15it/s, est. speed input: 978.18 toks/s, output: 9426.16 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 900/1920 [02:04<03:30,  4.84it/s, est. speed input: 975.99 toks/s, output: 9436.81 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 902/1920 [02:04<02:52,  5.89it/s, est. speed input: 976.68 toks/s, output: 9445.93 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 904/1920 [02:04<02:43,  6.23it/s, est. speed input: 976.54 toks/s, output: 9461.18 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 906/1920 [02:04<02:16,  7.41it/s, est. speed input: 977.77 toks/s, output: 9467.65 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 907/1920 [02:04<02:42,  6.24it/s, est. speed input: 976.49 toks/s, output: 9466.84 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 909/1920 [02:05<02:27,  6.84it/s, est. speed input: 976.57 toks/s, output: 9470.42 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 910/1920 [02:05<02:40,  6.28it/s, est. speed input: 975.84 toks/s, output: 9457.55 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 912/1920 [02:05<02:18,  7.29it/s, est. speed input: 976.55 toks/s, output: 9476.79 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 913/1920 [02:05<02:20,  7.15it/s, est. speed input: 976.30 toks/s, output: 9489.85 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 915/1920 [02:05<01:49,  9.20it/s, est. speed input: 977.81 toks/s, output: 9514.17 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 917/1920 [02:06<02:06,  7.91it/s, est. speed input: 977.31 toks/s, output: 9507.89 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 920/1920 [02:06<01:49,  9.12it/s, est. speed input: 978.37 toks/s, output: 9508.34 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 923/1920 [02:06<01:53,  8.75it/s, est. speed input: 977.72 toks/s, output: 9515.25 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 924/1920 [02:06<02:05,  7.93it/s, est. speed input: 977.52 toks/s, output: 9510.90 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 925/1920 [02:07<02:21,  7.05it/s, est. speed input: 977.21 toks/s, output: 9507.52 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 926/1920 [02:07<02:31,  6.58it/s, est. speed input: 977.52 toks/s, output: 9517.32 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 928/1920 [02:07<02:10,  7.59it/s, est. speed input: 980.31 toks/s, output: 9529.84 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 929/1920 [02:07<02:14,  7.37it/s, est. speed input: 980.93 toks/s, output: 9542.69 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 930/1920 [02:08<03:00,  5.47it/s, est. speed input: 980.09 toks/s, output: 9541.23 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 932/1920 [02:08<02:27,  6.72it/s, est. speed input: 980.38 toks/s, output: 9540.59 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 934/1920 [02:08<02:08,  7.68it/s, est. speed input: 980.76 toks/s, output: 9536.42 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 935/1920 [02:08<02:12,  7.45it/s, est. speed input: 980.31 toks/s, output: 9549.16 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 937/1920 [02:08<01:47,  9.18it/s, est. speed input: 981.53 toks/s, output: 9556.07 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 938/1920 [02:09<03:07,  5.24it/s, est. speed input: 979.48 toks/s, output: 9533.55 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 940/1920 [02:09<02:17,  7.15it/s, est. speed input: 981.46 toks/s, output: 9536.02 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 942/1920 [02:09<01:58,  8.23it/s, est. speed input: 982.17 toks/s, output: 9559.95 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 944/1920 [02:09<02:04,  7.81it/s, est. speed input: 982.37 toks/s, output: 9571.40 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 945/1920 [02:09<02:16,  7.13it/s, est. speed input: 982.53 toks/s, output: 9560.78 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 946/1920 [02:10<02:23,  6.81it/s, est. speed input: 982.21 toks/s, output: 9557.06 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 948/1920 [02:10<02:04,  7.82it/s, est. speed input: 982.81 toks/s, output: 9563.62 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 950/1920 [02:10<02:18,  6.99it/s, est. speed input: 982.14 toks/s, output: 9551.65 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 952/1920 [02:10<02:03,  7.83it/s, est. speed input: 983.36 toks/s, output: 9559.42 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 953/1920 [02:11<02:35,  6.20it/s, est. speed input: 982.69 toks/s, output: 9541.40 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 955/1920 [02:11<02:35,  6.20it/s, est. speed input: 982.54 toks/s, output: 9532.41 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 957/1920 [02:11<02:11,  7.35it/s, est. speed input: 983.52 toks/s, output: 9528.95 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 959/1920 [02:11<02:15,  7.10it/s, est. speed input: 984.01 toks/s, output: 9526.35 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 960/1920 [02:12<02:45,  5.81it/s, est. speed input: 983.07 toks/s, output: 9508.69 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 961/1920 [02:12<03:06,  5.15it/s, est. speed input: 982.25 toks/s, output: 9489.57 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 962/1920 [02:12<03:19,  4.80it/s, est. speed input: 981.05 toks/s, output: 9473.90 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 965/1920 [02:12<01:57,  8.12it/s, est. speed input: 984.70 toks/s, output: 9479.53 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 967/1920 [02:13<01:36,  9.91it/s, est. speed input: 988.44 toks/s, output: 9483.02 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 969/1920 [02:13<01:37,  9.71it/s, est. speed input: 988.04 toks/s, output: 9481.23 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 971/1920 [02:13<01:41,  9.31it/s, est. speed input: 988.42 toks/s, output: 9473.47 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 973/1920 [02:13<01:44,  9.04it/s, est. speed input: 989.30 toks/s, output: 9475.62 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 976/1920 [02:13<01:19, 11.85it/s, est. speed input: 992.87 toks/s, output: 9496.86 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 978/1920 [02:14<01:46,  8.81it/s, est. speed input: 991.96 toks/s, output: 9490.23 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 980/1920 [02:14<01:56,  8.09it/s, est. speed input: 992.29 toks/s, output: 9514.80 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 981/1920 [02:14<01:56,  8.04it/s, est. speed input: 991.96 toks/s, output: 9522.32 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 982/1920 [02:14<02:12,  7.06it/s, est. speed input: 991.67 toks/s, output: 9529.96 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 983/1920 [02:15<02:35,  6.02it/s, est. speed input: 990.74 toks/s, output: 9522.01 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 984/1920 [02:15<02:40,  5.82it/s, est. speed input: 989.92 toks/s, output: 9518.23 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 985/1920 [02:15<02:50,  5.50it/s, est. speed input: 989.05 toks/s, output: 9526.03 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 986/1920 [02:15<02:36,  5.96it/s, est. speed input: 988.79 toks/s, output: 9539.66 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 994/1920 [02:15<01:06, 13.89it/s, est. speed input: 998.51 toks/s, output: 9677.18 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 996/1920 [02:16<01:43,  8.89it/s, est. speed input: 995.78 toks/s, output: 9657.10 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 997/1920 [02:16<01:48,  8.54it/s, est. speed input: 995.66 toks/s, output: 9649.18 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 998/1920 [02:16<01:58,  7.78it/s, est. speed input: 995.48 toks/s, output: 9637.87 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 999/1920 [02:16<02:05,  7.33it/s, est. speed input: 995.27 toks/s, output: 9633.17 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1000/1920 [02:17<02:19,  6.58it/s, est. speed input: 994.40 toks/s, output: 9622.10 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1002/1920 [02:17<01:53,  8.11it/s, est. speed input: 994.99 toks/s, output: 9626.42 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1003/1920 [02:17<02:30,  6.11it/s, est. speed input: 993.54 toks/s, output: 9612.59 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1004/1920 [02:17<02:22,  6.43it/s, est. speed input: 993.42 toks/s, output: 9625.98 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1006/1920 [02:17<01:45,  8.68it/s, est. speed input: 994.68 toks/s, output: 9633.27 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1008/1920 [02:18<01:59,  7.64it/s, est. speed input: 994.22 toks/s, output: 9641.10 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1009/1920 [02:18<01:55,  7.92it/s, est. speed input: 994.28 toks/s, output: 9640.78 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1011/1920 [02:18<01:33,  9.67it/s, est. speed input: 995.24 toks/s, output: 9647.44 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1014/1920 [02:18<01:15, 12.05it/s, est. speed input: 996.66 toks/s, output: 9648.15 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1016/1920 [02:18<01:07, 13.44it/s, est. speed input: 997.62 toks/s, output: 9662.55 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1018/1920 [02:19<01:26, 10.39it/s, est. speed input: 997.93 toks/s, output: 9661.24 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1020/1920 [02:19<01:20, 11.12it/s, est. speed input: 998.01 toks/s, output: 9669.09 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1022/1920 [02:19<01:33,  9.59it/s, est. speed input: 997.90 toks/s, output: 9659.69 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1024/1920 [02:19<01:53,  7.88it/s, est. speed input: 996.90 toks/s, output: 9659.40 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1025/1920 [02:20<02:33,  5.84it/s, est. speed input: 995.18 toks/s, output: 9646.17 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1026/1920 [02:20<02:32,  5.85it/s, est. speed input: 994.77 toks/s, output: 9656.42 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1028/1920 [02:20<01:57,  7.59it/s, est. speed input: 995.35 toks/s, output: 9660.49 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1029/1920 [02:20<01:56,  7.64it/s, est. speed input: 995.12 toks/s, output: 9673.57 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1030/1920 [02:20<02:00,  7.38it/s, est. speed input: 994.92 toks/s, output: 9672.63 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1033/1920 [02:20<01:17, 11.51it/s, est. speed input: 996.32 toks/s, output: 9692.09 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1035/1920 [02:20<01:07, 13.09it/s, est. speed input: 997.41 toks/s, output: 9692.10 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1037/1920 [02:21<01:35,  9.20it/s, est. speed input: 996.56 toks/s, output: 9674.13 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1040/1920 [02:21<01:12, 12.11it/s, est. speed input: 998.01 toks/s, output: 9680.49 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1042/1920 [02:21<01:30,  9.65it/s, est. speed input: 997.45 toks/s, output: 9675.73 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1044/1920 [02:22<02:02,  7.14it/s, est. speed input: 996.34 toks/s, output: 9654.16 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1046/1920 [02:22<01:59,  7.33it/s, est. speed input: 996.68 toks/s, output: 9668.50 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1047/1920 [02:22<02:24,  6.03it/s, est. speed input: 995.80 toks/s, output: 9669.13 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1049/1920 [02:23<02:44,  5.30it/s, est. speed input: 994.97 toks/s, output: 9675.01 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1050/1920 [02:23<03:23,  4.27it/s, est. speed input: 992.87 toks/s, output: 9667.43 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1051/1920 [02:23<03:21,  4.31it/s, est. speed input: 991.96 toks/s, output: 9657.79 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1053/1920 [02:24<02:37,  5.49it/s, est. speed input: 992.10 toks/s, output: 9671.80 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1054/1920 [02:24<02:34,  5.59it/s, est. speed input: 991.58 toks/s, output: 9666.33 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1055/1920 [02:24<02:49,  5.11it/s, est. speed input: 990.43 toks/s, output: 9658.62 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1056/1920 [02:25<04:01,  3.58it/s, est. speed input: 987.70 toks/s, output: 9628.07 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1058/1920 [02:25<03:21,  4.27it/s, est. speed input: 986.77 toks/s, output: 9612.70 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1060/1920 [02:25<02:31,  5.68it/s, est. speed input: 987.05 toks/s, output: 9614.93 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1062/1920 [02:25<02:15,  6.34it/s, est. speed input: 987.28 toks/s, output: 9629.94 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1064/1920 [02:25<01:47,  7.95it/s, est. speed input: 988.56 toks/s, output: 9654.60 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1066/1920 [02:26<01:56,  7.36it/s, est. speed input: 989.97 toks/s, output: 9642.52 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1068/1920 [02:26<01:48,  7.83it/s, est. speed input: 990.14 toks/s, output: 9640.18 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1071/1920 [02:27<02:01,  7.02it/s, est. speed input: 989.07 toks/s, output: 9643.46 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1073/1920 [02:27<01:44,  8.07it/s, est. speed input: 989.44 toks/s, output: 9658.09 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1075/1920 [02:27<01:28,  9.58it/s, est. speed input: 991.09 toks/s, output: 9663.21 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1077/1920 [02:27<01:23, 10.07it/s, est. speed input: 993.35 toks/s, output: 9676.65 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1081/1920 [02:27<01:10, 11.93it/s, est. speed input: 996.78 toks/s, output: 9680.51 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1083/1920 [02:27<01:21, 10.24it/s, est. speed input: 996.02 toks/s, output: 9703.66 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1086/1920 [02:28<01:36,  8.66it/s, est. speed input: 995.65 toks/s, output: 9706.91 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1087/1920 [02:28<01:35,  8.75it/s, est. speed input: 995.72 toks/s, output: 9700.08 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1089/1920 [02:28<01:45,  7.86it/s, est. speed input: 995.14 toks/s, output: 9688.35 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1090/1920 [02:28<01:45,  7.83it/s, est. speed input: 994.91 toks/s, output: 9684.21 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1092/1920 [02:29<01:31,  9.03it/s, est. speed input: 995.94 toks/s, output: 9708.53 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1093/1920 [02:29<01:41,  8.14it/s, est. speed input: 995.59 toks/s, output: 9717.73 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1094/1920 [02:29<01:38,  8.37it/s, est. speed input: 995.62 toks/s, output: 9715.45 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1095/1920 [02:29<01:36,  8.51it/s, est. speed input: 995.45 toks/s, output: 9710.68 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1096/1920 [02:29<01:56,  7.07it/s, est. speed input: 994.85 toks/s, output: 9717.35 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1097/1920 [02:29<02:07,  6.47it/s, est. speed input: 995.09 toks/s, output: 9714.69 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1099/1920 [02:30<01:38,  8.32it/s, est. speed input: 995.45 toks/s, output: 9728.99 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1102/1920 [02:30<01:11, 11.47it/s, est. speed input: 997.39 toks/s, output: 9741.73 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1104/1920 [02:30<01:24,  9.68it/s, est. speed input: 997.28 toks/s, output: 9749.79 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1106/1920 [02:30<01:32,  8.78it/s, est. speed input: 997.14 toks/s, output: 9739.89 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1108/1920 [02:30<01:30,  8.99it/s, est. speed input: 996.90 toks/s, output: 9734.75 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1110/1920 [02:31<01:18, 10.33it/s, est. speed input: 997.57 toks/s, output: 9737.41 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1112/1920 [02:31<01:15, 10.69it/s, est. speed input: 999.99 toks/s, output: 9744.24 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1116/1920 [02:31<01:23,  9.60it/s, est. speed input: 1000.89 toks/s, output: 9746.15 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1118/1920 [02:32<01:28,  9.07it/s, est. speed input: 1001.24 toks/s, output: 9743.00 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1119/1920 [02:32<01:52,  7.14it/s, est. speed input: 1000.15 toks/s, output: 9743.44 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1121/1920 [02:32<01:41,  7.89it/s, est. speed input: 1000.76 toks/s, output: 9750.53 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1123/1920 [02:32<01:26,  9.23it/s, est. speed input: 1001.19 toks/s, output: 9755.69 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1125/1920 [02:32<01:38,  8.06it/s, est. speed input: 1000.95 toks/s, output: 9775.39 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1127/1920 [02:33<01:44,  7.62it/s, est. speed input: 1000.47 toks/s, output: 9766.24 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1129/1920 [02:33<01:25,  9.25it/s, est. speed input: 1000.99 toks/s, output: 9768.16 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1131/1920 [02:33<01:35,  8.27it/s, est. speed input: 1000.92 toks/s, output: 9769.65 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1133/1920 [02:34<02:58,  4.40it/s, est. speed input: 995.90 toks/s, output: 9738.22 toks/s] [A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1134/1920 [02:34<03:14,  4.04it/s, est. speed input: 994.39 toks/s, output: 9723.18 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1136/1920 [02:35<03:01,  4.31it/s, est. speed input: 993.77 toks/s, output: 9716.73 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1137/1920 [02:35<02:49,  4.62it/s, est. speed input: 993.91 toks/s, output: 9716.41 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1139/1920 [02:35<02:31,  5.17it/s, est. speed input: 993.97 toks/s, output: 9721.43 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1140/1920 [02:36<02:30,  5.17it/s, est. speed input: 993.79 toks/s, output: 9716.81 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1141/1920 [02:36<02:19,  5.59it/s, est. speed input: 993.67 toks/s, output: 9724.52 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1144/1920 [02:36<02:10,  5.95it/s, est. speed input: 993.29 toks/s, output: 9714.16 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1145/1920 [02:36<02:32,  5.09it/s, est. speed input: 992.08 toks/s, output: 9700.57 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1146/1920 [02:37<02:17,  5.63it/s, est. speed input: 991.97 toks/s, output: 9713.47 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1148/1920 [02:37<01:47,  7.20it/s, est. speed input: 992.27 toks/s, output: 9728.42 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1150/1920 [02:37<01:32,  8.29it/s, est. speed input: 992.66 toks/s, output: 9728.50 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1151/1920 [02:37<02:15,  5.68it/s, est. speed input: 990.73 toks/s, output: 9723.50 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1153/1920 [02:37<01:50,  6.94it/s, est. speed input: 991.23 toks/s, output: 9739.72 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1154/1920 [02:38<02:57,  4.32it/s, est. speed input: 988.49 toks/s, output: 9710.29 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1155/1920 [02:38<03:37,  3.51it/s, est. speed input: 986.68 toks/s, output: 9691.64 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1156/1920 [02:39<03:08,  4.06it/s, est. speed input: 986.97 toks/s, output: 9693.40 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1159/1920 [02:39<01:45,  7.20it/s, est. speed input: 988.60 toks/s, output: 9702.26 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1161/1920 [02:39<01:27,  8.70it/s, est. speed input: 991.40 toks/s, output: 9708.47 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1164/1920 [02:39<01:02, 12.08it/s, est. speed input: 994.00 toks/s, output: 9759.50 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1166/1920 [02:39<00:56, 13.34it/s, est. speed input: 995.18 toks/s, output: 9768.78 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1170/1920 [02:39<00:49, 15.22it/s, est. speed input: 996.50 toks/s, output: 9794.93 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1172/1920 [02:39<00:54, 13.65it/s, est. speed input: 996.82 toks/s, output: 9798.00 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1174/1920 [02:40<00:51, 14.58it/s, est. speed input: 997.93 toks/s, output: 9817.20 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1176/1920 [02:40<01:15,  9.85it/s, est. speed input: 997.26 toks/s, output: 9818.23 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1178/1920 [02:40<01:12, 10.26it/s, est. speed input: 998.31 toks/s, output: 9845.85 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1180/1920 [02:40<01:05, 11.37it/s, est. speed input: 998.67 toks/s, output: 9852.01 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1182/1920 [02:41<01:17,  9.47it/s, est. speed input: 999.22 toks/s, output: 9839.25 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1184/1920 [02:41<01:20,  9.16it/s, est. speed input: 1000.18 toks/s, output: 9834.53 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1187/1920 [02:41<01:47,  6.82it/s, est. speed input: 999.08 toks/s, output: 9827.02 toks/s] [A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1191/1920 [02:42<01:15,  9.69it/s, est. speed input: 1001.34 toks/s, output: 9851.70 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1193/1920 [02:42<01:15,  9.60it/s, est. speed input: 1001.35 toks/s, output: 9864.51 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1197/1920 [02:42<00:53, 13.57it/s, est. speed input: 1004.22 toks/s, output: 9896.59 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1199/1920 [02:42<00:51, 13.93it/s, est. speed input: 1004.66 toks/s, output: 9924.38 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1203/1920 [02:42<00:47, 14.95it/s, est. speed input: 1006.38 toks/s, output: 9955.51 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1205/1920 [02:43<01:11,  9.95it/s, est. speed input: 1005.22 toks/s, output: 9941.52 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1207/1920 [02:43<01:05, 10.86it/s, est. speed input: 1008.09 toks/s, output: 9955.13 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1209/1920 [02:43<01:04, 11.06it/s, est. speed input: 1010.71 toks/s, output: 9949.16 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1211/1920 [02:43<01:17,  9.18it/s, est. speed input: 1010.48 toks/s, output: 9954.66 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1213/1920 [02:43<01:06, 10.64it/s, est. speed input: 1011.50 toks/s, output: 9970.34 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1215/1920 [02:44<01:02, 11.24it/s, est. speed input: 1011.68 toks/s, output: 9973.15 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1217/1920 [02:44<00:57, 12.20it/s, est. speed input: 1012.48 toks/s, output: 9975.05 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1219/1920 [02:44<01:47,  6.51it/s, est. speed input: 1009.59 toks/s, output: 9949.94 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1221/1920 [02:45<01:37,  7.14it/s, est. speed input: 1011.93 toks/s, output: 9963.53 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1224/1920 [02:45<01:17,  9.03it/s, est. speed input: 1014.32 toks/s, output: 9980.73 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1226/1920 [02:45<01:23,  8.28it/s, est. speed input: 1014.04 toks/s, output: 9973.13 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1228/1920 [02:46<01:38,  6.99it/s, est. speed input: 1012.84 toks/s, output: 9956.50 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1229/1920 [02:46<01:34,  7.28it/s, est. speed input: 1012.87 toks/s, output: 9954.79 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1230/1920 [02:46<01:41,  6.78it/s, est. speed input: 1012.78 toks/s, output: 9956.17 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1234/1920 [02:46<01:03, 10.73it/s, est. speed input: 1014.91 toks/s, output: 9965.47 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1236/1920 [02:46<01:06, 10.35it/s, est. speed input: 1015.51 toks/s, output: 9968.87 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1238/1920 [02:47<01:23,  8.15it/s, est. speed input: 1014.58 toks/s, output: 9968.06 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1240/1920 [02:47<01:55,  5.89it/s, est. speed input: 1012.74 toks/s, output: 9944.72 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1243/1920 [02:47<01:23,  8.13it/s, est. speed input: 1014.26 toks/s, output: 9951.66 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1245/1920 [02:48<01:38,  6.85it/s, est. speed input: 1012.91 toks/s, output: 9937.78 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1248/1920 [02:48<01:15,  8.88it/s, est. speed input: 1013.92 toks/s, output: 9949.73 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1250/1920 [02:48<01:26,  7.77it/s, est. speed input: 1013.36 toks/s, output: 9964.18 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1252/1920 [02:49<02:01,  5.48it/s, est. speed input: 1010.85 toks/s, output: 9961.75 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1254/1920 [02:49<01:43,  6.43it/s, est. speed input: 1011.08 toks/s, output: 9987.96 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1255/1920 [02:49<01:53,  5.88it/s, est. speed input: 1010.16 toks/s, output: 9978.82 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1256/1920 [02:49<01:50,  6.03it/s, est. speed input: 1010.32 toks/s, output: 9975.07 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1258/1920 [02:50<01:30,  7.33it/s, est. speed input: 1011.20 toks/s, output: 9974.67 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1260/1920 [02:50<01:34,  6.99it/s, est. speed input: 1010.65 toks/s, output: 9992.42 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1262/1920 [02:50<01:16,  8.60it/s, est. speed input: 1011.10 toks/s, output: 9991.17 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1264/1920 [02:50<01:22,  7.99it/s, est. speed input: 1010.57 toks/s, output: 9989.30 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1265/1920 [02:51<01:35,  6.86it/s, est. speed input: 1009.73 toks/s, output: 9993.43 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1267/1920 [02:51<01:18,  8.34it/s, est. speed input: 1010.19 toks/s, output: 9991.06 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1268/1920 [02:51<01:36,  6.78it/s, est. speed input: 1009.32 toks/s, output: 9982.67 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1271/1920 [02:51<01:08,  9.47it/s, est. speed input: 1010.84 toks/s, output: 9982.95 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1273/1920 [02:51<01:15,  8.57it/s, est. speed input: 1010.23 toks/s, output: 9975.97 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1274/1920 [02:52<01:18,  8.26it/s, est. speed input: 1009.88 toks/s, output: 9974.17 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1275/1920 [02:52<02:13,  4.83it/s, est. speed input: 1007.46 toks/s, output: 9945.65 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1279/1920 [02:52<01:14,  8.55it/s, est. speed input: 1009.91 toks/s, output: 9972.66 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1281/1920 [02:53<02:27,  4.32it/s, est. speed input: 1005.04 toks/s, output: 9919.01 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1282/1920 [02:53<02:19,  4.58it/s, est. speed input: 1004.77 toks/s, output: 9912.93 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1284/1920 [02:54<02:17,  4.63it/s, est. speed input: 1004.36 toks/s, output: 9912.69 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1285/1920 [02:54<02:26,  4.34it/s, est. speed input: 1003.45 toks/s, output: 9899.03 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1287/1920 [02:55<02:09,  4.91it/s, est. speed input: 1002.65 toks/s, output: 9903.13 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1289/1920 [02:55<01:36,  6.53it/s, est. speed input: 1003.66 toks/s, output: 9907.75 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1291/1920 [02:55<01:19,  7.87it/s, est. speed input: 1004.32 toks/s, output: 9927.05 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1293/1920 [02:55<01:40,  6.24it/s, est. speed input: 1002.71 toks/s, output: 9921.28 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1294/1920 [02:56<02:00,  5.18it/s, est. speed input: 1001.39 toks/s, output: 9907.81 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1296/1920 [02:56<01:50,  5.67it/s, est. speed input: 1000.99 toks/s, output: 9913.13 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1298/1920 [02:56<01:37,  6.36it/s, est. speed input: 1000.88 toks/s, output: 9923.65 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1299/1920 [02:56<01:36,  6.47it/s, est. speed input: 1000.87 toks/s, output: 9923.06 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1304/1920 [02:56<00:55, 11.02it/s, est. speed input: 1002.77 toks/s, output: 9943.87 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1306/1920 [02:57<00:57, 10.70it/s, est. speed input: 1002.94 toks/s, output: 9944.72 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1309/1920 [02:57<00:49, 12.38it/s, est. speed input: 1004.02 toks/s, output: 9963.06 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1312/1920 [02:57<01:09,  8.80it/s, est. speed input: 1003.21 toks/s, output: 9970.93 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1315/1920 [02:58<01:11,  8.43it/s, est. speed input: 1002.94 toks/s, output: 9985.32 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1318/1920 [02:58<01:11,  8.44it/s, est. speed input: 1002.62 toks/s, output: 10017.09 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1319/1920 [02:58<01:22,  7.29it/s, est. speed input: 1001.62 toks/s, output: 10019.60 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1321/1920 [02:58<01:10,  8.52it/s, est. speed input: 1001.96 toks/s, output: 10033.23 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1326/1920 [02:59<00:46, 12.91it/s, est. speed input: 1005.18 toks/s, output: 10096.10 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1328/1920 [02:59<00:59,  9.97it/s, est. speed input: 1004.38 toks/s, output: 10104.26 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1330/1920 [03:00<01:23,  7.09it/s, est. speed input: 1002.47 toks/s, output: 10081.42 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1334/1920 [03:00<01:01,  9.47it/s, est. speed input: 1004.36 toks/s, output: 10090.93 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1336/1920 [03:00<01:01,  9.46it/s, est. speed input: 1004.32 toks/s, output: 10084.43 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1338/1920 [03:00<01:17,  7.48it/s, est. speed input: 1003.35 toks/s, output: 10077.42 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1339/1920 [03:01<02:04,  4.68it/s, est. speed input: 1000.12 toks/s, output: 10045.28 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1341/1920 [03:01<01:50,  5.22it/s, est. speed input: 999.69 toks/s, output: 10040.65 toks/s] [A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1342/1920 [03:02<01:56,  4.94it/s, est. speed input: 999.05 toks/s, output: 10031.41 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1343/1920 [03:02<01:48,  5.34it/s, est. speed input: 999.60 toks/s, output: 10032.41 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1346/1920 [03:02<01:11,  8.08it/s, est. speed input: 1003.05 toks/s, output: 10040.67 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1348/1920 [03:02<01:03,  8.94it/s, est. speed input: 1003.49 toks/s, output: 10060.39 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1350/1920 [03:03<01:24,  6.76it/s, est. speed input: 1002.18 toks/s, output: 10052.96 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1352/1920 [03:03<01:07,  8.40it/s, est. speed input: 1003.31 toks/s, output: 10070.50 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1354/1920 [03:03<01:44,  5.42it/s, est. speed input: 1000.87 toks/s, output: 10053.08 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1355/1920 [03:04<02:02,  4.60it/s, est. speed input: 999.54 toks/s, output: 10036.58 toks/s] [A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1356/1920 [03:04<01:54,  4.92it/s, est. speed input: 999.51 toks/s, output: 10045.23 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1357/1920 [03:04<01:44,  5.37it/s, est. speed input: 999.40 toks/s, output: 10043.27 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1358/1920 [03:04<01:42,  5.50it/s, est. speed input: 998.93 toks/s, output: 10050.77 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1359/1920 [03:04<01:45,  5.30it/s, est. speed input: 998.50 toks/s, output: 10042.92 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1360/1920 [03:05<01:45,  5.29it/s, est. speed input: 997.90 toks/s, output: 10036.60 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1361/1920 [03:05<02:40,  3.48it/s, est. speed input: 995.40 toks/s, output: 10011.19 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1363/1920 [03:05<01:52,  4.93it/s, est. speed input: 995.62 toks/s, output: 10006.90 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1364/1920 [03:05<01:39,  5.56it/s, est. speed input: 995.98 toks/s, output: 10008.14 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1365/1920 [03:06<01:32,  6.01it/s, est. speed input: 995.98 toks/s, output: 10005.23 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1368/1920 [03:06<01:02,  8.82it/s, est. speed input: 996.68 toks/s, output: 10009.01 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1371/1920 [03:06<00:49, 11.16it/s, est. speed input: 997.53 toks/s, output: 10011.69 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1373/1920 [03:06<00:46, 11.72it/s, est. speed input: 997.56 toks/s, output: 10010.74 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1376/1920 [03:06<00:36, 14.96it/s, est. speed input: 999.56 toks/s, output: 10029.17 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1378/1920 [03:06<00:48, 11.27it/s, est. speed input: 999.61 toks/s, output: 10033.92 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1380/1920 [03:07<00:58,  9.22it/s, est. speed input: 999.20 toks/s, output: 10037.02 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1382/1920 [03:07<00:56,  9.54it/s, est. speed input: 999.28 toks/s, output: 10032.98 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1384/1920 [03:07<01:05,  8.15it/s, est. speed input: 998.46 toks/s, output: 10047.84 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1385/1920 [03:07<01:07,  7.87it/s, est. speed input: 998.15 toks/s, output: 10056.26 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1386/1920 [03:08<01:14,  7.17it/s, est. speed input: 997.97 toks/s, output: 10050.11 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1387/1920 [03:08<01:10,  7.56it/s, est. speed input: 997.93 toks/s, output: 10051.08 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1389/1920 [03:08<01:02,  8.45it/s, est. speed input: 998.09 toks/s, output: 10054.64 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1390/1920 [03:08<01:18,  6.78it/s, est. speed input: 998.99 toks/s, output: 10055.14 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1393/1920 [03:08<00:51, 10.25it/s, est. speed input: 1001.03 toks/s, output: 10086.99 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1395/1920 [03:09<00:54,  9.65it/s, est. speed input: 1001.26 toks/s, output: 10090.88 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1397/1920 [03:09<01:20,  6.52it/s, est. speed input: 999.65 toks/s, output: 10069.16 toks/s] [A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1398/1920 [03:09<01:15,  6.90it/s, est. speed input: 1000.00 toks/s, output: 10071.11 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1399/1920 [03:09<01:13,  7.07it/s, est. speed input: 1000.14 toks/s, output: 10068.67 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1401/1920 [03:09<01:00,  8.51it/s, est. speed input: 1000.42 toks/s, output: 10084.82 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1404/1920 [03:10<00:42, 12.23it/s, est. speed input: 1002.21 toks/s, output: 10117.60 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1406/1920 [03:10<00:48, 10.50it/s, est. speed input: 1002.12 toks/s, output: 10115.32 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1408/1920 [03:10<01:03,  8.10it/s, est. speed input: 1001.23 toks/s, output: 10127.39 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1410/1920 [03:11<01:17,  6.55it/s, est. speed input: 1000.42 toks/s, output: 10114.88 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1411/1920 [03:11<01:30,  5.63it/s, est. speed input: 999.69 toks/s, output: 10103.99 toks/s] [A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1412/1920 [03:11<01:40,  5.08it/s, est. speed input: 999.11 toks/s, output: 10096.30 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1413/1920 [03:12<02:02,  4.13it/s, est. speed input: 997.95 toks/s, output: 10077.42 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1415/1920 [03:12<01:27,  5.76it/s, est. speed input: 999.02 toks/s, output: 10102.45 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1416/1920 [03:12<01:33,  5.36it/s, est. speed input: 998.90 toks/s, output: 10092.00 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1420/1920 [03:13<01:25,  5.85it/s, est. speed input: 998.24 toks/s, output: 10083.94 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1422/1920 [03:13<01:26,  5.76it/s, est. speed input: 997.70 toks/s, output: 10084.54 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1425/1920 [03:13<01:06,  7.40it/s, est. speed input: 998.56 toks/s, output: 10091.53 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1427/1920 [03:13<00:57,  8.59it/s, est. speed input: 999.46 toks/s, output: 10102.42 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1429/1920 [03:13<00:53,  9.23it/s, est. speed input: 999.37 toks/s, output: 10103.46 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1431/1920 [03:14<00:52,  9.26it/s, est. speed input: 999.77 toks/s, output: 10098.51 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1435/1920 [03:14<00:47, 10.23it/s, est. speed input: 1002.39 toks/s, output: 10094.23 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1437/1920 [03:14<00:44, 10.83it/s, est. speed input: 1002.56 toks/s, output: 10103.76 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1439/1920 [03:14<00:48,  9.88it/s, est. speed input: 1002.36 toks/s, output: 10110.88 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1442/1920 [03:15<00:39, 12.00it/s, est. speed input: 1002.91 toks/s, output: 10139.28 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1444/1920 [03:15<00:44, 10.59it/s, est. speed input: 1003.00 toks/s, output: 10148.32 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1446/1920 [03:15<00:46, 10.25it/s, est. speed input: 1003.72 toks/s, output: 10143.30 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1448/1920 [03:15<00:48,  9.73it/s, est. speed input: 1004.59 toks/s, output: 10144.86 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1450/1920 [03:15<00:41, 11.23it/s, est. speed input: 1005.04 toks/s, output: 10147.72 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1452/1920 [03:16<00:39, 11.77it/s, est. speed input: 1005.29 toks/s, output: 10149.26 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1454/1920 [03:16<00:45, 10.20it/s, est. speed input: 1005.09 toks/s, output: 10145.42 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1458/1920 [03:16<00:33, 13.66it/s, est. speed input: 1006.54 toks/s, output: 10169.95 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1460/1920 [03:16<00:42, 10.93it/s, est. speed input: 1006.52 toks/s, output: 10165.99 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1462/1920 [03:17<00:51,  8.96it/s, est. speed input: 1005.98 toks/s, output: 10160.62 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1464/1920 [03:17<00:59,  7.70it/s, est. speed input: 1005.59 toks/s, output: 10158.92 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1466/1920 [03:17<00:53,  8.51it/s, est. speed input: 1006.40 toks/s, output: 10158.19 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1467/1920 [03:18<01:22,  5.50it/s, est. speed input: 1005.98 toks/s, output: 10147.83 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1470/1920 [03:18<00:54,  8.23it/s, est. speed input: 1008.51 toks/s, output: 10153.97 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1472/1920 [03:18<00:52,  8.51it/s, est. speed input: 1008.66 toks/s, output: 10151.18 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1474/1920 [03:18<01:03,  7.06it/s, est. speed input: 1007.57 toks/s, output: 10143.23 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1475/1920 [03:19<01:03,  6.99it/s, est. speed input: 1007.28 toks/s, output: 10138.07 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1476/1920 [03:19<01:02,  7.14it/s, est. speed input: 1007.77 toks/s, output: 10135.87 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1477/1920 [03:19<00:58,  7.54it/s, est. speed input: 1008.08 toks/s, output: 10133.46 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1479/1920 [03:19<00:45,  9.76it/s, est. speed input: 1009.21 toks/s, output: 10142.79 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1481/1920 [03:19<01:00,  7.28it/s, est. speed input: 1008.17 toks/s, output: 10132.07 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1482/1920 [03:20<01:19,  5.50it/s, est. speed input: 1007.02 toks/s, output: 10115.76 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1484/1920 [03:20<01:00,  7.19it/s, est. speed input: 1007.51 toks/s, output: 10119.43 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1485/1920 [03:20<01:08,  6.31it/s, est. speed input: 1006.88 toks/s, output: 10111.04 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1486/1920 [03:20<01:09,  6.20it/s, est. speed input: 1006.52 toks/s, output: 10104.96 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1488/1920 [03:20<00:58,  7.35it/s, est. speed input: 1007.21 toks/s, output: 10106.49 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1489/1920 [03:21<01:05,  6.55it/s, est. speed input: 1006.77 toks/s, output: 10103.30 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1490/1920 [03:21<01:11,  5.99it/s, est. speed input: 1006.84 toks/s, output: 10097.43 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1492/1920 [03:21<01:04,  6.63it/s, est. speed input: 1006.70 toks/s, output: 10101.25 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1495/1920 [03:21<00:47,  9.00it/s, est. speed input: 1007.51 toks/s, output: 10100.68 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1496/1920 [03:21<00:56,  7.50it/s, est. speed input: 1006.76 toks/s, output: 10102.25 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1497/1920 [03:22<01:01,  6.89it/s, est. speed input: 1006.38 toks/s, output: 10098.43 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1500/1920 [03:22<00:39, 10.60it/s, est. speed input: 1007.32 toks/s, output: 10113.85 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1503/1920 [03:22<00:31, 13.04it/s, est. speed input: 1008.33 toks/s, output: 10119.14 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1506/1920 [03:22<00:39, 10.51it/s, est. speed input: 1008.02 toks/s, output: 10133.21 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1509/1920 [03:23<00:43,  9.42it/s, est. speed input: 1007.78 toks/s, output: 10139.97 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1511/1920 [03:23<00:52,  7.72it/s, est. speed input: 1006.81 toks/s, output: 10130.18 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1512/1920 [03:23<00:52,  7.73it/s, est. speed input: 1006.62 toks/s, output: 10127.19 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1513/1920 [03:23<00:58,  6.96it/s, est. speed input: 1006.12 toks/s, output: 10125.44 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1517/1920 [03:24<00:38, 10.39it/s, est. speed input: 1008.19 toks/s, output: 10144.05 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1519/1920 [03:24<00:49,  8.08it/s, est. speed input: 1007.32 toks/s, output: 10130.31 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1521/1920 [03:24<00:41,  9.55it/s, est. speed input: 1008.11 toks/s, output: 10143.53 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1523/1920 [03:24<00:41,  9.52it/s, est. speed input: 1008.65 toks/s, output: 10154.14 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1525/1920 [03:25<00:38, 10.36it/s, est. speed input: 1009.10 toks/s, output: 10155.80 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1527/1920 [03:25<00:53,  7.34it/s, est. speed input: 1007.86 toks/s, output: 10152.98 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1528/1920 [03:25<00:57,  6.87it/s, est. speed input: 1007.47 toks/s, output: 10152.61 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1531/1920 [03:25<00:45,  8.53it/s, est. speed input: 1007.83 toks/s, output: 10151.12 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1533/1920 [03:26<00:39,  9.78it/s, est. speed input: 1008.25 toks/s, output: 10163.55 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1535/1920 [03:26<00:43,  8.87it/s, est. speed input: 1008.19 toks/s, output: 10171.28 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1538/1920 [03:26<00:42,  9.00it/s, est. speed input: 1008.02 toks/s, output: 10179.73 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1539/1920 [03:26<00:45,  8.29it/s, est. speed input: 1007.56 toks/s, output: 10186.10 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1540/1920 [03:27<00:54,  6.92it/s, est. speed input: 1006.71 toks/s, output: 10188.47 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1541/1920 [03:27<01:16,  4.97it/s, est. speed input: 1005.13 toks/s, output: 10170.27 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1542/1920 [03:27<01:11,  5.26it/s, est. speed input: 1005.01 toks/s, output: 10177.61 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1544/1920 [03:27<01:02,  6.01it/s, est. speed input: 1005.48 toks/s, output: 10180.68 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1546/1920 [03:28<00:50,  7.48it/s, est. speed input: 1005.94 toks/s, output: 10190.40 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1550/1920 [03:28<00:45,  8.14it/s, est. speed input: 1007.52 toks/s, output: 10200.71 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1552/1920 [03:28<00:40,  9.07it/s, est. speed input: 1009.63 toks/s, output: 10208.78 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1554/1920 [03:28<00:38,  9.56it/s, est. speed input: 1011.52 toks/s, output: 10218.48 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1556/1920 [03:29<01:19,  4.56it/s, est. speed input: 1007.85 toks/s, output: 10173.59 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1558/1920 [03:30<01:07,  5.34it/s, est. speed input: 1007.74 toks/s, output: 10172.25 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1559/1920 [03:30<01:09,  5.22it/s, est. speed input: 1007.23 toks/s, output: 10176.57 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1560/1920 [03:30<01:04,  5.59it/s, est. speed input: 1007.12 toks/s, output: 10173.62 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1561/1920 [03:30<01:13,  4.89it/s, est. speed input: 1006.78 toks/s, output: 10165.89 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1562/1920 [03:30<01:06,  5.37it/s, est. speed input: 1006.57 toks/s, output: 10174.26 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1566/1920 [03:30<00:33, 10.51it/s, est. speed input: 1008.29 toks/s, output: 10201.61 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1568/1920 [03:32<01:31,  3.84it/s, est. speed input: 1003.15 toks/s, output: 10145.36 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1570/1920 [03:32<01:10,  5.00it/s, est. speed input: 1003.60 toks/s, output: 10145.00 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1572/1920 [03:32<01:04,  5.40it/s, est. speed input: 1003.22 toks/s, output: 10138.02 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1574/1920 [03:32<00:52,  6.56it/s, est. speed input: 1003.85 toks/s, output: 10149.31 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1576/1920 [03:33<00:47,  7.19it/s, est. speed input: 1003.73 toks/s, output: 10145.97 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1578/1920 [03:33<01:02,  5.48it/s, est. speed input: 1002.05 toks/s, output: 10124.99 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1579/1920 [03:33<01:11,  4.76it/s, est. speed input: 1001.04 toks/s, output: 10123.32 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1581/1920 [03:34<00:58,  5.81it/s, est. speed input: 1001.62 toks/s, output: 10128.27 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1582/1920 [03:34<00:56,  5.96it/s, est. speed input: 1001.41 toks/s, output: 10125.26 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1585/1920 [03:34<00:48,  6.96it/s, est. speed input: 1001.33 toks/s, output: 10128.10 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1586/1920 [03:34<00:46,  7.12it/s, est. speed input: 1001.50 toks/s, output: 10126.57 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1589/1920 [03:35<00:43,  7.61it/s, est. speed input: 1001.96 toks/s, output: 10144.14 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1590/1920 [03:35<01:13,  4.50it/s, est. speed input: 1000.83 toks/s, output: 10117.99 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1594/1920 [03:35<00:41,  7.79it/s, est. speed input: 1002.33 toks/s, output: 10150.04 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1597/1920 [03:36<00:35,  9.22it/s, est. speed input: 1002.62 toks/s, output: 10172.69 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1599/1920 [03:36<00:30, 10.54it/s, est. speed input: 1004.46 toks/s, output: 10187.16 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1604/1920 [03:36<00:19, 15.94it/s, est. speed input: 1005.85 toks/s, output: 10204.95 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1607/1920 [03:36<00:22, 14.01it/s, est. speed input: 1006.63 toks/s, output: 10220.15 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1610/1920 [03:36<00:26, 11.92it/s, est. speed input: 1007.20 toks/s, output: 10221.94 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1612/1920 [03:37<00:39,  7.84it/s, est. speed input: 1006.94 toks/s, output: 10211.17 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1614/1920 [03:37<00:37,  8.15it/s, est. speed input: 1007.07 toks/s, output: 10211.70 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1616/1920 [03:37<00:34,  8.80it/s, est. speed input: 1007.80 toks/s, output: 10231.02 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1618/1920 [03:38<00:33,  8.91it/s, est. speed input: 1008.54 toks/s, output: 10238.22 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1620/1920 [03:38<00:30,  9.78it/s, est. speed input: 1009.63 toks/s, output: 10250.29 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1622/1920 [03:39<00:55,  5.38it/s, est. speed input: 1007.18 toks/s, output: 10231.43 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1624/1920 [03:39<00:44,  6.61it/s, est. speed input: 1007.90 toks/s, output: 10240.30 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1626/1920 [03:39<00:39,  7.38it/s, est. speed input: 1007.99 toks/s, output: 10247.94 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1629/1920 [03:39<00:36,  8.03it/s, est. speed input: 1009.99 toks/s, output: 10258.23 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1631/1920 [03:40<00:52,  5.51it/s, est. speed input: 1007.86 toks/s, output: 10241.63 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1632/1920 [03:40<00:49,  5.79it/s, est. speed input: 1008.06 toks/s, output: 10242.57 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1634/1920 [03:40<00:39,  7.19it/s, est. speed input: 1008.99 toks/s, output: 10254.35 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1636/1920 [03:40<00:37,  7.58it/s, est. speed input: 1008.99 toks/s, output: 10251.52 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1638/1920 [03:41<00:46,  6.03it/s, est. speed input: 1007.95 toks/s, output: 10246.75 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1641/1920 [03:41<00:32,  8.49it/s, est. speed input: 1008.64 toks/s, output: 10269.07 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1643/1920 [03:41<00:31,  8.93it/s, est. speed input: 1009.18 toks/s, output: 10281.69 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1645/1920 [03:42<00:36,  7.46it/s, est. speed input: 1008.95 toks/s, output: 10276.68 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1647/1920 [03:42<00:31,  8.76it/s, est. speed input: 1009.09 toks/s, output: 10277.77 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1649/1920 [03:42<00:28,  9.43it/s, est. speed input: 1009.57 toks/s, output: 10278.61 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1651/1920 [03:42<00:30,  8.90it/s, est. speed input: 1009.54 toks/s, output: 10283.17 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1653/1920 [03:43<00:38,  7.00it/s, est. speed input: 1008.28 toks/s, output: 10271.73 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1654/1920 [03:43<00:43,  6.16it/s, est. speed input: 1007.95 toks/s, output: 10265.17 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1656/1920 [03:43<00:40,  6.47it/s, est. speed input: 1008.17 toks/s, output: 10272.21 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1658/1920 [03:43<00:33,  7.76it/s, est. speed input: 1008.57 toks/s, output: 10271.62 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1659/1920 [03:43<00:34,  7.53it/s, est. speed input: 1008.39 toks/s, output: 10270.49 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1660/1920 [03:44<00:47,  5.52it/s, est. speed input: 1007.54 toks/s, output: 10267.60 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1664/1920 [03:44<00:38,  6.59it/s, est. speed input: 1007.30 toks/s, output: 10265.07 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1666/1920 [03:44<00:31,  8.04it/s, est. speed input: 1008.19 toks/s, output: 10286.21 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1670/1920 [03:45<00:23, 10.56it/s, est. speed input: 1009.19 toks/s, output: 10297.48 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1672/1920 [03:45<00:30,  8.03it/s, est. speed input: 1008.42 toks/s, output: 10291.92 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1674/1920 [03:45<00:26,  9.42it/s, est. speed input: 1009.15 toks/s, output: 10302.95 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1676/1920 [03:45<00:22, 10.90it/s, est. speed input: 1009.87 toks/s, output: 10313.98 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1678/1920 [03:45<00:20, 11.97it/s, est. speed input: 1010.51 toks/s, output: 10324.20 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1681/1920 [03:46<00:18, 13.19it/s, est. speed input: 1010.88 toks/s, output: 10356.35 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1683/1920 [03:46<00:20, 11.33it/s, est. speed input: 1010.69 toks/s, output: 10362.51 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1685/1920 [03:46<00:23,  9.95it/s, est. speed input: 1010.44 toks/s, output: 10361.11 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1687/1920 [03:46<00:25,  9.11it/s, est. speed input: 1010.94 toks/s, output: 10359.16 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1689/1920 [03:47<00:23,  9.82it/s, est. speed input: 1011.12 toks/s, output: 10366.80 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1691/1920 [03:47<00:23,  9.82it/s, est. speed input: 1011.91 toks/s, output: 10362.16 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1693/1920 [03:47<00:25,  8.79it/s, est. speed input: 1011.38 toks/s, output: 10367.16 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1696/1920 [03:47<00:18, 12.03it/s, est. speed input: 1012.35 toks/s, output: 10386.61 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1699/1920 [03:47<00:15, 14.69it/s, est. speed input: 1015.02 toks/s, output: 10397.89 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1701/1920 [03:48<00:18, 11.89it/s, est. speed input: 1015.13 toks/s, output: 10391.59 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1703/1920 [03:48<00:16, 12.82it/s, est. speed input: 1018.30 toks/s, output: 10412.95 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1705/1920 [03:48<00:15, 14.20it/s, est. speed input: 1018.60 toks/s, output: 10414.88 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1707/1920 [03:48<00:16, 13.15it/s, est. speed input: 1019.02 toks/s, output: 10421.58 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1710/1920 [03:48<00:13, 15.98it/s, est. speed input: 1021.64 toks/s, output: 10435.06 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1713/1920 [03:48<00:17, 12.14it/s, est. speed input: 1021.80 toks/s, output: 10433.26 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1715/1920 [03:49<00:26,  7.78it/s, est. speed input: 1020.31 toks/s, output: 10423.20 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1717/1920 [03:49<00:22,  9.06it/s, est. speed input: 1020.53 toks/s, output: 10435.56 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1719/1920 [03:49<00:25,  7.77it/s, est. speed input: 1019.84 toks/s, output: 10428.35 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1721/1920 [03:50<00:26,  7.61it/s, est. speed input: 1020.03 toks/s, output: 10436.48 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1724/1920 [03:50<00:18, 10.33it/s, est. speed input: 1021.36 toks/s, output: 10445.88 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1727/1920 [03:50<00:14, 13.04it/s, est. speed input: 1022.63 toks/s, output: 10459.49 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1730/1920 [03:50<00:15, 12.59it/s, est. speed input: 1022.82 toks/s, output: 10469.30 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1732/1920 [03:50<00:14, 12.64it/s, est. speed input: 1023.05 toks/s, output: 10471.07 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1734/1920 [03:51<00:15, 12.31it/s, est. speed input: 1023.12 toks/s, output: 10479.86 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1736/1920 [03:51<00:23,  7.74it/s, est. speed input: 1021.76 toks/s, output: 10475.28 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1739/1920 [03:51<00:21,  8.53it/s, est. speed input: 1021.97 toks/s, output: 10470.84 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1741/1920 [03:52<00:20,  8.95it/s, est. speed input: 1022.17 toks/s, output: 10473.12 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1743/1920 [03:52<00:17, 10.30it/s, est. speed input: 1023.21 toks/s, output: 10473.50 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1745/1920 [03:52<00:22,  7.80it/s, est. speed input: 1022.66 toks/s, output: 10459.40 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1749/1920 [03:52<00:14, 11.57it/s, est. speed input: 1023.86 toks/s, output: 10473.09 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1751/1920 [03:53<00:22,  7.40it/s, est. speed input: 1022.29 toks/s, output: 10468.27 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1753/1920 [03:53<00:21,  7.83it/s, est. speed input: 1022.35 toks/s, output: 10468.40 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1755/1920 [03:53<00:22,  7.31it/s, est. speed input: 1021.92 toks/s, output: 10464.45 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1757/1920 [03:53<00:18,  8.70it/s, est. speed input: 1022.50 toks/s, output: 10479.40 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1760/1920 [03:54<00:16,  9.72it/s, est. speed input: 1022.80 toks/s, output: 10490.35 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1763/1920 [03:54<00:14, 10.70it/s, est. speed input: 1023.82 toks/s, output: 10507.08 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1767/1920 [03:54<00:12, 12.69it/s, est. speed input: 1024.97 toks/s, output: 10513.17 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1769/1920 [03:55<00:16,  9.35it/s, est. speed input: 1023.89 toks/s, output: 10512.13 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1771/1920 [03:55<00:21,  6.92it/s, est. speed input: 1022.64 toks/s, output: 10502.63 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1772/1920 [03:55<00:20,  7.15it/s, est. speed input: 1022.54 toks/s, output: 10500.62 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1774/1920 [03:55<00:20,  7.15it/s, est. speed input: 1022.20 toks/s, output: 10500.99 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1776/1920 [03:56<00:20,  7.02it/s, est. speed input: 1022.04 toks/s, output: 10494.66 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1777/1920 [03:56<00:23,  6.13it/s, est. speed input: 1021.47 toks/s, output: 10485.86 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1779/1920 [03:56<00:19,  7.33it/s, est. speed input: 1022.92 toks/s, output: 10484.69 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1781/1920 [03:57<00:23,  5.88it/s, est. speed input: 1022.15 toks/s, output: 10489.35 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1782/1920 [03:57<00:29,  4.67it/s, est. speed input: 1020.85 toks/s, output: 10484.39 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1783/1920 [03:57<00:33,  4.12it/s, est. speed input: 1019.80 toks/s, output: 10481.85 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1788/1920 [03:58<00:15,  8.55it/s, est. speed input: 1021.54 toks/s, output: 10518.85 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1790/1920 [03:58<00:15,  8.36it/s, est. speed input: 1021.15 toks/s, output: 10533.35 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1792/1920 [03:58<00:16,  7.75it/s, est. speed input: 1021.24 toks/s, output: 10533.45 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1794/1920 [03:58<00:15,  8.10it/s, est. speed input: 1022.43 toks/s, output: 10539.96 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1795/1920 [03:59<00:19,  6.51it/s, est. speed input: 1021.54 toks/s, output: 10530.18 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1796/1920 [03:59<00:21,  5.80it/s, est. speed input: 1021.41 toks/s, output: 10524.62 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1797/1920 [03:59<00:24,  4.97it/s, est. speed input: 1020.69 toks/s, output: 10523.41 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1798/1920 [04:00<00:42,  2.87it/s, est. speed input: 1018.05 toks/s, output: 10498.19 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1800/1920 [04:00<00:27,  4.34it/s, est. speed input: 1018.47 toks/s, output: 10511.66 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1801/1920 [04:01<00:43,  2.72it/s, est. speed input: 1015.35 toks/s, output: 10480.18 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1802/1920 [04:01<00:37,  3.15it/s, est. speed input: 1015.14 toks/s, output: 10485.86 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1803/1920 [04:02<00:40,  2.86it/s, est. speed input: 1013.87 toks/s, output: 10479.36 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1804/1920 [04:02<00:33,  3.45it/s, est. speed input: 1014.28 toks/s, output: 10479.92 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1807/1920 [04:02<00:18,  6.07it/s, est. speed input: 1014.94 toks/s, output: 10497.36 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1808/1920 [04:02<00:22,  4.91it/s, est. speed input: 1014.31 toks/s, output: 10487.48 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1809/1920 [04:02<00:21,  5.16it/s, est. speed input: 1014.02 toks/s, output: 10491.37 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1810/1920 [04:03<00:22,  4.93it/s, est. speed input: 1013.76 toks/s, output: 10486.70 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1811/1920 [04:03<00:19,  5.48it/s, est. speed input: 1013.71 toks/s, output: 10488.48 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1814/1920 [04:03<00:11,  9.22it/s, est. speed input: 1014.73 toks/s, output: 10515.35 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1816/1920 [04:04<00:21,  4.85it/s, est. speed input: 1012.68 toks/s, output: 10499.28 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1817/1920 [04:04<00:20,  5.07it/s, est. speed input: 1012.73 toks/s, output: 10497.67 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1818/1920 [04:04<00:22,  4.58it/s, est. speed input: 1012.43 toks/s, output: 10497.52 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1819/1920 [04:06<00:50,  1.99it/s, est. speed input: 1006.92 toks/s, output: 10449.05 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1822/1920 [04:06<00:28,  3.40it/s, est. speed input: 1007.35 toks/s, output: 10461.63 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1823/1920 [04:06<00:25,  3.83it/s, est. speed input: 1007.55 toks/s, output: 10462.09 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1824/1920 [04:07<00:32,  2.93it/s, est. speed input: 1005.44 toks/s, output: 10442.55 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1825/1920 [04:07<00:40,  2.34it/s, est. speed input: 1003.29 toks/s, output: 10425.18 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1826/1920 [04:08<00:38,  2.47it/s, est. speed input: 1002.61 toks/s, output: 10417.19 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1827/1920 [04:08<00:32,  2.83it/s, est. speed input: 1002.43 toks/s, output: 10414.45 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1829/1920 [04:08<00:21,  4.31it/s, est. speed input: 1003.39 toks/s, output: 10426.84 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1830/1920 [04:08<00:23,  3.77it/s, est. speed input: 1002.26 toks/s, output: 10416.95 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1831/1920 [04:09<00:20,  4.25it/s, est. speed input: 1002.50 toks/s, output: 10423.12 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1832/1920 [04:09<00:27,  3.23it/s, est. speed input: 1001.05 toks/s, output: 10410.70 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1833/1920 [04:10<00:32,  2.64it/s, est. speed input: 999.27 toks/s, output: 10395.11 toks/s] [A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1834/1920 [04:10<00:31,  2.70it/s, est. speed input: 998.29 toks/s, output: 10392.78 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1842/1920 [04:10<00:08,  8.80it/s, est. speed input: 1002.12 toks/s, output: 10467.57 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1844/1920 [04:11<00:13,  5.79it/s, est. speed input: 1000.07 toks/s, output: 10453.95 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1846/1920 [04:11<00:12,  6.11it/s, est. speed input: 1000.05 toks/s, output: 10461.75 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1847/1920 [04:12<00:15,  4.76it/s, est. speed input: 999.80 toks/s, output: 10447.61 toks/s] [A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1848/1920 [04:12<00:14,  5.14it/s, est. speed input: 999.69 toks/s, output: 10450.54 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1849/1920 [04:12<00:18,  3.79it/s, est. speed input: 998.07 toks/s, output: 10436.52 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1850/1920 [04:14<00:41,  1.69it/s, est. speed input: 992.81 toks/s, output: 10376.22 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1851/1920 [04:15<00:43,  1.59it/s, est. speed input: 991.55 toks/s, output: 10352.56 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1852/1920 [04:15<00:35,  1.94it/s, est. speed input: 991.21 toks/s, output: 10356.56 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1854/1920 [04:15<00:21,  3.08it/s, est. speed input: 991.84 toks/s, output: 10373.28 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1855/1920 [04:16<00:20,  3.14it/s, est. speed input: 991.50 toks/s, output: 10369.30 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1857/1920 [04:16<00:15,  4.07it/s, est. speed input: 991.46 toks/s, output: 10380.11 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1858/1920 [04:17<00:24,  2.52it/s, est. speed input: 988.29 toks/s, output: 10354.55 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1860/1920 [04:17<00:20,  2.93it/s, est. speed input: 987.19 toks/s, output: 10358.09 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1862/1920 [04:17<00:13,  4.21it/s, est. speed input: 987.54 toks/s, output: 10377.84 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1864/1920 [04:18<00:12,  4.33it/s, est. speed input: 986.80 toks/s, output: 10381.83 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1865/1920 [04:18<00:15,  3.56it/s, est. speed input: 985.64 toks/s, output: 10374.12 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1866/1920 [04:18<00:13,  4.14it/s, est. speed input: 985.61 toks/s, output: 10378.17 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1867/1920 [04:19<00:13,  3.92it/s, est. speed input: 985.17 toks/s, output: 10378.04 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1870/1920 [04:19<00:07,  6.58it/s, est. speed input: 986.69 toks/s, output: 10407.56 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1872/1920 [04:19<00:09,  5.30it/s, est. speed input: 985.86 toks/s, output: 10409.99 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1873/1920 [04:20<00:09,  5.17it/s, est. speed input: 985.53 toks/s, output: 10413.21 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1874/1920 [04:20<00:08,  5.54it/s, est. speed input: 985.52 toks/s, output: 10419.73 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1875/1920 [04:20<00:11,  3.79it/s, est. speed input: 983.78 toks/s, output: 10409.91 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1876/1920 [04:21<00:12,  3.42it/s, est. speed input: 982.66 toks/s, output: 10406.59 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1877/1920 [04:21<00:12,  3.36it/s, est. speed input: 981.98 toks/s, output: 10405.98 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1878/1920 [04:21<00:10,  3.83it/s, est. speed input: 981.85 toks/s, output: 10411.21 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1879/1920 [04:21<00:09,  4.12it/s, est. speed input: 981.61 toks/s, output: 10415.17 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1880/1920 [04:22<00:13,  2.90it/s, est. speed input: 979.90 toks/s, output: 10401.99 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1882/1920 [04:22<00:10,  3.65it/s, est. speed input: 979.50 toks/s, output: 10410.59 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1883/1920 [04:23<00:12,  3.02it/s, est. speed input: 978.01 toks/s, output: 10402.13 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1885/1920 [04:23<00:07,  4.38it/s, est. speed input: 978.62 toks/s, output: 10416.99 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1886/1920 [04:23<00:07,  4.63it/s, est. speed input: 978.29 toks/s, output: 10421.75 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1887/1920 [04:23<00:07,  4.68it/s, est. speed input: 977.84 toks/s, output: 10425.27 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1888/1920 [04:24<00:06,  4.64it/s, est. speed input: 977.34 toks/s, output: 10428.17 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1889/1920 [04:24<00:10,  2.88it/s, est. speed input: 975.03 toks/s, output: 10412.03 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1891/1920 [04:24<00:07,  4.13it/s, est. speed input: 975.25 toks/s, output: 10426.38 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1892/1920 [04:25<00:06,  4.25it/s, est. speed input: 974.94 toks/s, output: 10429.61 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1893/1920 [04:25<00:05,  4.81it/s, est. speed input: 974.93 toks/s, output: 10436.17 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1894/1920 [04:25<00:04,  5.48it/s, est. speed input: 974.98 toks/s, output: 10443.34 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1895/1920 [04:26<00:11,  2.20it/s, est. speed input: 971.22 toks/s, output: 10408.90 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1898/1920 [04:27<00:07,  2.85it/s, est. speed input: 969.75 toks/s, output: 10411.73 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1899/1920 [04:27<00:07,  2.79it/s, est. speed input: 968.66 toks/s, output: 10408.17 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1901/1920 [04:27<00:04,  3.87it/s, est. speed input: 968.64 toks/s, output: 10424.30 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1902/1920 [04:29<00:07,  2.27it/s, est. speed input: 964.97 toks/s, output: 10391.17 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1903/1920 [04:29<00:08,  1.95it/s, est. speed input: 963.10 toks/s, output: 10373.38 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1904/1920 [04:30<00:07,  2.14it/s, est. speed input: 962.76 toks/s, output: 10372.08 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1906/1920 [04:30<00:04,  3.15it/s, est. speed input: 963.70 toks/s, output: 10386.81 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1907/1920 [04:31<00:07,  1.76it/s, est. speed input: 959.34 toks/s, output: 10344.12 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1908/1920 [04:32<00:08,  1.40it/s, est. speed input: 956.00 toks/s, output: 10311.07 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1911/1920 [04:33<00:03,  2.48it/s, est. speed input: 956.03 toks/s, output: 10332.59 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1912/1920 [04:34<00:04,  1.65it/s, est. speed input: 951.69 toks/s, output: 10290.00 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1913/1920 [04:35<00:05,  1.36it/s, est. speed input: 947.92 toks/s, output: 10256.80 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1914/1920 [04:36<00:03,  1.50it/s, est. speed input: 946.70 toks/s, output: 10251.14 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1915/1920 [04:36<00:03,  1.60it/s, est. speed input: 945.30 toks/s, output: 10243.48 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1916/1920 [04:37<00:02,  1.47it/s, est. speed input: 942.82 toks/s, output: 10223.78 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1917/1920 [04:38<00:02,  1.25it/s, est. speed input: 940.60 toks/s, output: 10194.33 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1918/1920 [04:39<00:01,  1.43it/s, est. speed input: 940.63 toks/s, output: 10189.16 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1920/1920 [04:39<00:00,  6.88it/s, est. speed input: 942.61 toks/s, output: 10211.11 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/1920 [00:00<?, ?it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1920/1920 [00:00<00:00, 38712.37it/s]
{'num_samples': 240, 'num_scores': 1920, 'timeout_samples': 0, 'empty_samples': 1, 'acc': 6.7, 'total_acc': 7.083333333333333, 'pass_at_k_percent': {'1': 7.1, '8': 24.2}, 'pass_at_k_valid_counts': {'1': 240, '8': 240}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_noise_rlvr_1_5b_128batchsize_deepscaler_noise_robust_qwen25-math-cot/base__Qwen2.5-math-1.5B/g1/aime24x8/test_qwen25-math-cot_-1_seed0_t0.6_s0_e-1.jsonl
[2025-09-23 15:28:22] ‚úì base__Qwen2.5-math-1.5B/g1/aime24x8  acc=6.7 pass_at_k={'1': 7.1, '8': 24.2}
base__Qwen2.5-math-1.5B/g1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [14:45<00:00, 295.06s/ds]base__Qwen2.5-math-1.5B/g1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [14:45<00:00, 295.29s/ds]
[2025-09-23 15:28:22] ‚ñ∂ base__Qwen2.5-math-1.5B/g2  ÂæÖËØÑÊµã=['minerva_math', 'olympiadbench', 'math500']  T=0.0  n=8
base__Qwen2.5-math-1.5B/g2:   0%|          | 0/3 [00:00<?, ?ds/s]==================================================
data: minerva_math  ,remain samples: 272
{'problem': 'Each of the two Magellan telescopes has a diameter of $6.5 \\mathrm{~m}$. In one configuration the effective focal length is $72 \\mathrm{~m}$. Find the diameter of the image of a planet (in $\\mathrm{cm}$ ) at this focus if the angular diameter of the planet at the time of the observation is $45^{\\prime \\prime}$.', 'solution': 'Start with:\n\\[\ns=\\alpha f \\text {, }\n\\]\nwhere $s$ is the diameter of the image, $f$ the focal length, and $\\alpha$ the angular diameter of the planet. For the values given in the problem:\n\\[\ns=\\frac{45}{3600} \\frac{\\pi}{180} 7200=\\boxed{1.6} \\mathrm{~cm}\n\\]', 'type': 'Introduction to Astronomy (8.282J Spring 2006)', 'idx': 0}

  0%|          | 0/272 [00:00<?, ?it/s][A<|im_start|>system
Please reason step by step, and put your final answer within \boxed{{}}.<|im_end|>
<|im_start|>user
Each of the two Magellan telescopes has a diameter of $6.5 \mathrm{~m}$. In one configuration the effective focal length is $72 \mathrm{~m}$. Find the diameter of the image of a planet (in $\mathrm{cm}$ ) at this focus if the angular diameter of the planet at the time of the observation is $45^{\prime \prime}$.<|im_end|>
<|im_start|>assistant

100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 272/272 [00:00<00:00, 13862.10it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/2176 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 1/2176 [00:04<2:42:33,  4.48s/it, est. speed input: 36.13 toks/s, output: 59.77 toks/s][A
Processed prompts:   1%|          | 15/2176 [00:04<08:07,  4.43it/s, est. speed input: 478.73 toks/s, output: 858.76 toks/s][A
Processed prompts:   2%|‚ñè         | 33/2176 [00:04<03:04, 11.61it/s, est. speed input: 957.46 toks/s, output: 1857.57 toks/s][A
Processed prompts:   2%|‚ñè         | 43/2176 [00:06<03:48,  9.32it/s, est. speed input: 889.96 toks/s, output: 1882.97 toks/s][A
Processed prompts:   2%|‚ñè         | 50/2176 [00:06<03:38,  9.72it/s, est. speed input: 898.11 toks/s, output: 2071.43 toks/s][A
Processed prompts:   3%|‚ñé         | 57/2176 [00:07<03:45,  9.41it/s, est. speed input: 916.51 toks/s, output: 2206.07 toks/s][A
Processed prompts:   3%|‚ñé         | 61/2176 [00:08<03:54,  9.01it/s, est. speed input: 903.50 toks/s, output: 2272.39 toks/s][A
Processed prompts:   3%|‚ñé         | 65/2176 [00:08<04:00,  8.78it/s, est. speed input: 893.35 toks/s, output: 2349.96 toks/s][A
Processed prompts:   3%|‚ñé         | 73/2176 [00:09<04:10,  8.40it/s, est. speed input: 869.20 toks/s, output: 2492.37 toks/s][A
Processed prompts:   4%|‚ñç         | 82/2176 [00:10<03:36,  9.68it/s, est. speed input: 948.82 toks/s, output: 2781.96 toks/s][A
Processed prompts:   4%|‚ñç         | 84/2176 [00:10<03:32,  9.84it/s, est. speed input: 947.81 toks/s, output: 2840.12 toks/s][A
Processed prompts:   4%|‚ñç         | 86/2176 [00:10<03:26, 10.14it/s, est. speed input: 948.49 toks/s, output: 2903.80 toks/s][A
Processed prompts:   4%|‚ñç         | 96/2176 [00:11<03:03, 11.36it/s, est. speed input: 948.32 toks/s, output: 3189.71 toks/s][A
Processed prompts:   5%|‚ñç         | 104/2176 [00:12<02:48, 12.32it/s, est. speed input: 956.89 toks/s, output: 3294.08 toks/s][A
Processed prompts:   5%|‚ñå         | 112/2176 [00:12<02:32, 13.56it/s, est. speed input: 999.66 toks/s, output: 3574.93 toks/s][A
Processed prompts:   5%|‚ñå         | 115/2176 [00:12<02:48, 12.26it/s, est. speed input: 996.10 toks/s, output: 3624.99 toks/s][A
Processed prompts:   6%|‚ñå         | 123/2176 [00:13<02:43, 12.54it/s, est. speed input: 1050.54 toks/s, output: 3862.97 toks/s][A
Processed prompts:   6%|‚ñå         | 125/2176 [00:13<02:43, 12.52it/s, est. speed input: 1054.31 toks/s, output: 3882.48 toks/s][A
Processed prompts:   6%|‚ñå         | 132/2176 [00:13<02:08, 15.91it/s, est. speed input: 1090.52 toks/s, output: 4061.41 toks/s][A
Processed prompts:   6%|‚ñã         | 136/2176 [00:14<02:11, 15.56it/s, est. speed input: 1101.99 toks/s, output: 4151.87 toks/s][A
Processed prompts:   7%|‚ñã         | 144/2176 [00:14<01:36, 21.04it/s, est. speed input: 1205.29 toks/s, output: 4263.13 toks/s][A
Processed prompts:   7%|‚ñã         | 147/2176 [00:14<02:20, 14.44it/s, est. speed input: 1193.47 toks/s, output: 4270.77 toks/s][A
Processed prompts:   7%|‚ñã         | 153/2176 [00:15<02:33, 13.20it/s, est. speed input: 1197.03 toks/s, output: 4426.74 toks/s][A
Processed prompts:   8%|‚ñä         | 164/2176 [00:15<01:49, 18.31it/s, est. speed input: 1246.83 toks/s, output: 4730.55 toks/s][A
Processed prompts:   8%|‚ñä         | 168/2176 [00:15<01:44, 19.31it/s, est. speed input: 1260.81 toks/s, output: 4809.55 toks/s][A
Processed prompts:   8%|‚ñä         | 172/2176 [00:16<02:14, 14.87it/s, est. speed input: 1254.63 toks/s, output: 4841.63 toks/s][A
Processed prompts:   8%|‚ñä         | 181/2176 [00:16<01:53, 17.65it/s, est. speed input: 1284.03 toks/s, output: 5111.81 toks/s][A
Processed prompts:   9%|‚ñä         | 186/2176 [00:16<01:36, 20.62it/s, est. speed input: 1328.87 toks/s, output: 5334.39 toks/s][A
Processed prompts:   9%|‚ñä         | 189/2176 [00:17<02:00, 16.51it/s, est. speed input: 1330.94 toks/s, output: 5378.82 toks/s][A
Processed prompts:   9%|‚ñâ         | 195/2176 [00:17<01:52, 17.66it/s, est. speed input: 1370.31 toks/s, output: 5596.58 toks/s][A
Processed prompts:   9%|‚ñâ         | 198/2176 [00:17<02:15, 14.63it/s, est. speed input: 1359.19 toks/s, output: 5641.67 toks/s][A
Processed prompts:   9%|‚ñâ         | 201/2176 [00:18<02:27, 13.35it/s, est. speed input: 1358.78 toks/s, output: 5703.73 toks/s][A
Processed prompts:   9%|‚ñâ         | 205/2176 [00:18<02:58, 11.06it/s, est. speed input: 1358.85 toks/s, output: 5716.77 toks/s][A
Processed prompts:  10%|‚ñâ         | 212/2176 [00:19<02:17, 14.27it/s, est. speed input: 1368.60 toks/s, output: 5750.67 toks/s][A
Processed prompts:  10%|‚ñâ         | 217/2176 [00:19<01:59, 16.46it/s, est. speed input: 1377.29 toks/s, output: 5773.80 toks/s][A
Processed prompts:  10%|‚ñà         | 219/2176 [00:19<03:03, 10.67it/s, est. speed input: 1364.14 toks/s, output: 5710.72 toks/s][A
Processed prompts:  10%|‚ñà         | 225/2176 [00:19<02:12, 14.77it/s, est. speed input: 1428.22 toks/s, output: 5973.91 toks/s][A
Processed prompts:  10%|‚ñà         | 228/2176 [00:21<05:37,  5.77it/s, est. speed input: 1334.44 toks/s, output: 5559.21 toks/s][A
Processed prompts:  11%|‚ñà         | 234/2176 [00:21<04:10,  7.75it/s, est. speed input: 1351.72 toks/s, output: 5560.20 toks/s][A
Processed prompts:  11%|‚ñà         | 236/2176 [00:22<04:33,  7.08it/s, est. speed input: 1348.26 toks/s, output: 5479.01 toks/s][A
Processed prompts:  11%|‚ñà         | 238/2176 [00:22<05:06,  6.32it/s, est. speed input: 1335.45 toks/s, output: 5397.95 toks/s][A
Processed prompts:  11%|‚ñà‚ñè        | 247/2176 [00:23<02:46, 11.59it/s, est. speed input: 1386.56 toks/s, output: 5616.82 toks/s][A
Processed prompts:  11%|‚ñà‚ñè        | 250/2176 [00:23<03:01, 10.62it/s, est. speed input: 1389.43 toks/s, output: 5572.55 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 252/2176 [00:23<02:56, 10.92it/s, est. speed input: 1394.69 toks/s, output: 5568.10 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 257/2176 [00:23<02:18, 13.82it/s, est. speed input: 1405.43 toks/s, output: 5611.92 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 259/2176 [00:24<03:00, 10.64it/s, est. speed input: 1402.15 toks/s, output: 5621.96 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 261/2176 [00:24<02:46, 11.49it/s, est. speed input: 1407.62 toks/s, output: 5662.78 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 264/2176 [00:24<02:26, 13.02it/s, est. speed input: 1410.44 toks/s, output: 5676.99 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 275/2176 [00:24<01:25, 22.15it/s, est. speed input: 1455.06 toks/s, output: 5772.91 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 278/2176 [00:25<01:45, 18.06it/s, est. speed input: 1454.61 toks/s, output: 5786.71 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 281/2176 [00:25<01:46, 17.74it/s, est. speed input: 1460.12 toks/s, output: 5795.54 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 286/2176 [00:25<01:58, 15.98it/s, est. speed input: 1457.62 toks/s, output: 5835.28 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 291/2176 [00:25<01:38, 19.07it/s, est. speed input: 1485.20 toks/s, output: 5977.17 toks/s][A
Processed prompts:  14%|‚ñà‚ñé        | 294/2176 [00:26<02:27, 12.80it/s, est. speed input: 1471.55 toks/s, output: 5872.43 toks/s][A
Processed prompts:  14%|‚ñà‚ñé        | 296/2176 [00:26<03:01, 10.34it/s, est. speed input: 1460.99 toks/s, output: 5798.80 toks/s][A
Processed prompts:  14%|‚ñà‚ñé        | 299/2176 [00:27<03:19,  9.40it/s, est. speed input: 1453.83 toks/s, output: 5762.45 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 301/2176 [00:28<05:54,  5.29it/s, est. speed input: 1415.49 toks/s, output: 5653.92 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 309/2176 [00:29<05:06,  6.09it/s, est. speed input: 1396.15 toks/s, output: 5740.65 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 315/2176 [00:29<04:16,  7.27it/s, est. speed input: 1409.28 toks/s, output: 5899.21 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 316/2176 [00:30<04:39,  6.66it/s, est. speed input: 1399.90 toks/s, output: 5854.95 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 323/2176 [00:30<02:50, 10.85it/s, est. speed input: 1426.88 toks/s, output: 5944.38 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 326/2176 [00:30<03:26,  8.94it/s, est. speed input: 1412.68 toks/s, output: 5944.63 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 332/2176 [00:30<02:22, 12.97it/s, est. speed input: 1432.60 toks/s, output: 6131.48 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 335/2176 [00:31<03:19,  9.23it/s, est. speed input: 1425.25 toks/s, output: 6060.44 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 338/2176 [00:31<02:49, 10.84it/s, est. speed input: 1431.10 toks/s, output: 6133.21 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 343/2176 [00:31<02:27, 12.44it/s, est. speed input: 1438.10 toks/s, output: 6201.06 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 350/2176 [00:34<05:25,  5.61it/s, est. speed input: 1391.90 toks/s, output: 5904.91 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 352/2176 [00:34<06:19,  4.80it/s, est. speed input: 1372.10 toks/s, output: 5819.24 toks/s][A
Processed prompts:  16%|‚ñà‚ñã        | 354/2176 [00:35<06:35,  4.61it/s, est. speed input: 1362.89 toks/s, output: 5779.43 toks/s][A
Processed prompts:  16%|‚ñà‚ñã        | 355/2176 [00:36<08:13,  3.69it/s, est. speed input: 1338.56 toks/s, output: 5673.87 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 361/2176 [00:36<04:42,  6.41it/s, est. speed input: 1346.09 toks/s, output: 5694.23 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 363/2176 [00:36<05:00,  6.03it/s, est. speed input: 1339.09 toks/s, output: 5680.00 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 372/2176 [00:36<02:29, 12.10it/s, est. speed input: 1357.39 toks/s, output: 5779.02 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 375/2176 [00:37<02:30, 12.00it/s, est. speed input: 1356.30 toks/s, output: 5785.05 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 378/2176 [00:37<03:43,  8.05it/s, est. speed input: 1334.72 toks/s, output: 5698.55 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 380/2176 [00:41<12:09,  2.46it/s, est. speed input: 1228.89 toks/s, output: 5243.81 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 384/2176 [00:41<08:54,  3.35it/s, est. speed input: 1228.23 toks/s, output: 5222.93 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 387/2176 [00:42<08:37,  3.46it/s, est. speed input: 1212.21 toks/s, output: 5141.61 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 388/2176 [00:43<09:49,  3.03it/s, est. speed input: 1198.06 toks/s, output: 5081.27 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 393/2176 [00:44<07:51,  3.78it/s, est. speed input: 1191.31 toks/s, output: 5059.58 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 397/2176 [00:44<05:34,  5.32it/s, est. speed input: 1196.36 toks/s, output: 5120.31 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 399/2176 [00:44<04:57,  5.96it/s, est. speed input: 1197.48 toks/s, output: 5148.36 toks/s][A
Processed prompts:  19%|‚ñà‚ñä        | 404/2176 [00:44<03:53,  7.58it/s, est. speed input: 1199.58 toks/s, output: 5210.32 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 409/2176 [00:44<02:50, 10.38it/s, est. speed input: 1203.21 toks/s, output: 5267.14 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 412/2176 [00:45<02:57,  9.97it/s, est. speed input: 1198.43 toks/s, output: 5274.48 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 414/2176 [00:46<04:22,  6.72it/s, est. speed input: 1182.45 toks/s, output: 5222.69 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 416/2176 [00:50<17:37,  1.66it/s, est. speed input: 1082.94 toks/s, output: 4825.61 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 417/2176 [00:50<16:33,  1.77it/s, est. speed input: 1079.53 toks/s, output: 4844.91 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 425/2176 [00:52<10:23,  2.81it/s, est. speed input: 1072.46 toks/s, output: 5075.24 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 429/2176 [00:53<08:15,  3.52it/s, est. speed input: 1078.38 toks/s, output: 5200.32 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 431/2176 [00:55<13:04,  2.22it/s, est. speed input: 1033.52 toks/s, output: 4999.60 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 434/2176 [00:55<10:22,  2.80it/s, est. speed input: 1031.72 toks/s, output: 4996.75 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 436/2176 [00:56<09:39,  3.00it/s, est. speed input: 1025.96 toks/s, output: 4972.72 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 437/2176 [00:58<15:05,  1.92it/s, est. speed input: 996.91 toks/s, output: 4832.89 toks/s] [A
Processed prompts:  20%|‚ñà‚ñà        | 438/2176 [00:59<17:56,  1.61it/s, est. speed input: 979.95 toks/s, output: 4753.14 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 440/2176 [01:00<17:04,  1.69it/s, est. speed input: 967.83 toks/s, output: 4698.65 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 442/2176 [01:01<15:03,  1.92it/s, est. speed input: 961.13 toks/s, output: 4670.37 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 445/2176 [01:02<12:39,  2.28it/s, est. speed input: 952.66 toks/s, output: 4635.61 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 447/2176 [01:02<09:53,  2.91it/s, est. speed input: 953.12 toks/s, output: 4679.93 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 459/2176 [01:02<03:13,  8.86it/s, est. speed input: 983.44 toks/s, output: 5257.42 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 502/2176 [01:07<03:19,  8.41it/s, est. speed input: 1033.73 toks/s, output: 6808.31 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 510/2176 [01:07<02:54,  9.52it/s, est. speed input: 1053.49 toks/s, output: 7139.78 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñé       | 515/2176 [01:08<02:35, 10.66it/s, est. speed input: 1058.35 toks/s, output: 7354.73 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 518/2176 [01:08<02:32, 10.89it/s, est. speed input: 1058.28 toks/s, output: 7424.86 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 521/2176 [01:11<05:38,  4.88it/s, est. speed input: 1020.61 toks/s, output: 7143.07 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 523/2176 [01:13<08:52,  3.10it/s, est. speed input: 987.37 toks/s, output: 6901.38 toks/s] [A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 527/2176 [01:13<07:11,  3.82it/s, est. speed input: 991.86 toks/s, output: 6930.18 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñç       | 537/2176 [01:14<04:37,  5.90it/s, est. speed input: 1015.96 toks/s, output: 7142.85 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñç       | 539/2176 [01:14<04:15,  6.41it/s, est. speed input: 1021.26 toks/s, output: 7183.26 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 548/2176 [01:15<03:09,  8.59it/s, est. speed input: 1035.30 toks/s, output: 7467.01 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 550/2176 [01:15<03:02,  8.91it/s, est. speed input: 1037.46 toks/s, output: 7468.04 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 554/2176 [01:15<02:29, 10.82it/s, est. speed input: 1044.37 toks/s, output: 7488.84 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 557/2176 [01:15<02:21, 11.47it/s, est. speed input: 1047.11 toks/s, output: 7526.38 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 565/2176 [01:16<01:51, 14.40it/s, est. speed input: 1048.66 toks/s, output: 7621.14 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 567/2176 [01:17<04:02,  6.64it/s, est. speed input: 1034.41 toks/s, output: 7542.63 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñã       | 574/2176 [01:17<02:38, 10.14it/s, est. speed input: 1040.62 toks/s, output: 7803.74 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 577/2176 [01:18<04:09,  6.41it/s, est. speed input: 1039.59 toks/s, output: 7806.19 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 579/2176 [01:19<04:00,  6.63it/s, est. speed input: 1045.81 toks/s, output: 7859.62 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 582/2176 [01:19<03:21,  7.92it/s, est. speed input: 1057.80 toks/s, output: 7959.58 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 586/2176 [01:19<03:20,  7.93it/s, est. speed input: 1061.73 toks/s, output: 8063.65 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 591/2176 [01:20<03:55,  6.72it/s, est. speed input: 1064.12 toks/s, output: 8160.32 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 593/2176 [01:20<03:45,  7.03it/s, est. speed input: 1069.74 toks/s, output: 8213.91 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 595/2176 [01:21<04:07,  6.40it/s, est. speed input: 1072.61 toks/s, output: 8246.42 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 599/2176 [01:21<03:24,  7.73it/s, est. speed input: 1084.92 toks/s, output: 8363.79 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 603/2176 [01:22<03:32,  7.40it/s, est. speed input: 1092.87 toks/s, output: 8453.71 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 610/2176 [01:22<02:30, 10.38it/s, est. speed input: 1112.01 toks/s, output: 8677.72 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 615/2176 [01:25<06:24,  4.06it/s, est. speed input: 1090.72 toks/s, output: 8570.67 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 616/2176 [01:25<06:29,  4.00it/s, est. speed input: 1090.72 toks/s, output: 8577.52 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 617/2176 [01:26<07:06,  3.65it/s, est. speed input: 1088.39 toks/s, output: 8565.87 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 620/2176 [01:26<05:36,  4.62it/s, est. speed input: 1095.97 toks/s, output: 8645.58 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñä       | 623/2176 [01:27<06:12,  4.17it/s, est. speed input: 1092.95 toks/s, output: 8639.48 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñä       | 625/2176 [01:28<07:32,  3.43it/s, est. speed input: 1082.79 toks/s, output: 8592.86 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 635/2176 [01:28<03:25,  7.51it/s, est. speed input: 1085.49 toks/s, output: 8905.18 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 637/2176 [01:28<03:33,  7.19it/s, est. speed input: 1082.65 toks/s, output: 8939.70 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 641/2176 [01:29<04:14,  6.02it/s, est. speed input: 1077.53 toks/s, output: 8985.35 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 643/2176 [01:30<03:55,  6.52it/s, est. speed input: 1083.00 toks/s, output: 9034.73 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 644/2176 [01:30<05:25,  4.70it/s, est. speed input: 1078.70 toks/s, output: 9000.72 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 647/2176 [01:30<04:19,  5.90it/s, est. speed input: 1087.35 toks/s, output: 9078.45 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 648/2176 [01:31<04:55,  5.17it/s, est. speed input: 1087.01 toks/s, output: 9077.45 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 649/2176 [01:36<25:24,  1.00it/s, est. speed input: 1030.61 toks/s, output: 8619.39 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 651/2176 [01:36<18:04,  1.41it/s, est. speed input: 1033.33 toks/s, output: 8667.73 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 655/2176 [01:36<10:10,  2.49it/s, est. speed input: 1039.97 toks/s, output: 8774.45 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 665/2176 [01:37<04:09,  6.06it/s, est. speed input: 1060.58 toks/s, output: 8981.54 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 669/2176 [01:38<05:10,  4.85it/s, est. speed input: 1055.42 toks/s, output: 8901.31 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 671/2176 [01:38<04:57,  5.07it/s, est. speed input: 1053.73 toks/s, output: 8888.97 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 675/2176 [01:38<03:43,  6.73it/s, est. speed input: 1056.88 toks/s, output: 8907.07 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 677/2176 [01:39<03:32,  7.06it/s, est. speed input: 1058.58 toks/s, output: 8949.18 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 679/2176 [01:39<04:14,  5.88it/s, est. speed input: 1057.20 toks/s, output: 8960.81 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà‚ñè      | 681/2176 [01:40<06:48,  3.66it/s, est. speed input: 1049.12 toks/s, output: 8911.03 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 687/2176 [01:41<03:51,  6.44it/s, est. speed input: 1060.08 toks/s, output: 9074.92 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 689/2176 [01:41<04:01,  6.15it/s, est. speed input: 1057.49 toks/s, output: 9077.73 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 697/2176 [01:42<03:53,  6.34it/s, est. speed input: 1050.69 toks/s, output: 9185.82 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 700/2176 [01:45<07:08,  3.44it/s, est. speed input: 1030.37 toks/s, output: 9044.40 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 703/2176 [01:46<07:37,  3.22it/s, est. speed input: 1022.15 toks/s, output: 8979.62 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 707/2176 [01:46<05:54,  4.15it/s, est. speed input: 1022.21 toks/s, output: 9065.47 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 708/2176 [01:46<06:17,  3.89it/s, est. speed input: 1019.50 toks/s, output: 9040.72 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 711/2176 [01:47<04:58,  4.91it/s, est. speed input: 1020.55 toks/s, output: 9047.64 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 714/2176 [01:47<03:59,  6.12it/s, est. speed input: 1021.69 toks/s, output: 9049.26 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 717/2176 [01:47<04:10,  5.83it/s, est. speed input: 1019.20 toks/s, output: 9012.47 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 719/2176 [01:48<04:43,  5.13it/s, est. speed input: 1016.01 toks/s, output: 8976.61 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 721/2176 [01:48<04:44,  5.12it/s, est. speed input: 1015.21 toks/s, output: 8973.38 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 725/2176 [01:49<03:10,  7.60it/s, est. speed input: 1021.69 toks/s, output: 9073.26 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 727/2176 [01:49<02:55,  8.27it/s, est. speed input: 1024.07 toks/s, output: 9115.50 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñé      | 732/2176 [01:49<02:07, 11.30it/s, est. speed input: 1028.72 toks/s, output: 9213.26 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 736/2176 [01:49<01:44, 13.80it/s, est. speed input: 1031.37 toks/s, output: 9244.25 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 741/2176 [01:50<03:07,  7.66it/s, est. speed input: 1027.00 toks/s, output: 9266.14 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 743/2176 [01:51<03:12,  7.46it/s, est. speed input: 1026.11 toks/s, output: 9252.11 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 745/2176 [01:56<16:12,  1.47it/s, est. speed input: 977.82 toks/s, output: 8833.57 toks/s] [A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 753/2176 [01:57<09:12,  2.58it/s, est. speed input: 974.76 toks/s, output: 8944.03 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 754/2176 [01:57<08:43,  2.71it/s, est. speed input: 974.24 toks/s, output: 8940.34 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 763/2176 [01:58<04:59,  4.72it/s, est. speed input: 980.27 toks/s, output: 9038.28 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 765/2176 [01:58<04:30,  5.21it/s, est. speed input: 981.71 toks/s, output: 9061.88 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 767/2176 [02:01<08:16,  2.84it/s, est. speed input: 966.85 toks/s, output: 8942.63 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 770/2176 [02:02<08:32,  2.75it/s, est. speed input: 962.60 toks/s, output: 8929.47 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 773/2176 [02:03<08:55,  2.62it/s, est. speed input: 958.53 toks/s, output: 8892.84 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 775/2176 [02:03<07:28,  3.13it/s, est. speed input: 961.52 toks/s, output: 8899.95 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 776/2176 [02:03<07:10,  3.25it/s, est. speed input: 961.94 toks/s, output: 8893.55 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 778/2176 [02:05<10:42,  2.18it/s, est. speed input: 952.16 toks/s, output: 8804.22 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 780/2176 [02:06<11:03,  2.10it/s, est. speed input: 948.11 toks/s, output: 8781.04 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 782/2176 [02:06<08:18,  2.79it/s, est. speed input: 949.71 toks/s, output: 8803.03 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 786/2176 [02:06<04:52,  4.75it/s, est. speed input: 953.92 toks/s, output: 8856.33 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 795/2176 [02:07<02:12, 10.39it/s, est. speed input: 974.18 toks/s, output: 9045.56 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 829/2176 [02:08<01:25, 15.70it/s, est. speed input: 1007.78 toks/s, output: 9639.33 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 837/2176 [02:09<01:13, 18.22it/s, est. speed input: 1013.02 toks/s, output: 9663.20 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñä      | 841/2176 [02:11<02:47,  7.97it/s, est. speed input: 996.35 toks/s, output: 9497.31 toks/s] [A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 844/2176 [02:12<03:07,  7.11it/s, est. speed input: 993.27 toks/s, output: 9471.93 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 847/2176 [02:12<02:59,  7.42it/s, est. speed input: 994.66 toks/s, output: 9519.98 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 849/2176 [02:12<02:45,  8.02it/s, est. speed input: 994.83 toks/s, output: 9558.75 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 852/2176 [02:12<02:20,  9.42it/s, est. speed input: 996.69 toks/s, output: 9598.92 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 856/2176 [02:12<01:55, 11.42it/s, est. speed input: 1002.18 toks/s, output: 9593.05 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 859/2176 [02:13<02:05, 10.47it/s, est. speed input: 1001.78 toks/s, output: 9581.13 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 861/2176 [02:13<01:59, 10.98it/s, est. speed input: 1003.61 toks/s, output: 9588.57 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 863/2176 [02:13<02:34,  8.52it/s, est. speed input: 1004.30 toks/s, output: 9581.64 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 865/2176 [02:14<02:28,  8.81it/s, est. speed input: 1004.60 toks/s, output: 9578.57 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 867/2176 [02:15<05:24,  4.03it/s, est. speed input: 998.08 toks/s, output: 9487.83 toks/s] [A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 869/2176 [02:15<04:34,  4.76it/s, est. speed input: 998.70 toks/s, output: 9497.74 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 871/2176 [02:15<03:41,  5.89it/s, est. speed input: 999.34 toks/s, output: 9517.06 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 873/2176 [02:16<03:52,  5.61it/s, est. speed input: 997.96 toks/s, output: 9497.79 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 880/2176 [02:17<03:29,  6.17it/s, est. speed input: 995.01 toks/s, output: 9448.93 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 881/2176 [02:17<03:48,  5.68it/s, est. speed input: 994.72 toks/s, output: 9430.31 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 883/2176 [02:17<03:42,  5.80it/s, est. speed input: 996.09 toks/s, output: 9411.65 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 885/2176 [02:17<03:09,  6.82it/s, est. speed input: 998.78 toks/s, output: 9405.54 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 887/2176 [02:18<03:06,  6.92it/s, est. speed input: 999.26 toks/s, output: 9410.55 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 892/2176 [02:18<01:56, 11.06it/s, est. speed input: 1002.49 toks/s, output: 9489.82 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 894/2176 [02:18<01:45, 12.13it/s, est. speed input: 1002.99 toks/s, output: 9526.80 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 903/2176 [02:18<00:52, 24.05it/s, est. speed input: 1007.72 toks/s, output: 9698.19 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 907/2176 [02:19<01:30, 14.08it/s, est. speed input: 1005.02 toks/s, output: 9744.46 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 915/2176 [02:19<01:25, 14.76it/s, est. speed input: 1006.33 toks/s, output: 9867.52 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 918/2176 [02:19<01:19, 15.89it/s, est. speed input: 1007.93 toks/s, output: 9889.63 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 924/2176 [02:19<00:59, 21.13it/s, est. speed input: 1012.20 toks/s, output: 9926.55 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 928/2176 [02:20<01:09, 17.91it/s, est. speed input: 1012.88 toks/s, output: 9991.14 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 932/2176 [02:20<01:22, 15.15it/s, est. speed input: 1012.49 toks/s, output: 10051.69 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 935/2176 [02:22<03:24,  6.06it/s, est. speed input: 1003.21 toks/s, output: 10007.16 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 941/2176 [02:22<02:17,  8.95it/s, est. speed input: 1005.74 toks/s, output: 10125.27 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 944/2176 [02:23<03:51,  5.33it/s, est. speed input: 998.08 toks/s, output: 10078.82 toks/s] [A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 946/2176 [02:24<03:38,  5.62it/s, est. speed input: 1000.36 toks/s, output: 10103.17 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 956/2176 [02:24<01:47, 11.30it/s, est. speed input: 1019.04 toks/s, output: 10168.66 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 961/2176 [02:24<01:51, 10.91it/s, est. speed input: 1026.27 toks/s, output: 10220.29 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 967/2176 [02:25<01:42, 11.77it/s, est. speed input: 1038.05 toks/s, output: 10300.20 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 971/2176 [02:25<01:39, 12.09it/s, est. speed input: 1041.45 toks/s, output: 10295.03 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 973/2176 [02:25<01:45, 11.35it/s, est. speed input: 1045.08 toks/s, output: 10320.27 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 975/2176 [02:26<02:14,  8.91it/s, est. speed input: 1043.27 toks/s, output: 10311.08 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 977/2176 [02:26<02:02,  9.78it/s, est. speed input: 1043.86 toks/s, output: 10325.55 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 982/2176 [02:26<01:41, 11.81it/s, est. speed input: 1044.71 toks/s, output: 10409.38 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 986/2176 [02:26<01:19, 14.88it/s, est. speed input: 1047.65 toks/s, output: 10465.82 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 989/2176 [02:27<01:39, 11.92it/s, est. speed input: 1047.72 toks/s, output: 10462.68 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 995/2176 [02:29<04:52,  4.04it/s, est. speed input: 1034.47 toks/s, output: 10373.39 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 997/2176 [02:31<06:34,  2.99it/s, est. speed input: 1026.66 toks/s, output: 10280.38 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 999/2176 [02:32<07:05,  2.77it/s, est. speed input: 1023.83 toks/s, output: 10242.58 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1009/2176 [02:32<03:16,  5.93it/s, est. speed input: 1038.70 toks/s, output: 10424.43 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1011/2176 [02:32<03:13,  6.02it/s, est. speed input: 1037.48 toks/s, output: 10444.16 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1015/2176 [02:33<03:03,  6.31it/s, est. speed input: 1037.62 toks/s, output: 10486.16 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1017/2176 [02:33<02:48,  6.88it/s, est. speed input: 1041.93 toks/s, output: 10515.00 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1019/2176 [02:33<02:33,  7.54it/s, est. speed input: 1041.89 toks/s, output: 10508.66 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1021/2176 [02:34<02:44,  7.00it/s, est. speed input: 1042.70 toks/s, output: 10506.58 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1028/2176 [02:34<01:32, 12.45it/s, est. speed input: 1051.78 toks/s, output: 10564.59 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1031/2176 [02:34<01:30, 12.70it/s, est. speed input: 1054.72 toks/s, output: 10574.16 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1033/2176 [02:35<02:10,  8.76it/s, est. speed input: 1051.84 toks/s, output: 10544.41 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1038/2176 [02:35<01:54,  9.93it/s, est. speed input: 1051.02 toks/s, output: 10533.97 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1041/2176 [02:37<04:25,  4.28it/s, est. speed input: 1040.35 toks/s, output: 10418.07 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1042/2176 [02:39<07:59,  2.36it/s, est. speed input: 1028.29 toks/s, output: 10291.07 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1045/2176 [02:40<07:42,  2.44it/s, est. speed input: 1023.53 toks/s, output: 10224.99 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1051/2176 [02:40<04:18,  4.36it/s, est. speed input: 1031.39 toks/s, output: 10310.93 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1055/2176 [02:41<04:42,  3.97it/s, est. speed input: 1029.39 toks/s, output: 10299.98 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1058/2176 [02:44<07:36,  2.45it/s, est. speed input: 1015.98 toks/s, output: 10171.45 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1064/2176 [02:44<04:40,  3.96it/s, est. speed input: 1023.76 toks/s, output: 10270.49 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1066/2176 [02:45<04:29,  4.12it/s, est. speed input: 1023.80 toks/s, output: 10283.75 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1074/2176 [02:49<07:44,  2.37it/s, est. speed input: 1002.59 toks/s, output: 10133.03 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1076/2176 [02:50<07:25,  2.47it/s, est. speed input: 1002.78 toks/s, output: 10132.18 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1077/2176 [02:50<07:25,  2.47it/s, est. speed input: 1002.30 toks/s, output: 10126.05 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1080/2176 [02:51<05:41,  3.21it/s, est. speed input: 1006.56 toks/s, output: 10165.04 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1083/2176 [02:51<04:23,  4.14it/s, est. speed input: 1010.56 toks/s, output: 10205.84 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1086/2176 [02:52<04:08,  4.40it/s, est. speed input: 1012.18 toks/s, output: 10224.86 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1088/2176 [02:52<04:20,  4.17it/s, est. speed input: 1012.22 toks/s, output: 10227.00 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1090/2176 [02:53<04:10,  4.33it/s, est. speed input: 1011.98 toks/s, output: 10238.40 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1094/2176 [02:53<02:45,  6.53it/s, est. speed input: 1012.99 toks/s, output: 10300.17 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1096/2176 [02:53<02:28,  7.27it/s, est. speed input: 1012.97 toks/s, output: 10325.66 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1098/2176 [02:53<02:45,  6.53it/s, est. speed input: 1011.52 toks/s, output: 10337.07 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1102/2176 [02:54<03:41,  4.84it/s, est. speed input: 1006.64 toks/s, output: 10340.20 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1103/2176 [02:55<03:55,  4.57it/s, est. speed input: 1005.32 toks/s, output: 10339.83 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1106/2176 [03:01<16:03,  1.11it/s, est. speed input: 970.93 toks/s, output: 10024.10 toks/s] [A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1107/2176 [03:01<14:13,  1.25it/s, est. speed input: 970.34 toks/s, output: 10030.50 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1114/2176 [03:04<10:22,  1.71it/s, est. speed input: 957.79 toks/s, output: 9965.73 toks/s] [A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1115/2176 [03:08<15:57,  1.11it/s, est. speed input: 941.64 toks/s, output: 9795.43 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1116/2176 [03:10<17:40,  1.00s/it, est. speed input: 935.27 toks/s, output: 9727.04 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1118/2176 [03:11<15:54,  1.11it/s, est. speed input: 932.48 toks/s, output: 9693.70 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1120/2176 [03:11<11:41,  1.51it/s, est. speed input: 935.40 toks/s, output: 9719.72 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1123/2176 [03:11<07:55,  2.22it/s, est. speed input: 938.20 toks/s, output: 9752.74 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1151/2176 [03:11<01:20, 12.79it/s, est. speed input: 963.68 toks/s, output: 10181.68 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1160/2176 [03:13<01:49,  9.28it/s, est. speed input: 962.74 toks/s, output: 10155.67 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1166/2176 [03:13<01:31, 11.08it/s, est. speed input: 964.23 toks/s, output: 10166.43 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1172/2176 [03:17<03:32,  4.73it/s, est. speed input: 949.13 toks/s, output: 10023.86 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1176/2176 [03:19<04:46,  3.49it/s, est. speed input: 939.77 toks/s, output: 9932.25 toks/s] [A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1182/2176 [03:20<03:37,  4.57it/s, est. speed input: 941.90 toks/s, output: 9930.53 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1185/2176 [03:20<03:20,  4.95it/s, est. speed input: 942.72 toks/s, output: 9959.38 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1188/2176 [03:20<03:02,  5.42it/s, est. speed input: 943.58 toks/s, output: 9988.68 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1190/2176 [03:21<03:04,  5.34it/s, est. speed input: 942.73 toks/s, output: 9999.06 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1197/2176 [03:22<02:47,  5.84it/s, est. speed input: 939.52 toks/s, output: 10053.28 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1199/2176 [03:22<02:43,  5.96it/s, est. speed input: 938.63 toks/s, output: 10068.99 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1200/2176 [03:22<02:57,  5.49it/s, est. speed input: 937.42 toks/s, output: 10068.47 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1202/2176 [03:23<02:34,  6.31it/s, est. speed input: 937.22 toks/s, output: 10091.49 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1204/2176 [03:23<02:30,  6.47it/s, est. speed input: 936.40 toks/s, output: 10107.59 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1209/2176 [03:23<01:35, 10.13it/s, est. speed input: 937.20 toks/s, output: 10174.92 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1211/2176 [03:23<01:26, 11.17it/s, est. speed input: 937.36 toks/s, output: 10199.66 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1214/2176 [03:24<01:58,  8.13it/s, est. speed input: 935.84 toks/s, output: 10215.10 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1216/2176 [03:24<01:43,  9.32it/s, est. speed input: 936.46 toks/s, output: 10239.76 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1222/2176 [03:24<01:31, 10.44it/s, est. speed input: 937.57 toks/s, output: 10304.59 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1225/2176 [03:24<01:18, 12.16it/s, est. speed input: 940.27 toks/s, output: 10342.94 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1228/2176 [03:25<01:06, 14.24it/s, est. speed input: 945.93 toks/s, output: 10382.17 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1232/2176 [03:25<01:09, 13.49it/s, est. speed input: 952.64 toks/s, output: 10425.47 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1236/2176 [03:25<01:16, 12.35it/s, est. speed input: 952.20 toks/s, output: 10465.91 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1238/2176 [03:27<02:58,  5.27it/s, est. speed input: 946.83 toks/s, output: 10429.32 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1245/2176 [03:27<01:41,  9.18it/s, est. speed input: 954.09 toks/s, output: 10524.77 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1248/2176 [03:28<02:38,  5.87it/s, est. speed input: 953.30 toks/s, output: 10511.88 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1250/2176 [03:28<02:31,  6.10it/s, est. speed input: 952.63 toks/s, output: 10527.84 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1260/2176 [03:28<01:13, 12.40it/s, est. speed input: 957.71 toks/s, output: 10667.06 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1265/2176 [03:29<01:39,  9.11it/s, est. speed input: 959.41 toks/s, output: 10693.94 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1268/2176 [03:30<01:52,  8.10it/s, est. speed input: 962.12 toks/s, output: 10710.38 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1270/2176 [03:30<01:50,  8.22it/s, est. speed input: 964.53 toks/s, output: 10728.20 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1272/2176 [03:30<01:49,  8.24it/s, est. speed input: 966.87 toks/s, output: 10745.10 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1274/2176 [03:30<01:38,  9.18it/s, est. speed input: 966.82 toks/s, output: 10767.95 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1278/2176 [03:31<01:26, 10.39it/s, est. speed input: 966.47 toks/s, output: 10810.90 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1281/2176 [03:32<03:39,  4.09it/s, est. speed input: 959.01 toks/s, output: 10747.80 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1282/2176 [03:33<03:23,  4.40it/s, est. speed input: 958.98 toks/s, output: 10744.58 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1284/2176 [03:33<03:04,  4.83it/s, est. speed input: 958.50 toks/s, output: 10733.54 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1285/2176 [03:33<03:03,  4.86it/s, est. speed input: 958.03 toks/s, output: 10725.56 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1289/2176 [03:37<07:51,  1.88it/s, est. speed input: 943.65 toks/s, output: 10567.40 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1297/2176 [03:37<03:38,  4.02it/s, est. speed input: 944.86 toks/s, output: 10666.14 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1299/2176 [03:37<03:23,  4.31it/s, est. speed input: 944.25 toks/s, output: 10679.54 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1303/2176 [03:38<02:56,  4.96it/s, est. speed input: 943.25 toks/s, output: 10708.58 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1305/2176 [03:38<02:36,  5.58it/s, est. speed input: 943.75 toks/s, output: 10728.54 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1307/2176 [03:38<02:17,  6.31it/s, est. speed input: 944.78 toks/s, output: 10748.62 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1309/2176 [03:39<02:21,  6.12it/s, est. speed input: 944.96 toks/s, output: 10759.09 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1316/2176 [03:39<01:15, 11.32it/s, est. speed input: 948.39 toks/s, output: 10848.98 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1319/2176 [03:39<01:09, 12.25it/s, est. speed input: 949.42 toks/s, output: 10870.63 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1324/2176 [03:39<01:19, 10.77it/s, est. speed input: 950.92 toks/s, output: 10879.22 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1330/2176 [03:40<01:11, 11.85it/s, est. speed input: 959.28 toks/s, output: 10941.78 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1333/2176 [03:40<01:15, 11.21it/s, est. speed input: 962.33 toks/s, output: 10956.51 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1336/2176 [03:42<02:36,  5.36it/s, est. speed input: 959.70 toks/s, output: 10902.03 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1340/2176 [03:42<02:21,  5.91it/s, est. speed input: 958.84 toks/s, output: 10888.57 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1344/2176 [03:43<01:57,  7.06it/s, est. speed input: 958.85 toks/s, output: 10885.62 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1346/2176 [03:43<02:29,  5.55it/s, est. speed input: 959.41 toks/s, output: 10878.51 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1348/2176 [03:44<03:41,  3.73it/s, est. speed input: 957.80 toks/s, output: 10846.92 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1350/2176 [03:45<03:02,  4.52it/s, est. speed input: 960.85 toks/s, output: 10868.26 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1358/2176 [03:46<02:32,  5.37it/s, est. speed input: 960.88 toks/s, output: 10915.75 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1361/2176 [03:48<03:49,  3.55it/s, est. speed input: 955.02 toks/s, output: 10861.70 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1365/2176 [03:49<03:32,  3.81it/s, est. speed input: 954.68 toks/s, output: 10839.63 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1366/2176 [03:49<03:26,  3.93it/s, est. speed input: 954.26 toks/s, output: 10844.40 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1372/2176 [03:49<02:03,  6.51it/s, est. speed input: 955.48 toks/s, output: 10915.05 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1374/2176 [03:49<02:08,  6.25it/s, est. speed input: 956.47 toks/s, output: 10923.71 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1386/2176 [03:50<01:03, 12.51it/s, est. speed input: 967.95 toks/s, output: 11022.68 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1388/2176 [03:50<01:06, 11.78it/s, est. speed input: 967.80 toks/s, output: 11015.98 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1390/2176 [03:50<01:08, 11.48it/s, est. speed input: 967.83 toks/s, output: 11011.16 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1392/2176 [03:50<01:03, 12.41it/s, est. speed input: 968.26 toks/s, output: 11011.03 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1394/2176 [03:53<04:17,  3.04it/s, est. speed input: 958.74 toks/s, output: 10893.92 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1396/2176 [03:53<03:44,  3.47it/s, est. speed input: 959.20 toks/s, output: 10886.54 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1400/2176 [03:53<02:25,  5.34it/s, est. speed input: 961.70 toks/s, output: 10893.55 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1402/2176 [03:53<02:15,  5.72it/s, est. speed input: 961.59 toks/s, output: 10887.23 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1405/2176 [03:54<01:46,  7.23it/s, est. speed input: 962.65 toks/s, output: 10887.91 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1407/2176 [03:54<01:52,  6.85it/s, est. speed input: 963.31 toks/s, output: 10888.39 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1409/2176 [03:54<01:56,  6.57it/s, est. speed input: 964.36 toks/s, output: 10898.67 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1411/2176 [03:55<02:06,  6.07it/s, est. speed input: 965.17 toks/s, output: 10906.28 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1413/2176 [03:55<01:56,  6.56it/s, est. speed input: 966.64 toks/s, output: 10921.27 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1416/2176 [03:55<01:32,  8.23it/s, est. speed input: 967.75 toks/s, output: 10950.86 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1420/2176 [03:56<01:38,  7.64it/s, est. speed input: 967.82 toks/s, output: 10966.49 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1422/2176 [03:56<02:03,  6.09it/s, est. speed input: 966.86 toks/s, output: 10966.80 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1424/2176 [03:57<02:32,  4.93it/s, est. speed input: 964.81 toks/s, output: 10962.93 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1428/2176 [03:57<01:40,  7.43it/s, est. speed input: 965.35 toks/s, output: 11007.77 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1430/2176 [03:57<01:31,  8.11it/s, est. speed input: 965.23 toks/s, output: 11025.76 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1432/2176 [03:58<01:45,  7.05it/s, est. speed input: 965.60 toks/s, output: 11033.15 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1436/2176 [03:59<02:15,  5.47it/s, est. speed input: 965.14 toks/s, output: 11031.17 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1438/2176 [03:59<01:57,  6.27it/s, est. speed input: 965.94 toks/s, output: 11040.61 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1439/2176 [03:59<02:11,  5.58it/s, est. speed input: 965.72 toks/s, output: 11039.60 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1441/2176 [04:05<12:25,  1.01s/it, est. speed input: 942.58 toks/s, output: 10785.37 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1442/2176 [04:07<14:06,  1.15s/it, est. speed input: 936.07 toks/s, output: 10710.04 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1443/2176 [04:08<13:17,  1.09s/it, est. speed input: 933.31 toks/s, output: 10687.13 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1444/2176 [04:08<10:46,  1.13it/s, est. speed input: 933.23 toks/s, output: 10685.28 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1447/2176 [04:09<06:42,  1.81it/s, est. speed input: 932.38 toks/s, output: 10673.29 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1448/2176 [04:09<06:26,  1.88it/s, est. speed input: 931.15 toks/s, output: 10656.97 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1451/2176 [04:09<03:48,  3.18it/s, est. speed input: 931.89 toks/s, output: 10658.75 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1453/2176 [04:10<03:13,  3.74it/s, est. speed input: 931.59 toks/s, output: 10652.86 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1456/2176 [04:10<02:22,  5.07it/s, est. speed input: 931.94 toks/s, output: 10654.00 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1457/2176 [04:11<04:32,  2.64it/s, est. speed input: 927.23 toks/s, output: 10608.58 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1458/2176 [04:12<05:42,  2.10it/s, est. speed input: 924.28 toks/s, output: 10573.21 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1460/2176 [04:13<05:04,  2.35it/s, est. speed input: 922.61 toks/s, output: 10560.82 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1462/2176 [04:14<05:25,  2.20it/s, est. speed input: 919.50 toks/s, output: 10542.15 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1464/2176 [04:14<04:01,  2.95it/s, est. speed input: 919.47 toks/s, output: 10558.58 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1467/2176 [04:14<02:55,  4.04it/s, est. speed input: 919.46 toks/s, output: 10580.62 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1481/2176 [04:15<00:58, 11.97it/s, est. speed input: 934.06 toks/s, output: 10735.85 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1486/2176 [04:17<01:55,  5.96it/s, est. speed input: 934.17 toks/s, output: 10713.45 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1490/2176 [04:17<01:34,  7.25it/s, est. speed input: 938.93 toks/s, output: 10754.23 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1498/2176 [04:17<01:03, 10.76it/s, est. speed input: 946.49 toks/s, output: 10831.00 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1501/2176 [04:19<02:19,  4.85it/s, est. speed input: 939.86 toks/s, output: 10752.05 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1503/2176 [04:19<02:07,  5.29it/s, est. speed input: 940.05 toks/s, output: 10760.83 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1505/2176 [04:20<02:45,  4.07it/s, est. speed input: 937.09 toks/s, output: 10741.44 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1507/2176 [04:21<02:28,  4.52it/s, est. speed input: 937.13 toks/s, output: 10745.63 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1509/2176 [04:22<03:16,  3.39it/s, est. speed input: 934.12 toks/s, output: 10707.06 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1513/2176 [04:22<02:26,  4.53it/s, est. speed input: 934.58 toks/s, output: 10709.13 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1516/2176 [04:22<02:02,  5.37it/s, est. speed input: 934.92 toks/s, output: 10712.57 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1517/2176 [04:23<02:37,  4.17it/s, est. speed input: 933.10 toks/s, output: 10698.85 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1524/2176 [04:23<01:19,  8.17it/s, est. speed input: 935.14 toks/s, output: 10753.86 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1527/2176 [04:24<01:22,  7.86it/s, est. speed input: 934.82 toks/s, output: 10761.69 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1530/2176 [04:24<01:12,  8.97it/s, est. speed input: 935.12 toks/s, output: 10788.30 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1534/2176 [04:24<00:54, 11.76it/s, est. speed input: 936.40 toks/s, output: 10810.00 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1536/2176 [04:24<01:08,  9.31it/s, est. speed input: 935.66 toks/s, output: 10816.81 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1543/2176 [04:25<00:59, 10.66it/s, est. speed input: 935.88 toks/s, output: 10865.38 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1545/2176 [04:25<00:55, 11.30it/s, est. speed input: 936.51 toks/s, output: 10864.08 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1547/2176 [04:26<01:26,  7.30it/s, est. speed input: 934.61 toks/s, output: 10859.42 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1549/2176 [04:26<01:28,  7.05it/s, est. speed input: 933.97 toks/s, output: 10869.41 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1551/2176 [04:26<01:18,  7.97it/s, est. speed input: 933.90 toks/s, output: 10886.57 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1553/2176 [04:27<01:20,  7.71it/s, est. speed input: 933.33 toks/s, output: 10898.00 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1558/2176 [04:27<00:51, 11.94it/s, est. speed input: 934.02 toks/s, output: 10948.82 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1560/2176 [04:27<00:47, 12.99it/s, est. speed input: 934.48 toks/s, output: 10967.53 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1563/2176 [04:27<01:10,  8.69it/s, est. speed input: 933.63 toks/s, output: 10977.53 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1565/2176 [04:28<01:01,  9.92it/s, est. speed input: 934.09 toks/s, output: 10996.14 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1571/2176 [04:28<00:55, 10.83it/s, est. speed input: 934.08 toks/s, output: 11044.19 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1574/2176 [04:28<00:49, 12.06it/s, est. speed input: 934.49 toks/s, output: 11062.50 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1588/2176 [04:30<01:09,  8.47it/s, est. speed input: 933.85 toks/s, output: 11016.98 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1590/2176 [04:32<01:58,  4.93it/s, est. speed input: 928.72 toks/s, output: 10961.57 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1593/2176 [04:32<01:39,  5.88it/s, est. speed input: 929.41 toks/s, output: 10991.01 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1598/2176 [04:33<01:40,  5.73it/s, est. speed input: 928.02 toks/s, output: 11010.26 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1603/2176 [04:33<01:16,  7.53it/s, est. speed input: 929.42 toks/s, output: 11017.99 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1606/2176 [04:33<01:03,  8.91it/s, est. speed input: 930.03 toks/s, output: 11029.32 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1608/2176 [04:33<01:04,  8.77it/s, est. speed input: 929.86 toks/s, output: 11041.86 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1610/2176 [04:34<01:17,  7.32it/s, est. speed input: 928.96 toks/s, output: 11045.66 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1615/2176 [04:34<00:50, 11.16it/s, est. speed input: 931.43 toks/s, output: 11060.59 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1623/2176 [04:34<00:30, 18.32it/s, est. speed input: 935.15 toks/s, output: 11117.11 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1628/2176 [04:34<00:27, 19.77it/s, est. speed input: 936.62 toks/s, output: 11128.48 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1632/2176 [04:35<00:28, 19.34it/s, est. speed input: 938.28 toks/s, output: 11145.84 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1635/2176 [04:35<00:48, 11.26it/s, est. speed input: 937.79 toks/s, output: 11125.22 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1638/2176 [04:36<01:27,  6.18it/s, est. speed input: 934.80 toks/s, output: 11101.50 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1640/2176 [04:37<01:27,  6.15it/s, est. speed input: 934.15 toks/s, output: 11110.32 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1642/2176 [04:37<01:21,  6.58it/s, est. speed input: 934.23 toks/s, output: 11115.06 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1644/2176 [04:37<01:09,  7.70it/s, est. speed input: 934.32 toks/s, output: 11132.76 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1646/2176 [04:37<01:07,  7.91it/s, est. speed input: 934.37 toks/s, output: 11137.10 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1648/2176 [04:39<03:12,  2.75it/s, est. speed input: 928.61 toks/s, output: 11060.24 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1649/2176 [04:41<05:19,  1.65it/s, est. speed input: 922.55 toks/s, output: 10996.25 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1657/2176 [04:43<02:52,  3.00it/s, est. speed input: 919.74 toks/s, output: 11026.98 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1658/2176 [04:43<02:44,  3.14it/s, est. speed input: 919.46 toks/s, output: 11030.42 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1661/2176 [04:43<02:14,  3.83it/s, est. speed input: 919.19 toks/s, output: 11047.64 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1666/2176 [04:43<01:23,  6.13it/s, est. speed input: 921.08 toks/s, output: 11080.42 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1668/2176 [04:45<02:07,  3.97it/s, est. speed input: 919.05 toks/s, output: 11046.06 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1670/2176 [04:45<01:48,  4.66it/s, est. speed input: 921.14 toks/s, output: 11061.36 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1672/2176 [04:45<01:40,  5.02it/s, est. speed input: 922.15 toks/s, output: 11063.63 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1675/2176 [04:45<01:14,  6.76it/s, est. speed input: 925.62 toks/s, output: 11090.44 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1677/2176 [04:46<01:21,  6.09it/s, est. speed input: 925.56 toks/s, output: 11080.01 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1679/2176 [04:47<02:16,  3.65it/s, est. speed input: 923.09 toks/s, output: 11041.00 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1682/2176 [04:47<01:41,  4.87it/s, est. speed input: 925.21 toks/s, output: 11048.17 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1686/2176 [04:48<01:18,  6.20it/s, est. speed input: 927.20 toks/s, output: 11076.11 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1690/2176 [04:48<01:02,  7.80it/s, est. speed input: 929.50 toks/s, output: 11100.32 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1692/2176 [04:48<01:00,  8.05it/s, est. speed input: 930.40 toks/s, output: 11105.83 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1694/2176 [04:49<01:13,  6.57it/s, est. speed input: 930.41 toks/s, output: 11093.21 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1700/2176 [04:49<00:49,  9.61it/s, est. speed input: 932.26 toks/s, output: 11121.10 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1703/2176 [04:50<01:20,  5.85it/s, est. speed input: 930.00 toks/s, output: 11094.82 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1716/2176 [04:51<00:46,  9.92it/s, est. speed input: 934.88 toks/s, output: 11142.58 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1719/2176 [04:51<00:44, 10.36it/s, est. speed input: 936.40 toks/s, output: 11140.65 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1724/2176 [04:51<00:34, 12.92it/s, est. speed input: 939.53 toks/s, output: 11146.37 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1726/2176 [04:52<00:59,  7.50it/s, est. speed input: 937.62 toks/s, output: 11115.74 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1732/2176 [04:52<00:41, 10.81it/s, est. speed input: 939.90 toks/s, output: 11125.87 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1739/2176 [04:53<00:36, 11.92it/s, est. speed input: 941.68 toks/s, output: 11134.28 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1745/2176 [04:53<00:34, 12.40it/s, est. speed input: 942.82 toks/s, output: 11155.57 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1747/2176 [04:53<00:32, 13.03it/s, est. speed input: 943.34 toks/s, output: 11156.80 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1749/2176 [04:53<00:37, 11.53it/s, est. speed input: 943.00 toks/s, output: 11159.22 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1751/2176 [04:54<00:34, 12.47it/s, est. speed input: 944.15 toks/s, output: 11156.61 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1758/2176 [04:54<00:22, 18.81it/s, est. speed input: 945.64 toks/s, output: 11213.54 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1761/2176 [04:54<00:32, 12.65it/s, est. speed input: 944.90 toks/s, output: 11225.74 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1773/2176 [04:55<00:22, 18.08it/s, est. speed input: 949.95 toks/s, output: 11333.71 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1776/2176 [04:55<00:20, 19.06it/s, est. speed input: 951.80 toks/s, output: 11331.24 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1779/2176 [04:55<00:21, 18.74it/s, est. speed input: 953.10 toks/s, output: 11331.54 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1784/2176 [04:55<00:19, 19.76it/s, est. speed input: 955.00 toks/s, output: 11365.19 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1787/2176 [04:55<00:18, 21.22it/s, est. speed input: 956.12 toks/s, output: 11392.40 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1790/2176 [04:58<01:40,  3.84it/s, est. speed input: 948.40 toks/s, output: 11313.05 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1794/2176 [04:58<01:12,  5.27it/s, est. speed input: 950.05 toks/s, output: 11349.59 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1797/2176 [04:59<01:02,  6.07it/s, est. speed input: 950.14 toks/s, output: 11353.37 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1802/2176 [04:59<00:43,  8.65it/s, est. speed input: 951.11 toks/s, output: 11381.54 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1805/2176 [04:59<00:43,  8.54it/s, est. speed input: 950.77 toks/s, output: 11398.42 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1808/2176 [04:59<00:39,  9.29it/s, est. speed input: 950.94 toks/s, output: 11403.04 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1815/2176 [04:59<00:23, 15.38it/s, est. speed input: 953.16 toks/s, output: 11416.07 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1819/2176 [05:00<00:20, 17.17it/s, est. speed input: 954.19 toks/s, output: 11413.12 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1822/2176 [05:00<00:21, 16.65it/s, est. speed input: 954.47 toks/s, output: 11411.08 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1826/2176 [05:00<00:20, 17.46it/s, est. speed input: 955.17 toks/s, output: 11435.86 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1831/2176 [05:00<00:15, 22.52it/s, est. speed input: 957.05 toks/s, output: 11456.89 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1835/2176 [05:00<00:15, 22.38it/s, est. speed input: 958.97 toks/s, output: 11472.03 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1838/2176 [05:01<00:26, 12.67it/s, est. speed input: 958.30 toks/s, output: 11480.81 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1841/2176 [05:02<00:48,  6.89it/s, est. speed input: 956.07 toks/s, output: 11446.92 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1850/2176 [05:02<00:30, 10.61it/s, est. speed input: 958.52 toks/s, output: 11444.92 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1852/2176 [05:03<00:30, 10.53it/s, est. speed input: 959.02 toks/s, output: 11450.24 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1855/2176 [05:03<00:30, 10.41it/s, est. speed input: 960.37 toks/s, output: 11459.99 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1857/2176 [05:03<00:30, 10.35it/s, est. speed input: 961.05 toks/s, output: 11456.16 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1862/2176 [05:04<00:30, 10.43it/s, est. speed input: 963.35 toks/s, output: 11453.67 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1864/2176 [05:04<00:28, 10.77it/s, est. speed input: 964.25 toks/s, output: 11467.90 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1866/2176 [05:04<00:32,  9.57it/s, est. speed input: 964.71 toks/s, output: 11476.87 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1868/2176 [05:04<00:31,  9.91it/s, est. speed input: 964.97 toks/s, output: 11475.86 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1870/2176 [05:07<02:13,  2.28it/s, est. speed input: 956.60 toks/s, output: 11374.05 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1871/2176 [05:07<01:59,  2.54it/s, est. speed input: 956.66 toks/s, output: 11370.33 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1873/2176 [05:07<01:29,  3.38it/s, est. speed input: 957.23 toks/s, output: 11368.06 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1875/2176 [05:08<01:12,  4.15it/s, est. speed input: 957.47 toks/s, output: 11366.36 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1880/2176 [05:08<00:44,  6.58it/s, est. speed input: 959.18 toks/s, output: 11360.74 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1886/2176 [05:08<00:25, 11.25it/s, est. speed input: 962.89 toks/s, output: 11372.53 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1889/2176 [05:08<00:21, 13.29it/s, est. speed input: 964.59 toks/s, output: 11376.61 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1892/2176 [05:12<02:03,  2.30it/s, est. speed input: 953.53 toks/s, output: 11225.63 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1894/2176 [05:13<01:43,  2.73it/s, est. speed input: 954.34 toks/s, output: 11222.50 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1899/2176 [05:15<01:43,  2.67it/s, est. speed input: 951.68 toks/s, output: 11171.42 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1904/2176 [05:15<01:06,  4.11it/s, est. speed input: 954.27 toks/s, output: 11201.07 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1907/2176 [05:15<00:55,  4.84it/s, est. speed input: 954.53 toks/s, output: 11220.34 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1909/2176 [05:16<01:03,  4.19it/s, est. speed input: 953.53 toks/s, output: 11205.40 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1911/2176 [05:17<01:24,  3.14it/s, est. speed input: 951.54 toks/s, output: 11164.81 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1914/2176 [05:17<01:05,  4.02it/s, est. speed input: 953.11 toks/s, output: 11156.95 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1917/2176 [05:19<01:28,  2.94it/s, est. speed input: 950.34 toks/s, output: 11102.37 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1919/2176 [05:19<01:21,  3.16it/s, est. speed input: 949.88 toks/s, output: 11093.49 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1920/2176 [05:20<01:17,  3.29it/s, est. speed input: 950.08 toks/s, output: 11095.26 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1925/2176 [05:21<01:09,  3.62it/s, est. speed input: 950.36 toks/s, output: 11091.54 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1928/2176 [05:21<00:50,  4.87it/s, est. speed input: 951.47 toks/s, output: 11090.38 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1931/2176 [05:21<00:38,  6.34it/s, est. speed input: 952.90 toks/s, output: 11097.17 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1935/2176 [05:21<00:27,  8.85it/s, est. speed input: 954.73 toks/s, output: 11130.58 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1943/2176 [05:21<00:15, 15.02it/s, est. speed input: 956.44 toks/s, output: 11200.87 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1946/2176 [05:22<00:24,  9.45it/s, est. speed input: 955.33 toks/s, output: 11181.43 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1953/2176 [05:22<00:15, 14.33it/s, est. speed input: 957.47 toks/s, output: 11206.69 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1956/2176 [05:24<00:32,  6.83it/s, est. speed input: 954.56 toks/s, output: 11188.80 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1959/2176 [05:24<00:38,  5.58it/s, est. speed input: 952.87 toks/s, output: 11174.65 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1961/2176 [05:27<01:19,  2.72it/s, est. speed input: 946.18 toks/s, output: 11094.58 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1964/2176 [05:27<01:02,  3.37it/s, est. speed input: 946.04 toks/s, output: 11094.53 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1967/2176 [05:28<00:48,  4.30it/s, est. speed input: 947.24 toks/s, output: 11109.82 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1971/2176 [05:28<00:33,  6.19it/s, est. speed input: 949.99 toks/s, output: 11143.36 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1973/2176 [05:28<00:28,  7.01it/s, est. speed input: 950.64 toks/s, output: 11151.86 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1975/2176 [05:30<01:15,  2.66it/s, est. speed input: 944.80 toks/s, output: 11089.67 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1980/2176 [05:30<00:43,  4.48it/s, est. speed input: 945.78 toks/s, output: 11131.10 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1985/2176 [05:31<00:35,  5.35it/s, est. speed input: 946.98 toks/s, output: 11155.68 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1991/2176 [05:32<00:30,  6.10it/s, est. speed input: 949.31 toks/s, output: 11185.15 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1999/2176 [05:34<00:37,  4.73it/s, est. speed input: 946.89 toks/s, output: 11185.31 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2001/2176 [05:34<00:36,  4.74it/s, est. speed input: 947.03 toks/s, output: 11183.12 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2004/2176 [05:35<00:43,  4.00it/s, est. speed input: 945.83 toks/s, output: 11158.81 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2008/2176 [05:36<00:30,  5.43it/s, est. speed input: 948.43 toks/s, output: 11191.64 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2012/2176 [05:36<00:31,  5.26it/s, est. speed input: 949.74 toks/s, output: 11200.93 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2019/2176 [05:37<00:18,  8.32it/s, est. speed input: 953.28 toks/s, output: 11245.69 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2023/2176 [05:37<00:15, 10.16it/s, est. speed input: 954.37 toks/s, output: 11270.83 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2026/2176 [05:37<00:14, 10.05it/s, est. speed input: 954.32 toks/s, output: 11282.02 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2029/2176 [05:38<00:19,  7.72it/s, est. speed input: 953.36 toks/s, output: 11269.38 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2031/2176 [05:39<00:30,  4.82it/s, est. speed input: 950.88 toks/s, output: 11239.23 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2033/2176 [05:39<00:29,  4.88it/s, est. speed input: 951.13 toks/s, output: 11235.12 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2034/2176 [05:43<01:33,  1.51it/s, est. speed input: 941.01 toks/s, output: 11121.94 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2042/2176 [05:44<00:47,  2.84it/s, est. speed input: 939.78 toks/s, output: 11156.18 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2043/2176 [05:44<00:44,  3.01it/s, est. speed input: 939.76 toks/s, output: 11160.48 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2046/2176 [05:45<00:34,  3.76it/s, est. speed input: 940.03 toks/s, output: 11176.93 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2051/2176 [05:45<00:20,  6.04it/s, est. speed input: 942.04 toks/s, output: 11218.00 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2053/2176 [05:45<00:24,  4.95it/s, est. speed input: 941.41 toks/s, output: 11208.07 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2055/2176 [05:46<00:23,  5.15it/s, est. speed input: 941.67 toks/s, output: 11215.09 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2058/2176 [05:46<00:18,  6.37it/s, est. speed input: 942.79 toks/s, output: 11234.32 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2060/2176 [05:47<00:31,  3.65it/s, est. speed input: 941.18 toks/s, output: 11209.05 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2064/2176 [05:48<00:21,  5.10it/s, est. speed input: 944.06 toks/s, output: 11229.82 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2066/2176 [05:48<00:18,  5.95it/s, est. speed input: 945.67 toks/s, output: 11242.99 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2068/2176 [05:50<00:37,  2.90it/s, est. speed input: 941.97 toks/s, output: 11202.50 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2076/2176 [05:51<00:22,  4.44it/s, est. speed input: 941.14 toks/s, output: 11237.26 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2080/2176 [05:52<00:22,  4.31it/s, est. speed input: 941.69 toks/s, output: 11240.49 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2087/2176 [05:52<00:12,  7.00it/s, est. speed input: 947.57 toks/s, output: 11296.80 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2094/2176 [05:52<00:09,  8.77it/s, est. speed input: 951.20 toks/s, output: 11342.95 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2100/2176 [05:53<00:07, 10.00it/s, est. speed input: 951.95 toks/s, output: 11381.75 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2103/2176 [05:53<00:07,  9.65it/s, est. speed input: 951.60 toks/s, output: 11396.23 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2108/2176 [05:53<00:05, 12.11it/s, est. speed input: 952.35 toks/s, output: 11434.12 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2114/2176 [05:53<00:04, 15.33it/s, est. speed input: 954.16 toks/s, output: 11479.99 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2117/2176 [05:54<00:06,  9.15it/s, est. speed input: 953.64 toks/s, output: 11477.88 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2123/2176 [05:55<00:04, 10.87it/s, est. speed input: 956.95 toks/s, output: 11517.92 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2125/2176 [05:57<00:13,  3.65it/s, est. speed input: 950.68 toks/s, output: 11449.09 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2128/2176 [05:58<00:11,  4.31it/s, est. speed input: 951.21 toks/s, output: 11465.38 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2131/2176 [05:58<00:08,  5.28it/s, est. speed input: 952.01 toks/s, output: 11484.91 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2133/2176 [05:58<00:08,  4.89it/s, est. speed input: 951.67 toks/s, output: 11484.97 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2139/2176 [05:58<00:04,  8.33it/s, est. speed input: 954.57 toks/s, output: 11532.67 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2142/2176 [05:59<00:04,  7.31it/s, est. speed input: 955.47 toks/s, output: 11540.21 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2144/2176 [06:00<00:06,  5.23it/s, est. speed input: 954.98 toks/s, output: 11530.05 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2152/2176 [06:00<00:02,  8.98it/s, est. speed input: 960.58 toks/s, output: 11588.58 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2154/2176 [06:00<00:02,  9.41it/s, est. speed input: 960.75 toks/s, output: 11600.56 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2157/2176 [06:01<00:01, 10.08it/s, est. speed input: 961.01 toks/s, output: 11618.56 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2159/2176 [06:02<00:03,  5.51it/s, est. speed input: 958.87 toks/s, output: 11601.85 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2161/2176 [06:02<00:02,  6.23it/s, est. speed input: 959.14 toks/s, output: 11613.38 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2164/2176 [06:04<00:03,  3.02it/s, est. speed input: 954.67 toks/s, output: 11571.73 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2165/2176 [06:04<00:03,  3.31it/s, est. speed input: 954.74 toks/s, output: 11576.71 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2167/2176 [06:04<00:02,  4.26it/s, est. speed input: 955.53 toks/s, output: 11590.12 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2169/2176 [06:04<00:01,  5.19it/s, est. speed input: 956.52 toks/s, output: 11601.57 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2174/2176 [06:05<00:00,  8.17it/s, est. speed input: 959.43 toks/s, output: 11635.38 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2176/2176 [06:05<00:00,  8.92it/s, est. speed input: 960.43 toks/s, output: 11647.36 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2176/2176 [06:05<00:00,  5.96it/s, est. speed input: 960.43 toks/s, output: 11647.36 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/2176 [00:00<?, ?it/s][A
Evaluate:  10%|‚ñâ         | 217/2176 [00:00<00:04, 446.76it/s][A
Evaluate:  12%|‚ñà‚ñè        | 262/2176 [00:00<00:04, 412.48it/s][A
Evaluate:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2009/2176 [00:00<00:00, 3278.60it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2176/2176 [00:02<00:00, 878.17it/s] 
{'num_samples': 272, 'num_scores': 2176, 'timeout_samples': 0, 'empty_samples': 9, 'acc': 3.7, 'total_acc': 4.917279411764706, 'pass_at_k_percent': {'1': 4.9, '8': 6.2}, 'pass_at_k_valid_counts': {'1': 272, '8': 272}, 'type_acc': {'Differential Equations (18.03 Spring 2010)': 4.2, 'Dynamics and Control (2.003 Spring 2005)': 3.8, 'Ecology I (1.018J Fall 2009)': 20.0, 'Information and Entropy (6.050J Spring 2008)': 0.0, 'Introduction to Astronomy (8.282J Spring 2006)': 9.4, 'Introduction to Solid State Chemistry (3.091 Fall 2010)': 2.1, 'Physical Chemistry (5.61 Fall 2017)': 0.0, 'Principles of Microeconomics (14.01 Fall 2011)': 16.7, 'Relativity (8.033 Fall 2006)': 0.0}, 'type_pass_at_k_percent': {'Differential Equations (18.03 Spring 2010)': {'1': 3.4, '8': 4.2}, 'Dynamics and Control (2.003 Spring 2005)': {'1': 4.8, '8': 7.7}, 'Ecology I (1.018J Fall 2009)': {'1': 20.0, '8': 20.0}, 'Information and Entropy (6.050J Spring 2008)': {'1': 0.0, '8': 0.0}, 'Introduction to Astronomy (8.282J Spring 2006)': {'1': 7.8, '8': 9.4}, 'Introduction to Solid State Chemistry (3.091 Fall 2010)': {'1': 2.3, '8': 3.1}, 'Physical Chemistry (5.61 Fall 2017)': {'1': 1.1, '8': 9.1}, 'Principles of Microeconomics (14.01 Fall 2011)': {'1': 16.7, '8': 16.7}, 'Relativity (8.033 Fall 2006)': {'1': 0.0, '8': 0.0}}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_noise_rlvr_1_5b_128batchsize_deepscaler_noise_robust_qwen25-math-cot/base__Qwen2.5-math-1.5B/g2/minerva_math/test_qwen25-math-cot_-1_seed0_t0.0_s0_e-1.jsonl
[2025-09-23 15:34:32] ‚úì base__Qwen2.5-math-1.5B/g2/minerva_math  acc=3.7 pass_at_k={'1': 4.9, '8': 6.2}
base__Qwen2.5-math-1.5B/g2:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [06:10<12:20, 370.11s/ds]==================================================
data: olympiadbench  ,remain samples: 675
{'idx': 0, 'id': 1606, 'subfield': 'Combinatorics', 'context': None, 'question': 'Xenia and Sergey play the following game. Xenia thinks of a positive integer $N$ not exceeding 5000. Then she fixes 20 distinct positive integers $a_{1}, a_{2}, \\ldots, a_{20}$ such that, for each $k=1,2, \\ldots, 20$, the numbers $N$ and $a_{k}$ are congruent modulo $k$. By a move, Sergey tells Xenia a set $S$ of positive integers not exceeding 20 , and she tells him back the set $\\left\\{a_{k}: k \\in S\\right\\}$ without spelling out which number corresponds to which index. How many moves does Sergey need to determine for sure the number Xenia thought of?', 'solution': ["Sergey can determine Xenia's number in 2 but not fewer moves.\n\n\n\nWe first show that 2 moves are sufficient. Let Sergey provide the set $\\{17,18\\}$ on his first move, and the set $\\{18,19\\}$ on the second move. In Xenia's two responses, exactly one number occurs twice, namely, $a_{18}$. Thus, Sergey is able to identify $a_{17}, a_{18}$, and $a_{19}$, and thence the residue of $N$ modulo $17 \\cdot 18 \\cdot 19=5814>5000$, by the Chinese Remainder Theorem. This means that the given range contains a single number satisfying all congruences, and Sergey achieves his goal.\n\n\n\nTo show that 1 move is not sufficient, let $M=\\operatorname{lcm}(1,2, \\ldots, 10)=2^{3} \\cdot 3^{2} \\cdot 5 \\cdot 7=2520$. Notice that $M$ is divisible by the greatest common divisor of every pair of distinct positive integers not exceeding 20. Let Sergey provide the set $S=\\left\\{s_{1}, s_{2}, \\ldots, s_{k}\\right\\}$. We show that there exist pairwise distinct positive integers $b_{1}, b_{2}, \\ldots, b_{k}$ such that $1 \\equiv b_{i}\\left(\\bmod s_{i}\\right)$ and $M+1 \\equiv b_{i-1}\\left(\\bmod s_{i}\\right)$ (indices are reduced modulo $k$ ). Thus, if in response Xenia provides the set $\\left\\{b_{1}, b_{2}, \\ldots, b_{k}\\right\\}$, then Sergey will be unable to distinguish 1 from $M+1$, as desired.\n\n\n\nTo this end, notice that, for each $i$, the numbers of the form $1+m s_{i}, m \\in \\mathbb{Z}$, cover all residues modulo $s_{i+1}$ which are congruent to $1(\\equiv M+1)$ modulo $\\operatorname{gcd}\\left(s_{i}, s_{i+1}\\right) \\mid M$. Xenia can therefore choose a positive integer $b_{i}$ such that $b_{i} \\equiv 1\\left(\\bmod s_{i}\\right)$ and $b_{i} \\equiv M+1\\left(\\bmod s_{i+1}\\right)$. Clearly, such choices can be performed so as to make the $b_{i}$ pairwise distinct, as required."], 'final_answer': ['2'], 'is_multiple_answer': False, 'unit': None, 'answer_type': 'Numerical', 'error': None}

  0%|          | 0/675 [00:00<?, ?it/s][A<|im_start|>system
Please reason step by step, and put your final answer within \boxed{{}}.<|im_end|>
<|im_start|>user
Xenia and Sergey play the following game. Xenia thinks of a positive integer $N$ not exceeding 5000. Then she fixes 20 distinct positive integers $a_{1}, a_{2}, \ldots, a_{20}$ such that, for each $k=1,2, \ldots, 20$, the numbers $N$ and $a_{k}$ are congruent modulo $k$. By a move, Sergey tells Xenia a set $S$ of positive integers not exceeding 20 , and she tells him back the set $\left\{a_{k}: k \in S\right\}$ without spelling out which number corresponds to which index. How many moves does Sergey need to determine for sure the number Xenia thought of?<|im_end|>
<|im_start|>assistant


  5%|‚ñå         | 37/675 [00:00<00:01, 364.76it/s][A
 11%|‚ñà         | 74/675 [00:00<00:01, 354.25it/s][A
 17%|‚ñà‚ñã        | 113/675 [00:00<00:01, 366.81it/s][A
 22%|‚ñà‚ñà‚ñè       | 151/675 [00:00<00:01, 370.21it/s][A
 28%|‚ñà‚ñà‚ñä       | 189/675 [00:00<00:01, 348.51it/s][A
 34%|‚ñà‚ñà‚ñà‚ñç      | 229/675 [00:00<00:01, 362.52it/s][A
 40%|‚ñà‚ñà‚ñà‚ñâ      | 267/675 [00:00<00:01, 367.70it/s][A
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 304/675 [00:00<00:01, 360.50it/s][A
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 346/675 [00:00<00:00, 376.38it/s][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 389/675 [00:01<00:00, 390.45it/s][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 434/675 [00:01<00:00, 406.41it/s][A
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 478/675 [00:01<00:00, 414.13it/s][A
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 520/675 [00:01<00:00, 415.07it/s][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 564/675 [00:01<00:00, 420.33it/s][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 607/675 [00:01<00:00, 421.38it/s][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 650/675 [00:01<00:00, 422.91it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 675/675 [00:01<00:00, 394.58it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/5400 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 1/5400 [00:03<5:52:35,  3.92s/it, est. speed input: 28.07 toks/s, output: 71.71 toks/s][A
Processed prompts:   0%|          | 9/5400 [00:07<1:05:49,  1.36it/s, est. speed input: 133.91 toks/s, output: 356.97 toks/s][A
Processed prompts:   0%|          | 17/5400 [00:07<30:02,  2.99it/s, est. speed input: 273.23 toks/s, output: 804.69 toks/s] [A
Processed prompts:   0%|          | 25/5400 [00:08<19:08,  4.68it/s, est. speed input: 438.16 toks/s, output: 1198.72 toks/s][A
Processed prompts:   1%|          | 41/5400 [00:08<10:12,  8.75it/s, est. speed input: 665.62 toks/s, output: 1993.71 toks/s][A
Processed prompts:   1%|          | 49/5400 [00:09<07:42, 11.56it/s, est. speed input: 805.60 toks/s, output: 2416.69 toks/s][A
Processed prompts:   1%|          | 57/5400 [00:10<08:42, 10.23it/s, est. speed input: 857.98 toks/s, output: 2592.85 toks/s][A
Processed prompts:   1%|‚ñè         | 72/5400 [00:10<05:11, 17.09it/s, est. speed input: 1078.57 toks/s, output: 3407.34 toks/s][A
Processed prompts:   1%|‚ñè         | 80/5400 [00:10<04:16, 20.73it/s, est. speed input: 1151.04 toks/s, output: 3808.46 toks/s][A
Processed prompts:   2%|‚ñè         | 88/5400 [00:10<03:53, 22.73it/s, est. speed input: 1176.64 toks/s, output: 4158.47 toks/s][A
Processed prompts:   2%|‚ñè         | 96/5400 [00:11<05:27, 16.18it/s, est. speed input: 1169.48 toks/s, output: 4260.33 toks/s][A
Processed prompts:   2%|‚ñè         | 104/5400 [00:12<08:01, 11.00it/s, est. speed input: 1130.02 toks/s, output: 4224.49 toks/s][A
Processed prompts:   2%|‚ñè         | 112/5400 [00:13<06:50, 12.89it/s, est. speed input: 1224.33 toks/s, output: 4543.58 toks/s][A
Processed prompts:   2%|‚ñè         | 115/5400 [00:13<08:09, 10.80it/s, est. speed input: 1199.27 toks/s, output: 4519.04 toks/s][A
Processed prompts:   2%|‚ñè         | 121/5400 [00:13<06:51, 12.82it/s, est. speed input: 1227.31 toks/s, output: 4767.69 toks/s][A
Processed prompts:   2%|‚ñè         | 133/5400 [00:14<05:36, 15.66it/s, est. speed input: 1264.80 toks/s, output: 5223.49 toks/s][A
Processed prompts:   3%|‚ñé         | 141/5400 [00:15<06:02, 14.49it/s, est. speed input: 1290.12 toks/s, output: 5420.40 toks/s][A
Processed prompts:   3%|‚ñé         | 157/5400 [00:15<03:48, 22.95it/s, est. speed input: 1373.10 toks/s, output: 6061.81 toks/s][A
Processed prompts:   3%|‚ñé         | 165/5400 [00:15<03:17, 26.52it/s, est. speed input: 1426.34 toks/s, output: 6432.51 toks/s][A
Processed prompts:   3%|‚ñé         | 173/5400 [00:17<08:27, 10.29it/s, est. speed input: 1326.45 toks/s, output: 6017.51 toks/s][A
Processed prompts:   3%|‚ñé         | 181/5400 [00:18<09:30,  9.14it/s, est. speed input: 1313.85 toks/s, output: 5858.39 toks/s][A
Processed prompts:   4%|‚ñé         | 189/5400 [00:18<07:19, 11.86it/s, est. speed input: 1375.92 toks/s, output: 6067.96 toks/s][A
Processed prompts:   4%|‚ñé         | 197/5400 [00:19<05:35, 15.49it/s, est. speed input: 1421.71 toks/s, output: 6428.58 toks/s][A
Processed prompts:   4%|‚ñé         | 202/5400 [00:19<05:04, 17.07it/s, est. speed input: 1444.90 toks/s, output: 6522.90 toks/s][A
Processed prompts:   4%|‚ñç         | 206/5400 [00:20<07:54, 10.96it/s, est. speed input: 1407.98 toks/s, output: 6334.19 toks/s][A
Processed prompts:   4%|‚ñç         | 213/5400 [00:20<07:14, 11.95it/s, est. speed input: 1435.54 toks/s, output: 6386.18 toks/s][A
Processed prompts:   4%|‚ñç         | 221/5400 [00:21<07:10, 12.02it/s, est. speed input: 1443.52 toks/s, output: 6601.27 toks/s][A
Processed prompts:   4%|‚ñç         | 229/5400 [00:22<08:19, 10.35it/s, est. speed input: 1424.87 toks/s, output: 6713.67 toks/s][A
Processed prompts:   4%|‚ñç         | 233/5400 [00:23<12:13,  7.04it/s, est. speed input: 1373.72 toks/s, output: 6508.27 toks/s][A
Processed prompts:   4%|‚ñç         | 240/5400 [00:25<15:27,  5.56it/s, est. speed input: 1328.24 toks/s, output: 6224.38 toks/s][A
Processed prompts:   5%|‚ñç         | 247/5400 [00:26<14:06,  6.08it/s, est. speed input: 1319.10 toks/s, output: 6194.57 toks/s][A
Processed prompts:   5%|‚ñç         | 255/5400 [00:26<10:49,  7.92it/s, est. speed input: 1337.22 toks/s, output: 6267.29 toks/s][A
Processed prompts:   5%|‚ñç         | 263/5400 [00:28<14:52,  5.75it/s, est. speed input: 1308.48 toks/s, output: 6008.17 toks/s][A
Processed prompts:   5%|‚ñç         | 269/5400 [00:29<11:26,  7.47it/s, est. speed input: 1351.01 toks/s, output: 6108.48 toks/s][A
Processed prompts:   5%|‚ñå         | 272/5400 [00:30<17:16,  4.95it/s, est. speed input: 1289.20 toks/s, output: 5849.02 toks/s][A
Processed prompts:   5%|‚ñå         | 278/5400 [00:31<13:55,  6.13it/s, est. speed input: 1295.74 toks/s, output: 5925.46 toks/s][A
Processed prompts:   5%|‚ñå         | 280/5400 [00:32<16:26,  5.19it/s, est. speed input: 1276.93 toks/s, output: 5812.25 toks/s][A
Processed prompts:   5%|‚ñå         | 283/5400 [00:32<14:56,  5.71it/s, est. speed input: 1279.64 toks/s, output: 5804.34 toks/s][A
Processed prompts:   5%|‚ñå         | 291/5400 [00:33<12:22,  6.88it/s, est. speed input: 1272.58 toks/s, output: 5846.68 toks/s][A
Processed prompts:   6%|‚ñå         | 299/5400 [00:34<11:12,  7.59it/s, est. speed input: 1267.24 toks/s, output: 5959.32 toks/s][A
Processed prompts:   6%|‚ñå         | 303/5400 [00:34<12:50,  6.61it/s, est. speed input: 1255.70 toks/s, output: 5885.32 toks/s][A
Processed prompts:   6%|‚ñå         | 307/5400 [00:35<10:54,  7.78it/s, est. speed input: 1271.30 toks/s, output: 5958.99 toks/s][A
Processed prompts:   6%|‚ñå         | 326/5400 [00:35<05:11, 16.27it/s, est. speed input: 1346.27 toks/s, output: 6620.38 toks/s][A
Processed prompts:   6%|‚ñå         | 330/5400 [00:35<05:33, 15.20it/s, est. speed input: 1354.91 toks/s, output: 6646.90 toks/s][A
Processed prompts:   6%|‚ñã         | 349/5400 [00:36<03:22, 24.96it/s, est. speed input: 1412.59 toks/s, output: 7225.52 toks/s][A
Processed prompts:   7%|‚ñã         | 356/5400 [00:37<05:11, 16.21it/s, est. speed input: 1424.57 toks/s, output: 7160.34 toks/s][A
Processed prompts:   7%|‚ñã         | 364/5400 [00:37<04:22, 19.16it/s, est. speed input: 1453.68 toks/s, output: 7310.37 toks/s][A
Processed prompts:   7%|‚ñã         | 372/5400 [00:37<04:46, 17.58it/s, est. speed input: 1482.48 toks/s, output: 7492.66 toks/s][A
Processed prompts:   7%|‚ñã         | 376/5400 [00:38<06:03, 13.83it/s, est. speed input: 1480.00 toks/s, output: 7481.45 toks/s][A
Processed prompts:   7%|‚ñã         | 378/5400 [00:38<06:11, 13.52it/s, est. speed input: 1480.68 toks/s, output: 7475.62 toks/s][A
Processed prompts:   7%|‚ñã         | 382/5400 [00:39<09:56,  8.42it/s, est. speed input: 1447.38 toks/s, output: 7323.75 toks/s][A
Processed prompts:   7%|‚ñã         | 384/5400 [00:40<11:52,  7.04it/s, est. speed input: 1437.78 toks/s, output: 7255.64 toks/s][A
Processed prompts:   7%|‚ñã         | 389/5400 [00:40<10:20,  8.08it/s, est. speed input: 1446.10 toks/s, output: 7279.09 toks/s][A
Processed prompts:   7%|‚ñã         | 393/5400 [00:43<21:27,  3.89it/s, est. speed input: 1373.81 toks/s, output: 6985.98 toks/s][A
Processed prompts:   7%|‚ñã         | 397/5400 [00:43<16:05,  5.18it/s, est. speed input: 1380.35 toks/s, output: 7075.93 toks/s][A
Processed prompts:   7%|‚ñã         | 399/5400 [00:43<14:22,  5.80it/s, est. speed input: 1387.29 toks/s, output: 7092.37 toks/s][A
Processed prompts:   7%|‚ñã         | 401/5400 [00:43<13:58,  5.96it/s, est. speed input: 1381.05 toks/s, output: 7074.01 toks/s][A
Processed prompts:   7%|‚ñã         | 403/5400 [00:44<19:52,  4.19it/s, est. speed input: 1355.02 toks/s, output: 6983.15 toks/s][A
Processed prompts:   8%|‚ñä         | 411/5400 [00:44<09:41,  8.59it/s, est. speed input: 1376.82 toks/s, output: 7338.12 toks/s][A
Processed prompts:   8%|‚ñä         | 419/5400 [00:45<08:39,  9.58it/s, est. speed input: 1389.44 toks/s, output: 7386.52 toks/s][A
Processed prompts:   8%|‚ñä         | 425/5400 [00:47<14:12,  5.83it/s, est. speed input: 1348.55 toks/s, output: 7207.11 toks/s][A
Processed prompts:   8%|‚ñä         | 431/5400 [00:47<10:20,  8.00it/s, est. speed input: 1362.76 toks/s, output: 7262.96 toks/s][A
Processed prompts:   8%|‚ñä         | 434/5400 [00:47<08:58,  9.22it/s, est. speed input: 1366.84 toks/s, output: 7286.39 toks/s][A
Processed prompts:   8%|‚ñä         | 439/5400 [00:48<08:14, 10.03it/s, est. speed input: 1365.41 toks/s, output: 7293.40 toks/s][A
Processed prompts:   8%|‚ñä         | 445/5400 [00:48<05:59, 13.79it/s, est. speed input: 1378.46 toks/s, output: 7364.59 toks/s][A
Processed prompts:   8%|‚ñä         | 449/5400 [00:48<05:01, 16.43it/s, est. speed input: 1404.19 toks/s, output: 7397.13 toks/s][A
Processed prompts:   8%|‚ñä         | 453/5400 [00:49<07:00, 11.76it/s, est. speed input: 1393.91 toks/s, output: 7441.91 toks/s][A
Processed prompts:   8%|‚ñä         | 457/5400 [00:50<10:37,  7.76it/s, est. speed input: 1376.65 toks/s, output: 7363.37 toks/s][A
Processed prompts:   9%|‚ñä         | 461/5400 [00:50<09:21,  8.79it/s, est. speed input: 1377.34 toks/s, output: 7431.82 toks/s][A
Processed prompts:   9%|‚ñä         | 467/5400 [00:50<06:35, 12.49it/s, est. speed input: 1388.75 toks/s, output: 7490.90 toks/s][A
Processed prompts:   9%|‚ñä         | 470/5400 [00:50<07:22, 11.15it/s, est. speed input: 1384.48 toks/s, output: 7516.50 toks/s][A
Processed prompts:   9%|‚ñâ         | 473/5400 [00:50<06:32, 12.55it/s, est. speed input: 1386.76 toks/s, output: 7574.46 toks/s][A
Processed prompts:   9%|‚ñâ         | 479/5400 [00:52<10:26,  7.86it/s, est. speed input: 1369.38 toks/s, output: 7471.95 toks/s][A
Processed prompts:   9%|‚ñâ         | 481/5400 [00:52<12:00,  6.83it/s, est. speed input: 1360.86 toks/s, output: 7423.71 toks/s][A
Processed prompts:   9%|‚ñâ         | 485/5400 [00:52<08:54,  9.20it/s, est. speed input: 1365.62 toks/s, output: 7453.71 toks/s][A
Processed prompts:   9%|‚ñâ         | 490/5400 [00:53<08:30,  9.61it/s, est. speed input: 1363.90 toks/s, output: 7447.57 toks/s][A
Processed prompts:   9%|‚ñâ         | 493/5400 [00:53<08:17,  9.86it/s, est. speed input: 1365.78 toks/s, output: 7458.13 toks/s][A
Processed prompts:   9%|‚ñâ         | 497/5400 [00:54<09:07,  8.96it/s, est. speed input: 1363.60 toks/s, output: 7449.23 toks/s][A
Processed prompts:   9%|‚ñâ         | 504/5400 [00:55<13:29,  6.05it/s, est. speed input: 1349.52 toks/s, output: 7333.92 toks/s][A
Processed prompts:   9%|‚ñâ         | 512/5400 [00:56<12:24,  6.57it/s, est. speed input: 1355.43 toks/s, output: 7274.23 toks/s][A
Processed prompts:  10%|‚ñâ         | 515/5400 [00:57<11:19,  7.19it/s, est. speed input: 1368.62 toks/s, output: 7294.44 toks/s][A
Processed prompts:  10%|‚ñâ         | 519/5400 [00:58<15:42,  5.18it/s, est. speed input: 1355.49 toks/s, output: 7192.72 toks/s][A
Processed prompts:  10%|‚ñâ         | 521/5400 [00:58<15:18,  5.31it/s, est. speed input: 1351.86 toks/s, output: 7196.18 toks/s][A
Processed prompts:  10%|‚ñâ         | 526/5400 [00:59<11:41,  6.95it/s, est. speed input: 1352.35 toks/s, output: 7257.81 toks/s][A
Processed prompts:  10%|‚ñâ         | 532/5400 [00:59<08:06, 10.01it/s, est. speed input: 1360.39 toks/s, output: 7310.94 toks/s][A
Processed prompts:  10%|‚ñâ         | 538/5400 [00:59<05:55, 13.67it/s, est. speed input: 1374.78 toks/s, output: 7359.31 toks/s][A
Processed prompts:  10%|‚ñà         | 542/5400 [01:00<12:31,  6.47it/s, est. speed input: 1345.54 toks/s, output: 7239.49 toks/s][A
Processed prompts:  11%|‚ñà         | 586/5400 [01:01<03:44, 21.47it/s, est. speed input: 1415.68 toks/s, output: 9287.87 toks/s][A
Processed prompts:  11%|‚ñà         | 596/5400 [01:01<03:09, 25.32it/s, est. speed input: 1440.55 toks/s, output: 9373.93 toks/s][A
Processed prompts:  11%|‚ñà         | 601/5400 [01:02<03:55, 20.36it/s, est. speed input: 1443.50 toks/s, output: 9347.67 toks/s][A
Processed prompts:  11%|‚ñà         | 605/5400 [01:02<03:43, 21.41it/s, est. speed input: 1447.48 toks/s, output: 9397.98 toks/s][A
Processed prompts:  11%|‚ñà‚ñè        | 612/5400 [01:02<03:32, 22.56it/s, est. speed input: 1457.06 toks/s, output: 9406.88 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 623/5400 [01:04<05:09, 15.42it/s, est. speed input: 1455.47 toks/s, output: 9492.60 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 626/5400 [01:04<07:16, 10.93it/s, est. speed input: 1444.44 toks/s, output: 9405.83 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 630/5400 [01:05<06:35, 12.06it/s, est. speed input: 1450.80 toks/s, output: 9425.02 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 635/5400 [01:05<05:20, 14.89it/s, est. speed input: 1459.76 toks/s, output: 9445.84 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 638/5400 [01:05<05:02, 15.75it/s, est. speed input: 1464.31 toks/s, output: 9458.41 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 641/5400 [01:05<06:39, 11.92it/s, est. speed input: 1459.42 toks/s, output: 9407.34 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 644/5400 [01:06<07:47, 10.17it/s, est. speed input: 1455.44 toks/s, output: 9362.47 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 646/5400 [01:06<08:45,  9.04it/s, est. speed input: 1451.82 toks/s, output: 9334.17 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 648/5400 [01:06<08:06,  9.78it/s, est. speed input: 1453.65 toks/s, output: 9328.34 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 650/5400 [01:07<09:36,  8.25it/s, est. speed input: 1447.37 toks/s, output: 9300.40 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 652/5400 [01:07<12:02,  6.57it/s, est. speed input: 1439.94 toks/s, output: 9267.31 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 654/5400 [01:07<10:34,  7.48it/s, est. speed input: 1439.85 toks/s, output: 9283.34 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 657/5400 [01:07<08:07,  9.74it/s, est. speed input: 1442.51 toks/s, output: 9300.51 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 663/5400 [01:08<05:13, 15.10it/s, est. speed input: 1450.59 toks/s, output: 9373.19 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 666/5400 [01:08<05:38, 13.97it/s, est. speed input: 1451.45 toks/s, output: 9383.16 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 672/5400 [01:08<05:20, 14.76it/s, est. speed input: 1455.99 toks/s, output: 9399.97 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 674/5400 [01:09<12:15,  6.43it/s, est. speed input: 1435.33 toks/s, output: 9272.71 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 676/5400 [01:10<10:47,  7.30it/s, est. speed input: 1436.61 toks/s, output: 9293.82 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 680/5400 [01:10<10:24,  7.56it/s, est. speed input: 1434.28 toks/s, output: 9302.64 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 684/5400 [01:10<08:36,  9.14it/s, est. speed input: 1436.65 toks/s, output: 9324.62 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 686/5400 [01:10<08:27,  9.29it/s, est. speed input: 1438.21 toks/s, output: 9311.99 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 697/5400 [01:11<05:34, 14.07it/s, est. speed input: 1452.96 toks/s, output: 9331.45 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 701/5400 [01:11<04:59, 15.68it/s, est. speed input: 1458.15 toks/s, output: 9367.18 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 704/5400 [01:12<08:01,  9.75it/s, est. speed input: 1448.95 toks/s, output: 9311.93 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 707/5400 [01:12<08:53,  8.80it/s, est. speed input: 1445.40 toks/s, output: 9277.59 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 715/5400 [01:13<06:03, 12.88it/s, est. speed input: 1470.16 toks/s, output: 9394.43 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 722/5400 [01:13<06:40, 11.68it/s, est. speed input: 1473.92 toks/s, output: 9565.13 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 724/5400 [01:14<06:43, 11.59it/s, est. speed input: 1473.14 toks/s, output: 9619.01 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 728/5400 [01:14<06:20, 12.28it/s, est. speed input: 1476.03 toks/s, output: 9710.72 toks/s][A
Processed prompts:  14%|‚ñà‚ñé        | 735/5400 [01:14<06:19, 12.31it/s, est. speed input: 1484.40 toks/s, output: 9698.16 toks/s][A
Processed prompts:  14%|‚ñà‚ñé        | 737/5400 [01:15<07:17, 10.65it/s, est. speed input: 1479.95 toks/s, output: 9667.02 toks/s][A
Processed prompts:  14%|‚ñà‚ñé        | 741/5400 [01:15<08:34,  9.06it/s, est. speed input: 1475.95 toks/s, output: 9629.13 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 744/5400 [01:15<07:23, 10.50it/s, est. speed input: 1477.43 toks/s, output: 9685.88 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 751/5400 [01:16<06:21, 12.19it/s, est. speed input: 1482.71 toks/s, output: 9909.45 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 753/5400 [01:17<10:48,  7.17it/s, est. speed input: 1467.75 toks/s, output: 9848.62 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 761/5400 [01:17<06:28, 11.95it/s, est. speed input: 1477.17 toks/s, output: 10112.57 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 764/5400 [01:17<06:35, 11.71it/s, est. speed input: 1475.30 toks/s, output: 10098.18 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 768/5400 [01:17<05:40, 13.62it/s, est. speed input: 1476.81 toks/s, output: 10109.65 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 773/5400 [01:18<04:25, 17.43it/s, est. speed input: 1482.25 toks/s, output: 10135.51 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 776/5400 [01:18<04:55, 15.65it/s, est. speed input: 1484.36 toks/s, output: 10127.67 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 779/5400 [01:18<04:28, 17.18it/s, est. speed input: 1486.77 toks/s, output: 10198.32 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 784/5400 [01:18<03:37, 21.25it/s, est. speed input: 1494.07 toks/s, output: 10284.90 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 792/5400 [01:18<02:29, 30.84it/s, est. speed input: 1518.40 toks/s, output: 10351.36 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 796/5400 [01:18<02:26, 31.51it/s, est. speed input: 1522.16 toks/s, output: 10430.03 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 800/5400 [01:18<02:23, 31.99it/s, est. speed input: 1525.27 toks/s, output: 10515.62 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 806/5400 [01:19<02:36, 29.28it/s, est. speed input: 1533.56 toks/s, output: 10654.29 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 815/5400 [01:19<02:46, 27.55it/s, est. speed input: 1541.73 toks/s, output: 10701.15 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 819/5400 [01:20<04:41, 16.26it/s, est. speed input: 1539.25 toks/s, output: 10677.29 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 822/5400 [01:20<05:30, 13.86it/s, est. speed input: 1539.53 toks/s, output: 10652.50 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 824/5400 [01:20<05:27, 13.97it/s, est. speed input: 1541.13 toks/s, output: 10648.36 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 826/5400 [01:20<05:57, 12.81it/s, est. speed input: 1542.26 toks/s, output: 10630.70 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 834/5400 [01:21<04:43, 16.10it/s, est. speed input: 1552.72 toks/s, output: 10696.60 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 840/5400 [01:21<04:53, 15.54it/s, est. speed input: 1553.88 toks/s, output: 10796.32 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 842/5400 [01:21<04:49, 15.75it/s, est. speed input: 1555.42 toks/s, output: 10798.41 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 844/5400 [01:22<06:32, 11.60it/s, est. speed input: 1552.06 toks/s, output: 10757.03 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 846/5400 [01:22<08:10,  9.28it/s, est. speed input: 1547.38 toks/s, output: 10780.24 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 848/5400 [01:23<10:45,  7.05it/s, est. speed input: 1540.23 toks/s, output: 10755.77 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 850/5400 [01:23<09:08,  8.29it/s, est. speed input: 1541.19 toks/s, output: 10757.98 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 857/5400 [01:23<05:33, 13.63it/s, est. speed input: 1548.07 toks/s, output: 10784.43 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 867/5400 [01:23<03:29, 21.62it/s, est. speed input: 1560.49 toks/s, output: 10818.95 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 873/5400 [01:24<05:19, 14.18it/s, est. speed input: 1553.79 toks/s, output: 10754.51 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 876/5400 [01:24<05:28, 13.77it/s, est. speed input: 1553.98 toks/s, output: 10753.03 toks/s][A
Processed prompts:  16%|‚ñà‚ñã        | 880/5400 [01:25<07:48,  9.65it/s, est. speed input: 1546.79 toks/s, output: 10690.90 toks/s][A
Processed prompts:  16%|‚ñà‚ñã        | 886/5400 [01:25<05:48, 12.95it/s, est. speed input: 1549.52 toks/s, output: 10697.17 toks/s][A
Processed prompts:  16%|‚ñà‚ñã        | 891/5400 [01:25<04:36, 16.32it/s, est. speed input: 1552.40 toks/s, output: 10721.43 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 894/5400 [01:25<04:45, 15.76it/s, est. speed input: 1551.82 toks/s, output: 10721.63 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 899/5400 [01:26<06:12, 12.07it/s, est. speed input: 1545.63 toks/s, output: 10683.45 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 901/5400 [01:27<09:31,  7.88it/s, est. speed input: 1534.91 toks/s, output: 10623.50 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 907/5400 [01:27<06:34, 11.38it/s, est. speed input: 1539.39 toks/s, output: 10681.32 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 914/5400 [01:28<06:38, 11.26it/s, est. speed input: 1541.82 toks/s, output: 10691.46 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 916/5400 [01:28<10:11,  7.34it/s, est. speed input: 1530.88 toks/s, output: 10613.10 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 920/5400 [01:29<08:37,  8.65it/s, est. speed input: 1535.79 toks/s, output: 10623.33 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 922/5400 [01:30<13:44,  5.43it/s, est. speed input: 1520.59 toks/s, output: 10527.15 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 925/5400 [01:30<11:54,  6.27it/s, est. speed input: 1519.19 toks/s, output: 10517.38 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 933/5400 [01:30<06:26, 11.56it/s, est. speed input: 1528.28 toks/s, output: 10535.08 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 937/5400 [01:30<05:48, 12.80it/s, est. speed input: 1529.83 toks/s, output: 10530.55 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 940/5400 [01:31<06:33, 11.32it/s, est. speed input: 1526.89 toks/s, output: 10507.32 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 942/5400 [01:31<08:43,  8.52it/s, est. speed input: 1520.59 toks/s, output: 10461.14 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 944/5400 [01:32<09:27,  7.86it/s, est. speed input: 1516.99 toks/s, output: 10437.14 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 955/5400 [01:32<04:15, 17.42it/s, est. speed input: 1524.84 toks/s, output: 10501.13 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 959/5400 [01:32<04:37, 16.00it/s, est. speed input: 1524.64 toks/s, output: 10494.93 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 965/5400 [01:32<03:32, 20.84it/s, est. speed input: 1530.05 toks/s, output: 10524.92 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 973/5400 [01:32<03:00, 24.49it/s, est. speed input: 1538.38 toks/s, output: 10554.22 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 977/5400 [01:32<02:51, 25.78it/s, est. speed input: 1544.39 toks/s, output: 10559.90 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 982/5400 [01:33<02:47, 26.33it/s, est. speed input: 1552.05 toks/s, output: 10572.68 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 986/5400 [01:33<05:19, 13.81it/s, est. speed input: 1547.40 toks/s, output: 10519.15 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 989/5400 [01:34<07:14, 10.15it/s, est. speed input: 1543.76 toks/s, output: 10477.56 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 991/5400 [01:34<06:41, 10.97it/s, est. speed input: 1543.79 toks/s, output: 10487.41 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 993/5400 [01:34<07:23,  9.95it/s, est. speed input: 1541.70 toks/s, output: 10489.72 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 996/5400 [01:35<10:58,  6.69it/s, est. speed input: 1532.74 toks/s, output: 10441.20 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 998/5400 [01:36<12:40,  5.79it/s, est. speed input: 1527.71 toks/s, output: 10399.26 toks/s][A
Processed prompts:  19%|‚ñà‚ñä        | 1000/5400 [01:36<11:22,  6.45it/s, est. speed input: 1528.16 toks/s, output: 10389.39 toks/s][A
Processed prompts:  19%|‚ñà‚ñä        | 1002/5400 [01:36<09:40,  7.57it/s, est. speed input: 1527.50 toks/s, output: 10393.05 toks/s][A
Processed prompts:  19%|‚ñà‚ñä        | 1006/5400 [01:36<06:49, 10.74it/s, est. speed input: 1527.76 toks/s, output: 10411.11 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 1014/5400 [01:36<03:46, 19.32it/s, est. speed input: 1536.10 toks/s, output: 10503.51 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 1023/5400 [01:36<02:31, 28.80it/s, est. speed input: 1547.98 toks/s, output: 10543.49 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 1027/5400 [01:37<04:18, 16.89it/s, est. speed input: 1545.47 toks/s, output: 10513.43 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 1031/5400 [01:37<04:11, 17.37it/s, est. speed input: 1549.23 toks/s, output: 10534.40 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 1035/5400 [01:38<04:44, 15.35it/s, est. speed input: 1548.81 toks/s, output: 10595.21 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 1038/5400 [01:38<04:30, 16.10it/s, est. speed input: 1549.88 toks/s, output: 10593.00 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 1041/5400 [01:38<05:14, 13.86it/s, est. speed input: 1547.44 toks/s, output: 10584.58 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 1046/5400 [01:38<05:36, 12.93it/s, est. speed input: 1544.71 toks/s, output: 10573.76 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 1050/5400 [01:39<05:07, 14.13it/s, est. speed input: 1545.34 toks/s, output: 10597.42 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 1053/5400 [01:39<05:02, 14.36it/s, est. speed input: 1545.11 toks/s, output: 10597.67 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 1057/5400 [01:39<05:03, 14.33it/s, est. speed input: 1544.09 toks/s, output: 10593.59 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 1062/5400 [01:39<04:55, 14.68it/s, est. speed input: 1545.59 toks/s, output: 10623.18 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 1069/5400 [01:40<03:36, 20.05it/s, est. speed input: 1549.39 toks/s, output: 10653.27 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 1073/5400 [01:40<03:10, 22.75it/s, est. speed input: 1550.62 toks/s, output: 10671.29 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 1079/5400 [01:40<03:31, 20.45it/s, est. speed input: 1552.44 toks/s, output: 10671.24 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 1082/5400 [01:40<04:49, 14.90it/s, est. speed input: 1549.63 toks/s, output: 10657.49 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 1087/5400 [01:41<03:52, 18.54it/s, est. speed input: 1551.50 toks/s, output: 10683.84 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 1094/5400 [01:41<04:31, 15.89it/s, est. speed input: 1552.89 toks/s, output: 10793.95 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 1097/5400 [01:41<05:03, 14.16it/s, est. speed input: 1553.85 toks/s, output: 10791.98 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 1102/5400 [01:42<04:32, 15.79it/s, est. speed input: 1565.75 toks/s, output: 10902.96 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 1104/5400 [01:43<12:50,  5.57it/s, est. speed input: 1543.49 toks/s, output: 10759.62 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 1106/5400 [01:44<17:20,  4.13it/s, est. speed input: 1530.27 toks/s, output: 10661.95 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 1113/5400 [01:45<10:15,  6.96it/s, est. speed input: 1535.53 toks/s, output: 10685.08 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 1117/5400 [01:45<08:28,  8.43it/s, est. speed input: 1538.68 toks/s, output: 10713.04 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 1119/5400 [01:45<08:33,  8.33it/s, est. speed input: 1538.17 toks/s, output: 10709.63 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 1121/5400 [01:48<23:33,  3.03it/s, est. speed input: 1505.31 toks/s, output: 10493.04 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 1126/5400 [01:48<15:13,  4.68it/s, est. speed input: 1505.94 toks/s, output: 10494.93 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 1128/5400 [01:49<20:29,  3.47it/s, est. speed input: 1490.69 toks/s, output: 10388.31 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 1132/5400 [01:50<18:22,  3.87it/s, est. speed input: 1484.22 toks/s, output: 10335.70 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 1134/5400 [01:50<17:20,  4.10it/s, est. speed input: 1482.58 toks/s, output: 10315.49 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 1137/5400 [01:50<13:16,  5.35it/s, est. speed input: 1487.83 toks/s, output: 10321.79 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 1139/5400 [01:51<12:21,  5.74it/s, est. speed input: 1487.71 toks/s, output: 10312.41 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 1143/5400 [01:51<10:32,  6.73it/s, est. speed input: 1487.08 toks/s, output: 10302.82 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 1144/5400 [01:51<11:38,  6.10it/s, est. speed input: 1486.24 toks/s, output: 10304.85 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 1146/5400 [01:52<18:20,  3.86it/s, est. speed input: 1475.78 toks/s, output: 10262.32 toks/s][A
Processed prompts:  21%|‚ñà‚ñà‚ñè       | 1152/5400 [01:53<10:03,  7.04it/s, est. speed input: 1478.76 toks/s, output: 10374.77 toks/s][A
Processed prompts:  21%|‚ñà‚ñà‚ñè       | 1158/5400 [01:53<06:26, 10.97it/s, est. speed input: 1486.03 toks/s, output: 10405.92 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 1161/5400 [01:53<07:05,  9.95it/s, est. speed input: 1486.44 toks/s, output: 10392.47 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 1163/5400 [01:54<08:35,  8.21it/s, est. speed input: 1483.93 toks/s, output: 10367.56 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 1171/5400 [01:54<05:27, 12.92it/s, est. speed input: 1492.43 toks/s, output: 10426.98 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 1177/5400 [01:54<04:10, 16.85it/s, est. speed input: 1498.51 toks/s, output: 10467.36 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 1180/5400 [01:55<05:56, 11.82it/s, est. speed input: 1493.79 toks/s, output: 10458.75 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 1187/5400 [01:55<05:08, 13.65it/s, est. speed input: 1494.95 toks/s, output: 10475.51 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 1191/5400 [01:55<04:43, 14.83it/s, est. speed input: 1496.02 toks/s, output: 10481.78 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 1196/5400 [01:55<04:28, 15.69it/s, est. speed input: 1496.07 toks/s, output: 10482.26 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 1198/5400 [01:57<11:06,  6.31it/s, est. speed input: 1480.29 toks/s, output: 10372.54 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 1203/5400 [01:57<08:25,  8.31it/s, est. speed input: 1484.85 toks/s, output: 10370.74 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 1212/5400 [01:57<04:53, 14.29it/s, est. speed input: 1500.69 toks/s, output: 10408.68 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 1218/5400 [01:57<04:18, 16.19it/s, est. speed input: 1503.06 toks/s, output: 10424.76 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 1222/5400 [01:58<03:57, 17.61it/s, est. speed input: 1508.52 toks/s, output: 10435.88 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 1229/5400 [01:58<03:01, 23.00it/s, est. speed input: 1515.66 toks/s, output: 10475.09 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 1233/5400 [01:59<06:10, 11.26it/s, est. speed input: 1506.13 toks/s, output: 10404.28 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 1236/5400 [01:59<05:56, 11.68it/s, est. speed input: 1505.46 toks/s, output: 10391.74 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 1240/5400 [01:59<05:48, 11.93it/s, est. speed input: 1504.93 toks/s, output: 10389.04 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 1242/5400 [02:02<17:49,  3.89it/s, est. speed input: 1477.88 toks/s, output: 10201.04 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 1248/5400 [02:02<11:31,  6.00it/s, est. speed input: 1478.94 toks/s, output: 10204.76 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 1250/5400 [02:02<11:32,  5.99it/s, est. speed input: 1477.46 toks/s, output: 10226.79 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 1254/5400 [02:02<08:57,  7.71it/s, est. speed input: 1479.52 toks/s, output: 10290.23 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 1256/5400 [02:02<08:03,  8.57it/s, est. speed input: 1479.95 toks/s, output: 10310.25 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 1259/5400 [02:03<07:03,  9.77it/s, est. speed input: 1481.05 toks/s, output: 10353.07 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 1261/5400 [02:03<08:03,  8.56it/s, est. speed input: 1478.75 toks/s, output: 10343.54 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 1265/5400 [02:03<06:03, 11.37it/s, est. speed input: 1480.08 toks/s, output: 10363.71 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 1267/5400 [02:03<06:46, 10.17it/s, est. speed input: 1478.29 toks/s, output: 10355.75 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñé       | 1269/5400 [02:05<15:02,  4.58it/s, est. speed input: 1465.40 toks/s, output: 10270.45 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñé       | 1273/5400 [02:05<10:15,  6.71it/s, est. speed input: 1466.20 toks/s, output: 10282.62 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñé       | 1276/5400 [02:05<08:58,  7.66it/s, est. speed input: 1465.42 toks/s, output: 10276.62 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñé       | 1281/5400 [02:05<06:22, 10.77it/s, est. speed input: 1468.02 toks/s, output: 10299.94 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 1283/5400 [02:05<06:13, 11.03it/s, est. speed input: 1467.71 toks/s, output: 10313.84 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 1287/5400 [02:06<05:34, 12.29it/s, est. speed input: 1468.70 toks/s, output: 10372.83 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 1292/5400 [02:06<04:09, 16.44it/s, est. speed input: 1470.17 toks/s, output: 10408.77 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 1295/5400 [02:06<04:08, 16.50it/s, est. speed input: 1471.95 toks/s, output: 10466.83 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 1297/5400 [02:06<04:08, 16.49it/s, est. speed input: 1473.11 toks/s, output: 10505.31 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 1301/5400 [02:06<04:51, 14.07it/s, est. speed input: 1473.43 toks/s, output: 10558.36 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 1305/5400 [02:07<04:21, 15.64it/s, est. speed input: 1474.77 toks/s, output: 10580.36 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 1307/5400 [02:07<04:19, 15.79it/s, est. speed input: 1474.64 toks/s, output: 10590.98 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 1312/5400 [02:07<03:13, 21.10it/s, est. speed input: 1476.15 toks/s, output: 10630.82 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 1315/5400 [02:07<02:58, 22.85it/s, est. speed input: 1476.35 toks/s, output: 10655.92 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 1318/5400 [02:07<03:23, 20.10it/s, est. speed input: 1475.80 toks/s, output: 10671.20 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 1321/5400 [02:10<16:59,  4.00it/s, est. speed input: 1453.88 toks/s, output: 10539.85 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 1323/5400 [02:10<15:07,  4.49it/s, est. speed input: 1454.45 toks/s, output: 10556.61 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñç       | 1327/5400 [02:10<10:41,  6.34it/s, est. speed input: 1457.65 toks/s, output: 10583.65 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñç       | 1329/5400 [02:10<09:51,  6.89it/s, est. speed input: 1457.37 toks/s, output: 10578.90 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñç       | 1332/5400 [02:10<08:02,  8.43it/s, est. speed input: 1459.04 toks/s, output: 10599.37 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñç       | 1335/5400 [02:11<07:54,  8.57it/s, est. speed input: 1457.47 toks/s, output: 10586.67 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñç       | 1345/5400 [02:11<04:10, 16.17it/s, est. speed input: 1464.93 toks/s, output: 10619.99 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñç       | 1348/5400 [02:11<04:03, 16.63it/s, est. speed input: 1466.68 toks/s, output: 10636.99 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 1356/5400 [02:11<02:39, 25.36it/s, est. speed input: 1471.57 toks/s, output: 10672.81 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 1361/5400 [02:11<02:21, 28.49it/s, est. speed input: 1473.61 toks/s, output: 10692.20 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 1365/5400 [02:11<02:16, 29.59it/s, est. speed input: 1474.49 toks/s, output: 10704.54 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 1369/5400 [02:12<04:30, 14.89it/s, est. speed input: 1471.87 toks/s, output: 10677.13 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 1375/5400 [02:12<03:18, 20.30it/s, est. speed input: 1480.15 toks/s, output: 10702.41 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 1379/5400 [02:13<05:38, 11.87it/s, est. speed input: 1477.64 toks/s, output: 10665.34 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 1389/5400 [02:14<05:46, 11.58it/s, est. speed input: 1482.91 toks/s, output: 10657.37 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 1393/5400 [02:14<05:14, 12.75it/s, est. speed input: 1483.15 toks/s, output: 10654.42 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 1396/5400 [02:14<05:58, 11.17it/s, est. speed input: 1481.47 toks/s, output: 10671.09 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 1398/5400 [02:15<08:25,  7.92it/s, est. speed input: 1475.97 toks/s, output: 10644.98 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 1402/5400 [02:17<13:47,  4.83it/s, est. speed input: 1461.79 toks/s, output: 10539.55 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 1404/5400 [02:17<12:24,  5.37it/s, est. speed input: 1460.78 toks/s, output: 10532.55 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 1406/5400 [02:17<10:34,  6.30it/s, est. speed input: 1460.77 toks/s, output: 10532.22 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 1412/5400 [02:17<06:17, 10.56it/s, est. speed input: 1462.79 toks/s, output: 10548.23 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 1415/5400 [02:17<05:16, 12.58it/s, est. speed input: 1463.81 toks/s, output: 10564.65 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñã       | 1423/5400 [02:18<05:53, 11.25it/s, est. speed input: 1460.51 toks/s, output: 10549.63 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñã       | 1426/5400 [02:18<05:07, 12.92it/s, est. speed input: 1463.29 toks/s, output: 10558.70 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñã       | 1431/5400 [02:18<04:02, 16.34it/s, est. speed input: 1467.61 toks/s, output: 10583.42 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 1434/5400 [02:19<07:10,  9.21it/s, est. speed input: 1460.87 toks/s, output: 10535.38 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 1437/5400 [02:19<07:01,  9.40it/s, est. speed input: 1459.85 toks/s, output: 10521.49 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 1444/5400 [02:19<04:20, 15.16it/s, est. speed input: 1464.08 toks/s, output: 10538.77 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 1448/5400 [02:20<04:24, 14.93it/s, est. speed input: 1464.12 toks/s, output: 10531.70 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 1451/5400 [02:20<03:55, 16.79it/s, est. speed input: 1465.93 toks/s, output: 10531.25 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 1459/5400 [02:20<02:35, 25.31it/s, est. speed input: 1471.01 toks/s, output: 10571.00 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 1463/5400 [02:20<03:38, 18.01it/s, est. speed input: 1468.94 toks/s, output: 10561.90 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 1469/5400 [02:21<03:22, 19.45it/s, est. speed input: 1470.08 toks/s, output: 10601.65 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 1478/5400 [02:21<02:33, 25.56it/s, est. speed input: 1472.66 toks/s, output: 10735.04 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 1482/5400 [02:21<03:39, 17.88it/s, est. speed input: 1469.45 toks/s, output: 10711.96 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1486/5400 [02:21<03:15, 20.03it/s, est. speed input: 1470.71 toks/s, output: 10718.82 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1489/5400 [02:22<03:13, 20.26it/s, est. speed input: 1470.58 toks/s, output: 10773.03 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1494/5400 [02:22<02:41, 24.17it/s, est. speed input: 1471.53 toks/s, output: 10871.75 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1498/5400 [02:22<04:02, 16.09it/s, est. speed input: 1468.63 toks/s, output: 10903.35 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1502/5400 [02:22<04:09, 15.60it/s, est. speed input: 1469.07 toks/s, output: 10959.85 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1506/5400 [02:23<06:15, 10.37it/s, est. speed input: 1465.88 toks/s, output: 10977.34 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1508/5400 [02:24<11:02,  5.88it/s, est. speed input: 1455.78 toks/s, output: 10938.88 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1514/5400 [02:25<08:00,  8.09it/s, est. speed input: 1455.82 toks/s, output: 11027.03 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1516/5400 [02:25<08:53,  7.28it/s, est. speed input: 1452.91 toks/s, output: 11021.84 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1518/5400 [02:27<20:28,  3.16it/s, est. speed input: 1432.90 toks/s, output: 10870.61 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1522/5400 [02:27<14:41,  4.40it/s, est. speed input: 1431.79 toks/s, output: 10860.80 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1526/5400 [02:28<11:39,  5.54it/s, est. speed input: 1430.19 toks/s, output: 10844.89 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1528/5400 [02:28<13:05,  4.93it/s, est. speed input: 1426.02 toks/s, output: 10807.94 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1534/5400 [02:28<07:50,  8.22it/s, est. speed input: 1428.96 toks/s, output: 10815.83 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1539/5400 [02:29<06:00, 10.71it/s, est. speed input: 1433.22 toks/s, output: 10871.03 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñä       | 1542/5400 [02:29<05:12, 12.34it/s, est. speed input: 1434.41 toks/s, output: 10875.74 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñä       | 1545/5400 [02:29<06:06, 10.51it/s, est. speed input: 1434.13 toks/s, output: 10868.24 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñä       | 1548/5400 [02:30<07:16,  8.83it/s, est. speed input: 1432.43 toks/s, output: 10851.20 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñä       | 1551/5400 [02:30<06:00, 10.69it/s, est. speed input: 1433.99 toks/s, output: 10864.25 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 1557/5400 [02:30<03:55, 16.29it/s, est. speed input: 1441.99 toks/s, output: 10933.62 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 1560/5400 [02:30<03:30, 18.27it/s, est. speed input: 1443.41 toks/s, output: 10944.95 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 1566/5400 [02:30<02:31, 25.31it/s, est. speed input: 1447.32 toks/s, output: 10974.65 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 1573/5400 [02:30<02:19, 27.40it/s, est. speed input: 1449.86 toks/s, output: 10983.05 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 1582/5400 [02:31<01:45, 36.19it/s, est. speed input: 1456.27 toks/s, output: 11012.00 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 1587/5400 [02:31<02:08, 29.65it/s, est. speed input: 1456.81 toks/s, output: 11010.92 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 1595/5400 [02:31<02:16, 27.89it/s, est. speed input: 1461.63 toks/s, output: 11040.31 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 1599/5400 [02:31<02:34, 24.55it/s, est. speed input: 1463.33 toks/s, output: 11055.64 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 1602/5400 [02:33<07:24,  8.55it/s, est. speed input: 1451.91 toks/s, output: 10974.12 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 1605/5400 [02:33<06:39,  9.50it/s, est. speed input: 1451.69 toks/s, output: 10977.80 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 1607/5400 [02:33<06:28,  9.76it/s, est. speed input: 1451.29 toks/s, output: 10975.16 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 1609/5400 [02:33<07:16,  8.69it/s, est. speed input: 1449.15 toks/s, output: 10961.93 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 1613/5400 [02:34<05:55, 10.64it/s, est. speed input: 1448.79 toks/s, output: 10997.69 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 1617/5400 [02:34<04:59, 12.63it/s, est. speed input: 1448.54 toks/s, output: 11035.71 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 1619/5400 [02:34<04:53, 12.90it/s, est. speed input: 1448.67 toks/s, output: 11033.74 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 1629/5400 [02:34<02:29, 25.22it/s, est. speed input: 1469.08 toks/s, output: 11089.84 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 1636/5400 [02:34<01:58, 31.77it/s, est. speed input: 1474.48 toks/s, output: 11114.27 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 1642/5400 [02:34<01:48, 34.56it/s, est. speed input: 1476.45 toks/s, output: 11148.02 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 1647/5400 [02:35<03:19, 18.85it/s, est. speed input: 1473.36 toks/s, output: 11172.72 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 1654/5400 [02:35<02:35, 24.14it/s, est. speed input: 1476.34 toks/s, output: 11243.55 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 1658/5400 [02:35<02:37, 23.83it/s, est. speed input: 1476.73 toks/s, output: 11295.47 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 1662/5400 [02:36<02:56, 21.15it/s, est. speed input: 1477.35 toks/s, output: 11347.95 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 1666/5400 [02:36<02:48, 22.13it/s, est. speed input: 1477.72 toks/s, output: 11397.38 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 1671/5400 [02:36<02:32, 24.38it/s, est. speed input: 1478.51 toks/s, output: 11466.15 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 1681/5400 [02:36<01:40, 36.85it/s, est. speed input: 1482.17 toks/s, output: 11536.84 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 1686/5400 [02:37<03:07, 19.83it/s, est. speed input: 1478.82 toks/s, output: 11561.20 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà‚ñè      | 1690/5400 [02:38<07:47,  7.94it/s, est. speed input: 1466.34 toks/s, output: 11458.19 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà‚ñè      | 1693/5400 [02:38<06:49,  9.05it/s, est. speed input: 1466.75 toks/s, output: 11461.74 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà‚ñè      | 1696/5400 [02:40<12:16,  5.03it/s, est. speed input: 1454.87 toks/s, output: 11358.49 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà‚ñè      | 1699/5400 [02:40<11:05,  5.57it/s, est. speed input: 1454.59 toks/s, output: 11340.81 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 1701/5400 [02:40<10:02,  6.14it/s, est. speed input: 1455.74 toks/s, output: 11332.62 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 1705/5400 [02:40<07:18,  8.43it/s, est. speed input: 1459.32 toks/s, output: 11335.15 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 1707/5400 [02:41<06:34,  9.36it/s, est. speed input: 1461.00 toks/s, output: 11331.07 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 1709/5400 [02:41<06:03, 10.16it/s, est. speed input: 1461.41 toks/s, output: 11337.68 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 1711/5400 [02:41<10:05,  6.09it/s, est. speed input: 1456.83 toks/s, output: 11293.20 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 1716/5400 [02:42<06:19,  9.70it/s, est. speed input: 1459.17 toks/s, output: 11308.48 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 1720/5400 [02:42<06:13,  9.85it/s, est. speed input: 1458.86 toks/s, output: 11308.14 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 1723/5400 [02:42<06:49,  8.98it/s, est. speed input: 1457.06 toks/s, output: 11310.45 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 1727/5400 [02:43<05:19, 11.49it/s, est. speed input: 1457.34 toks/s, output: 11374.80 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 1732/5400 [02:43<04:29, 13.62it/s, est. speed input: 1458.08 toks/s, output: 11423.43 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 1739/5400 [02:43<03:03, 19.92it/s, est. speed input: 1460.46 toks/s, output: 11431.66 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 1742/5400 [02:44<07:25,  8.22it/s, est. speed input: 1452.28 toks/s, output: 11361.53 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 1745/5400 [02:44<06:18,  9.66it/s, est. speed input: 1454.67 toks/s, output: 11408.66 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 1748/5400 [02:44<05:44, 10.61it/s, est. speed input: 1456.43 toks/s, output: 11450.81 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 1750/5400 [02:45<05:46, 10.53it/s, est. speed input: 1456.45 toks/s, output: 11458.48 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 1752/5400 [02:45<05:17, 11.48it/s, est. speed input: 1457.47 toks/s, output: 11457.88 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 1767/5400 [02:45<01:59, 30.46it/s, est. speed input: 1466.96 toks/s, output: 11492.68 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 1772/5400 [02:45<02:08, 28.30it/s, est. speed input: 1469.51 toks/s, output: 11493.14 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 1776/5400 [02:45<02:46, 21.79it/s, est. speed input: 1471.75 toks/s, output: 11484.64 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 1780/5400 [02:46<02:53, 20.90it/s, est. speed input: 1472.89 toks/s, output: 11487.92 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 1784/5400 [02:48<10:02,  6.00it/s, est. speed input: 1458.11 toks/s, output: 11379.83 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 1794/5400 [02:48<05:56, 10.12it/s, est. speed input: 1462.14 toks/s, output: 11407.55 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 1797/5400 [02:49<08:56,  6.71it/s, est. speed input: 1453.85 toks/s, output: 11346.09 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 1805/5400 [02:49<05:49, 10.27it/s, est. speed input: 1456.12 toks/s, output: 11386.52 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñé      | 1811/5400 [02:50<07:18,  8.18it/s, est. speed input: 1451.34 toks/s, output: 11334.57 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñé      | 1817/5400 [02:51<05:33, 10.75it/s, est. speed input: 1460.17 toks/s, output: 11345.73 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñé      | 1820/5400 [02:51<07:44,  7.70it/s, est. speed input: 1456.39 toks/s, output: 11291.15 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 1823/5400 [02:52<06:40,  8.92it/s, est. speed input: 1457.40 toks/s, output: 11291.54 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 1826/5400 [02:52<07:00,  8.49it/s, est. speed input: 1455.45 toks/s, output: 11272.75 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 1834/5400 [02:52<04:10, 14.22it/s, est. speed input: 1462.97 toks/s, output: 11283.98 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 1838/5400 [02:52<04:17, 13.84it/s, est. speed input: 1467.42 toks/s, output: 11272.03 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 1841/5400 [02:54<08:28,  6.99it/s, est. speed input: 1459.29 toks/s, output: 11207.29 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 1848/5400 [02:54<05:24, 10.94it/s, est. speed input: 1461.82 toks/s, output: 11234.75 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 1852/5400 [02:54<04:29, 13.17it/s, est. speed input: 1463.61 toks/s, output: 11248.48 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 1856/5400 [02:54<03:50, 15.34it/s, est. speed input: 1464.67 toks/s, output: 11261.17 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 1862/5400 [02:54<02:54, 20.30it/s, est. speed input: 1467.17 toks/s, output: 11286.48 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 1866/5400 [02:54<02:41, 21.94it/s, est. speed input: 1468.41 toks/s, output: 11298.34 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 1870/5400 [02:54<02:40, 22.05it/s, est. speed input: 1468.72 toks/s, output: 11308.99 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 1874/5400 [02:55<04:49, 12.20it/s, est. speed input: 1467.68 toks/s, output: 11288.60 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 1877/5400 [02:56<05:28, 10.72it/s, est. speed input: 1465.56 toks/s, output: 11279.88 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 1879/5400 [02:56<05:13, 11.23it/s, est. speed input: 1465.84 toks/s, output: 11281.86 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 1883/5400 [02:56<04:37, 12.68it/s, est. speed input: 1466.52 toks/s, output: 11293.44 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 1885/5400 [02:56<05:26, 10.76it/s, est. speed input: 1465.43 toks/s, output: 11284.98 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 1887/5400 [02:56<05:00, 11.68it/s, est. speed input: 1465.25 toks/s, output: 11291.78 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 1889/5400 [02:57<11:02,  5.30it/s, est. speed input: 1458.11 toks/s, output: 11236.70 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 1892/5400 [02:58<08:21,  6.99it/s, est. speed input: 1458.73 toks/s, output: 11236.98 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 1894/5400 [02:58<09:16,  6.30it/s, est. speed input: 1456.90 toks/s, output: 11217.93 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 1901/5400 [02:58<05:32, 10.54it/s, est. speed input: 1457.54 toks/s, output: 11229.99 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 1905/5400 [02:58<04:21, 13.37it/s, est. speed input: 1461.37 toks/s, output: 11244.71 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 1908/5400 [02:59<05:16, 11.04it/s, est. speed input: 1461.53 toks/s, output: 11229.92 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 1911/5400 [02:59<05:11, 11.20it/s, est. speed input: 1463.56 toks/s, output: 11228.16 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 1913/5400 [02:59<05:04, 11.44it/s, est. speed input: 1464.07 toks/s, output: 11224.99 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 1915/5400 [03:00<06:36,  8.78it/s, est. speed input: 1461.96 toks/s, output: 11205.02 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 1918/5400 [03:00<05:35, 10.38it/s, est. speed input: 1463.26 toks/s, output: 11216.70 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 1920/5400 [03:00<06:35,  8.81it/s, est. speed input: 1462.40 toks/s, output: 11220.75 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 1922/5400 [03:00<05:48,  9.99it/s, est. speed input: 1463.30 toks/s, output: 11238.34 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 1924/5400 [03:01<11:55,  4.86it/s, est. speed input: 1456.76 toks/s, output: 11186.96 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 1925/5400 [03:01<11:40,  4.96it/s, est. speed input: 1455.72 toks/s, output: 11184.28 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 1927/5400 [03:02<10:30,  5.51it/s, est. speed input: 1454.53 toks/s, output: 11184.09 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 1929/5400 [03:02<08:18,  6.96it/s, est. speed input: 1454.82 toks/s, output: 11193.73 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 1931/5400 [03:02<08:35,  6.73it/s, est. speed input: 1454.01 toks/s, output: 11185.27 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 1935/5400 [03:04<14:06,  4.10it/s, est. speed input: 1447.27 toks/s, output: 11109.96 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 1936/5400 [03:04<13:04,  4.42it/s, est. speed input: 1447.44 toks/s, output: 11105.39 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 1937/5400 [03:04<12:36,  4.58it/s, est. speed input: 1446.64 toks/s, output: 11103.42 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 1943/5400 [03:04<05:42, 10.09it/s, est. speed input: 1450.44 toks/s, output: 11132.00 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 1946/5400 [03:05<07:53,  7.29it/s, est. speed input: 1446.45 toks/s, output: 11099.92 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 1950/5400 [03:05<07:29,  7.67it/s, est. speed input: 1445.06 toks/s, output: 11085.90 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 1952/5400 [03:05<06:32,  8.79it/s, est. speed input: 1445.18 toks/s, output: 11086.15 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 1956/5400 [03:05<04:51, 11.83it/s, est. speed input: 1445.99 toks/s, output: 11089.25 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñã      | 1961/5400 [03:06<04:06, 13.96it/s, est. speed input: 1446.28 toks/s, output: 11095.98 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñã      | 1964/5400 [03:06<03:41, 15.53it/s, est. speed input: 1446.74 toks/s, output: 11096.39 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñã      | 1967/5400 [03:06<03:29, 16.35it/s, est. speed input: 1446.88 toks/s, output: 11096.43 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 1973/5400 [03:06<03:13, 17.71it/s, est. speed input: 1446.89 toks/s, output: 11103.00 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 1976/5400 [03:07<04:30, 12.65it/s, est. speed input: 1445.90 toks/s, output: 11090.29 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 1978/5400 [03:07<06:46,  8.41it/s, est. speed input: 1442.32 toks/s, output: 11064.34 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 1980/5400 [03:08<07:25,  7.68it/s, est. speed input: 1441.37 toks/s, output: 11053.63 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 1983/5400 [03:08<08:04,  7.05it/s, est. speed input: 1439.68 toks/s, output: 11042.13 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 1986/5400 [03:08<07:05,  8.02it/s, est. speed input: 1440.88 toks/s, output: 11053.59 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 1991/5400 [03:09<06:30,  8.72it/s, est. speed input: 1441.48 toks/s, output: 11092.74 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 1994/5400 [03:09<06:20,  8.96it/s, est. speed input: 1441.09 toks/s, output: 11098.00 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 1995/5400 [03:09<06:19,  8.98it/s, est. speed input: 1440.97 toks/s, output: 11095.38 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 1997/5400 [03:09<05:31, 10.26it/s, est. speed input: 1441.97 toks/s, output: 11098.30 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 2001/5400 [03:10<08:10,  6.93it/s, est. speed input: 1439.00 toks/s, output: 11070.70 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 2003/5400 [03:10<07:28,  7.57it/s, est. speed input: 1438.66 toks/s, output: 11069.82 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 2005/5400 [03:11<08:27,  6.69it/s, est. speed input: 1436.62 toks/s, output: 11051.60 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 2008/5400 [03:11<07:14,  7.80it/s, est. speed input: 1436.19 toks/s, output: 11044.41 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 2009/5400 [03:11<08:48,  6.42it/s, est. speed input: 1434.27 toks/s, output: 11028.39 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 2014/5400 [03:12<05:10, 10.91it/s, est. speed input: 1436.29 toks/s, output: 11046.51 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 2020/5400 [03:12<05:45,  9.80it/s, est. speed input: 1438.28 toks/s, output: 11035.52 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 2022/5400 [03:13<09:31,  5.91it/s, est. speed input: 1432.97 toks/s, output: 10992.81 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 2027/5400 [03:13<06:16,  8.95it/s, est. speed input: 1434.03 toks/s, output: 11037.86 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 2030/5400 [03:13<05:33, 10.09it/s, est. speed input: 1433.72 toks/s, output: 11074.86 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 2032/5400 [03:14<05:39,  9.92it/s, est. speed input: 1432.82 toks/s, output: 11094.15 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 2034/5400 [03:15<13:30,  4.15it/s, est. speed input: 1422.69 toks/s, output: 11040.70 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 2039/5400 [03:16<11:11,  5.01it/s, est. speed input: 1419.78 toks/s, output: 11070.19 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 2047/5400 [03:16<06:37,  8.43it/s, est. speed input: 1421.10 toks/s, output: 11087.65 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 2049/5400 [03:16<06:11,  9.03it/s, est. speed input: 1421.08 toks/s, output: 11111.35 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 2051/5400 [03:17<06:15,  8.91it/s, est. speed input: 1420.04 toks/s, output: 11102.70 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 2053/5400 [03:17<07:52,  7.08it/s, est. speed input: 1417.03 toks/s, output: 11091.85 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 2055/5400 [03:17<06:44,  8.27it/s, est. speed input: 1416.95 toks/s, output: 11117.23 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 2061/5400 [03:17<03:59, 13.96it/s, est. speed input: 1418.38 toks/s, output: 11193.39 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 2064/5400 [03:18<04:05, 13.62it/s, est. speed input: 1419.18 toks/s, output: 11192.31 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 2067/5400 [03:18<04:39, 11.93it/s, est. speed input: 1418.92 toks/s, output: 11183.14 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 2072/5400 [03:18<03:21, 16.53it/s, est. speed input: 1421.40 toks/s, output: 11197.00 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 2076/5400 [03:19<04:35, 12.07it/s, est. speed input: 1419.91 toks/s, output: 11192.07 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 2079/5400 [03:19<03:59, 13.84it/s, est. speed input: 1421.45 toks/s, output: 11197.67 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñä      | 2082/5400 [03:19<04:28, 12.36it/s, est. speed input: 1420.70 toks/s, output: 11194.57 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñä      | 2085/5400 [03:20<06:12,  8.89it/s, est. speed input: 1418.92 toks/s, output: 11174.08 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñä      | 2087/5400 [03:20<06:57,  7.94it/s, est. speed input: 1417.81 toks/s, output: 11164.52 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñä      | 2091/5400 [03:20<06:00,  9.17it/s, est. speed input: 1418.24 toks/s, output: 11166.00 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 2095/5400 [03:21<05:14, 10.49it/s, est. speed input: 1418.72 toks/s, output: 11167.41 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 2097/5400 [03:21<05:48,  9.47it/s, est. speed input: 1417.63 toks/s, output: 11161.42 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 2099/5400 [03:21<05:44,  9.59it/s, est. speed input: 1417.08 toks/s, output: 11170.82 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 2104/5400 [03:21<03:41, 14.86it/s, est. speed input: 1418.55 toks/s, output: 11221.25 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 2107/5400 [03:21<03:11, 17.21it/s, est. speed input: 1418.91 toks/s, output: 11261.29 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 2115/5400 [03:22<04:39, 11.73it/s, est. speed input: 1419.98 toks/s, output: 11333.14 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 2117/5400 [03:23<06:25,  8.51it/s, est. speed input: 1417.07 toks/s, output: 11316.48 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 2119/5400 [03:23<08:35,  6.36it/s, est. speed input: 1413.39 toks/s, output: 11290.07 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 2121/5400 [03:24<09:41,  5.64it/s, est. speed input: 1410.86 toks/s, output: 11273.12 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 2123/5400 [03:24<10:27,  5.23it/s, est. speed input: 1408.69 toks/s, output: 11255.41 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 2127/5400 [03:25<07:30,  7.26it/s, est. speed input: 1409.43 toks/s, output: 11260.77 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 2129/5400 [03:25<10:06,  5.39it/s, est. speed input: 1405.67 toks/s, output: 11231.01 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 2135/5400 [03:26<06:27,  8.44it/s, est. speed input: 1407.14 toks/s, output: 11240.57 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 2137/5400 [03:26<06:14,  8.70it/s, est. speed input: 1406.66 toks/s, output: 11245.78 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 2140/5400 [03:26<05:10, 10.48it/s, est. speed input: 1407.34 toks/s, output: 11251.68 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 2142/5400 [03:26<05:06, 10.63it/s, est. speed input: 1407.14 toks/s, output: 11252.79 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 2153/5400 [03:26<02:24, 22.49it/s, est. speed input: 1411.26 toks/s, output: 11317.26 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2161/5400 [03:26<01:46, 30.45it/s, est. speed input: 1413.73 toks/s, output: 11343.94 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2166/5400 [03:27<03:31, 15.32it/s, est. speed input: 1410.59 toks/s, output: 11341.25 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2170/5400 [03:28<06:25,  8.38it/s, est. speed input: 1403.88 toks/s, output: 11300.78 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2173/5400 [03:29<05:31,  9.73it/s, est. speed input: 1404.29 toks/s, output: 11316.61 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2179/5400 [03:29<04:29, 11.94it/s, est. speed input: 1405.14 toks/s, output: 11367.85 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 2182/5400 [03:30<06:45,  7.94it/s, est. speed input: 1401.10 toks/s, output: 11332.13 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 2190/5400 [03:30<05:10, 10.34it/s, est. speed input: 1402.12 toks/s, output: 11325.36 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 2195/5400 [03:30<04:01, 13.30it/s, est. speed input: 1405.50 toks/s, output: 11342.79 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 2200/5400 [03:30<03:35, 14.85it/s, est. speed input: 1406.36 toks/s, output: 11352.92 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 2204/5400 [03:31<03:05, 17.19it/s, est. speed input: 1406.86 toks/s, output: 11358.74 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 2208/5400 [03:31<02:38, 20.19it/s, est. speed input: 1408.00 toks/s, output: 11363.88 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 2212/5400 [03:31<02:33, 20.74it/s, est. speed input: 1409.07 toks/s, output: 11368.32 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 2222/5400 [03:31<01:33, 33.88it/s, est. speed input: 1413.12 toks/s, output: 11388.20 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 2227/5400 [03:32<02:33, 20.64it/s, est. speed input: 1412.22 toks/s, output: 11380.87 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2233/5400 [03:32<02:18, 22.85it/s, est. speed input: 1413.46 toks/s, output: 11390.74 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2237/5400 [03:32<02:11, 23.99it/s, est. speed input: 1415.27 toks/s, output: 11414.31 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2241/5400 [03:32<02:02, 25.77it/s, est. speed input: 1418.63 toks/s, output: 11455.99 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2250/5400 [03:32<01:29, 35.19it/s, est. speed input: 1422.16 toks/s, output: 11489.47 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2255/5400 [03:32<01:25, 36.79it/s, est. speed input: 1423.56 toks/s, output: 11496.93 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2261/5400 [03:32<01:40, 31.33it/s, est. speed input: 1424.30 toks/s, output: 11514.00 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2265/5400 [03:33<02:37, 19.90it/s, est. speed input: 1424.99 toks/s, output: 11526.03 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2273/5400 [03:33<01:53, 27.54it/s, est. speed input: 1431.42 toks/s, output: 11579.49 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2278/5400 [03:34<03:40, 14.16it/s, est. speed input: 1428.80 toks/s, output: 11565.18 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2282/5400 [03:34<04:09, 12.47it/s, est. speed input: 1427.20 toks/s, output: 11560.85 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2287/5400 [03:34<03:21, 15.47it/s, est. speed input: 1427.88 toks/s, output: 11579.11 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2290/5400 [03:36<06:39,  7.79it/s, est. speed input: 1421.78 toks/s, output: 11530.80 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2293/5400 [03:36<07:07,  7.28it/s, est. speed input: 1420.19 toks/s, output: 11516.68 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2296/5400 [03:37<08:33,  6.04it/s, est. speed input: 1416.72 toks/s, output: 11489.66 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2298/5400 [03:37<08:51,  5.84it/s, est. speed input: 1415.24 toks/s, output: 11477.03 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2300/5400 [03:38<08:55,  5.79it/s, est. speed input: 1413.52 toks/s, output: 11466.27 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2302/5400 [03:38<09:46,  5.28it/s, est. speed input: 1411.49 toks/s, output: 11446.47 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2305/5400 [03:38<07:59,  6.45it/s, est. speed input: 1411.40 toks/s, output: 11442.07 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2312/5400 [03:39<04:38, 11.09it/s, est. speed input: 1418.25 toks/s, output: 11518.51 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2315/5400 [03:39<04:00, 12.85it/s, est. speed input: 1418.56 toks/s, output: 11554.36 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2318/5400 [03:39<04:06, 12.51it/s, est. speed input: 1418.09 toks/s, output: 11559.47 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2321/5400 [03:39<03:37, 14.14it/s, est. speed input: 1418.43 toks/s, output: 11557.29 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2323/5400 [03:40<06:04,  8.45it/s, est. speed input: 1415.34 toks/s, output: 11529.62 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2325/5400 [03:40<05:56,  8.63it/s, est. speed input: 1414.77 toks/s, output: 11522.07 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2327/5400 [03:40<07:17,  7.02it/s, est. speed input: 1412.73 toks/s, output: 11502.70 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2330/5400 [03:41<06:23,  8.00it/s, est. speed input: 1412.51 toks/s, output: 11498.43 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2334/5400 [03:41<05:38,  9.06it/s, est. speed input: 1411.99 toks/s, output: 11490.41 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2341/5400 [03:41<03:45, 13.54it/s, est. speed input: 1414.17 toks/s, output: 11508.26 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2346/5400 [03:43<07:56,  6.41it/s, est. speed input: 1406.50 toks/s, output: 11440.78 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2352/5400 [03:43<05:49,  8.73it/s, est. speed input: 1408.96 toks/s, output: 11443.88 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2354/5400 [03:43<06:04,  8.36it/s, est. speed input: 1407.88 toks/s, output: 11432.29 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2357/5400 [03:44<05:43,  8.86it/s, est. speed input: 1407.43 toks/s, output: 11430.07 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2361/5400 [03:44<04:51, 10.42it/s, est. speed input: 1407.57 toks/s, output: 11434.03 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2366/5400 [03:44<03:28, 14.57it/s, est. speed input: 1409.40 toks/s, output: 11441.84 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2370/5400 [03:44<03:06, 16.23it/s, est. speed input: 1409.85 toks/s, output: 11444.39 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2374/5400 [03:44<02:42, 18.58it/s, est. speed input: 1410.58 toks/s, output: 11481.29 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2377/5400 [03:44<02:37, 19.22it/s, est. speed input: 1410.94 toks/s, output: 11493.47 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2381/5400 [03:45<02:11, 22.95it/s, est. speed input: 1411.84 toks/s, output: 11512.12 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2384/5400 [03:45<02:52, 17.44it/s, est. speed input: 1411.15 toks/s, output: 11515.80 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2387/5400 [03:45<03:46, 13.31it/s, est. speed input: 1410.03 toks/s, output: 11528.50 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2391/5400 [03:45<03:05, 16.22it/s, est. speed input: 1410.17 toks/s, output: 11575.76 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2397/5400 [03:46<02:12, 22.66it/s, est. speed input: 1411.05 toks/s, output: 11619.52 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2404/5400 [03:46<02:06, 23.75it/s, est. speed input: 1412.35 toks/s, output: 11638.83 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2407/5400 [03:46<02:36, 19.13it/s, est. speed input: 1412.56 toks/s, output: 11643.92 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2410/5400 [03:46<02:24, 20.73it/s, est. speed input: 1413.75 toks/s, output: 11652.27 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2417/5400 [03:46<01:49, 27.27it/s, est. speed input: 1417.00 toks/s, output: 11669.38 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2426/5400 [03:47<01:47, 27.55it/s, est. speed input: 1418.98 toks/s, output: 11684.83 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2431/5400 [03:47<01:37, 30.34it/s, est. speed input: 1420.09 toks/s, output: 11718.80 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2435/5400 [03:47<01:48, 27.31it/s, est. speed input: 1420.67 toks/s, output: 11724.49 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2439/5400 [03:47<02:50, 17.39it/s, est. speed input: 1421.01 toks/s, output: 11716.73 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2442/5400 [03:48<02:47, 17.63it/s, est. speed input: 1422.43 toks/s, output: 11725.05 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2445/5400 [03:48<03:31, 14.00it/s, est. speed input: 1421.91 toks/s, output: 11714.24 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2452/5400 [03:48<02:24, 20.46it/s, est. speed input: 1424.92 toks/s, output: 11722.65 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2456/5400 [03:48<02:19, 21.06it/s, est. speed input: 1425.78 toks/s, output: 11735.71 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2459/5400 [03:49<04:45, 10.30it/s, est. speed input: 1422.11 toks/s, output: 11709.73 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2461/5400 [03:50<06:55,  7.08it/s, est. speed input: 1419.09 toks/s, output: 11681.84 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2465/5400 [03:50<05:12,  9.41it/s, est. speed input: 1420.84 toks/s, output: 11683.73 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2473/5400 [03:50<03:32, 13.78it/s, est. speed input: 1423.39 toks/s, output: 11718.62 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2476/5400 [03:51<05:00,  9.74it/s, est. speed input: 1420.36 toks/s, output: 11697.57 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2479/5400 [03:51<04:22, 11.15it/s, est. speed input: 1420.46 toks/s, output: 11701.05 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2489/5400 [03:51<02:44, 17.72it/s, est. speed input: 1422.29 toks/s, output: 11729.72 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2495/5400 [03:52<02:28, 19.55it/s, est. speed input: 1423.13 toks/s, output: 11749.78 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2498/5400 [03:52<03:07, 15.51it/s, est. speed input: 1424.21 toks/s, output: 11739.71 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2508/5400 [03:52<01:55, 25.05it/s, est. speed input: 1440.18 toks/s, output: 11755.43 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2513/5400 [03:52<02:05, 23.02it/s, est. speed input: 1443.55 toks/s, output: 11757.70 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2517/5400 [03:53<02:46, 17.36it/s, est. speed input: 1443.29 toks/s, output: 11755.47 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2520/5400 [03:53<03:04, 15.63it/s, est. speed input: 1443.51 toks/s, output: 11751.74 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2523/5400 [03:53<02:52, 16.68it/s, est. speed input: 1444.60 toks/s, output: 11753.78 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2526/5400 [03:53<03:04, 15.59it/s, est. speed input: 1444.74 toks/s, output: 11772.35 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2528/5400 [03:54<03:21, 14.24it/s, est. speed input: 1444.77 toks/s, output: 11768.66 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2531/5400 [03:54<03:27, 13.82it/s, est. speed input: 1444.69 toks/s, output: 11767.76 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2533/5400 [03:54<04:12, 11.37it/s, est. speed input: 1443.95 toks/s, output: 11759.79 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2535/5400 [03:54<04:05, 11.67it/s, est. speed input: 1443.97 toks/s, output: 11768.40 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2541/5400 [03:55<04:18, 11.04it/s, est. speed input: 1443.02 toks/s, output: 11807.25 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2543/5400 [03:56<09:05,  5.24it/s, est. speed input: 1436.16 toks/s, output: 11750.51 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2545/5400 [03:56<08:32,  5.57it/s, est. speed input: 1435.11 toks/s, output: 11741.54 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2547/5400 [03:57<07:43,  6.15it/s, est. speed input: 1434.46 toks/s, output: 11735.92 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2555/5400 [03:57<03:40, 12.89it/s, est. speed input: 1436.39 toks/s, output: 11750.48 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2560/5400 [03:57<03:02, 15.52it/s, est. speed input: 1436.53 toks/s, output: 11750.52 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2564/5400 [03:57<02:46, 17.08it/s, est. speed input: 1436.45 toks/s, output: 11748.97 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2567/5400 [03:58<04:10, 11.31it/s, est. speed input: 1434.26 toks/s, output: 11732.74 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2572/5400 [03:58<03:51, 12.21it/s, est. speed input: 1438.60 toks/s, output: 11731.49 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2575/5400 [03:58<03:27, 13.62it/s, est. speed input: 1438.69 toks/s, output: 11733.84 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2577/5400 [03:58<03:49, 12.29it/s, est. speed input: 1438.01 toks/s, output: 11726.57 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2580/5400 [03:58<03:15, 14.41it/s, est. speed input: 1438.61 toks/s, output: 11734.50 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2585/5400 [03:59<04:27, 10.53it/s, est. speed input: 1436.53 toks/s, output: 11713.50 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2587/5400 [03:59<04:13, 11.10it/s, est. speed input: 1436.73 toks/s, output: 11717.85 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2592/5400 [03:59<03:03, 15.34it/s, est. speed input: 1438.25 toks/s, output: 11738.69 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2601/5400 [03:59<01:51, 25.09it/s, est. speed input: 1456.74 toks/s, output: 11756.21 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2605/5400 [04:00<02:07, 21.92it/s, est. speed input: 1456.86 toks/s, output: 11766.13 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2608/5400 [04:00<02:48, 16.58it/s, est. speed input: 1455.50 toks/s, output: 11787.33 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2611/5400 [04:00<02:46, 16.71it/s, est. speed input: 1455.40 toks/s, output: 11799.53 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2614/5400 [04:01<03:08, 14.77it/s, est. speed input: 1459.52 toks/s, output: 11814.30 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2616/5400 [04:01<03:50, 12.09it/s, est. speed input: 1458.66 toks/s, output: 11806.51 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2618/5400 [04:01<05:56,  7.79it/s, est. speed input: 1455.74 toks/s, output: 11793.41 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2620/5400 [04:02<06:53,  6.73it/s, est. speed input: 1453.94 toks/s, output: 11778.99 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2621/5400 [04:02<07:11,  6.44it/s, est. speed input: 1453.12 toks/s, output: 11772.86 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2623/5400 [04:02<06:32,  7.08it/s, est. speed input: 1452.69 toks/s, output: 11769.23 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2626/5400 [04:02<04:43,  9.80it/s, est. speed input: 1453.37 toks/s, output: 11774.24 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2635/5400 [04:03<02:16, 20.25it/s, est. speed input: 1456.37 toks/s, output: 11790.34 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2638/5400 [04:03<02:09, 21.30it/s, est. speed input: 1457.00 toks/s, output: 11799.81 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2641/5400 [04:03<02:21, 19.53it/s, est. speed input: 1457.06 toks/s, output: 11799.52 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2644/5400 [04:03<03:46, 12.17it/s, est. speed input: 1459.83 toks/s, output: 11781.65 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2646/5400 [04:04<06:39,  6.90it/s, est. speed input: 1455.77 toks/s, output: 11747.82 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2650/5400 [04:05<06:20,  7.22it/s, est. speed input: 1456.24 toks/s, output: 11740.23 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2654/5400 [04:06<07:49,  5.85it/s, est. speed input: 1451.97 toks/s, output: 11704.70 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2656/5400 [04:07<10:44,  4.26it/s, est. speed input: 1446.71 toks/s, output: 11666.54 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2660/5400 [04:07<07:45,  5.89it/s, est. speed input: 1446.65 toks/s, output: 11684.05 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2663/5400 [04:07<06:10,  7.39it/s, est. speed input: 1446.75 toks/s, output: 11698.39 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2665/5400 [04:07<06:00,  7.59it/s, est. speed input: 1446.23 toks/s, output: 11694.96 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2671/5400 [04:07<04:00, 11.37it/s, est. speed input: 1448.38 toks/s, output: 11707.19 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2673/5400 [04:08<03:44, 12.12it/s, est. speed input: 1449.63 toks/s, output: 11712.03 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2675/5400 [04:08<03:55, 11.59it/s, est. speed input: 1449.42 toks/s, output: 11709.30 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2680/5400 [04:08<02:40, 16.90it/s, est. speed input: 1450.53 toks/s, output: 11719.27 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2683/5400 [04:09<05:04,  8.93it/s, est. speed input: 1447.17 toks/s, output: 11691.58 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2685/5400 [04:09<04:30, 10.05it/s, est. speed input: 1447.64 toks/s, output: 11711.51 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2689/5400 [04:09<03:25, 13.21it/s, est. speed input: 1448.29 toks/s, output: 11713.52 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2693/5400 [04:09<02:41, 16.74it/s, est. speed input: 1449.05 toks/s, output: 11717.71 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2696/5400 [04:10<04:25, 10.18it/s, est. speed input: 1456.16 toks/s, output: 11700.83 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2698/5400 [04:10<04:03, 11.08it/s, est. speed input: 1456.08 toks/s, output: 11699.68 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2700/5400 [04:10<03:39, 12.32it/s, est. speed input: 1456.13 toks/s, output: 11698.75 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2702/5400 [04:10<03:24, 13.20it/s, est. speed input: 1456.19 toks/s, output: 11698.62 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2706/5400 [04:10<02:33, 17.60it/s, est. speed input: 1466.51 toks/s, output: 11706.77 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2709/5400 [04:10<02:41, 16.69it/s, est. speed input: 1466.20 toks/s, output: 11702.84 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2712/5400 [04:10<03:02, 14.75it/s, est. speed input: 1465.64 toks/s, output: 11698.17 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2714/5400 [04:11<03:10, 14.13it/s, est. speed input: 1465.16 toks/s, output: 11694.02 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2716/5400 [04:11<05:45,  7.76it/s, est. speed input: 1467.25 toks/s, output: 11679.56 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2718/5400 [04:12<10:05,  4.43it/s, est. speed input: 1462.31 toks/s, output: 11636.84 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2723/5400 [04:13<07:01,  6.36it/s, est. speed input: 1462.04 toks/s, output: 11627.73 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2725/5400 [04:13<06:32,  6.82it/s, est. speed input: 1461.72 toks/s, output: 11622.01 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2730/5400 [04:13<04:46,  9.31it/s, est. speed input: 1462.13 toks/s, output: 11629.97 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2735/5400 [04:14<04:21, 10.20it/s, est. speed input: 1461.91 toks/s, output: 11624.85 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2739/5400 [04:14<03:45, 11.80it/s, est. speed input: 1462.31 toks/s, output: 11629.08 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2744/5400 [04:14<02:48, 15.79it/s, est. speed input: 1463.65 toks/s, output: 11645.88 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2749/5400 [04:14<02:23, 18.53it/s, est. speed input: 1464.37 toks/s, output: 11648.59 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2753/5400 [04:14<02:22, 18.53it/s, est. speed input: 1465.00 toks/s, output: 11647.09 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2759/5400 [04:15<01:58, 22.30it/s, est. speed input: 1466.13 toks/s, output: 11664.78 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2763/5400 [04:15<02:52, 15.33it/s, est. speed input: 1465.12 toks/s, output: 11671.69 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2768/5400 [04:15<02:16, 19.22it/s, est. speed input: 1466.45 toks/s, output: 11689.28 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2771/5400 [04:15<02:32, 17.29it/s, est. speed input: 1470.81 toks/s, output: 11698.06 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2774/5400 [04:16<03:21, 13.00it/s, est. speed input: 1469.56 toks/s, output: 11683.59 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2782/5400 [04:16<02:23, 18.21it/s, est. speed input: 1471.60 toks/s, output: 11716.41 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2785/5400 [04:17<04:36,  9.47it/s, est. speed input: 1476.69 toks/s, output: 11687.60 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2787/5400 [04:18<06:33,  6.63it/s, est. speed input: 1477.78 toks/s, output: 11663.33 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2789/5400 [04:18<06:14,  6.97it/s, est. speed input: 1477.33 toks/s, output: 11661.56 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2791/5400 [04:19<08:28,  5.13it/s, est. speed input: 1473.49 toks/s, output: 11632.33 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2792/5400 [04:19<08:30,  5.10it/s, est. speed input: 1472.86 toks/s, output: 11628.45 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2793/5400 [04:19<09:18,  4.67it/s, est. speed input: 1471.62 toks/s, output: 11619.67 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2799/5400 [04:19<04:41,  9.25it/s, est. speed input: 1472.31 toks/s, output: 11629.63 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2801/5400 [04:20<05:26,  7.97it/s, est. speed input: 1470.88 toks/s, output: 11617.42 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2803/5400 [04:20<05:04,  8.54it/s, est. speed input: 1470.64 toks/s, output: 11612.47 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2808/5400 [04:20<03:46, 11.44it/s, est. speed input: 1470.65 toks/s, output: 11615.10 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2813/5400 [04:20<02:40, 16.15it/s, est. speed input: 1471.97 toks/s, output: 11616.16 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2816/5400 [04:21<05:41,  7.58it/s, est. speed input: 1467.41 toks/s, output: 11575.13 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2818/5400 [04:22<05:19,  8.07it/s, est. speed input: 1467.14 toks/s, output: 11571.45 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2820/5400 [04:22<05:02,  8.53it/s, est. speed input: 1467.13 toks/s, output: 11574.29 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2823/5400 [04:22<04:25,  9.71it/s, est. speed input: 1467.42 toks/s, output: 11581.08 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2825/5400 [04:22<05:50,  7.35it/s, est. speed input: 1465.56 toks/s, output: 11562.52 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2827/5400 [04:23<04:59,  8.59it/s, est. speed input: 1465.80 toks/s, output: 11560.54 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2831/5400 [04:23<03:59, 10.72it/s, est. speed input: 1466.12 toks/s, output: 11558.71 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2837/5400 [04:23<04:09, 10.27it/s, est. speed input: 1464.85 toks/s, output: 11556.48 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2839/5400 [04:24<06:14,  6.84it/s, est. speed input: 1461.42 toks/s, output: 11532.20 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2845/5400 [04:25<05:12,  8.19it/s, est. speed input: 1459.84 toks/s, output: 11525.20 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2849/5400 [04:25<04:30,  9.45it/s, est. speed input: 1459.57 toks/s, output: 11520.44 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2858/5400 [04:25<02:37, 16.14it/s, est. speed input: 1461.67 toks/s, output: 11533.83 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2861/5400 [04:26<03:23, 12.50it/s, est. speed input: 1460.59 toks/s, output: 11532.42 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2864/5400 [04:26<05:09,  8.20it/s, est. speed input: 1457.13 toks/s, output: 11504.28 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2866/5400 [04:27<05:04,  8.33it/s, est. speed input: 1456.70 toks/s, output: 11500.15 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2869/5400 [04:27<05:13,  8.07it/s, est. speed input: 1455.87 toks/s, output: 11498.80 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2871/5400 [04:28<06:30,  6.47it/s, est. speed input: 1453.44 toks/s, output: 11480.88 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2873/5400 [04:28<05:48,  7.25it/s, est. speed input: 1453.68 toks/s, output: 11480.60 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2875/5400 [04:28<06:37,  6.35it/s, est. speed input: 1452.14 toks/s, output: 11468.06 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2877/5400 [04:29<07:29,  5.61it/s, est. speed input: 1450.41 toks/s, output: 11454.09 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2879/5400 [04:29<08:24,  5.00it/s, est. speed input: 1448.38 toks/s, output: 11437.99 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2880/5400 [04:29<08:40,  4.84it/s, est. speed input: 1447.39 toks/s, output: 11430.78 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2892/5400 [04:30<02:34, 16.18it/s, est. speed input: 1452.57 toks/s, output: 11527.30 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2896/5400 [04:30<03:44, 11.15it/s, est. speed input: 1453.43 toks/s, output: 11506.18 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2899/5400 [04:31<04:54,  8.48it/s, est. speed input: 1450.97 toks/s, output: 11494.98 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2902/5400 [04:32<06:47,  6.13it/s, est. speed input: 1449.11 toks/s, output: 11471.47 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2905/5400 [04:32<06:18,  6.59it/s, est. speed input: 1450.24 toks/s, output: 11463.41 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2909/5400 [04:32<04:47,  8.66it/s, est. speed input: 1453.76 toks/s, output: 11465.69 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2911/5400 [04:33<05:22,  7.73it/s, est. speed input: 1454.53 toks/s, output: 11454.06 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2913/5400 [04:33<05:16,  7.85it/s, est. speed input: 1455.05 toks/s, output: 11447.41 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2916/5400 [04:33<04:04, 10.14it/s, est. speed input: 1455.33 toks/s, output: 11466.71 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2919/5400 [04:33<04:01, 10.27it/s, est. speed input: 1454.52 toks/s, output: 11488.50 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2921/5400 [04:33<03:39, 11.27it/s, est. speed input: 1454.32 toks/s, output: 11490.18 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2923/5400 [04:34<03:34, 11.54it/s, est. speed input: 1454.22 toks/s, output: 11494.37 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2925/5400 [04:34<03:42, 11.13it/s, est. speed input: 1453.94 toks/s, output: 11491.29 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2929/5400 [04:34<02:45, 14.95it/s, est. speed input: 1454.36 toks/s, output: 11495.01 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2934/5400 [04:34<01:56, 21.22it/s, est. speed input: 1458.25 toks/s, output: 11528.41 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2942/5400 [04:34<01:26, 28.45it/s, est. speed input: 1466.45 toks/s, output: 11536.59 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2948/5400 [04:34<01:22, 29.82it/s, est. speed input: 1474.83 toks/s, output: 11543.69 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2952/5400 [04:35<02:22, 17.16it/s, est. speed input: 1477.87 toks/s, output: 11530.51 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2956/5400 [04:35<02:11, 18.64it/s, est. speed input: 1491.22 toks/s, output: 11550.70 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2959/5400 [04:36<03:06, 13.06it/s, est. speed input: 1491.58 toks/s, output: 11540.54 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2962/5400 [04:36<02:53, 14.07it/s, est. speed input: 1497.15 toks/s, output: 11540.21 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2964/5400 [04:36<03:18, 12.24it/s, est. speed input: 1497.44 toks/s, output: 11544.51 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2967/5400 [04:37<05:17,  7.65it/s, est. speed input: 1496.75 toks/s, output: 11523.07 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2973/5400 [04:37<03:45, 10.77it/s, est. speed input: 1511.10 toks/s, output: 11526.58 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2980/5400 [04:37<02:41, 15.01it/s, est. speed input: 1522.75 toks/s, output: 11537.02 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2985/5400 [04:37<02:12, 18.22it/s, est. speed input: 1526.15 toks/s, output: 11546.91 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2989/5400 [04:37<01:54, 21.13it/s, est. speed input: 1526.47 toks/s, output: 11551.58 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2992/5400 [04:38<03:00, 13.30it/s, est. speed input: 1526.05 toks/s, output: 11539.96 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2998/5400 [04:38<02:13, 17.98it/s, est. speed input: 1527.99 toks/s, output: 11549.77 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3002/5400 [04:38<02:12, 18.05it/s, est. speed input: 1527.91 toks/s, output: 11552.98 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3005/5400 [04:39<02:18, 17.25it/s, est. speed input: 1528.20 toks/s, output: 11560.32 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3008/5400 [04:39<02:12, 18.09it/s, est. speed input: 1528.94 toks/s, output: 11564.24 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3012/5400 [04:39<01:49, 21.79it/s, est. speed input: 1529.99 toks/s, output: 11578.57 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3015/5400 [04:40<03:58, 10.00it/s, est. speed input: 1527.00 toks/s, output: 11557.68 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3018/5400 [04:40<03:28, 11.40it/s, est. speed input: 1527.30 toks/s, output: 11558.65 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3020/5400 [04:40<03:15, 12.16it/s, est. speed input: 1527.34 toks/s, output: 11570.81 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3022/5400 [04:40<03:10, 12.48it/s, est. speed input: 1527.55 toks/s, output: 11575.52 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3031/5400 [04:40<01:41, 23.33it/s, est. speed input: 1529.69 toks/s, output: 11587.02 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3034/5400 [04:40<01:42, 23.18it/s, est. speed input: 1529.87 toks/s, output: 11585.30 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3037/5400 [04:41<01:54, 20.72it/s, est. speed input: 1530.30 toks/s, output: 11582.92 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3040/5400 [04:41<02:55, 13.46it/s, est. speed input: 1529.57 toks/s, output: 11573.76 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3042/5400 [04:42<06:27,  6.08it/s, est. speed input: 1524.82 toks/s, output: 11537.24 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3044/5400 [04:43<08:15,  4.75it/s, est. speed input: 1523.11 toks/s, output: 11512.37 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3046/5400 [04:45<15:40,  2.50it/s, est. speed input: 1513.37 toks/s, output: 11434.51 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3053/5400 [04:45<08:00,  4.89it/s, est. speed input: 1514.33 toks/s, output: 11432.68 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3055/5400 [04:46<08:15,  4.74it/s, est. speed input: 1516.51 toks/s, output: 11434.10 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3057/5400 [04:46<08:01,  4.86it/s, est. speed input: 1515.14 toks/s, output: 11425.47 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3061/5400 [04:46<05:27,  7.15it/s, est. speed input: 1516.02 toks/s, output: 11435.44 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3063/5400 [04:46<05:13,  7.47it/s, est. speed input: 1515.53 toks/s, output: 11436.91 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3065/5400 [04:47<06:26,  6.05it/s, est. speed input: 1513.33 toks/s, output: 11427.85 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3073/5400 [04:47<03:34, 10.83it/s, est. speed input: 1514.41 toks/s, output: 11483.09 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3075/5400 [04:47<03:28, 11.15it/s, est. speed input: 1514.47 toks/s, output: 11480.34 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3077/5400 [04:47<03:18, 11.71it/s, est. speed input: 1514.51 toks/s, output: 11478.79 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3079/5400 [04:48<05:20,  7.23it/s, est. speed input: 1511.75 toks/s, output: 11456.24 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3081/5400 [04:49<06:38,  5.83it/s, est. speed input: 1509.89 toks/s, output: 11437.24 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3082/5400 [04:49<07:40,  5.04it/s, est. speed input: 1508.55 toks/s, output: 11424.67 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3084/5400 [04:49<07:49,  4.93it/s, est. speed input: 1507.24 toks/s, output: 11420.01 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3085/5400 [04:50<07:37,  5.06it/s, est. speed input: 1506.75 toks/s, output: 11419.55 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3087/5400 [04:50<06:29,  5.93it/s, est. speed input: 1506.32 toks/s, output: 11423.34 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3094/5400 [04:50<02:49, 13.57it/s, est. speed input: 1508.50 toks/s, output: 11456.82 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3099/5400 [04:50<02:07, 18.06it/s, est. speed input: 1508.98 toks/s, output: 11504.44 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3103/5400 [04:50<01:55, 19.86it/s, est. speed input: 1510.69 toks/s, output: 11524.44 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3111/5400 [04:51<03:22, 11.32it/s, est. speed input: 1511.79 toks/s, output: 11510.56 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3115/5400 [04:53<07:01,  5.42it/s, est. speed input: 1503.67 toks/s, output: 11453.25 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3117/5400 [04:53<07:00,  5.42it/s, est. speed input: 1502.18 toks/s, output: 11450.52 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3119/5400 [04:54<06:12,  6.13it/s, est. speed input: 1501.90 toks/s, output: 11457.01 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3125/5400 [04:54<03:54,  9.69it/s, est. speed input: 1502.41 toks/s, output: 11467.61 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3128/5400 [04:54<04:23,  8.61it/s, est. speed input: 1501.01 toks/s, output: 11467.48 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3132/5400 [04:55<04:19,  8.74it/s, est. speed input: 1499.49 toks/s, output: 11483.80 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3134/5400 [04:55<04:04,  9.27it/s, est. speed input: 1499.19 toks/s, output: 11482.44 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3137/5400 [04:55<03:24, 11.07it/s, est. speed input: 1499.23 toks/s, output: 11484.16 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3139/5400 [04:55<03:05, 12.16it/s, est. speed input: 1499.51 toks/s, output: 11500.90 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3141/5400 [04:57<10:20,  3.64it/s, est. speed input: 1490.78 toks/s, output: 11435.26 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3143/5400 [04:57<10:08,  3.71it/s, est. speed input: 1488.63 toks/s, output: 11436.38 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3146/5400 [04:58<07:57,  4.72it/s, est. speed input: 1487.66 toks/s, output: 11455.37 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3150/5400 [04:58<05:14,  7.15it/s, est. speed input: 1487.92 toks/s, output: 11476.81 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3152/5400 [04:58<05:23,  6.95it/s, est. speed input: 1486.81 toks/s, output: 11478.83 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3154/5400 [04:58<05:19,  7.02it/s, est. speed input: 1486.05 toks/s, output: 11474.83 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3157/5400 [04:59<04:16,  8.74it/s, est. speed input: 1486.05 toks/s, output: 11478.44 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3161/5400 [04:59<03:15, 11.48it/s, est. speed input: 1486.35 toks/s, output: 11485.33 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3163/5400 [04:59<03:45,  9.94it/s, est. speed input: 1485.52 toks/s, output: 11479.80 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3165/5400 [05:00<07:49,  4.76it/s, est. speed input: 1480.74 toks/s, output: 11440.64 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3166/5400 [05:00<07:32,  4.94it/s, est. speed input: 1480.28 toks/s, output: 11437.76 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3175/5400 [05:00<02:54, 12.77it/s, est. speed input: 1482.81 toks/s, output: 11481.43 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3182/5400 [05:01<01:55, 19.22it/s, est. speed input: 1484.80 toks/s, output: 11500.25 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3190/5400 [05:01<01:25, 25.76it/s, est. speed input: 1486.30 toks/s, output: 11562.57 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3195/5400 [05:01<01:36, 22.84it/s, est. speed input: 1487.64 toks/s, output: 11574.34 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3200/5400 [05:01<01:26, 25.35it/s, est. speed input: 1488.36 toks/s, output: 11603.14 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3204/5400 [05:02<01:55, 19.03it/s, est. speed input: 1487.96 toks/s, output: 11612.86 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3207/5400 [05:02<02:08, 17.08it/s, est. speed input: 1487.51 toks/s, output: 11626.01 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3212/5400 [05:02<02:45, 13.23it/s, est. speed input: 1486.04 toks/s, output: 11647.66 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3215/5400 [05:03<02:32, 14.33it/s, est. speed input: 1486.05 toks/s, output: 11672.40 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3219/5400 [05:03<02:03, 17.64it/s, est. speed input: 1487.14 toks/s, output: 11686.85 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3222/5400 [05:03<03:06, 11.70it/s, est. speed input: 1485.85 toks/s, output: 11680.08 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3224/5400 [05:04<04:48,  7.54it/s, est. speed input: 1483.20 toks/s, output: 11658.41 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3226/5400 [05:05<08:09,  4.44it/s, est. speed input: 1478.66 toks/s, output: 11622.07 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3228/5400 [05:06<08:33,  4.23it/s, est. speed input: 1477.55 toks/s, output: 11611.28 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3229/5400 [05:06<11:14,  3.22it/s, est. speed input: 1474.16 toks/s, output: 11584.62 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3231/5400 [05:06<08:57,  4.04it/s, est. speed input: 1473.83 toks/s, output: 11581.78 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3233/5400 [05:07<08:05,  4.47it/s, est. speed input: 1472.78 toks/s, output: 11574.32 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3236/5400 [05:07<05:49,  6.19it/s, est. speed input: 1472.44 toks/s, output: 11597.31 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3242/5400 [05:07<03:11, 11.27it/s, est. speed input: 1473.15 toks/s, output: 11626.32 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3249/5400 [05:07<01:58, 18.14it/s, est. speed input: 1475.02 toks/s, output: 11656.83 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3253/5400 [05:08<02:17, 15.65it/s, est. speed input: 1474.43 toks/s, output: 11657.64 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3258/5400 [05:08<02:02, 17.45it/s, est. speed input: 1474.74 toks/s, output: 11662.23 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3261/5400 [05:08<02:54, 12.24it/s, est. speed input: 1473.27 toks/s, output: 11653.94 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3263/5400 [05:08<02:50, 12.54it/s, est. speed input: 1473.22 toks/s, output: 11656.09 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3266/5400 [05:09<02:27, 14.43it/s, est. speed input: 1473.66 toks/s, output: 11654.35 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3268/5400 [05:09<02:22, 14.92it/s, est. speed input: 1473.86 toks/s, output: 11653.47 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3271/5400 [05:09<02:17, 15.52it/s, est. speed input: 1474.44 toks/s, output: 11654.65 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3273/5400 [05:09<02:17, 15.44it/s, est. speed input: 1474.50 toks/s, output: 11651.61 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3275/5400 [05:09<03:00, 11.75it/s, est. speed input: 1474.10 toks/s, output: 11646.21 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3277/5400 [05:10<04:18,  8.20it/s, est. speed input: 1472.62 toks/s, output: 11631.06 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3279/5400 [05:11<07:05,  4.99it/s, est. speed input: 1469.55 toks/s, output: 11605.50 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3281/5400 [05:11<05:38,  6.25it/s, est. speed input: 1469.63 toks/s, output: 11605.34 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3283/5400 [05:11<04:38,  7.61it/s, est. speed input: 1469.81 toks/s, output: 11605.02 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3287/5400 [05:11<03:11, 11.05it/s, est. speed input: 1470.24 toks/s, output: 11606.98 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3289/5400 [05:11<03:00, 11.69it/s, est. speed input: 1470.19 toks/s, output: 11613.79 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3294/5400 [05:11<02:08, 16.38it/s, est. speed input: 1471.00 toks/s, output: 11633.98 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3297/5400 [05:11<02:08, 16.36it/s, est. speed input: 1470.96 toks/s, output: 11640.08 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3299/5400 [05:12<02:24, 14.49it/s, est. speed input: 1470.80 toks/s, output: 11636.52 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3305/5400 [05:12<01:32, 22.56it/s, est. speed input: 1472.29 toks/s, output: 11642.89 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3308/5400 [05:12<01:56, 17.93it/s, est. speed input: 1471.89 toks/s, output: 11639.81 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3311/5400 [05:13<05:45,  6.05it/s, est. speed input: 1466.12 toks/s, output: 11600.85 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3314/5400 [05:14<04:59,  6.95it/s, est. speed input: 1465.91 toks/s, output: 11604.30 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3316/5400 [05:14<04:37,  7.51it/s, est. speed input: 1465.56 toks/s, output: 11605.06 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3319/5400 [05:14<04:20,  7.97it/s, est. speed input: 1465.29 toks/s, output: 11608.83 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3322/5400 [05:14<03:59,  8.68it/s, est. speed input: 1465.69 toks/s, output: 11614.69 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3324/5400 [05:15<03:37,  9.52it/s, est. speed input: 1465.44 toks/s, output: 11629.04 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3326/5400 [05:15<03:14, 10.64it/s, est. speed input: 1465.28 toks/s, output: 11644.11 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3328/5400 [05:15<03:16, 10.54it/s, est. speed input: 1465.01 toks/s, output: 11642.94 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3333/5400 [05:15<02:36, 13.23it/s, est. speed input: 1464.76 toks/s, output: 11647.56 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3338/5400 [05:15<01:53, 18.10it/s, est. speed input: 1465.88 toks/s, output: 11669.09 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3342/5400 [05:16<02:20, 14.66it/s, est. speed input: 1465.84 toks/s, output: 11664.00 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3344/5400 [05:17<05:38,  6.08it/s, est. speed input: 1461.63 toks/s, output: 11631.33 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3346/5400 [05:18<07:33,  4.53it/s, est. speed input: 1458.26 toks/s, output: 11611.83 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3353/5400 [05:18<04:06,  8.31it/s, est. speed input: 1459.42 toks/s, output: 11625.55 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3357/5400 [05:19<05:03,  6.74it/s, est. speed input: 1456.46 toks/s, output: 11614.93 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3362/5400 [05:19<03:32,  9.60it/s, est. speed input: 1457.05 toks/s, output: 11659.38 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3366/5400 [05:19<02:57, 11.45it/s, est. speed input: 1457.50 toks/s, output: 11674.43 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3373/5400 [05:19<02:32, 13.30it/s, est. speed input: 1458.39 toks/s, output: 11669.20 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3376/5400 [05:20<02:25, 13.87it/s, est. speed input: 1458.51 toks/s, output: 11669.39 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3379/5400 [05:20<02:11, 15.40it/s, est. speed input: 1459.02 toks/s, output: 11670.97 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3383/5400 [05:20<02:18, 14.59it/s, est. speed input: 1458.88 toks/s, output: 11667.73 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3385/5400 [05:22<07:28,  4.49it/s, est. speed input: 1450.81 toks/s, output: 11603.07 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3387/5400 [05:22<07:32,  4.45it/s, est. speed input: 1449.22 toks/s, output: 11595.41 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3389/5400 [05:23<07:01,  4.77it/s, est. speed input: 1448.30 toks/s, output: 11596.73 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3393/5400 [05:23<04:59,  6.69it/s, est. speed input: 1448.21 toks/s, output: 11601.97 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3395/5400 [05:24<06:32,  5.11it/s, est. speed input: 1445.36 toks/s, output: 11577.85 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3398/5400 [05:24<06:28,  5.16it/s, est. speed input: 1443.48 toks/s, output: 11561.39 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3399/5400 [05:24<06:18,  5.28it/s, est. speed input: 1443.03 toks/s, output: 11558.50 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3403/5400 [05:25<04:15,  7.81it/s, est. speed input: 1443.30 toks/s, output: 11560.11 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3409/5400 [05:25<02:31, 13.11it/s, est. speed input: 1444.00 toks/s, output: 11567.53 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3412/5400 [05:25<04:00,  8.27it/s, est. speed input: 1441.69 toks/s, output: 11545.43 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3414/5400 [05:26<03:32,  9.34it/s, est. speed input: 1441.94 toks/s, output: 11544.99 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3416/5400 [05:26<03:50,  8.59it/s, est. speed input: 1441.36 toks/s, output: 11538.46 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3419/5400 [05:26<03:24,  9.67it/s, est. speed input: 1441.70 toks/s, output: 11538.29 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3421/5400 [05:26<03:38,  9.07it/s, est. speed input: 1441.34 toks/s, output: 11533.95 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3423/5400 [05:27<03:37,  9.09it/s, est. speed input: 1440.81 toks/s, output: 11530.71 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3426/5400 [05:27<02:50, 11.60it/s, est. speed input: 1440.99 toks/s, output: 11534.67 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3429/5400 [05:27<02:24, 13.63it/s, est. speed input: 1441.18 toks/s, output: 11536.45 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3435/5400 [05:27<01:56, 16.89it/s, est. speed input: 1443.12 toks/s, output: 11547.85 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3437/5400 [05:27<02:11, 14.94it/s, est. speed input: 1443.17 toks/s, output: 11546.31 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3439/5400 [05:28<02:41, 12.17it/s, est. speed input: 1443.00 toks/s, output: 11542.60 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3441/5400 [05:28<04:40,  6.98it/s, est. speed input: 1440.78 toks/s, output: 11523.48 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3443/5400 [05:28<04:13,  7.73it/s, est. speed input: 1440.70 toks/s, output: 11528.93 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3445/5400 [05:29<04:12,  7.76it/s, est. speed input: 1440.01 toks/s, output: 11526.29 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3446/5400 [05:29<05:17,  6.15it/s, est. speed input: 1438.90 toks/s, output: 11517.49 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3448/5400 [05:29<04:52,  6.67it/s, est. speed input: 1438.38 toks/s, output: 11514.38 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3450/5400 [05:30<08:37,  3.77it/s, est. speed input: 1434.36 toks/s, output: 11483.48 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3453/5400 [05:30<05:39,  5.74it/s, est. speed input: 1435.05 toks/s, output: 11486.23 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3460/5400 [05:31<03:08, 10.29it/s, est. speed input: 1436.62 toks/s, output: 11493.55 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3466/5400 [05:31<02:10, 14.78it/s, est. speed input: 1437.72 toks/s, output: 11508.15 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3469/5400 [05:32<03:12, 10.02it/s, est. speed input: 1435.77 toks/s, output: 11491.91 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3471/5400 [05:32<04:06,  7.82it/s, est. speed input: 1434.13 toks/s, output: 11481.43 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3473/5400 [05:33<07:13,  4.44it/s, est. speed input: 1429.88 toks/s, output: 11447.89 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3475/5400 [05:33<06:15,  5.13it/s, est. speed input: 1430.07 toks/s, output: 11450.12 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3477/5400 [05:34<07:43,  4.15it/s, est. speed input: 1427.96 toks/s, output: 11431.10 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3478/5400 [05:34<07:04,  4.53it/s, est. speed input: 1427.70 toks/s, output: 11430.46 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3481/5400 [05:34<04:56,  6.46it/s, est. speed input: 1428.00 toks/s, output: 11447.47 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3483/5400 [05:35<04:14,  7.52it/s, est. speed input: 1427.74 toks/s, output: 11454.50 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3485/5400 [05:35<03:32,  9.02it/s, est. speed input: 1427.66 toks/s, output: 11456.68 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3487/5400 [05:35<03:16,  9.74it/s, est. speed input: 1427.34 toks/s, output: 11456.92 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3489/5400 [05:35<03:11, 10.00it/s, est. speed input: 1426.91 toks/s, output: 11462.61 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3491/5400 [05:35<03:54,  8.13it/s, est. speed input: 1425.98 toks/s, output: 11454.60 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3498/5400 [05:36<01:59, 15.93it/s, est. speed input: 1427.27 toks/s, output: 11489.83 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3501/5400 [05:36<01:49, 17.42it/s, est. speed input: 1427.75 toks/s, output: 11490.41 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3506/5400 [05:36<01:28, 21.43it/s, est. speed input: 1428.57 toks/s, output: 11501.84 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3509/5400 [05:36<02:21, 13.36it/s, est. speed input: 1427.18 toks/s, output: 11499.44 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3511/5400 [05:37<04:07,  7.62it/s, est. speed input: 1424.51 toks/s, output: 11478.75 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3513/5400 [05:37<03:58,  7.90it/s, est. speed input: 1424.07 toks/s, output: 11489.52 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3515/5400 [05:37<03:47,  8.27it/s, est. speed input: 1423.82 toks/s, output: 11489.88 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3519/5400 [05:38<03:46,  8.32it/s, est. speed input: 1422.72 toks/s, output: 11488.66 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3522/5400 [05:38<02:57, 10.56it/s, est. speed input: 1423.03 toks/s, output: 11508.66 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3526/5400 [05:38<02:11, 14.30it/s, est. speed input: 1423.52 toks/s, output: 11537.72 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3529/5400 [05:39<02:54, 10.71it/s, est. speed input: 1422.20 toks/s, output: 11542.14 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3531/5400 [05:39<03:01, 10.27it/s, est. speed input: 1421.73 toks/s, output: 11538.61 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3533/5400 [05:39<03:55,  7.92it/s, est. speed input: 1420.50 toks/s, output: 11535.46 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3535/5400 [05:40<03:44,  8.32it/s, est. speed input: 1420.44 toks/s, output: 11543.25 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3539/5400 [05:40<02:50, 10.93it/s, est. speed input: 1421.18 toks/s, output: 11565.67 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3544/5400 [05:40<01:57, 15.78it/s, est. speed input: 1422.44 toks/s, output: 11593.64 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3547/5400 [05:41<03:27,  8.94it/s, est. speed input: 1420.38 toks/s, output: 11595.74 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3551/5400 [05:41<02:48, 11.00it/s, est. speed input: 1420.24 toks/s, output: 11624.95 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3555/5400 [05:41<02:17, 13.41it/s, est. speed input: 1420.29 toks/s, output: 11648.56 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3558/5400 [05:42<03:30,  8.76it/s, est. speed input: 1418.07 toks/s, output: 11631.71 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3560/5400 [05:42<03:28,  8.84it/s, est. speed input: 1417.58 toks/s, output: 11628.61 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3564/5400 [05:42<02:33, 11.98it/s, est. speed input: 1418.35 toks/s, output: 11631.22 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3566/5400 [05:42<02:21, 12.94it/s, est. speed input: 1418.51 toks/s, output: 11638.14 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3568/5400 [05:42<02:14, 13.62it/s, est. speed input: 1418.47 toks/s, output: 11651.98 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3570/5400 [05:42<02:21, 12.90it/s, est. speed input: 1418.18 toks/s, output: 11663.76 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3573/5400 [05:43<02:02, 14.87it/s, est. speed input: 1418.28 toks/s, output: 11685.76 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3576/5400 [05:43<01:54, 16.00it/s, est. speed input: 1418.66 toks/s, output: 11685.36 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3578/5400 [05:43<02:56, 10.29it/s, est. speed input: 1417.64 toks/s, output: 11677.64 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3580/5400 [05:44<03:48,  7.95it/s, est. speed input: 1416.58 toks/s, output: 11666.82 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3582/5400 [05:44<04:08,  7.32it/s, est. speed input: 1415.74 toks/s, output: 11666.31 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3584/5400 [05:44<03:25,  8.84it/s, est. speed input: 1415.91 toks/s, output: 11673.30 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3587/5400 [05:44<02:49, 10.68it/s, est. speed input: 1415.84 toks/s, output: 11693.88 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3591/5400 [05:44<02:08, 14.06it/s, est. speed input: 1416.21 toks/s, output: 11702.61 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3595/5400 [05:45<02:04, 14.52it/s, est. speed input: 1416.19 toks/s, output: 11714.30 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3605/5400 [05:45<01:41, 17.63it/s, est. speed input: 1417.25 toks/s, output: 11726.77 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3607/5400 [05:45<01:55, 15.55it/s, est. speed input: 1417.16 toks/s, output: 11722.56 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3609/5400 [05:46<02:29, 12.00it/s, est. speed input: 1416.23 toks/s, output: 11720.79 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3613/5400 [05:46<01:55, 15.43it/s, est. speed input: 1417.34 toks/s, output: 11732.26 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3617/5400 [05:46<02:22, 12.51it/s, est. speed input: 1417.20 toks/s, output: 11733.03 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3620/5400 [05:46<02:07, 13.92it/s, est. speed input: 1417.74 toks/s, output: 11741.35 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3622/5400 [05:46<02:07, 13.99it/s, est. speed input: 1417.87 toks/s, output: 11740.22 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3624/5400 [05:47<02:06, 14.07it/s, est. speed input: 1418.16 toks/s, output: 11743.52 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3626/5400 [05:47<02:34, 11.49it/s, est. speed input: 1417.55 toks/s, output: 11744.59 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3630/5400 [05:47<02:38, 11.15it/s, est. speed input: 1417.10 toks/s, output: 11737.76 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3633/5400 [05:48<04:15,  6.92it/s, est. speed input: 1414.52 toks/s, output: 11721.82 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3640/5400 [05:48<02:19, 12.60it/s, est. speed input: 1415.54 toks/s, output: 11772.47 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3643/5400 [05:48<02:11, 13.41it/s, est. speed input: 1415.85 toks/s, output: 11771.56 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3647/5400 [05:48<01:46, 16.46it/s, est. speed input: 1416.20 toks/s, output: 11779.92 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3650/5400 [05:50<05:22,  5.42it/s, est. speed input: 1410.10 toks/s, output: 11749.96 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3658/5400 [05:51<03:38,  7.98it/s, est. speed input: 1410.53 toks/s, output: 11796.65 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3660/5400 [05:51<03:33,  8.15it/s, est. speed input: 1410.29 toks/s, output: 11793.31 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3668/5400 [05:51<02:28, 11.66it/s, est. speed input: 1411.48 toks/s, output: 11797.23 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3670/5400 [05:51<02:29, 11.60it/s, est. speed input: 1411.39 toks/s, output: 11795.16 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3674/5400 [05:52<03:25,  8.40it/s, est. speed input: 1409.36 toks/s, output: 11776.30 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3676/5400 [05:53<03:47,  7.57it/s, est. speed input: 1408.25 toks/s, output: 11780.64 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3678/5400 [05:53<04:01,  7.14it/s, est. speed input: 1407.37 toks/s, output: 11780.90 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3679/5400 [05:53<03:53,  7.37it/s, est. speed input: 1407.26 toks/s, output: 11781.27 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3683/5400 [05:53<02:55,  9.76it/s, est. speed input: 1407.62 toks/s, output: 11787.96 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3685/5400 [05:53<02:39, 10.73it/s, est. speed input: 1407.79 toks/s, output: 11788.70 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3690/5400 [05:53<01:44, 16.42it/s, est. speed input: 1408.89 toks/s, output: 11796.30 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3693/5400 [05:54<01:49, 15.59it/s, est. speed input: 1408.74 toks/s, output: 11794.43 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3696/5400 [05:54<02:59,  9.51it/s, est. speed input: 1407.11 toks/s, output: 11780.10 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3699/5400 [05:54<02:30, 11.33it/s, est. speed input: 1407.42 toks/s, output: 11782.02 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3701/5400 [05:55<02:37, 10.79it/s, est. speed input: 1406.95 toks/s, output: 11777.42 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3703/5400 [05:55<02:24, 11.73it/s, est. speed input: 1406.87 toks/s, output: 11775.68 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3705/5400 [05:55<02:35, 10.91it/s, est. speed input: 1406.39 toks/s, output: 11770.82 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3707/5400 [05:55<02:29, 11.31it/s, est. speed input: 1406.62 toks/s, output: 11775.02 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3709/5400 [05:56<03:15,  8.65it/s, est. speed input: 1405.72 toks/s, output: 11768.18 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3711/5400 [05:56<04:49,  5.84it/s, est. speed input: 1403.73 toks/s, output: 11751.45 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3712/5400 [05:56<04:33,  6.18it/s, est. speed input: 1403.53 toks/s, output: 11749.75 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3715/5400 [05:56<03:02,  9.22it/s, est. speed input: 1404.07 toks/s, output: 11759.03 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3719/5400 [05:57<02:18, 12.12it/s, est. speed input: 1405.13 toks/s, output: 11786.89 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3721/5400 [05:57<02:57,  9.46it/s, est. speed input: 1404.63 toks/s, output: 11792.25 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3725/5400 [05:57<02:08, 12.99it/s, est. speed input: 1405.34 toks/s, output: 11806.43 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3727/5400 [05:58<03:39,  7.62it/s, est. speed input: 1403.70 toks/s, output: 11795.55 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3729/5400 [05:59<06:26,  4.32it/s, est. speed input: 1399.89 toks/s, output: 11763.74 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3731/5400 [05:59<05:11,  5.36it/s, est. speed input: 1400.01 toks/s, output: 11764.24 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3738/5400 [06:00<04:32,  6.10it/s, est. speed input: 1398.30 toks/s, output: 11751.62 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3740/5400 [06:00<04:01,  6.87it/s, est. speed input: 1398.51 toks/s, output: 11751.46 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3742/5400 [06:00<03:38,  7.58it/s, est. speed input: 1398.60 toks/s, output: 11750.32 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3744/5400 [06:00<03:18,  8.35it/s, est. speed input: 1398.61 toks/s, output: 11750.56 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3746/5400 [06:01<03:55,  7.01it/s, est. speed input: 1397.44 toks/s, output: 11742.20 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3750/5400 [06:01<03:28,  7.92it/s, est. speed input: 1396.62 toks/s, output: 11737.20 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3751/5400 [06:01<03:56,  6.98it/s, est. speed input: 1395.82 toks/s, output: 11730.94 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3753/5400 [06:02<03:16,  8.39it/s, est. speed input: 1395.85 toks/s, output: 11732.27 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3755/5400 [06:02<02:55,  9.39it/s, est. speed input: 1395.79 toks/s, output: 11732.95 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3761/5400 [06:02<01:52, 14.61it/s, est. speed input: 1396.53 toks/s, output: 11741.85 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3763/5400 [06:03<03:14,  8.41it/s, est. speed input: 1394.63 toks/s, output: 11726.94 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3765/5400 [06:03<02:57,  9.23it/s, est. speed input: 1394.64 toks/s, output: 11727.51 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3767/5400 [06:03<02:53,  9.42it/s, est. speed input: 1394.37 toks/s, output: 11724.81 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3769/5400 [06:03<02:47,  9.75it/s, est. speed input: 1394.17 toks/s, output: 11722.58 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3773/5400 [06:03<02:23, 11.33it/s, est. speed input: 1394.18 toks/s, output: 11721.05 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3775/5400 [06:04<02:37, 10.30it/s, est. speed input: 1393.88 toks/s, output: 11717.45 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3777/5400 [06:04<02:18, 11.69it/s, est. speed input: 1393.95 toks/s, output: 11718.53 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3779/5400 [06:04<02:40, 10.08it/s, est. speed input: 1393.47 toks/s, output: 11713.37 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3785/5400 [06:04<01:30, 17.84it/s, est. speed input: 1395.13 toks/s, output: 11733.81 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3791/5400 [06:04<01:05, 24.52it/s, est. speed input: 1396.75 toks/s, output: 11760.40 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3798/5400 [06:04<01:00, 26.39it/s, est. speed input: 1398.15 toks/s, output: 11765.37 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3802/5400 [06:05<00:57, 27.66it/s, est. speed input: 1398.73 toks/s, output: 11770.21 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3806/5400 [06:05<01:30, 17.66it/s, est. speed input: 1397.92 toks/s, output: 11763.96 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3811/5400 [06:05<01:25, 18.56it/s, est. speed input: 1398.33 toks/s, output: 11764.78 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3814/5400 [06:05<01:18, 20.20it/s, est. speed input: 1398.85 toks/s, output: 11773.32 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3818/5400 [06:05<01:09, 22.90it/s, est. speed input: 1399.52 toks/s, output: 11780.16 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3821/5400 [06:06<01:09, 22.61it/s, est. speed input: 1399.65 toks/s, output: 11780.68 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3826/5400 [06:06<00:56, 27.64it/s, est. speed input: 1400.46 toks/s, output: 11785.30 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3835/5400 [06:06<00:40, 38.41it/s, est. speed input: 1402.52 toks/s, output: 11803.45 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3840/5400 [06:06<00:44, 35.30it/s, est. speed input: 1403.08 toks/s, output: 11810.24 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3844/5400 [06:06<00:46, 33.14it/s, est. speed input: 1403.60 toks/s, output: 11814.13 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3848/5400 [06:07<01:16, 20.38it/s, est. speed input: 1403.05 toks/s, output: 11809.97 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3851/5400 [06:07<01:25, 18.05it/s, est. speed input: 1403.15 toks/s, output: 11807.97 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3854/5400 [06:07<02:22, 10.88it/s, est. speed input: 1401.43 toks/s, output: 11792.82 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3858/5400 [06:09<04:03,  6.34it/s, est. speed input: 1397.82 toks/s, output: 11766.17 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3864/5400 [06:09<02:56,  8.70it/s, est. speed input: 1398.29 toks/s, output: 11779.02 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3866/5400 [06:11<05:57,  4.29it/s, est. speed input: 1392.52 toks/s, output: 11731.32 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3872/5400 [06:11<03:42,  6.88it/s, est. speed input: 1393.88 toks/s, output: 11753.43 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3875/5400 [06:11<03:28,  7.31it/s, est. speed input: 1393.75 toks/s, output: 11748.74 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3878/5400 [06:12<03:31,  7.20it/s, est. speed input: 1393.19 toks/s, output: 11740.49 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3881/5400 [06:12<03:03,  8.26it/s, est. speed input: 1393.58 toks/s, output: 11744.45 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3883/5400 [06:12<02:54,  8.70it/s, est. speed input: 1393.66 toks/s, output: 11748.18 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3885/5400 [06:12<02:53,  8.72it/s, est. speed input: 1393.49 toks/s, output: 11757.49 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3887/5400 [06:12<02:41,  9.38it/s, est. speed input: 1393.74 toks/s, output: 11763.00 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3889/5400 [06:12<02:23, 10.54it/s, est. speed input: 1394.15 toks/s, output: 11769.78 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3893/5400 [06:13<01:45, 14.32it/s, est. speed input: 1396.08 toks/s, output: 11775.41 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3895/5400 [06:13<02:37,  9.56it/s, est. speed input: 1397.83 toks/s, output: 11763.32 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3897/5400 [06:13<02:24, 10.40it/s, est. speed input: 1397.74 toks/s, output: 11762.86 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3899/5400 [06:13<02:06, 11.89it/s, est. speed input: 1397.80 toks/s, output: 11763.69 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3901/5400 [06:13<02:00, 12.45it/s, est. speed input: 1397.91 toks/s, output: 11762.62 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3903/5400 [06:14<02:00, 12.45it/s, est. speed input: 1399.21 toks/s, output: 11759.53 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3905/5400 [06:14<02:13, 11.23it/s, est. speed input: 1398.81 toks/s, output: 11755.60 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3910/5400 [06:14<01:21, 18.39it/s, est. speed input: 1403.95 toks/s, output: 11759.37 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3913/5400 [06:14<01:23, 17.76it/s, est. speed input: 1405.38 toks/s, output: 11756.77 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3916/5400 [06:14<01:22, 18.08it/s, est. speed input: 1405.40 toks/s, output: 11755.04 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3919/5400 [06:15<02:23, 10.33it/s, est. speed input: 1403.64 toks/s, output: 11761.44 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3923/5400 [06:15<01:48, 13.60it/s, est. speed input: 1403.89 toks/s, output: 11787.73 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3927/5400 [06:15<01:30, 16.31it/s, est. speed input: 1404.09 toks/s, output: 11801.97 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3930/5400 [06:16<01:59, 12.29it/s, est. speed input: 1403.30 toks/s, output: 11793.10 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3932/5400 [06:16<02:59,  8.19it/s, est. speed input: 1401.69 toks/s, output: 11778.25 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3934/5400 [06:16<03:08,  7.77it/s, est. speed input: 1401.41 toks/s, output: 11772.49 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3939/5400 [06:17<02:23, 10.17it/s, est. speed input: 1402.38 toks/s, output: 11772.65 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3941/5400 [06:17<02:10, 11.20it/s, est. speed input: 1402.69 toks/s, output: 11774.00 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3946/5400 [06:17<01:36, 15.11it/s, est. speed input: 1403.52 toks/s, output: 11780.00 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3948/5400 [06:17<02:05, 11.54it/s, est. speed input: 1402.99 toks/s, output: 11773.71 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3950/5400 [06:18<03:23,  7.11it/s, est. speed input: 1401.01 toks/s, output: 11769.05 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3952/5400 [06:18<03:04,  7.84it/s, est. speed input: 1400.89 toks/s, output: 11779.97 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3955/5400 [06:18<02:49,  8.53it/s, est. speed input: 1400.75 toks/s, output: 11789.24 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3957/5400 [06:19<02:27,  9.80it/s, est. speed input: 1400.86 toks/s, output: 11802.05 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3959/5400 [06:19<02:13, 10.78it/s, est. speed input: 1400.89 toks/s, output: 11804.35 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3961/5400 [06:19<03:26,  6.98it/s, est. speed input: 1399.35 toks/s, output: 11793.34 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3967/5400 [06:19<01:49, 13.06it/s, est. speed input: 1399.96 toks/s, output: 11833.50 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3971/5400 [06:20<01:53, 12.56it/s, est. speed input: 1399.56 toks/s, output: 11849.22 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3973/5400 [06:21<04:59,  4.77it/s, est. speed input: 1395.90 toks/s, output: 11806.56 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3975/5400 [06:21<04:14,  5.61it/s, est. speed input: 1398.79 toks/s, output: 11805.85 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3977/5400 [06:21<03:38,  6.50it/s, est. speed input: 1401.62 toks/s, output: 11804.67 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3979/5400 [06:22<03:02,  7.79it/s, est. speed input: 1401.85 toks/s, output: 11802.85 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 3984/5400 [06:22<01:52, 12.54it/s, est. speed input: 1403.99 toks/s, output: 11806.09 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 3989/5400 [06:22<01:19, 17.85it/s, est. speed input: 1409.03 toks/s, output: 11810.31 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 3993/5400 [06:22<01:25, 16.46it/s, est. speed input: 1408.84 toks/s, output: 11805.36 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 3996/5400 [06:22<01:39, 14.07it/s, est. speed input: 1408.52 toks/s, output: 11798.44 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4000/5400 [06:23<01:24, 16.63it/s, est. speed input: 1409.02 toks/s, output: 11801.90 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4003/5400 [06:23<01:39, 14.06it/s, est. speed input: 1408.57 toks/s, output: 11802.43 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4005/5400 [06:23<02:00, 11.54it/s, est. speed input: 1407.91 toks/s, output: 11798.28 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4007/5400 [06:23<01:57, 11.89it/s, est. speed input: 1407.77 toks/s, output: 11804.13 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4009/5400 [06:23<01:46, 13.07it/s, est. speed input: 1407.79 toks/s, output: 11811.40 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4014/5400 [06:24<01:17, 17.97it/s, est. speed input: 1408.28 toks/s, output: 11841.04 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4017/5400 [06:24<01:14, 18.65it/s, est. speed input: 1408.37 toks/s, output: 11855.00 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4020/5400 [06:24<01:29, 15.41it/s, est. speed input: 1407.93 toks/s, output: 11852.10 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4027/5400 [06:24<00:56, 24.10it/s, est. speed input: 1409.03 toks/s, output: 11859.46 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4030/5400 [06:24<01:05, 21.02it/s, est. speed input: 1409.12 toks/s, output: 11856.53 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4033/5400 [06:25<01:12, 18.85it/s, est. speed input: 1409.12 toks/s, output: 11853.97 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4036/5400 [06:25<01:12, 18.86it/s, est. speed input: 1409.31 toks/s, output: 11855.84 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4039/5400 [06:25<02:22,  9.54it/s, est. speed input: 1407.43 toks/s, output: 11841.53 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4042/5400 [06:26<01:57, 11.52it/s, est. speed input: 1407.79 toks/s, output: 11840.04 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4044/5400 [06:26<02:47,  8.08it/s, est. speed input: 1409.19 toks/s, output: 11828.67 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4046/5400 [06:26<02:55,  7.71it/s, est. speed input: 1408.57 toks/s, output: 11823.05 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4050/5400 [06:27<02:06, 10.67it/s, est. speed input: 1408.78 toks/s, output: 11828.19 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4052/5400 [06:27<02:02, 10.98it/s, est. speed input: 1408.49 toks/s, output: 11833.83 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4054/5400 [06:27<01:57, 11.50it/s, est. speed input: 1408.25 toks/s, output: 11838.44 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4057/5400 [06:27<01:43, 12.99it/s, est. speed input: 1409.71 toks/s, output: 11840.07 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4059/5400 [06:27<01:38, 13.65it/s, est. speed input: 1409.76 toks/s, output: 11847.63 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4062/5400 [06:27<01:31, 14.56it/s, est. speed input: 1409.58 toks/s, output: 11852.49 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4064/5400 [06:27<01:35, 13.99it/s, est. speed input: 1409.24 toks/s, output: 11863.44 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4068/5400 [06:28<01:58, 11.28it/s, est. speed input: 1408.19 toks/s, output: 11867.85 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4075/5400 [06:28<01:23, 15.94it/s, est. speed input: 1409.96 toks/s, output: 11876.52 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4077/5400 [06:30<03:55,  5.62it/s, est. speed input: 1405.16 toks/s, output: 11845.16 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4079/5400 [06:30<03:42,  5.95it/s, est. speed input: 1404.63 toks/s, output: 11853.14 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4083/5400 [06:30<02:40,  8.22it/s, est. speed input: 1404.85 toks/s, output: 11879.85 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4085/5400 [06:30<02:44,  8.00it/s, est. speed input: 1404.38 toks/s, output: 11881.32 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4087/5400 [06:31<04:28,  4.89it/s, est. speed input: 1401.75 toks/s, output: 11857.44 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4089/5400 [06:32<04:18,  5.06it/s, est. speed input: 1401.28 toks/s, output: 11851.87 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4092/5400 [06:32<03:24,  6.39it/s, est. speed input: 1401.47 toks/s, output: 11852.72 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4096/5400 [06:32<02:17,  9.46it/s, est. speed input: 1401.85 toks/s, output: 11861.76 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4098/5400 [06:32<02:51,  7.59it/s, est. speed input: 1400.87 toks/s, output: 11852.73 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4100/5400 [06:33<02:35,  8.38it/s, est. speed input: 1401.19 toks/s, output: 11857.99 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4105/5400 [06:33<01:46, 12.19it/s, est. speed input: 1401.73 toks/s, output: 11875.81 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4108/5400 [06:33<01:33, 13.81it/s, est. speed input: 1401.98 toks/s, output: 11877.24 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4112/5400 [06:33<01:44, 12.34it/s, est. speed input: 1401.68 toks/s, output: 11870.51 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4114/5400 [06:33<01:36, 13.30it/s, est. speed input: 1401.74 toks/s, output: 11870.17 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4116/5400 [06:34<01:31, 14.10it/s, est. speed input: 1401.81 toks/s, output: 11875.95 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4119/5400 [06:34<01:16, 16.65it/s, est. speed input: 1402.11 toks/s, output: 11876.80 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4124/5400 [06:34<01:03, 20.02it/s, est. speed input: 1402.77 toks/s, output: 11878.42 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4127/5400 [06:34<01:03, 19.94it/s, est. speed input: 1402.87 toks/s, output: 11877.91 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4130/5400 [06:35<02:00, 10.56it/s, est. speed input: 1401.34 toks/s, output: 11882.33 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4132/5400 [06:36<05:26,  3.89it/s, est. speed input: 1395.70 toks/s, output: 11833.31 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4134/5400 [06:38<07:37,  2.77it/s, est. speed input: 1391.06 toks/s, output: 11794.59 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4136/5400 [06:38<06:00,  3.51it/s, est. speed input: 1391.05 toks/s, output: 11799.34 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4138/5400 [06:38<05:01,  4.19it/s, est. speed input: 1390.57 toks/s, output: 11795.62 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4140/5400 [06:39<05:06,  4.11it/s, est. speed input: 1389.05 toks/s, output: 11783.33 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4141/5400 [06:39<06:03,  3.46it/s, est. speed input: 1387.39 toks/s, output: 11771.89 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4143/5400 [06:39<04:59,  4.20it/s, est. speed input: 1387.08 toks/s, output: 11771.47 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4144/5400 [06:40<05:26,  3.85it/s, est. speed input: 1386.00 toks/s, output: 11765.05 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4145/5400 [06:40<05:03,  4.14it/s, est. speed input: 1385.59 toks/s, output: 11761.70 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4146/5400 [06:40<04:49,  4.33it/s, est. speed input: 1385.14 toks/s, output: 11759.42 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4148/5400 [06:40<03:43,  5.61it/s, est. speed input: 1385.00 toks/s, output: 11760.21 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4149/5400 [06:40<03:26,  6.05it/s, est. speed input: 1384.77 toks/s, output: 11758.45 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4151/5400 [06:41<03:03,  6.80it/s, est. speed input: 1384.38 toks/s, output: 11758.98 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4156/5400 [06:41<01:34, 13.17it/s, est. speed input: 1384.83 toks/s, output: 11764.06 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4158/5400 [06:41<01:47, 11.53it/s, est. speed input: 1384.44 toks/s, output: 11764.02 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4160/5400 [06:43<05:53,  3.51it/s, est. speed input: 1379.25 toks/s, output: 11722.38 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4163/5400 [06:43<04:09,  4.96it/s, est. speed input: 1379.58 toks/s, output: 11724.51 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4167/5400 [06:43<02:47,  7.35it/s, est. speed input: 1380.20 toks/s, output: 11728.84 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4169/5400 [06:44<03:53,  5.27it/s, est. speed input: 1378.05 toks/s, output: 11719.28 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4173/5400 [06:44<02:34,  7.94it/s, est. speed input: 1379.19 toks/s, output: 11723.33 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4176/5400 [06:44<02:03,  9.94it/s, est. speed input: 1379.72 toks/s, output: 11723.51 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4184/5400 [06:44<01:06, 18.36it/s, est. speed input: 1382.26 toks/s, output: 11755.73 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4189/5400 [06:44<00:52, 22.95it/s, est. speed input: 1383.27 toks/s, output: 11768.84 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4194/5400 [06:46<02:44,  7.32it/s, est. speed input: 1378.66 toks/s, output: 11736.44 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4197/5400 [06:46<02:19,  8.61it/s, est. speed input: 1379.08 toks/s, output: 11737.79 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4201/5400 [06:47<02:20,  8.55it/s, est. speed input: 1378.42 toks/s, output: 11728.56 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4204/5400 [06:47<01:56, 10.25it/s, est. speed input: 1378.84 toks/s, output: 11741.67 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4207/5400 [06:47<02:22,  8.36it/s, est. speed input: 1377.73 toks/s, output: 11738.11 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4209/5400 [06:47<02:22,  8.36it/s, est. speed input: 1377.55 toks/s, output: 11734.41 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4211/5400 [06:48<02:14,  8.83it/s, est. speed input: 1377.46 toks/s, output: 11731.91 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4213/5400 [06:48<02:08,  9.27it/s, est. speed input: 1377.28 toks/s, output: 11729.10 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4215/5400 [06:48<02:29,  7.92it/s, est. speed input: 1376.59 toks/s, output: 11721.73 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4217/5400 [06:48<02:21,  8.38it/s, est. speed input: 1376.35 toks/s, output: 11719.21 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4219/5400 [06:49<02:24,  8.18it/s, est. speed input: 1376.07 toks/s, output: 11716.61 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4220/5400 [06:49<02:35,  7.59it/s, est. speed input: 1375.68 toks/s, output: 11712.84 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4221/5400 [06:49<02:54,  6.75it/s, est. speed input: 1375.16 toks/s, output: 11707.98 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4222/5400 [06:49<03:16,  5.98it/s, est. speed input: 1374.58 toks/s, output: 11702.62 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4224/5400 [06:50<04:18,  4.55it/s, est. speed input: 1373.12 toks/s, output: 11694.68 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4229/5400 [06:50<02:04,  9.41it/s, est. speed input: 1373.96 toks/s, output: 11723.52 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4233/5400 [06:50<01:26, 13.49it/s, est. speed input: 1374.79 toks/s, output: 11739.70 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4236/5400 [06:51<03:44,  5.19it/s, est. speed input: 1370.66 toks/s, output: 11709.81 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4241/5400 [06:52<02:24,  8.01it/s, est. speed input: 1371.72 toks/s, output: 11719.78 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4244/5400 [06:52<02:10,  8.84it/s, est. speed input: 1371.63 toks/s, output: 11718.03 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4246/5400 [06:52<02:03,  9.38it/s, est. speed input: 1371.43 toks/s, output: 11716.27 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4248/5400 [06:52<02:10,  8.81it/s, est. speed input: 1370.85 toks/s, output: 11711.29 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4250/5400 [06:53<02:12,  8.70it/s, est. speed input: 1370.48 toks/s, output: 11708.38 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4255/5400 [06:53<01:42, 11.21it/s, est. speed input: 1370.80 toks/s, output: 11714.90 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4258/5400 [06:53<01:48, 10.48it/s, est. speed input: 1370.62 toks/s, output: 11718.06 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4260/5400 [06:53<01:44, 10.88it/s, est. speed input: 1370.73 toks/s, output: 11719.30 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4262/5400 [06:53<01:38, 11.54it/s, est. speed input: 1370.76 toks/s, output: 11721.48 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4264/5400 [06:55<04:12,  4.49it/s, est. speed input: 1367.16 toks/s, output: 11690.92 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4266/5400 [06:55<04:08,  4.57it/s, est. speed input: 1366.50 toks/s, output: 11681.11 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4269/5400 [06:55<03:21,  5.62it/s, est. speed input: 1366.61 toks/s, output: 11675.34 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4271/5400 [06:56<02:50,  6.63it/s, est. speed input: 1366.67 toks/s, output: 11674.35 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4273/5400 [06:57<05:22,  3.50it/s, est. speed input: 1363.33 toks/s, output: 11641.85 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4274/5400 [06:57<05:06,  3.68it/s, est. speed input: 1363.06 toks/s, output: 11637.48 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4275/5400 [06:58<07:59,  2.35it/s, est. speed input: 1359.67 toks/s, output: 11611.31 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4278/5400 [06:58<04:55,  3.80it/s, est. speed input: 1360.02 toks/s, output: 11618.24 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4280/5400 [06:59<03:44,  4.98it/s, est. speed input: 1360.74 toks/s, output: 11620.40 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4282/5400 [06:59<04:41,  3.97it/s, est. speed input: 1358.97 toks/s, output: 11603.45 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4284/5400 [06:59<03:57,  4.70it/s, est. speed input: 1358.52 toks/s, output: 11600.75 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4285/5400 [07:00<03:43,  5.00it/s, est. speed input: 1358.48 toks/s, output: 11597.72 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4286/5400 [07:00<04:27,  4.17it/s, est. speed input: 1357.34 toks/s, output: 11587.96 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4295/5400 [07:00<01:44, 10.58it/s, est. speed input: 1357.92 toks/s, output: 11590.73 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4299/5400 [07:01<01:24, 13.10it/s, est. speed input: 1359.12 toks/s, output: 11594.47 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4301/5400 [07:01<01:18, 13.96it/s, est. speed input: 1359.59 toks/s, output: 11595.57 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4304/5400 [07:01<01:18, 13.89it/s, est. speed input: 1359.91 toks/s, output: 11597.34 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4307/5400 [07:02<03:07,  5.83it/s, est. speed input: 1356.84 toks/s, output: 11572.50 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4310/5400 [07:02<02:32,  7.17it/s, est. speed input: 1357.94 toks/s, output: 11578.20 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4312/5400 [07:03<02:30,  7.25it/s, est. speed input: 1357.54 toks/s, output: 11577.52 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4314/5400 [07:03<02:17,  7.88it/s, est. speed input: 1357.44 toks/s, output: 11580.56 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4316/5400 [07:03<01:58,  9.18it/s, est. speed input: 1357.78 toks/s, output: 11592.02 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4321/5400 [07:03<01:25, 12.66it/s, est. speed input: 1358.65 toks/s, output: 11616.58 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4323/5400 [07:03<01:46, 10.15it/s, est. speed input: 1358.31 toks/s, output: 11611.17 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4326/5400 [07:04<01:26, 12.36it/s, est. speed input: 1359.13 toks/s, output: 11613.91 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4328/5400 [07:04<01:19, 13.42it/s, est. speed input: 1359.46 toks/s, output: 11620.50 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4330/5400 [07:04<01:16, 13.95it/s, est. speed input: 1359.50 toks/s, output: 11625.97 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4333/5400 [07:04<01:04, 16.42it/s, est. speed input: 1359.74 toks/s, output: 11638.79 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4335/5400 [07:04<01:02, 16.99it/s, est. speed input: 1359.77 toks/s, output: 11650.37 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4337/5400 [07:04<01:28, 12.08it/s, est. speed input: 1359.41 toks/s, output: 11650.68 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4341/5400 [07:05<01:15, 14.07it/s, est. speed input: 1360.17 toks/s, output: 11655.81 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4344/5400 [07:05<01:04, 16.28it/s, est. speed input: 1360.52 toks/s, output: 11668.63 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4346/5400 [07:05<01:21, 12.94it/s, est. speed input: 1360.34 toks/s, output: 11664.81 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4348/5400 [07:05<01:37, 10.80it/s, est. speed input: 1359.75 toks/s, output: 11659.41 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4350/5400 [07:05<01:31, 11.48it/s, est. speed input: 1359.59 toks/s, output: 11657.64 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4352/5400 [07:06<01:35, 10.97it/s, est. speed input: 1359.24 toks/s, output: 11654.30 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4354/5400 [07:06<01:46,  9.83it/s, est. speed input: 1358.79 toks/s, output: 11649.37 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4356/5400 [07:07<04:12,  4.14it/s, est. speed input: 1355.85 toks/s, output: 11620.34 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4357/5400 [07:07<04:18,  4.04it/s, est. speed input: 1355.11 toks/s, output: 11619.97 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4358/5400 [07:08<04:40,  3.72it/s, est. speed input: 1354.12 toks/s, output: 11617.45 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4359/5400 [07:08<04:19,  4.00it/s, est. speed input: 1353.70 toks/s, output: 11619.73 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4367/5400 [07:08<01:31, 11.23it/s, est. speed input: 1354.82 toks/s, output: 11650.59 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4373/5400 [07:08<01:13, 14.04it/s, est. speed input: 1355.01 toks/s, output: 11671.81 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4375/5400 [07:09<01:23, 12.29it/s, est. speed input: 1354.61 toks/s, output: 11669.85 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4377/5400 [07:09<01:28, 11.59it/s, est. speed input: 1354.37 toks/s, output: 11673.84 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4379/5400 [07:09<01:27, 11.73it/s, est. speed input: 1354.29 toks/s, output: 11673.31 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4381/5400 [07:09<01:53,  8.97it/s, est. speed input: 1353.66 toks/s, output: 11671.80 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4386/5400 [07:09<01:10, 14.36it/s, est. speed input: 1354.41 toks/s, output: 11698.81 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4391/5400 [07:10<01:02, 16.27it/s, est. speed input: 1354.71 toks/s, output: 11715.83 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4394/5400 [07:10<01:09, 14.46it/s, est. speed input: 1355.77 toks/s, output: 11717.97 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4397/5400 [07:10<01:24, 11.85it/s, est. speed input: 1357.77 toks/s, output: 11723.20 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4399/5400 [07:11<02:51,  5.83it/s, est. speed input: 1355.16 toks/s, output: 11706.64 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4402/5400 [07:12<02:50,  5.84it/s, est. speed input: 1354.46 toks/s, output: 11703.90 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4404/5400 [07:12<02:50,  5.83it/s, est. speed input: 1353.90 toks/s, output: 11700.25 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4415/5400 [07:12<01:14, 13.27it/s, est. speed input: 1356.06 toks/s, output: 11733.13 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4418/5400 [07:13<01:56,  8.40it/s, est. speed input: 1354.17 toks/s, output: 11719.54 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4420/5400 [07:14<02:09,  7.57it/s, est. speed input: 1353.22 toks/s, output: 11710.67 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4422/5400 [07:14<01:58,  8.29it/s, est. speed input: 1353.44 toks/s, output: 11711.84 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4424/5400 [07:14<01:47,  9.08it/s, est. speed input: 1353.49 toks/s, output: 11711.53 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4427/5400 [07:14<01:38,  9.87it/s, est. speed input: 1353.25 toks/s, output: 11708.47 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4430/5400 [07:14<01:19, 12.13it/s, est. speed input: 1353.59 toks/s, output: 11709.74 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4432/5400 [07:15<01:21, 11.93it/s, est. speed input: 1353.45 toks/s, output: 11707.46 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4434/5400 [07:15<01:13, 13.17it/s, est. speed input: 1353.79 toks/s, output: 11709.84 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4436/5400 [07:15<01:46,  9.07it/s, est. speed input: 1352.99 toks/s, output: 11701.96 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4438/5400 [07:15<01:36, 10.02it/s, est. speed input: 1353.17 toks/s, output: 11704.32 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4440/5400 [07:15<01:28, 10.91it/s, est. speed input: 1353.09 toks/s, output: 11714.63 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4442/5400 [07:15<01:16, 12.50it/s, est. speed input: 1353.29 toks/s, output: 11714.60 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4446/5400 [07:16<01:04, 14.87it/s, est. speed input: 1353.56 toks/s, output: 11727.65 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4448/5400 [07:16<01:00, 15.74it/s, est. speed input: 1353.68 toks/s, output: 11733.25 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4455/5400 [07:16<00:39, 23.80it/s, est. speed input: 1354.80 toks/s, output: 11750.48 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4458/5400 [07:16<00:42, 22.26it/s, est. speed input: 1355.27 toks/s, output: 11767.26 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4461/5400 [07:16<00:41, 22.85it/s, est. speed input: 1355.77 toks/s, output: 11776.98 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4464/5400 [07:16<00:38, 24.42it/s, est. speed input: 1356.14 toks/s, output: 11776.72 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4471/5400 [07:17<00:34, 27.27it/s, est. speed input: 1356.97 toks/s, output: 11776.53 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4474/5400 [07:17<00:48, 19.19it/s, est. speed input: 1356.58 toks/s, output: 11770.66 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4477/5400 [07:18<01:31, 10.12it/s, est. speed input: 1355.90 toks/s, output: 11772.08 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4479/5400 [07:18<02:27,  6.25it/s, est. speed input: 1354.06 toks/s, output: 11752.50 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4483/5400 [07:19<01:57,  7.79it/s, est. speed input: 1354.76 toks/s, output: 11751.35 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4487/5400 [07:19<02:19,  6.53it/s, est. speed input: 1353.45 toks/s, output: 11741.62 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4491/5400 [07:20<01:47,  8.44it/s, est. speed input: 1353.68 toks/s, output: 11753.61 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4499/5400 [07:20<01:06, 13.57it/s, est. speed input: 1354.55 toks/s, output: 11779.73 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4503/5400 [07:20<01:15, 11.90it/s, est. speed input: 1353.81 toks/s, output: 11790.58 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4505/5400 [07:21<02:03,  7.24it/s, est. speed input: 1351.47 toks/s, output: 11781.27 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4507/5400 [07:21<02:02,  7.30it/s, est. speed input: 1351.05 toks/s, output: 11783.56 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4512/5400 [07:22<01:23, 10.57it/s, est. speed input: 1351.54 toks/s, output: 11805.29 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4515/5400 [07:22<01:32,  9.61it/s, est. speed input: 1351.03 toks/s, output: 11811.87 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4517/5400 [07:22<01:51,  7.91it/s, est. speed input: 1350.09 toks/s, output: 11809.58 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4520/5400 [07:23<01:35,  9.18it/s, est. speed input: 1350.29 toks/s, output: 11808.75 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4526/5400 [07:23<01:02, 13.94it/s, est. speed input: 1350.98 toks/s, output: 11808.86 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4529/5400 [07:23<01:08, 12.77it/s, est. speed input: 1350.70 toks/s, output: 11803.24 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4531/5400 [07:23<01:03, 13.67it/s, est. speed input: 1350.82 toks/s, output: 11802.08 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4537/5400 [07:24<01:07, 12.72it/s, est. speed input: 1350.49 toks/s, output: 11793.61 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4542/5400 [07:24<00:51, 16.69it/s, est. speed input: 1350.89 toks/s, output: 11796.59 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4545/5400 [07:24<00:47, 17.96it/s, est. speed input: 1351.39 toks/s, output: 11802.13 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4548/5400 [07:25<01:13, 11.62it/s, est. speed input: 1350.62 toks/s, output: 11804.43 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4552/5400 [07:25<00:58, 14.58it/s, est. speed input: 1351.51 toks/s, output: 11828.70 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4557/5400 [07:25<00:43, 19.53it/s, est. speed input: 1352.51 toks/s, output: 11860.44 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4560/5400 [07:25<00:42, 19.89it/s, est. speed input: 1352.75 toks/s, output: 11877.35 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4563/5400 [07:25<00:45, 18.35it/s, est. speed input: 1352.80 toks/s, output: 11887.08 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4569/5400 [07:25<00:47, 17.61it/s, est. speed input: 1353.05 toks/s, output: 11885.86 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4572/5400 [07:26<00:48, 16.92it/s, est. speed input: 1353.06 toks/s, output: 11884.37 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4575/5400 [07:26<00:52, 15.63it/s, est. speed input: 1352.98 toks/s, output: 11882.13 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4577/5400 [07:26<01:08, 11.94it/s, est. speed input: 1352.28 toks/s, output: 11882.53 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4580/5400 [07:26<00:56, 14.45it/s, est. speed input: 1352.47 toks/s, output: 11891.61 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4582/5400 [07:27<01:03, 12.87it/s, est. speed input: 1352.32 toks/s, output: 11895.29 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4584/5400 [07:27<01:05, 12.39it/s, est. speed input: 1352.13 toks/s, output: 11898.55 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4588/5400 [07:27<00:49, 16.53it/s, est. speed input: 1352.36 toks/s, output: 11922.77 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4591/5400 [07:27<00:50, 16.13it/s, est. speed input: 1352.40 toks/s, output: 11933.35 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4595/5400 [07:27<00:47, 16.94it/s, est. speed input: 1352.81 toks/s, output: 11934.16 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4597/5400 [07:27<00:50, 15.80it/s, est. speed input: 1352.85 toks/s, output: 11937.73 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4601/5400 [07:28<00:43, 18.40it/s, est. speed input: 1353.23 toks/s, output: 11937.39 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4603/5400 [07:28<00:52, 15.24it/s, est. speed input: 1352.97 toks/s, output: 11935.55 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4605/5400 [07:28<01:07, 11.85it/s, est. speed input: 1352.47 toks/s, output: 11931.90 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4608/5400 [07:29<01:30,  8.78it/s, est. speed input: 1351.67 toks/s, output: 11924.44 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4611/5400 [07:29<01:27,  9.01it/s, est. speed input: 1351.60 toks/s, output: 11921.53 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4613/5400 [07:29<01:28,  8.89it/s, est. speed input: 1351.39 toks/s, output: 11921.45 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4616/5400 [07:29<01:14, 10.52it/s, est. speed input: 1351.52 toks/s, output: 11923.15 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4618/5400 [07:29<01:07, 11.56it/s, est. speed input: 1351.53 toks/s, output: 11923.26 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4621/5400 [07:30<01:08, 11.30it/s, est. speed input: 1351.23 toks/s, output: 11923.07 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4625/5400 [07:30<01:01, 12.70it/s, est. speed input: 1351.16 toks/s, output: 11932.43 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4627/5400 [07:30<01:00, 12.72it/s, est. speed input: 1351.04 toks/s, output: 11941.92 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4634/5400 [07:30<00:35, 21.57it/s, est. speed input: 1352.13 toks/s, output: 11962.16 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4638/5400 [07:30<00:35, 21.27it/s, est. speed input: 1352.30 toks/s, output: 11973.78 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4641/5400 [07:31<00:37, 20.10it/s, est. speed input: 1352.32 toks/s, output: 11980.39 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4644/5400 [07:31<00:52, 14.27it/s, est. speed input: 1351.90 toks/s, output: 11980.22 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4648/5400 [07:31<00:56, 13.28it/s, est. speed input: 1351.88 toks/s, output: 11989.45 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4650/5400 [07:32<01:30,  8.31it/s, est. speed input: 1350.59 toks/s, output: 11977.70 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4652/5400 [07:32<01:44,  7.13it/s, est. speed input: 1349.85 toks/s, output: 11969.39 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4654/5400 [07:33<01:54,  6.52it/s, est. speed input: 1349.22 toks/s, output: 11968.31 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4662/5400 [07:33<00:56, 13.11it/s, est. speed input: 1351.46 toks/s, output: 11976.28 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4668/5400 [07:33<00:47, 15.54it/s, est. speed input: 1352.81 toks/s, output: 11980.66 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4671/5400 [07:33<00:43, 16.64it/s, est. speed input: 1353.36 toks/s, output: 11987.36 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4674/5400 [07:33<00:42, 17.17it/s, est. speed input: 1354.04 toks/s, output: 11995.07 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4677/5400 [07:34<00:53, 13.41it/s, est. speed input: 1354.25 toks/s, output: 11993.49 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4680/5400 [07:34<01:05, 11.02it/s, est. speed input: 1354.72 toks/s, output: 11989.46 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4685/5400 [07:34<00:47, 15.20it/s, est. speed input: 1357.41 toks/s, output: 11992.38 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4688/5400 [07:35<00:53, 13.41it/s, est. speed input: 1357.12 toks/s, output: 11987.26 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4690/5400 [07:35<01:03, 11.23it/s, est. speed input: 1356.91 toks/s, output: 11984.81 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4695/5400 [07:35<00:46, 15.20it/s, est. speed input: 1357.57 toks/s, output: 11987.30 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4698/5400 [07:35<00:47, 14.82it/s, est. speed input: 1357.62 toks/s, output: 11985.28 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4701/5400 [07:36<00:41, 16.70it/s, est. speed input: 1358.55 toks/s, output: 11987.68 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4704/5400 [07:36<00:41, 16.72it/s, est. speed input: 1360.01 toks/s, output: 11986.19 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4707/5400 [07:36<00:45, 15.35it/s, est. speed input: 1360.99 toks/s, output: 11985.62 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4713/5400 [07:36<00:41, 16.46it/s, est. speed input: 1361.75 toks/s, output: 11993.68 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4715/5400 [07:36<00:44, 15.29it/s, est. speed input: 1362.23 toks/s, output: 11997.02 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4721/5400 [07:37<00:30, 21.94it/s, est. speed input: 1364.79 toks/s, output: 12017.75 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4724/5400 [07:37<00:43, 15.58it/s, est. speed input: 1364.78 toks/s, output: 12012.59 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4730/5400 [07:37<00:33, 19.89it/s, est. speed input: 1367.80 toks/s, output: 12016.41 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4733/5400 [07:37<00:37, 17.66it/s, est. speed input: 1368.28 toks/s, output: 12015.70 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4736/5400 [07:38<00:47, 14.09it/s, est. speed input: 1368.35 toks/s, output: 12011.07 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4742/5400 [07:38<00:32, 20.23it/s, est. speed input: 1369.66 toks/s, output: 12014.30 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4748/5400 [07:38<00:32, 19.84it/s, est. speed input: 1373.39 toks/s, output: 12014.20 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4753/5400 [07:38<00:28, 22.98it/s, est. speed input: 1374.23 toks/s, output: 12015.68 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4756/5400 [07:38<00:29, 22.12it/s, est. speed input: 1374.73 toks/s, output: 12014.64 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4760/5400 [07:39<00:27, 23.58it/s, est. speed input: 1376.51 toks/s, output: 12015.81 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4766/5400 [07:39<00:27, 22.87it/s, est. speed input: 1378.61 toks/s, output: 12016.41 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4769/5400 [07:39<00:32, 19.18it/s, est. speed input: 1379.68 toks/s, output: 12015.96 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4772/5400 [07:39<00:30, 20.35it/s, est. speed input: 1381.51 toks/s, output: 12017.42 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4775/5400 [07:40<00:57, 10.80it/s, est. speed input: 1381.70 toks/s, output: 12004.31 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4778/5400 [07:40<00:52, 11.90it/s, est. speed input: 1383.37 toks/s, output: 12004.24 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4780/5400 [07:41<01:13,  8.44it/s, est. speed input: 1382.11 toks/s, output: 11993.36 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4783/5400 [07:41<00:59, 10.36it/s, est. speed input: 1382.13 toks/s, output: 11993.51 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4785/5400 [07:41<00:56, 10.82it/s, est. speed input: 1381.94 toks/s, output: 11991.90 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4787/5400 [07:42<01:33,  6.57it/s, est. speed input: 1380.27 toks/s, output: 11978.45 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4789/5400 [07:43<02:58,  3.43it/s, est. speed input: 1377.41 toks/s, output: 11946.32 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 4794/5400 [07:44<02:24,  4.19it/s, est. speed input: 1377.19 toks/s, output: 11933.07 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 4796/5400 [07:44<02:14,  4.47it/s, est. speed input: 1376.61 toks/s, output: 11929.17 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 4798/5400 [07:44<02:00,  5.00it/s, est. speed input: 1376.27 toks/s, output: 11925.93 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 4799/5400 [07:44<01:51,  5.37it/s, est. speed input: 1376.15 toks/s, output: 11924.80 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 4804/5400 [07:45<01:02,  9.58it/s, est. speed input: 1376.63 toks/s, output: 11949.57 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 4806/5400 [07:45<01:03,  9.32it/s, est. speed input: 1376.26 toks/s, output: 11956.75 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 4808/5400 [07:45<01:02,  9.52it/s, est. speed input: 1376.19 toks/s, output: 11961.10 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 4813/5400 [07:46<01:08,  8.61it/s, est. speed input: 1375.52 toks/s, output: 11953.95 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 4817/5400 [07:46<00:51, 11.40it/s, est. speed input: 1376.27 toks/s, output: 11955.02 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 4827/5400 [07:46<00:27, 20.90it/s, est. speed input: 1378.45 toks/s, output: 11961.73 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 4831/5400 [07:46<00:26, 21.86it/s, est. speed input: 1379.19 toks/s, output: 11962.94 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 4835/5400 [07:46<00:24, 23.34it/s, est. speed input: 1379.94 toks/s, output: 11964.98 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 4840/5400 [07:46<00:21, 25.55it/s, est. speed input: 1380.86 toks/s, output: 11968.22 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 4844/5400 [07:47<00:20, 27.31it/s, est. speed input: 1381.52 toks/s, output: 11984.02 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 4848/5400 [07:47<00:27, 20.31it/s, est. speed input: 1381.32 toks/s, output: 11991.37 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 4851/5400 [07:47<00:27, 19.99it/s, est. speed input: 1381.49 toks/s, output: 11990.78 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 4854/5400 [07:47<00:29, 18.60it/s, est. speed input: 1381.86 toks/s, output: 11989.98 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 4864/5400 [07:48<00:21, 25.24it/s, est. speed input: 1384.30 toks/s, output: 11998.47 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 4868/5400 [07:48<00:31, 16.98it/s, est. speed input: 1383.46 toks/s, output: 11990.22 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 4871/5400 [07:48<00:29, 17.67it/s, est. speed input: 1383.63 toks/s, output: 11989.88 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 4875/5400 [07:48<00:26, 19.80it/s, est. speed input: 1383.93 toks/s, output: 11997.74 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 4883/5400 [07:49<00:22, 23.49it/s, est. speed input: 1384.84 toks/s, output: 12028.41 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 4888/5400 [07:49<00:18, 27.62it/s, est. speed input: 1385.66 toks/s, output: 12037.40 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 4892/5400 [07:49<00:20, 25.12it/s, est. speed input: 1385.98 toks/s, output: 12037.07 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 4896/5400 [07:49<00:23, 21.74it/s, est. speed input: 1386.18 toks/s, output: 12034.99 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 4899/5400 [07:50<00:36, 13.64it/s, est. speed input: 1385.26 toks/s, output: 12030.50 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 4901/5400 [07:50<00:46, 10.76it/s, est. speed input: 1384.57 toks/s, output: 12024.33 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 4904/5400 [07:50<00:42, 11.78it/s, est. speed input: 1385.44 toks/s, output: 12029.36 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 4906/5400 [07:51<00:53,  9.15it/s, est. speed input: 1384.76 toks/s, output: 12020.44 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 4910/5400 [07:51<00:58,  8.43it/s, est. speed input: 1384.09 toks/s, output: 12013.99 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 4912/5400 [07:52<01:14,  6.58it/s, est. speed input: 1383.01 toks/s, output: 12003.96 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 4913/5400 [07:52<01:15,  6.45it/s, est. speed input: 1382.77 toks/s, output: 12001.57 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 4916/5400 [07:52<01:00,  8.03it/s, est. speed input: 1382.99 toks/s, output: 12011.34 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 4918/5400 [07:52<00:55,  8.66it/s, est. speed input: 1383.07 toks/s, output: 12014.22 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 4920/5400 [07:53<01:06,  7.18it/s, est. speed input: 1382.46 toks/s, output: 12011.15 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 4923/5400 [07:53<00:50,  9.52it/s, est. speed input: 1382.97 toks/s, output: 12015.89 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 4925/5400 [07:53<00:44, 10.74it/s, est. speed input: 1383.22 toks/s, output: 12020.23 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4928/5400 [07:53<00:38, 12.22it/s, est. speed input: 1383.30 toks/s, output: 12019.96 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4931/5400 [07:55<02:01,  3.85it/s, est. speed input: 1378.85 toks/s, output: 11976.88 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4936/5400 [07:55<01:15,  6.12it/s, est. speed input: 1379.50 toks/s, output: 11979.00 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4938/5400 [07:55<01:09,  6.64it/s, est. speed input: 1379.33 toks/s, output: 11977.78 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4940/5400 [07:56<01:02,  7.39it/s, est. speed input: 1379.26 toks/s, output: 11977.42 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4944/5400 [07:56<00:43, 10.55it/s, est. speed input: 1379.68 toks/s, output: 11982.73 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4946/5400 [07:56<00:46,  9.74it/s, est. speed input: 1379.31 toks/s, output: 11979.21 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4948/5400 [07:56<01:04,  6.96it/s, est. speed input: 1378.10 toks/s, output: 11968.53 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4950/5400 [07:57<01:04,  7.02it/s, est. speed input: 1377.77 toks/s, output: 11965.66 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4952/5400 [07:57<00:57,  7.86it/s, est. speed input: 1377.66 toks/s, output: 11964.60 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4954/5400 [07:58<01:20,  5.57it/s, est. speed input: 1376.53 toks/s, output: 11961.60 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4955/5400 [07:58<01:16,  5.81it/s, est. speed input: 1376.45 toks/s, output: 11962.32 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4956/5400 [07:58<01:48,  4.08it/s, est. speed input: 1375.01 toks/s, output: 11950.92 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4958/5400 [07:59<02:02,  3.61it/s, est. speed input: 1373.58 toks/s, output: 11938.64 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4961/5400 [07:59<01:27,  5.00it/s, est. speed input: 1373.37 toks/s, output: 11942.00 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4963/5400 [07:59<01:12,  5.99it/s, est. speed input: 1373.21 toks/s, output: 11950.55 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4964/5400 [08:00<01:23,  5.22it/s, est. speed input: 1372.62 toks/s, output: 11945.56 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4965/5400 [08:00<01:25,  5.09it/s, est. speed input: 1372.15 toks/s, output: 11943.24 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4967/5400 [08:00<01:16,  5.64it/s, est. speed input: 1371.56 toks/s, output: 11938.13 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4978/5400 [08:00<00:22, 18.68it/s, est. speed input: 1372.73 toks/s, output: 11947.62 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4982/5400 [08:01<00:29, 14.00it/s, est. speed input: 1372.47 toks/s, output: 11942.73 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4985/5400 [08:01<00:28, 14.54it/s, est. speed input: 1372.48 toks/s, output: 11946.58 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4988/5400 [08:01<00:24, 16.49it/s, est. speed input: 1372.64 toks/s, output: 11951.51 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4991/5400 [08:01<00:29, 13.64it/s, est. speed input: 1372.22 toks/s, output: 11948.90 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 4996/5400 [08:02<00:24, 16.18it/s, est. speed input: 1372.46 toks/s, output: 11952.09 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5001/5400 [08:02<00:21, 18.69it/s, est. speed input: 1372.93 toks/s, output: 11955.39 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5004/5400 [08:02<00:23, 16.84it/s, est. speed input: 1372.72 toks/s, output: 11954.83 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5006/5400 [08:02<00:29, 13.32it/s, est. speed input: 1372.32 toks/s, output: 11951.96 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5008/5400 [08:04<01:23,  4.72it/s, est. speed input: 1368.59 toks/s, output: 11919.42 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5010/5400 [08:04<01:12,  5.35it/s, est. speed input: 1368.37 toks/s, output: 11916.73 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5016/5400 [08:04<00:50,  7.58it/s, est. speed input: 1368.36 toks/s, output: 11913.33 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5022/5400 [08:05<00:32, 11.48it/s, est. speed input: 1369.34 toks/s, output: 11920.90 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5025/5400 [08:05<00:32, 11.55it/s, est. speed input: 1369.33 toks/s, output: 11923.27 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5027/5400 [08:05<00:34, 10.85it/s, est. speed input: 1369.02 toks/s, output: 11920.92 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5029/5400 [08:05<00:32, 11.41it/s, est. speed input: 1369.16 toks/s, output: 11921.79 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5033/5400 [08:05<00:24, 15.12it/s, est. speed input: 1369.73 toks/s, output: 11926.67 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5037/5400 [08:06<00:21, 16.62it/s, est. speed input: 1370.40 toks/s, output: 11927.36 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5040/5400 [08:06<00:41,  8.74it/s, est. speed input: 1368.98 toks/s, output: 11913.31 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5043/5400 [08:06<00:35, 10.11it/s, est. speed input: 1369.13 toks/s, output: 11912.74 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5046/5400 [08:07<00:30, 11.69it/s, est. speed input: 1369.34 toks/s, output: 11912.66 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5048/5400 [08:07<00:39,  8.84it/s, est. speed input: 1368.57 toks/s, output: 11904.94 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5050/5400 [08:07<00:38,  9.11it/s, est. speed input: 1368.46 toks/s, output: 11902.94 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5052/5400 [08:08<00:44,  7.75it/s, est. speed input: 1367.85 toks/s, output: 11896.65 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5056/5400 [08:08<00:35,  9.62it/s, est. speed input: 1367.96 toks/s, output: 11897.19 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5059/5400 [08:08<00:29, 11.63it/s, est. speed input: 1368.24 toks/s, output: 11899.15 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5061/5400 [08:09<00:43,  7.78it/s, est. speed input: 1367.18 toks/s, output: 11890.25 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5064/5400 [08:09<00:52,  6.36it/s, est. speed input: 1365.99 toks/s, output: 11885.14 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5070/5400 [08:09<00:29, 11.19it/s, est. speed input: 1367.00 toks/s, output: 11908.89 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5073/5400 [08:10<00:34,  9.40it/s, est. speed input: 1366.64 toks/s, output: 11901.80 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5075/5400 [08:10<00:39,  8.32it/s, est. speed input: 1366.01 toks/s, output: 11896.94 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5078/5400 [08:10<00:34,  9.43it/s, est. speed input: 1366.35 toks/s, output: 11894.83 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5080/5400 [08:11<00:33,  9.59it/s, est. speed input: 1366.39 toks/s, output: 11892.19 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5082/5400 [08:11<00:38,  8.23it/s, est. speed input: 1365.74 toks/s, output: 11887.78 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5087/5400 [08:11<00:35,  8.73it/s, est. speed input: 1365.10 toks/s, output: 11886.05 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5089/5400 [08:12<00:43,  7.16it/s, est. speed input: 1364.29 toks/s, output: 11879.54 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5090/5400 [08:12<00:51,  6.08it/s, est. speed input: 1363.56 toks/s, output: 11872.75 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5095/5400 [08:13<00:51,  5.89it/s, est. speed input: 1362.13 toks/s, output: 11859.07 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5096/5400 [08:13<00:51,  5.95it/s, est. speed input: 1361.89 toks/s, output: 11857.73 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5097/5400 [08:13<00:50,  6.01it/s, est. speed input: 1361.66 toks/s, output: 11856.39 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5098/5400 [08:14<00:49,  6.06it/s, est. speed input: 1361.42 toks/s, output: 11855.03 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5101/5400 [08:14<00:56,  5.27it/s, est. speed input: 1360.26 toks/s, output: 11845.20 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5103/5400 [08:14<00:46,  6.45it/s, est. speed input: 1360.26 toks/s, output: 11844.71 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5107/5400 [08:15<00:47,  6.13it/s, est. speed input: 1359.30 toks/s, output: 11833.50 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5110/5400 [08:15<00:38,  7.47it/s, est. speed input: 1359.13 toks/s, output: 11836.76 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5114/5400 [08:15<00:26, 10.61it/s, est. speed input: 1359.44 toks/s, output: 11853.89 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5116/5400 [08:16<00:31,  9.07it/s, est. speed input: 1358.79 toks/s, output: 11854.65 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5118/5400 [08:16<00:30,  9.30it/s, est. speed input: 1358.82 toks/s, output: 11852.95 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5121/5400 [08:16<00:24, 11.47it/s, est. speed input: 1359.00 toks/s, output: 11855.96 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5123/5400 [08:16<00:23, 11.73it/s, est. speed input: 1358.83 toks/s, output: 11855.77 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5125/5400 [08:17<00:29,  9.19it/s, est. speed input: 1358.33 toks/s, output: 11854.15 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5127/5400 [08:17<00:26, 10.45it/s, est. speed input: 1358.24 toks/s, output: 11863.64 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5133/5400 [08:17<00:14, 18.10it/s, est. speed input: 1358.83 toks/s, output: 11876.08 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5143/5400 [08:17<00:09, 27.39it/s, est. speed input: 1360.92 toks/s, output: 11887.37 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5147/5400 [08:17<00:12, 20.43it/s, est. speed input: 1360.62 toks/s, output: 11884.05 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5151/5400 [08:18<00:11, 21.56it/s, est. speed input: 1360.72 toks/s, output: 11884.21 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5154/5400 [08:18<00:11, 21.67it/s, est. speed input: 1361.16 toks/s, output: 11885.33 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5158/5400 [08:18<00:12, 20.08it/s, est. speed input: 1362.24 toks/s, output: 11886.44 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5161/5400 [08:18<00:14, 16.40it/s, est. speed input: 1362.08 toks/s, output: 11883.86 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5163/5400 [08:19<00:19, 11.95it/s, est. speed input: 1361.54 toks/s, output: 11878.56 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5165/5400 [08:19<00:21, 11.08it/s, est. speed input: 1361.35 toks/s, output: 11876.15 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5167/5400 [08:19<00:19, 11.77it/s, est. speed input: 1361.42 toks/s, output: 11876.04 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5169/5400 [08:19<00:18, 12.42it/s, est. speed input: 1361.48 toks/s, output: 11875.57 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5171/5400 [08:20<00:29,  7.76it/s, est. speed input: 1360.45 toks/s, output: 11865.70 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5173/5400 [08:20<00:25,  8.80it/s, est. speed input: 1360.65 toks/s, output: 11874.32 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5176/5400 [08:20<00:24,  9.11it/s, est. speed input: 1360.57 toks/s, output: 11876.53 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5179/5400 [08:20<00:22,  9.97it/s, est. speed input: 1360.44 toks/s, output: 11876.17 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5186/5400 [08:21<00:13, 15.63it/s, est. speed input: 1360.73 toks/s, output: 11878.40 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5188/5400 [08:21<00:17, 12.33it/s, est. speed input: 1360.44 toks/s, output: 11879.57 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5190/5400 [08:21<00:21,  9.88it/s, est. speed input: 1359.88 toks/s, output: 11876.57 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5195/5400 [08:22<00:29,  6.98it/s, est. speed input: 1358.26 toks/s, output: 11867.03 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5196/5400 [08:23<00:40,  5.01it/s, est. speed input: 1356.80 toks/s, output: 11853.25 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5202/5400 [08:23<00:22,  8.63it/s, est. speed input: 1358.34 toks/s, output: 11860.65 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5204/5400 [08:24<00:26,  7.44it/s, est. speed input: 1357.61 toks/s, output: 11852.24 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5207/5400 [08:24<00:24,  7.80it/s, est. speed input: 1357.35 toks/s, output: 11848.33 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5209/5400 [08:24<00:28,  6.63it/s, est. speed input: 1356.52 toks/s, output: 11839.06 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5211/5400 [08:25<00:31,  6.05it/s, est. speed input: 1355.93 toks/s, output: 11832.13 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5212/5400 [08:25<00:30,  6.25it/s, est. speed input: 1355.76 toks/s, output: 11831.09 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5213/5400 [08:25<00:29,  6.33it/s, est. speed input: 1355.50 toks/s, output: 11831.14 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5215/5400 [08:26<00:34,  5.35it/s, est. speed input: 1354.69 toks/s, output: 11823.44 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5216/5400 [08:26<00:32,  5.58it/s, est. speed input: 1354.49 toks/s, output: 11823.63 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5221/5400 [08:26<00:15, 11.25it/s, est. speed input: 1355.29 toks/s, output: 11832.76 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5223/5400 [08:26<00:21,  8.41it/s, est. speed input: 1354.64 toks/s, output: 11828.93 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5227/5400 [08:26<00:15, 11.25it/s, est. speed input: 1354.95 toks/s, output: 11829.40 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5233/5400 [08:27<00:10, 16.27it/s, est. speed input: 1355.41 toks/s, output: 11831.32 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5237/5400 [08:27<00:09, 17.72it/s, est. speed input: 1355.58 toks/s, output: 11832.28 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5240/5400 [08:27<00:13, 12.07it/s, est. speed input: 1354.85 toks/s, output: 11824.88 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5244/5400 [08:28<00:13, 11.36it/s, est. speed input: 1354.66 toks/s, output: 11823.24 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5246/5400 [08:28<00:13, 11.76it/s, est. speed input: 1354.61 toks/s, output: 11824.36 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5248/5400 [08:29<00:23,  6.57it/s, est. speed input: 1353.04 toks/s, output: 11809.88 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5250/5400 [08:29<00:30,  4.86it/s, est. speed input: 1351.35 toks/s, output: 11795.32 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5255/5400 [08:29<00:18,  8.05it/s, est. speed input: 1352.01 toks/s, output: 11803.96 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5263/5400 [08:30<00:14,  9.55it/s, est. speed input: 1351.68 toks/s, output: 11808.74 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5265/5400 [08:31<00:24,  5.53it/s, est. speed input: 1348.89 toks/s, output: 11784.52 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5268/5400 [08:32<00:19,  6.77it/s, est. speed input: 1348.92 toks/s, output: 11785.92 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5270/5400 [08:32<00:17,  7.25it/s, est. speed input: 1348.69 toks/s, output: 11784.56 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5272/5400 [08:33<00:28,  4.43it/s, est. speed input: 1346.17 toks/s, output: 11763.18 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5274/5400 [08:33<00:29,  4.24it/s, est. speed input: 1345.20 toks/s, output: 11759.11 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5278/5400 [08:33<00:18,  6.58it/s, est. speed input: 1345.70 toks/s, output: 11778.78 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5280/5400 [08:34<00:16,  7.38it/s, est. speed input: 1345.69 toks/s, output: 11787.15 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5283/5400 [08:34<00:15,  7.43it/s, est. speed input: 1345.19 toks/s, output: 11791.81 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5285/5400 [08:34<00:16,  6.78it/s, est. speed input: 1344.64 toks/s, output: 11795.09 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5288/5400 [08:35<00:21,  5.33it/s, est. speed input: 1343.24 toks/s, output: 11784.11 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5289/5400 [08:36<00:30,  3.67it/s, est. speed input: 1341.34 toks/s, output: 11771.73 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5297/5400 [08:37<00:16,  6.09it/s, est. speed input: 1340.99 toks/s, output: 11801.87 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5300/5400 [08:37<00:14,  6.73it/s, est. speed input: 1340.92 toks/s, output: 11812.76 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5301/5400 [08:38<00:17,  5.54it/s, est. speed input: 1339.90 toks/s, output: 11808.36 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5302/5400 [08:38<00:16,  5.87it/s, est. speed input: 1339.80 toks/s, output: 11811.98 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5307/5400 [08:38<00:09,  9.87it/s, est. speed input: 1340.22 toks/s, output: 11838.51 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5309/5400 [08:38<00:11,  7.94it/s, est. speed input: 1339.40 toks/s, output: 11840.51 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5311/5400 [08:38<00:10,  8.34it/s, est. speed input: 1339.17 toks/s, output: 11847.78 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5317/5400 [08:39<00:12,  6.77it/s, est. speed input: 1337.48 toks/s, output: 11859.28 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5319/5400 [08:40<00:12,  6.34it/s, est. speed input: 1337.12 toks/s, output: 11862.00 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5320/5400 [08:41<00:26,  2.97it/s, est. speed input: 1333.15 toks/s, output: 11830.24 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5321/5400 [08:43<00:36,  2.16it/s, est. speed input: 1330.34 toks/s, output: 11806.60 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5322/5400 [08:45<01:00,  1.29it/s, est. speed input: 1324.78 toks/s, output: 11762.11 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5326/5400 [08:45<00:30,  2.40it/s, est. speed input: 1324.64 toks/s, output: 11780.35 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5329/5400 [08:45<00:20,  3.40it/s, est. speed input: 1324.48 toks/s, output: 11793.48 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5330/5400 [08:46<00:19,  3.55it/s, est. speed input: 1324.18 toks/s, output: 11792.39 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5331/5400 [08:46<00:21,  3.25it/s, est. speed input: 1323.20 toks/s, output: 11788.47 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5339/5400 [08:46<00:07,  8.11it/s, est. speed input: 1323.67 toks/s, output: 11830.18 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5341/5400 [08:47<00:12,  4.69it/s, est. speed input: 1321.06 toks/s, output: 11815.17 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5343/5400 [08:48<00:11,  4.94it/s, est. speed input: 1320.70 toks/s, output: 11815.45 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5344/5400 [08:48<00:12,  4.36it/s, est. speed input: 1319.81 toks/s, output: 11812.18 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5345/5400 [08:48<00:11,  4.74it/s, est. speed input: 1319.64 toks/s, output: 11815.42 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5351/5400 [08:48<00:05,  9.12it/s, est. speed input: 1319.84 toks/s, output: 11845.55 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5353/5400 [08:50<00:14,  3.31it/s, est. speed input: 1315.31 toks/s, output: 11809.04 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5357/5400 [08:51<00:08,  4.80it/s, est. speed input: 1315.58 toks/s, output: 11820.12 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5359/5400 [08:52<00:13,  3.12it/s, est. speed input: 1312.49 toks/s, output: 11799.08 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5364/5400 [08:52<00:07,  5.01it/s, est. speed input: 1313.21 toks/s, output: 11823.38 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5366/5400 [08:52<00:05,  5.80it/s, est. speed input: 1313.23 toks/s, output: 11832.14 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5368/5400 [08:53<00:04,  6.75it/s, est. speed input: 1313.25 toks/s, output: 11840.89 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5373/5400 [08:53<00:02,  9.63it/s, est. speed input: 1313.37 toks/s, output: 11864.38 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5375/5400 [08:53<00:03,  7.18it/s, est. speed input: 1312.22 toks/s, output: 11863.45 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5377/5400 [08:54<00:03,  7.43it/s, est. speed input: 1311.86 toks/s, output: 11869.72 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5379/5400 [08:54<00:02,  8.54it/s, est. speed input: 1311.77 toks/s, output: 11878.45 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5381/5400 [08:56<00:07,  2.39it/s, est. speed input: 1305.88 toks/s, output: 11832.67 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5382/5400 [09:00<00:15,  1.14it/s, est. speed input: 1297.91 toks/s, output: 11764.75 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5385/5400 [09:01<00:09,  1.54it/s, est. speed input: 1296.08 toks/s, output: 11761.33 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5390/5400 [09:01<00:03,  2.83it/s, est. speed input: 1296.17 toks/s, output: 11785.35 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5392/5400 [09:01<00:02,  3.19it/s, est. speed input: 1295.58 toks/s, output: 11789.31 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5393/5400 [09:09<00:09,  1.29s/it, est. speed input: 1277.78 toks/s, output: 11631.99 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5400/5400 [09:09<00:00,  1.78it/s, est. speed input: 1278.27 toks/s, output: 11668.71 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5400/5400 [09:09<00:00,  9.83it/s, est. speed input: 1278.27 toks/s, output: 11668.71 toks/s]
INFO 09-23 15:43:57 [__init__.py:239] Automatically detected platform cuda.
-------------------- Epoch 1

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.11s/it, est. speed input: 2841.77 toks/s, output: 52.24 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.11s/it, est. speed input: 2841.77 toks/s, output: 52.24 toks/s]
-------------------- Epoch 2
Unsolved samples: 0

Evaluate:   0%|          | 0/5400 [00:00<?, ?it/s][A
Evaluate:   3%|‚ñé         | 185/5400 [00:00<00:17, 302.10it/s][A
Evaluate:   4%|‚ñç         | 216/5400 [00:02<01:13, 70.18it/s] [A
Evaluate:   8%|‚ñä         | 417/5400 [00:02<00:27, 180.35it/s][A
Evaluate:   9%|‚ñâ         | 492/5400 [00:03<00:35, 140.06it/s][A
Evaluate:  11%|‚ñà         | 605/5400 [00:03<00:26, 181.51it/s][A
Evaluate:  12%|‚ñà‚ñè        | 651/5400 [00:04<00:33, 140.44it/s][A
Evaluate:  13%|‚ñà‚ñé        | 684/5400 [00:04<00:32, 143.61it/s][A
Evaluate:  14%|‚ñà‚ñé        | 729/5400 [00:04<00:29, 156.53it/s][A
Evaluate:  14%|‚ñà‚ñç        | 755/5400 [00:05<00:29, 157.33it/s][A
Evaluate:  15%|‚ñà‚ñå        | 810/5400 [00:05<00:30, 150.49it/s][A
Evaluate:  15%|‚ñà‚ñå        | 830/5400 [00:07<01:24, 53.77it/s] [A
Evaluate:  16%|‚ñà‚ñå        | 873/5400 [00:07<01:02, 72.90it/s][A
Evaluate:  17%|‚ñà‚ñã        | 895/5400 [00:07<00:58, 76.92it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5400/5400 [00:07<00:00, 705.79it/s]
{'num_samples': 675, 'num_scores': 5400, 'timeout_samples': 0, 'empty_samples': 3, 'acc': 24.9, 'total_acc': 24.574074074074073, 'pass_at_k_percent': {'1': 24.6, '8': 30.8}, 'pass_at_k_valid_counts': {'1': 675, '8': 675}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_noise_rlvr_1_5b_128batchsize_deepscaler_noise_robust_qwen25-math-cot/base__Qwen2.5-math-1.5B/g2/olympiadbench/test_qwen25-math-cot_-1_seed0_t0.0_s0_e-1.jsonl
[2025-09-23 15:44:32] ‚úì base__Qwen2.5-math-1.5B/g2/olympiadbench  acc=24.9 pass_at_k={'1': 24.6, '8': 30.8}
base__Qwen2.5-math-1.5B/g2:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [16:10<08:25, 505.33s/ds]==================================================
data: math500  ,remain samples: 500
{'idx': 0, 'problem': 'Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\\theta),$ where $r > 0$ and $0 \\le \\theta < 2 \\pi.$', 'solution': 'We have that $r = \\sqrt{0^2 + 3^2} = 3.$  Also, if we draw the line connecting the origin and $(0,3),$ this line makes an angle of $\\frac{\\pi}{2}$ with the positive $x$-axis.\n\n[asy]\nunitsize(0.8 cm);\n\ndraw((-0.5,0)--(3.5,0));\ndraw((0,-0.5)--(0,3.5));\ndraw(arc((0,0),3,0,90),red,Arrow(6));\n\ndot((0,3), red);\nlabel("$(0,3)$", (0,3), W);\ndot((3,0), red);\n[/asy]\n\nTherefore, the polar coordinates are $\\boxed{\\left( 3, \\frac{\\pi}{2} \\right)}.$', 'answer': '\\left( 3, \\frac{\\pi}{2} \\right)', 'subject': 'Precalculus', 'level': 2, 'unique_id': 'test/precalculus/807.json'}

  0%|          | 0/500 [00:00<?, ?it/s][A<|im_start|>system
Please reason step by step, and put your final answer within \boxed{{}}.<|im_end|>
<|im_start|>user
Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$<|im_end|>
<|im_start|>assistant


  4%|‚ñç         | 22/500 [00:00<00:02, 216.37it/s][A
  9%|‚ñâ         | 45/500 [00:00<00:02, 221.00it/s][A
 14%|‚ñà‚ñé        | 68/500 [00:00<00:01, 219.79it/s][A
 18%|‚ñà‚ñä        | 91/500 [00:00<00:01, 219.73it/s][A
 23%|‚ñà‚ñà‚ñé       | 113/500 [00:00<00:01, 216.36it/s][A
 27%|‚ñà‚ñà‚ñã       | 136/500 [00:00<00:01, 220.28it/s][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 159/500 [00:00<00:01, 219.29it/s][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 181/500 [00:00<00:01, 218.22it/s][A
 41%|‚ñà‚ñà‚ñà‚ñà      | 204/500 [00:00<00:01, 220.14it/s][A
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 227/500 [00:01<00:01, 218.21it/s][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 249/500 [00:01<00:01, 216.62it/s][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 272/500 [00:01<00:01, 218.14it/s][A
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 295/500 [00:01<00:00, 219.10it/s][A
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 317/500 [00:01<00:00, 218.49it/s][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 340/500 [00:01<00:00, 219.83it/s][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 362/500 [00:01<00:00, 218.78it/s][A
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 384/500 [00:01<00:00, 218.99it/s][A
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 406/500 [00:01<00:00, 218.26it/s][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 428/500 [00:01<00:00, 212.41it/s][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 450/500 [00:02<00:00, 212.25it/s][A
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 473/500 [00:02<00:00, 216.61it/s][A
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 496/500 [00:02<00:00, 218.95it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:02<00:00, 218.00it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/4000 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 1/4000 [00:02<2:31:09,  2.27s/it, est. speed input: 31.31 toks/s, output: 78.93 toks/s][A
Processed prompts:   0%|          | 9/4000 [00:02<17:20,  3.84it/s, est. speed input: 317.83 toks/s, output: 558.32 toks/s][A
Processed prompts:   0%|          | 17/4000 [00:04<13:46,  4.82it/s, est. speed input: 869.38 toks/s, output: 804.96 toks/s][A
Processed prompts:   1%|          | 33/4000 [00:04<05:55, 11.16it/s, est. speed input: 1398.10 toks/s, output: 1692.47 toks/s][A
Processed prompts:   1%|          | 41/4000 [00:05<06:13, 10.61it/s, est. speed input: 1273.45 toks/s, output: 1831.74 toks/s][A
Processed prompts:   1%|          | 49/4000 [00:05<04:51, 13.57it/s, est. speed input: 1298.97 toks/s, output: 2236.10 toks/s][A
Processed prompts:   1%|‚ñè         | 57/4000 [00:08<09:23,  7.00it/s, est. speed input: 1010.00 toks/s, output: 1895.50 toks/s][A
Processed prompts:   1%|‚ñè         | 59/4000 [00:08<08:57,  7.33it/s, est. speed input: 1006.54 toks/s, output: 1973.34 toks/s][A
Processed prompts:   2%|‚ñè         | 61/4000 [00:08<09:16,  7.08it/s, est. speed input: 980.16 toks/s, output: 2003.94 toks/s] [A
Processed prompts:   2%|‚ñè         | 75/4000 [00:09<05:28, 11.95it/s, est. speed input: 1107.56 toks/s, output: 2620.95 toks/s][A
Processed prompts:   2%|‚ñè         | 91/4000 [00:09<03:21, 19.38it/s, est. speed input: 1186.25 toks/s, output: 3378.37 toks/s][A
Processed prompts:   2%|‚ñé         | 100/4000 [00:10<04:26, 14.63it/s, est. speed input: 1150.43 toks/s, output: 3503.00 toks/s][A
Processed prompts:   3%|‚ñé         | 108/4000 [00:10<04:38, 13.98it/s, est. speed input: 1158.93 toks/s, output: 3697.09 toks/s][A
Processed prompts:   3%|‚ñé         | 116/4000 [00:11<04:36, 14.04it/s, est. speed input: 1149.62 toks/s, output: 3922.94 toks/s][A
Processed prompts:   3%|‚ñé         | 122/4000 [00:11<03:59, 16.18it/s, est. speed input: 1204.25 toks/s, output: 4195.97 toks/s][A
Processed prompts:   3%|‚ñé         | 125/4000 [00:11<03:54, 16.54it/s, est. speed input: 1208.84 toks/s, output: 4259.25 toks/s][A
Processed prompts:   3%|‚ñé         | 139/4000 [00:11<02:16, 28.19it/s, est. speed input: 1363.66 toks/s, output: 4895.37 toks/s][A
Processed prompts:   4%|‚ñé         | 147/4000 [00:12<01:53, 33.81it/s, est. speed input: 1453.11 toks/s, output: 5268.32 toks/s][A
Processed prompts:   4%|‚ñç         | 153/4000 [00:12<02:02, 31.52it/s, est. speed input: 1463.11 toks/s, output: 5503.28 toks/s][A
Processed prompts:   4%|‚ñç         | 159/4000 [00:12<01:59, 32.20it/s, est. speed input: 1533.21 toks/s, output: 5746.24 toks/s][A
Processed prompts:   4%|‚ñç         | 176/4000 [00:13<03:31, 18.10it/s, est. speed input: 1510.25 toks/s, output: 6022.12 toks/s][A
Processed prompts:   4%|‚ñç         | 180/4000 [00:14<05:20, 11.93it/s, est. speed input: 1447.55 toks/s, output: 5816.53 toks/s][A
Processed prompts:   5%|‚ñç         | 187/4000 [00:15<05:21, 11.84it/s, est. speed input: 1420.22 toks/s, output: 5945.28 toks/s][A
Processed prompts:   5%|‚ñå         | 203/4000 [00:15<03:26, 18.37it/s, est. speed input: 1482.35 toks/s, output: 6629.92 toks/s][A
Processed prompts:   5%|‚ñå         | 211/4000 [00:16<03:09, 20.02it/s, est. speed input: 1521.18 toks/s, output: 6687.98 toks/s][A
Processed prompts:   6%|‚ñå         | 221/4000 [00:16<02:26, 25.83it/s, est. speed input: 1564.91 toks/s, output: 6885.79 toks/s][A
Processed prompts:   6%|‚ñå         | 226/4000 [00:16<02:28, 25.38it/s, est. speed input: 1569.37 toks/s, output: 6980.12 toks/s][A
Processed prompts:   6%|‚ñå         | 231/4000 [00:17<03:55, 16.04it/s, est. speed input: 1523.76 toks/s, output: 6847.52 toks/s][A
Processed prompts:   6%|‚ñå         | 244/4000 [00:17<03:03, 20.42it/s, est. speed input: 1550.28 toks/s, output: 7117.19 toks/s][A
Processed prompts:   6%|‚ñå         | 247/4000 [00:17<03:02, 20.61it/s, est. speed input: 1547.04 toks/s, output: 7108.92 toks/s][A
Processed prompts:   6%|‚ñã         | 251/4000 [00:17<02:58, 21.05it/s, est. speed input: 1543.46 toks/s, output: 7101.84 toks/s][A
Processed prompts:   6%|‚ñã         | 254/4000 [00:17<02:52, 21.70it/s, est. speed input: 1548.35 toks/s, output: 7175.79 toks/s][A
Processed prompts:   7%|‚ñã         | 262/4000 [00:18<02:12, 28.18it/s, est. speed input: 1584.89 toks/s, output: 7499.77 toks/s][A
Processed prompts:   7%|‚ñã         | 266/4000 [00:18<03:54, 15.89it/s, est. speed input: 1545.04 toks/s, output: 7329.51 toks/s][A
Processed prompts:   7%|‚ñã         | 270/4000 [00:19<04:07, 15.06it/s, est. speed input: 1537.27 toks/s, output: 7292.95 toks/s][A
Processed prompts:   7%|‚ñã         | 273/4000 [00:19<04:41, 13.25it/s, est. speed input: 1527.21 toks/s, output: 7226.06 toks/s][A
Processed prompts:   7%|‚ñã         | 286/4000 [00:20<04:35, 13.46it/s, est. speed input: 1511.00 toks/s, output: 7124.27 toks/s][A
Processed prompts:   7%|‚ñã         | 292/4000 [00:21<07:45,  7.96it/s, est. speed input: 1424.09 toks/s, output: 6689.95 toks/s][A
Processed prompts:   7%|‚ñã         | 294/4000 [00:22<08:21,  7.40it/s, est. speed input: 1404.69 toks/s, output: 6612.05 toks/s][A
Processed prompts:   7%|‚ñã         | 299/4000 [00:23<10:09,  6.07it/s, est. speed input: 1349.77 toks/s, output: 6377.36 toks/s][A
Processed prompts:   8%|‚ñä         | 300/4000 [00:24<15:30,  3.98it/s, est. speed input: 1281.16 toks/s, output: 6055.08 toks/s][A
Processed prompts:   8%|‚ñä         | 302/4000 [00:25<17:00,  3.62it/s, est. speed input: 1246.20 toks/s, output: 5895.68 toks/s][A
Processed prompts:   8%|‚ñä         | 307/4000 [00:26<14:29,  4.25it/s, est. speed input: 1216.47 toks/s, output: 5777.75 toks/s][A
Processed prompts:   8%|‚ñä         | 309/4000 [00:26<12:56,  4.75it/s, est. speed input: 1213.76 toks/s, output: 5786.33 toks/s][A
Processed prompts:   8%|‚ñä         | 310/4000 [00:26<13:14,  4.65it/s, est. speed input: 1206.04 toks/s, output: 5750.22 toks/s][A
Processed prompts:   8%|‚ñä         | 318/4000 [00:27<09:52,  6.21it/s, est. speed input: 1192.39 toks/s, output: 5710.62 toks/s][A
Processed prompts:   8%|‚ñä         | 320/4000 [00:28<08:54,  6.89it/s, est. speed input: 1192.90 toks/s, output: 5730.98 toks/s][A
Processed prompts:   8%|‚ñä         | 323/4000 [00:28<07:29,  8.18it/s, est. speed input: 1195.13 toks/s, output: 5737.69 toks/s][A
Processed prompts:   8%|‚ñä         | 334/4000 [00:28<03:56, 15.51it/s, est. speed input: 1216.76 toks/s, output: 5971.60 toks/s][A
Processed prompts:   8%|‚ñä         | 337/4000 [00:29<05:28, 11.14it/s, est. speed input: 1201.11 toks/s, output: 5895.75 toks/s][A
Processed prompts:   9%|‚ñä         | 341/4000 [00:29<06:17,  9.70it/s, est. speed input: 1189.62 toks/s, output: 5851.85 toks/s][A
Processed prompts:   9%|‚ñä         | 343/4000 [00:29<06:02, 10.09it/s, est. speed input: 1189.84 toks/s, output: 5846.74 toks/s][A
Processed prompts:   9%|‚ñä         | 346/4000 [00:32<20:39,  2.95it/s, est. speed input: 1085.24 toks/s, output: 5332.29 toks/s][A
Processed prompts:   9%|‚ñä         | 348/4000 [00:33<17:57,  3.39it/s, est. speed input: 1085.18 toks/s, output: 5342.17 toks/s][A
Processed prompts:   9%|‚ñâ         | 352/4000 [00:33<12:37,  4.82it/s, est. speed input: 1092.89 toks/s, output: 5414.91 toks/s][A
Processed prompts:   9%|‚ñâ         | 354/4000 [00:34<14:24,  4.22it/s, est. speed input: 1077.59 toks/s, output: 5362.51 toks/s][A
Processed prompts:   9%|‚ñâ         | 364/4000 [00:34<08:36,  7.04it/s, est. speed input: 1089.24 toks/s, output: 5555.06 toks/s][A
Processed prompts:   9%|‚ñâ         | 367/4000 [00:35<08:27,  7.16it/s, est. speed input: 1088.64 toks/s, output: 5568.40 toks/s][A
Processed prompts:   9%|‚ñâ         | 368/4000 [00:36<16:19,  3.71it/s, est. speed input: 1043.04 toks/s, output: 5351.62 toks/s][A
Processed prompts:   9%|‚ñâ         | 374/4000 [00:37<10:25,  5.80it/s, est. speed input: 1048.03 toks/s, output: 5464.37 toks/s][A
Processed prompts:   9%|‚ñâ         | 379/4000 [00:37<07:36,  7.93it/s, est. speed input: 1051.44 toks/s, output: 5511.39 toks/s][A
Processed prompts:  10%|‚ñâ         | 381/4000 [00:37<09:32,  6.33it/s, est. speed input: 1037.10 toks/s, output: 5442.03 toks/s][A
Processed prompts:  10%|‚ñâ         | 384/4000 [00:38<07:41,  7.84it/s, est. speed input: 1037.93 toks/s, output: 5447.84 toks/s][A
Processed prompts:  10%|‚ñâ         | 386/4000 [00:38<06:59,  8.61it/s, est. speed input: 1037.14 toks/s, output: 5454.04 toks/s][A
Processed prompts:  10%|‚ñâ         | 388/4000 [00:38<08:25,  7.14it/s, est. speed input: 1028.03 toks/s, output: 5414.80 toks/s][A
Processed prompts:  10%|‚ñâ         | 392/4000 [00:38<05:45, 10.44it/s, est. speed input: 1030.60 toks/s, output: 5427.06 toks/s][A
Processed prompts:  10%|‚ñâ         | 395/4000 [00:39<06:29,  9.25it/s, est. speed input: 1024.62 toks/s, output: 5403.49 toks/s][A
Processed prompts:  10%|‚ñâ         | 399/4000 [00:39<05:14, 11.46it/s, est. speed input: 1026.87 toks/s, output: 5436.07 toks/s][A
Processed prompts:  10%|‚ñà         | 404/4000 [00:39<03:56, 15.18it/s, est. speed input: 1030.79 toks/s, output: 5481.70 toks/s][A
Processed prompts:  10%|‚ñà         | 412/4000 [00:40<04:18, 13.88it/s, est. speed input: 1028.78 toks/s, output: 5511.05 toks/s][A
Processed prompts:  10%|‚ñà         | 417/4000 [00:40<03:39, 16.29it/s, est. speed input: 1039.36 toks/s, output: 5595.39 toks/s][A
Processed prompts:  11%|‚ñà         | 426/4000 [00:40<02:38, 22.53it/s, est. speed input: 1071.23 toks/s, output: 5906.48 toks/s][A
Processed prompts:  11%|‚ñà         | 429/4000 [00:42<09:29,  6.27it/s, est. speed input: 1022.98 toks/s, output: 5639.94 toks/s][A
Processed prompts:  11%|‚ñà         | 432/4000 [00:43<08:51,  6.72it/s, est. speed input: 1019.07 toks/s, output: 5618.44 toks/s][A
Processed prompts:  11%|‚ñà         | 435/4000 [00:43<07:21,  8.07it/s, est. speed input: 1021.47 toks/s, output: 5620.83 toks/s][A
Processed prompts:  11%|‚ñà         | 439/4000 [00:43<06:03,  9.79it/s, est. speed input: 1024.05 toks/s, output: 5613.35 toks/s][A
Processed prompts:  11%|‚ñà         | 442/4000 [00:43<06:51,  8.65it/s, est. speed input: 1017.14 toks/s, output: 5570.65 toks/s][A
Processed prompts:  11%|‚ñà         | 444/4000 [00:43<06:14,  9.50it/s, est. speed input: 1016.73 toks/s, output: 5568.92 toks/s][A
Processed prompts:  11%|‚ñà         | 446/4000 [00:44<06:09,  9.62it/s, est. speed input: 1015.25 toks/s, output: 5569.13 toks/s][A
Processed prompts:  11%|‚ñà         | 448/4000 [00:44<06:21,  9.31it/s, est. speed input: 1012.87 toks/s, output: 5564.41 toks/s][A
Processed prompts:  11%|‚ñà‚ñè        | 451/4000 [00:44<05:32, 10.66it/s, est. speed input: 1012.94 toks/s, output: 5577.10 toks/s][A
Processed prompts:  11%|‚ñà‚ñè        | 453/4000 [00:50<47:46,  1.24it/s, est. speed input: 894.08 toks/s, output: 4932.41 toks/s] [A
Processed prompts:  11%|‚ñà‚ñè        | 458/4000 [00:50<26:30,  2.23it/s, est. speed input: 902.98 toks/s, output: 4970.12 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 461/4000 [00:51<25:16,  2.33it/s, est. speed input: 889.61 toks/s, output: 4893.14 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 464/4000 [00:52<18:36,  3.17it/s, est. speed input: 891.53 toks/s, output: 4916.15 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 466/4000 [00:52<18:22,  3.21it/s, est. speed input: 883.46 toks/s, output: 4883.10 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 472/4000 [00:52<10:36,  5.55it/s, est. speed input: 887.12 toks/s, output: 4927.93 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 474/4000 [00:54<15:54,  3.69it/s, est. speed input: 868.41 toks/s, output: 4830.08 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 476/4000 [00:54<13:14,  4.43it/s, est. speed input: 869.99 toks/s, output: 4840.30 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 479/4000 [00:54<12:10,  4.82it/s, est. speed input: 866.48 toks/s, output: 4834.39 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 484/4000 [00:54<07:32,  7.77it/s, est. speed input: 871.62 toks/s, output: 4895.30 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 487/4000 [00:56<11:29,  5.10it/s, est. speed input: 858.95 toks/s, output: 4894.14 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 489/4000 [00:56<12:20,  4.74it/s, est. speed input: 854.22 toks/s, output: 4896.87 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 494/4000 [00:56<07:57,  7.34it/s, est. speed input: 860.42 toks/s, output: 4965.53 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 497/4000 [00:57<09:15,  6.31it/s, est. speed input: 855.25 toks/s, output: 4945.71 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 499/4000 [00:58<10:43,  5.44it/s, est. speed input: 849.07 toks/s, output: 4907.41 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 505/4000 [00:58<06:47,  8.58it/s, est. speed input: 853.22 toks/s, output: 4914.22 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 514/4000 [00:59<05:44, 10.11it/s, est. speed input: 855.24 toks/s, output: 4974.94 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 517/4000 [00:59<07:31,  7.72it/s, est. speed input: 846.90 toks/s, output: 4927.87 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 519/4000 [01:00<10:57,  5.29it/s, est. speed input: 835.71 toks/s, output: 4913.17 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 525/4000 [01:01<07:58,  7.26it/s, est. speed input: 837.68 toks/s, output: 4997.13 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 534/4000 [01:01<05:03, 11.43it/s, est. speed input: 841.43 toks/s, output: 5426.02 toks/s][A
Processed prompts:  14%|‚ñà‚ñé        | 545/4000 [01:01<03:03, 18.78it/s, est. speed input: 849.53 toks/s, output: 5964.56 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 551/4000 [01:01<02:47, 20.56it/s, est. speed input: 853.81 toks/s, output: 6206.23 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 574/4000 [01:01<01:21, 42.03it/s, est. speed input: 877.09 toks/s, output: 7164.09 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 582/4000 [01:03<03:19, 17.12it/s, est. speed input: 866.26 toks/s, output: 7080.02 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 588/4000 [01:03<03:44, 15.17it/s, est. speed input: 865.82 toks/s, output: 7061.68 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 593/4000 [01:06<09:14,  6.15it/s, est. speed input: 834.94 toks/s, output: 6838.32 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 601/4000 [01:07<06:55,  8.18it/s, est. speed input: 840.45 toks/s, output: 7182.04 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 609/4000 [01:07<05:23, 10.47it/s, est. speed input: 844.07 toks/s, output: 7485.05 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 613/4000 [01:07<05:55,  9.53it/s, est. speed input: 840.19 toks/s, output: 7533.80 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 620/4000 [01:08<04:39, 12.11it/s, est. speed input: 844.11 toks/s, output: 7824.58 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 628/4000 [01:08<03:25, 16.41it/s, est. speed input: 850.81 toks/s, output: 8133.32 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 632/4000 [01:09<05:43,  9.82it/s, est. speed input: 857.28 toks/s, output: 8020.64 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 635/4000 [01:09<06:40,  8.40it/s, est. speed input: 864.63 toks/s, output: 7964.64 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 637/4000 [01:10<06:29,  8.63it/s, est. speed input: 864.56 toks/s, output: 7965.35 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 645/4000 [01:10<05:32, 10.09it/s, est. speed input: 862.19 toks/s, output: 7978.73 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 647/4000 [01:10<05:23, 10.37it/s, est. speed input: 865.91 toks/s, output: 8007.89 toks/s][A
Processed prompts:  16%|‚ñà‚ñã        | 651/4000 [01:11<04:35, 12.17it/s, est. speed input: 872.55 toks/s, output: 8091.85 toks/s][A
Processed prompts:  16%|‚ñà‚ñã        | 653/4000 [01:11<04:39, 11.97it/s, est. speed input: 871.93 toks/s, output: 8157.44 toks/s][A
Processed prompts:  16%|‚ñà‚ñã        | 656/4000 [01:11<05:24, 10.32it/s, est. speed input: 870.55 toks/s, output: 8205.93 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 663/4000 [01:11<03:27, 16.11it/s, est. speed input: 877.57 toks/s, output: 8256.83 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 666/4000 [01:12<03:13, 17.24it/s, est. speed input: 879.01 toks/s, output: 8272.70 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 669/4000 [01:12<04:38, 11.94it/s, est. speed input: 875.59 toks/s, output: 8227.00 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 675/4000 [01:12<03:50, 14.43it/s, est. speed input: 878.25 toks/s, output: 8220.49 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 677/4000 [01:14<09:13,  6.01it/s, est. speed input: 864.45 toks/s, output: 8155.54 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 682/4000 [01:14<08:23,  6.59it/s, est. speed input: 864.65 toks/s, output: 8193.82 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 687/4000 [01:15<06:55,  7.98it/s, est. speed input: 864.93 toks/s, output: 8357.40 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 695/4000 [01:15<06:03,  9.10it/s, est. speed input: 862.01 toks/s, output: 8601.81 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 701/4000 [01:16<05:20, 10.28it/s, est. speed input: 861.95 toks/s, output: 8795.80 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 710/4000 [01:17<05:31,  9.92it/s, est. speed input: 858.66 toks/s, output: 9016.65 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 717/4000 [01:17<04:54, 11.16it/s, est. speed input: 862.79 toks/s, output: 9070.93 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 719/4000 [01:18<05:27, 10.03it/s, est. speed input: 860.78 toks/s, output: 9080.22 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 721/4000 [01:18<07:40,  7.12it/s, est. speed input: 853.29 toks/s, output: 9067.65 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 735/4000 [01:19<04:39, 11.70it/s, est. speed input: 857.91 toks/s, output: 9245.33 toks/s][A
Processed prompts:  19%|‚ñà‚ñä        | 747/4000 [01:19<02:55, 18.56it/s, est. speed input: 866.64 toks/s, output: 9639.59 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 752/4000 [01:20<03:33, 15.20it/s, est. speed input: 866.25 toks/s, output: 9685.95 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 763/4000 [01:20<02:48, 19.23it/s, est. speed input: 871.58 toks/s, output: 9931.42 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 772/4000 [01:20<02:08, 25.22it/s, est. speed input: 876.94 toks/s, output: 10227.29 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 777/4000 [01:20<02:10, 24.71it/s, est. speed input: 879.45 toks/s, output: 10389.65 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 781/4000 [01:22<04:51, 11.06it/s, est. speed input: 872.81 toks/s, output: 10263.35 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 787/4000 [01:22<03:57, 13.52it/s, est. speed input: 886.77 toks/s, output: 10302.06 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 790/4000 [01:22<04:20, 12.32it/s, est. speed input: 892.74 toks/s, output: 10289.75 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 795/4000 [01:22<03:37, 14.71it/s, est. speed input: 910.12 toks/s, output: 10329.16 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 804/4000 [01:23<02:43, 19.59it/s, est. speed input: 913.93 toks/s, output: 10343.35 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 813/4000 [01:23<01:56, 27.24it/s, est. speed input: 919.82 toks/s, output: 10378.37 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 818/4000 [01:23<02:01, 26.24it/s, est. speed input: 923.13 toks/s, output: 10383.33 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 822/4000 [01:23<03:19, 15.92it/s, est. speed input: 919.08 toks/s, output: 10318.31 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 830/4000 [01:24<02:19, 22.70it/s, est. speed input: 924.89 toks/s, output: 10568.06 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 835/4000 [01:25<04:43, 11.16it/s, est. speed input: 918.38 toks/s, output: 10490.87 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 841/4000 [01:25<03:45, 13.99it/s, est. speed input: 924.12 toks/s, output: 10516.65 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 849/4000 [01:25<03:02, 17.28it/s, est. speed input: 929.20 toks/s, output: 10546.81 toks/s][A
Processed prompts:  21%|‚ñà‚ñà‚ñè       | 858/4000 [01:25<02:24, 21.67it/s, est. speed input: 941.64 toks/s, output: 10595.01 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 862/4000 [01:26<03:45, 13.91it/s, est. speed input: 936.66 toks/s, output: 10523.61 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 875/4000 [01:28<04:34, 11.37it/s, est. speed input: 937.05 toks/s, output: 10440.49 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 878/4000 [01:28<04:32, 11.44it/s, est. speed input: 939.87 toks/s, output: 10442.92 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 882/4000 [01:28<04:04, 12.74it/s, est. speed input: 940.38 toks/s, output: 10438.86 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 884/4000 [01:28<05:02, 10.30it/s, est. speed input: 938.14 toks/s, output: 10399.87 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 887/4000 [01:29<04:23, 11.81it/s, est. speed input: 941.87 toks/s, output: 10418.06 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 889/4000 [01:30<08:01,  6.46it/s, est. speed input: 932.55 toks/s, output: 10370.77 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 899/4000 [01:30<04:04, 12.68it/s, est. speed input: 946.47 toks/s, output: 10482.38 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 902/4000 [01:30<05:35,  9.23it/s, est. speed input: 942.06 toks/s, output: 10454.24 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 905/4000 [01:31<04:53, 10.54it/s, est. speed input: 942.90 toks/s, output: 10481.24 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 915/4000 [01:31<02:46, 18.56it/s, est. speed input: 951.18 toks/s, output: 10536.52 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 919/4000 [01:31<02:38, 19.39it/s, est. speed input: 952.68 toks/s, output: 10591.60 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 923/4000 [01:32<06:45,  7.58it/s, est. speed input: 939.63 toks/s, output: 10466.46 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 926/4000 [01:33<06:44,  7.60it/s, est. speed input: 937.79 toks/s, output: 10439.33 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 929/4000 [01:33<07:20,  6.98it/s, est. speed input: 934.62 toks/s, output: 10396.65 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 931/4000 [01:33<06:49,  7.49it/s, est. speed input: 936.51 toks/s, output: 10403.04 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 933/4000 [01:34<06:34,  7.77it/s, est. speed input: 937.96 toks/s, output: 10404.64 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 938/4000 [01:34<04:28, 11.39it/s, est. speed input: 944.74 toks/s, output: 10446.45 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñé       | 941/4000 [01:34<04:42, 10.85it/s, est. speed input: 945.01 toks/s, output: 10440.52 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñé       | 946/4000 [01:35<05:06,  9.95it/s, est. speed input: 944.46 toks/s, output: 10425.97 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 951/4000 [01:35<03:47, 13.43it/s, est. speed input: 947.83 toks/s, output: 10455.60 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 954/4000 [01:35<03:21, 15.10it/s, est. speed input: 949.27 toks/s, output: 10470.79 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 957/4000 [01:36<05:50,  8.69it/s, est. speed input: 944.32 toks/s, output: 10408.31 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 960/4000 [01:36<04:54, 10.32it/s, est. speed input: 945.76 toks/s, output: 10405.61 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 968/4000 [01:36<03:41, 13.71it/s, est. speed input: 951.36 toks/s, output: 10420.05 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 970/4000 [01:37<04:01, 12.54it/s, est. speed input: 950.92 toks/s, output: 10406.78 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 977/4000 [01:37<02:46, 18.19it/s, est. speed input: 956.07 toks/s, output: 10434.88 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 980/4000 [01:37<04:06, 12.23it/s, est. speed input: 953.38 toks/s, output: 10435.67 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñç       | 985/4000 [01:38<04:26, 11.30it/s, est. speed input: 952.51 toks/s, output: 10455.61 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñç       | 992/4000 [01:38<03:40, 13.65it/s, est. speed input: 954.21 toks/s, output: 10610.49 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñç       | 996/4000 [01:38<03:11, 15.69it/s, est. speed input: 958.65 toks/s, output: 10633.77 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 1002/4000 [01:39<03:16, 15.29it/s, est. speed input: 969.64 toks/s, output: 10644.54 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 1005/4000 [01:39<03:00, 16.63it/s, est. speed input: 971.23 toks/s, output: 10647.91 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 1012/4000 [01:39<02:58, 16.77it/s, est. speed input: 973.75 toks/s, output: 10652.74 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 1018/4000 [01:40<03:34, 13.88it/s, est. speed input: 973.49 toks/s, output: 10661.10 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 1021/4000 [01:41<04:18, 11.51it/s, est. speed input: 973.47 toks/s, output: 10639.10 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 1023/4000 [01:41<04:50, 10.26it/s, est. speed input: 973.35 toks/s, output: 10623.34 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 1027/4000 [01:43<12:15,  4.04it/s, est. speed input: 956.14 toks/s, output: 10414.22 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 1029/4000 [01:43<11:37,  4.26it/s, est. speed input: 954.91 toks/s, output: 10396.50 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 1039/4000 [01:44<07:28,  6.60it/s, est. speed input: 957.40 toks/s, output: 10380.27 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 1042/4000 [01:45<08:17,  5.95it/s, est. speed input: 953.69 toks/s, output: 10336.36 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 1043/4000 [01:45<08:25,  5.86it/s, est. speed input: 953.12 toks/s, output: 10326.26 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñã       | 1050/4000 [01:47<11:23,  4.32it/s, est. speed input: 941.42 toks/s, output: 10201.10 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñã       | 1052/4000 [01:47<09:59,  4.92it/s, est. speed input: 941.80 toks/s, output: 10248.52 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñã       | 1056/4000 [01:47<07:37,  6.43it/s, est. speed input: 942.60 toks/s, output: 10343.68 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñã       | 1059/4000 [01:48<06:21,  7.71it/s, est. speed input: 944.02 toks/s, output: 10366.79 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 1066/4000 [01:48<04:05, 11.96it/s, est. speed input: 949.60 toks/s, output: 10383.39 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 1069/4000 [01:48<03:49, 12.78it/s, est. speed input: 950.45 toks/s, output: 10383.10 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 1076/4000 [01:48<03:01, 16.13it/s, est. speed input: 954.27 toks/s, output: 10388.41 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 1079/4000 [01:48<03:03, 15.95it/s, est. speed input: 955.66 toks/s, output: 10383.04 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 1085/4000 [01:49<04:13, 11.52it/s, est. speed input: 957.12 toks/s, output: 10343.74 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 1089/4000 [01:49<03:32, 13.67it/s, est. speed input: 961.27 toks/s, output: 10355.11 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 1093/4000 [01:50<03:07, 15.52it/s, est. speed input: 964.36 toks/s, output: 10358.02 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 1099/4000 [01:50<02:26, 19.77it/s, est. speed input: 973.92 toks/s, output: 10378.79 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1102/4000 [01:50<02:55, 16.52it/s, est. speed input: 976.60 toks/s, output: 10369.03 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1105/4000 [01:50<03:24, 14.16it/s, est. speed input: 975.98 toks/s, output: 10353.78 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1107/4000 [01:51<04:09, 11.61it/s, est. speed input: 974.64 toks/s, output: 10334.12 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1110/4000 [01:51<03:42, 13.01it/s, est. speed input: 975.30 toks/s, output: 10334.89 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1113/4000 [01:51<03:32, 13.59it/s, est. speed input: 975.91 toks/s, output: 10328.15 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1117/4000 [01:52<05:30,  8.71it/s, est. speed input: 973.08 toks/s, output: 10262.35 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1121/4000 [01:53<08:47,  5.46it/s, est. speed input: 965.71 toks/s, output: 10159.75 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1124/4000 [01:53<08:17,  5.78it/s, est. speed input: 965.12 toks/s, output: 10147.65 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1125/4000 [01:55<13:31,  3.54it/s, est. speed input: 956.13 toks/s, output: 10058.26 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1127/4000 [01:55<12:11,  3.93it/s, est. speed input: 955.55 toks/s, output: 10049.21 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1128/4000 [01:55<11:56,  4.01it/s, est. speed input: 954.43 toks/s, output: 10042.99 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1129/4000 [01:55<11:30,  4.16it/s, est. speed input: 953.71 toks/s, output: 10029.24 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1130/4000 [01:56<10:54,  4.38it/s, est. speed input: 953.15 toks/s, output: 10017.21 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1133/4000 [01:56<10:12,  4.68it/s, est. speed input: 951.88 toks/s, output: 9982.23 toks/s] [A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1135/4000 [01:56<09:23,  5.09it/s, est. speed input: 951.73 toks/s, output: 9966.57 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 1139/4000 [01:57<09:16,  5.15it/s, est. speed input: 948.21 toks/s, output: 9911.03 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñä       | 1143/4000 [01:58<08:16,  5.75it/s, est. speed input: 947.36 toks/s, output: 9879.34 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñä       | 1145/4000 [01:58<07:53,  6.03it/s, est. speed input: 948.60 toks/s, output: 9874.67 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñä       | 1146/4000 [01:58<08:13,  5.78it/s, est. speed input: 948.57 toks/s, output: 9865.81 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 1152/4000 [01:59<05:08,  9.22it/s, est. speed input: 953.23 toks/s, output: 9870.54 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 1153/4000 [02:00<13:32,  3.51it/s, est. speed input: 940.95 toks/s, output: 9740.11 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 1154/4000 [02:00<12:27,  3.81it/s, est. speed input: 941.93 toks/s, output: 9735.21 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 1156/4000 [02:00<09:42,  4.88it/s, est. speed input: 943.34 toks/s, output: 9735.83 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 1158/4000 [02:01<13:07,  3.61it/s, est. speed input: 937.58 toks/s, output: 9675.70 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 1160/4000 [02:02<10:16,  4.60it/s, est. speed input: 937.31 toks/s, output: 9675.71 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 1165/4000 [02:02<06:22,  7.42it/s, est. speed input: 937.50 toks/s, output: 9688.67 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 1167/4000 [02:02<08:06,  5.82it/s, est. speed input: 934.28 toks/s, output: 9650.19 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 1171/4000 [02:03<08:30,  5.55it/s, est. speed input: 930.86 toks/s, output: 9620.34 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 1175/4000 [02:04<07:22,  6.38it/s, est. speed input: 929.74 toks/s, output: 9598.87 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 1181/4000 [02:04<04:37, 10.14it/s, est. speed input: 934.44 toks/s, output: 9645.99 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 1187/4000 [02:04<03:44, 12.52it/s, est. speed input: 936.80 toks/s, output: 9712.00 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 1190/4000 [02:04<03:25, 13.64it/s, est. speed input: 938.69 toks/s, output: 9759.99 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 1198/4000 [02:04<02:18, 20.23it/s, est. speed input: 940.97 toks/s, output: 9944.12 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 1201/4000 [02:04<02:10, 21.52it/s, est. speed input: 942.82 toks/s, output: 10009.69 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 1207/4000 [02:05<01:57, 23.82it/s, est. speed input: 952.36 toks/s, output: 10140.67 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 1210/4000 [02:06<05:37,  8.27it/s, est. speed input: 947.10 toks/s, output: 10096.41 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 1213/4000 [02:06<04:55,  9.44it/s, est. speed input: 947.12 toks/s, output: 10090.03 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 1216/4000 [02:06<04:46,  9.73it/s, est. speed input: 946.60 toks/s, output: 10082.34 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 1219/4000 [02:07<06:34,  7.05it/s, est. speed input: 942.32 toks/s, output: 10032.46 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 1221/4000 [02:08<07:48,  5.93it/s, est. speed input: 939.15 toks/s, output: 9992.50 toks/s] [A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 1227/4000 [02:08<04:43,  9.78it/s, est. speed input: 940.96 toks/s, output: 9989.65 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 1230/4000 [02:08<04:01, 11.46it/s, est. speed input: 946.45 toks/s, output: 9989.53 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 1234/4000 [02:09<06:52,  6.71it/s, est. speed input: 956.19 toks/s, output: 9932.27 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 1236/4000 [02:09<06:52,  6.71it/s, est. speed input: 958.32 toks/s, output: 9915.20 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 1239/4000 [02:11<10:43,  4.29it/s, est. speed input: 953.26 toks/s, output: 9822.74 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 1241/4000 [02:11<09:41,  4.74it/s, est. speed input: 952.41 toks/s, output: 9811.71 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 1244/4000 [02:11<07:09,  6.41it/s, est. speed input: 952.77 toks/s, output: 9811.18 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà‚ñè      | 1251/4000 [02:12<05:33,  8.24it/s, est. speed input: 952.03 toks/s, output: 9795.94 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà‚ñè      | 1253/4000 [02:12<05:00,  9.15it/s, est. speed input: 954.06 toks/s, output: 9797.69 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà‚ñè      | 1255/4000 [02:12<05:16,  8.68it/s, est. speed input: 953.34 toks/s, output: 9788.65 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà‚ñè      | 1257/4000 [02:13<10:33,  4.33it/s, est. speed input: 945.31 toks/s, output: 9711.87 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 1260/4000 [02:14<10:00,  4.56it/s, est. speed input: 947.39 toks/s, output: 9690.45 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 1265/4000 [02:14<06:19,  7.21it/s, est. speed input: 948.53 toks/s, output: 9695.83 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 1268/4000 [02:15<06:33,  6.94it/s, est. speed input: 948.19 toks/s, output: 9673.20 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 1270/4000 [02:15<07:15,  6.27it/s, est. speed input: 945.83 toks/s, output: 9687.23 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 1271/4000 [02:15<07:09,  6.35it/s, est. speed input: 946.90 toks/s, output: 9681.57 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 1272/4000 [02:15<07:28,  6.08it/s, est. speed input: 947.13 toks/s, output: 9680.49 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 1277/4000 [02:16<04:08, 10.94it/s, est. speed input: 953.20 toks/s, output: 9747.67 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 1283/4000 [02:16<02:34, 17.63it/s, est. speed input: 956.26 toks/s, output: 9857.39 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 1286/4000 [02:18<10:10,  4.44it/s, est. speed input: 942.47 toks/s, output: 9769.51 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 1290/4000 [02:18<07:27,  6.06it/s, est. speed input: 943.08 toks/s, output: 9834.40 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 1293/4000 [02:18<07:19,  6.16it/s, est. speed input: 941.32 toks/s, output: 9837.12 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 1302/4000 [02:19<03:54, 11.52it/s, est. speed input: 951.41 toks/s, output: 9975.28 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 1305/4000 [02:19<04:04, 11.00it/s, est. speed input: 950.76 toks/s, output: 9973.71 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 1309/4000 [02:19<03:19, 13.47it/s, est. speed input: 951.94 toks/s, output: 9990.03 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 1312/4000 [02:19<03:35, 12.45it/s, est. speed input: 951.31 toks/s, output: 9982.58 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 1315/4000 [02:20<06:05,  7.34it/s, est. speed input: 946.85 toks/s, output: 9929.24 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 1317/4000 [02:21<06:28,  6.91it/s, est. speed input: 945.44 toks/s, output: 9907.40 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 1322/4000 [02:21<04:18, 10.35it/s, est. speed input: 947.02 toks/s, output: 9910.72 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 1326/4000 [02:21<04:03, 10.96it/s, est. speed input: 947.29 toks/s, output: 9899.00 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 1328/4000 [02:21<04:04, 10.93it/s, est. speed input: 947.78 toks/s, output: 9896.41 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 1331/4000 [02:21<03:47, 11.75it/s, est. speed input: 950.10 toks/s, output: 9914.03 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñé      | 1344/4000 [02:22<01:37, 27.18it/s, est. speed input: 955.77 toks/s, output: 10153.83 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñé      | 1349/4000 [02:22<01:45, 25.10it/s, est. speed input: 956.21 toks/s, output: 10244.43 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 1353/4000 [02:22<02:21, 18.66it/s, est. speed input: 955.05 toks/s, output: 10301.81 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 1356/4000 [02:22<02:12, 20.01it/s, est. speed input: 955.47 toks/s, output: 10358.70 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 1359/4000 [02:23<05:08,  8.57it/s, est. speed input: 949.53 toks/s, output: 10306.34 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 1362/4000 [02:24<05:18,  8.27it/s, est. speed input: 948.31 toks/s, output: 10341.47 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 1365/4000 [02:24<05:18,  8.27it/s, est. speed input: 947.36 toks/s, output: 10360.78 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 1369/4000 [02:24<04:29,  9.77it/s, est. speed input: 947.48 toks/s, output: 10407.45 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 1371/4000 [02:25<04:33,  9.61it/s, est. speed input: 947.00 toks/s, output: 10433.86 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 1376/4000 [02:25<03:13, 13.53it/s, est. speed input: 948.33 toks/s, output: 10509.33 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 1381/4000 [02:25<02:30, 17.44it/s, est. speed input: 949.34 toks/s, output: 10525.79 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 1384/4000 [02:26<06:32,  6.66it/s, est. speed input: 942.93 toks/s, output: 10465.55 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 1386/4000 [02:27<08:15,  5.27it/s, est. speed input: 938.98 toks/s, output: 10455.62 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 1389/4000 [02:27<06:21,  6.85it/s, est. speed input: 939.33 toks/s, output: 10510.40 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 1393/4000 [02:27<05:10,  8.40it/s, est. speed input: 939.50 toks/s, output: 10560.93 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 1395/4000 [02:28<04:40,  9.30it/s, est. speed input: 940.48 toks/s, output: 10567.74 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 1399/4000 [02:28<04:24,  9.82it/s, est. speed input: 941.34 toks/s, output: 10567.95 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 1408/4000 [02:28<03:29, 12.36it/s, est. speed input: 942.26 toks/s, output: 10574.10 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 1410/4000 [02:29<04:56,  8.72it/s, est. speed input: 939.46 toks/s, output: 10553.72 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 1412/4000 [02:30<07:17,  5.92it/s, est. speed input: 935.22 toks/s, output: 10501.07 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 1414/4000 [02:30<06:42,  6.43it/s, est. speed input: 935.08 toks/s, output: 10494.45 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 1415/4000 [02:30<06:58,  6.18it/s, est. speed input: 934.40 toks/s, output: 10500.50 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 1417/4000 [02:30<05:48,  7.42it/s, est. speed input: 934.83 toks/s, output: 10516.47 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 1421/4000 [02:31<04:08, 10.39it/s, est. speed input: 935.99 toks/s, output: 10535.58 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 1430/4000 [02:33<07:14,  5.91it/s, est. speed input: 941.98 toks/s, output: 10489.21 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 1432/4000 [02:33<06:49,  6.28it/s, est. speed input: 941.83 toks/s, output: 10482.38 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 1434/4000 [02:33<06:20,  6.75it/s, est. speed input: 941.85 toks/s, output: 10475.74 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 1436/4000 [02:33<06:16,  6.82it/s, est. speed input: 941.15 toks/s, output: 10464.82 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 1437/4000 [02:34<07:21,  5.80it/s, est. speed input: 939.58 toks/s, output: 10449.40 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 1438/4000 [02:34<08:29,  5.03it/s, est. speed input: 937.79 toks/s, output: 10445.96 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 1442/4000 [02:34<05:03,  8.44it/s, est. speed input: 938.37 toks/s, output: 10517.98 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 1444/4000 [02:34<04:34,  9.30it/s, est. speed input: 938.08 toks/s, output: 10547.54 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 1446/4000 [02:36<11:12,  3.80it/s, est. speed input: 930.51 toks/s, output: 10492.70 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 1448/4000 [02:36<09:05,  4.68it/s, est. speed input: 930.52 toks/s, output: 10520.84 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñã      | 1450/4000 [02:37<10:33,  4.02it/s, est. speed input: 930.15 toks/s, output: 10501.94 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñã      | 1454/4000 [02:37<07:24,  5.73it/s, est. speed input: 930.34 toks/s, output: 10542.65 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñã      | 1457/4000 [02:37<06:08,  6.91it/s, est. speed input: 930.59 toks/s, output: 10553.94 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñã      | 1459/4000 [02:37<05:35,  7.57it/s, est. speed input: 930.29 toks/s, output: 10580.69 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 1462/4000 [02:37<04:12, 10.06it/s, est. speed input: 931.41 toks/s, output: 10601.36 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 1464/4000 [02:37<03:42, 11.38it/s, est. speed input: 932.14 toks/s, output: 10602.56 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 1470/4000 [02:38<02:28, 17.00it/s, est. speed input: 933.71 toks/s, output: 10706.71 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 1473/4000 [02:38<02:33, 16.48it/s, est. speed input: 934.34 toks/s, output: 10735.99 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 1477/4000 [02:38<02:15, 18.67it/s, est. speed input: 936.00 toks/s, output: 10756.18 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 1481/4000 [02:38<02:16, 18.46it/s, est. speed input: 936.74 toks/s, output: 10752.50 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 1484/4000 [02:39<03:11, 13.16it/s, est. speed input: 935.67 toks/s, output: 10731.72 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 1486/4000 [02:39<03:14, 12.95it/s, est. speed input: 937.88 toks/s, output: 10736.90 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 1489/4000 [02:39<03:00, 13.89it/s, est. speed input: 940.36 toks/s, output: 10742.36 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 1491/4000 [02:39<03:22, 12.40it/s, est. speed input: 939.78 toks/s, output: 10730.44 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 1497/4000 [02:39<02:09, 19.28it/s, est. speed input: 944.90 toks/s, output: 10772.34 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 1500/4000 [02:39<02:00, 20.82it/s, est. speed input: 946.91 toks/s, output: 10781.27 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 1503/4000 [02:40<01:51, 22.35it/s, est. speed input: 947.91 toks/s, output: 10786.49 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 1506/4000 [02:40<02:36, 15.94it/s, est. speed input: 947.74 toks/s, output: 10791.83 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 1510/4000 [02:40<02:13, 18.63it/s, est. speed input: 949.26 toks/s, output: 10831.88 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 1513/4000 [02:40<02:19, 17.81it/s, est. speed input: 949.56 toks/s, output: 10837.09 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 1516/4000 [02:41<04:23,  9.42it/s, est. speed input: 948.82 toks/s, output: 10806.58 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 1521/4000 [02:41<03:13, 12.78it/s, est. speed input: 956.56 toks/s, output: 10814.11 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 1525/4000 [02:41<02:33, 16.17it/s, est. speed input: 972.52 toks/s, output: 10816.80 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 1529/4000 [02:41<02:04, 19.77it/s, est. speed input: 989.96 toks/s, output: 10812.14 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 1532/4000 [02:41<01:58, 20.78it/s, est. speed input: 996.60 toks/s, output: 10809.67 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 1538/4000 [02:42<01:33, 26.34it/s, est. speed input: 1000.09 toks/s, output: 10832.31 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñä      | 1542/4000 [02:42<02:37, 15.65it/s, est. speed input: 999.71 toks/s, output: 10815.61 toks/s] [A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñä      | 1546/4000 [02:43<03:46, 10.83it/s, est. speed input: 998.66 toks/s, output: 10788.52 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1551/4000 [02:43<02:53, 14.15it/s, est. speed input: 999.91 toks/s, output: 10843.12 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1555/4000 [02:43<02:31, 16.11it/s, est. speed input: 1000.76 toks/s, output: 10845.73 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1558/4000 [02:43<02:15, 18.02it/s, est. speed input: 1001.12 toks/s, output: 10895.37 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1561/4000 [02:44<02:50, 14.28it/s, est. speed input: 1000.39 toks/s, output: 10915.28 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1564/4000 [02:44<03:01, 13.42it/s, est. speed input: 1000.93 toks/s, output: 10913.79 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1568/4000 [02:44<02:49, 14.32it/s, est. speed input: 1001.24 toks/s, output: 10922.21 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1571/4000 [02:44<03:07, 12.98it/s, est. speed input: 1001.13 toks/s, output: 10919.05 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1575/4000 [02:44<02:44, 14.71it/s, est. speed input: 1001.77 toks/s, output: 10955.87 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1577/4000 [02:45<02:51, 14.15it/s, est. speed input: 1001.60 toks/s, output: 10974.54 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1579/4000 [02:45<04:18,  9.35it/s, est. speed input: 999.71 toks/s, output: 10947.21 toks/s] [A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 1583/4000 [02:45<03:17, 12.27it/s, est. speed input: 1000.63 toks/s, output: 10944.95 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 1587/4000 [02:45<02:29, 16.16it/s, est. speed input: 1001.90 toks/s, output: 10946.49 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 1594/4000 [02:46<02:35, 15.44it/s, est. speed input: 1002.04 toks/s, output: 10931.98 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 1597/4000 [02:47<04:46,  8.38it/s, est. speed input: 997.43 toks/s, output: 10926.39 toks/s] [A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 1607/4000 [02:47<03:05, 12.91it/s, est. speed input: 998.17 toks/s, output: 11072.26 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 1609/4000 [02:48<03:57, 10.05it/s, est. speed input: 996.10 toks/s, output: 11060.00 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 1615/4000 [02:48<02:56, 13.53it/s, est. speed input: 998.48 toks/s, output: 11094.99 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 1618/4000 [02:48<03:02, 13.03it/s, est. speed input: 998.63 toks/s, output: 11087.24 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 1622/4000 [02:48<02:32, 15.60it/s, est. speed input: 999.58 toks/s, output: 11111.95 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 1625/4000 [02:48<02:34, 15.39it/s, est. speed input: 999.99 toks/s, output: 11137.33 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 1630/4000 [02:49<01:56, 20.31it/s, est. speed input: 1001.69 toks/s, output: 11211.63 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 1633/4000 [02:50<06:19,  6.23it/s, est. speed input: 994.02 toks/s, output: 11115.50 toks/s] [A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 1639/4000 [02:50<04:25,  8.90it/s, est. speed input: 995.82 toks/s, output: 11110.77 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 1642/4000 [02:51<05:40,  6.92it/s, est. speed input: 992.78 toks/s, output: 11070.40 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 1645/4000 [02:51<04:49,  8.14it/s, est. speed input: 993.27 toks/s, output: 11069.36 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1650/4000 [02:51<03:24, 11.50it/s, est. speed input: 994.68 toks/s, output: 11074.51 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1653/4000 [02:52<03:49, 10.21it/s, est. speed input: 994.20 toks/s, output: 11056.90 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1656/4000 [02:52<03:48, 10.26it/s, est. speed input: 994.61 toks/s, output: 11050.53 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1658/4000 [02:52<04:04,  9.59it/s, est. speed input: 994.69 toks/s, output: 11038.93 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1667/4000 [02:52<02:03, 18.88it/s, est. speed input: 1001.17 toks/s, output: 11057.31 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1671/4000 [02:53<01:49, 21.19it/s, est. speed input: 1001.89 toks/s, output: 11066.56 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1675/4000 [02:53<02:04, 18.74it/s, est. speed input: 1001.71 toks/s, output: 11065.85 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1678/4000 [02:53<02:28, 15.69it/s, est. speed input: 1012.03 toks/s, output: 11099.91 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1681/4000 [02:54<03:07, 12.34it/s, est. speed input: 1011.92 toks/s, output: 11098.50 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1683/4000 [02:54<03:09, 12.22it/s, est. speed input: 1011.57 toks/s, output: 11122.89 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1685/4000 [02:54<03:27, 11.13it/s, est. speed input: 1010.82 toks/s, output: 11142.86 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1687/4000 [02:54<04:05,  9.41it/s, est. speed input: 1009.61 toks/s, output: 11157.52 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1689/4000 [02:55<04:44,  8.12it/s, est. speed input: 1008.26 toks/s, output: 11156.85 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1691/4000 [02:55<04:03,  9.47it/s, est. speed input: 1008.51 toks/s, output: 11158.69 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1693/4000 [02:55<04:38,  8.30it/s, est. speed input: 1008.04 toks/s, output: 11147.99 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1695/4000 [02:56<09:40,  3.97it/s, est. speed input: 1002.56 toks/s, output: 11083.75 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1699/4000 [02:58<11:44,  3.27it/s, est. speed input: 996.14 toks/s, output: 11023.63 toks/s] [A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1702/4000 [02:58<09:55,  3.86it/s, est. speed input: 994.46 toks/s, output: 11045.53 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1707/4000 [02:58<06:24,  5.97it/s, est. speed input: 997.64 toks/s, output: 11067.80 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1709/4000 [03:00<09:20,  4.09it/s, est. speed input: 992.15 toks/s, output: 11033.62 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1710/4000 [03:00<09:19,  4.09it/s, est. speed input: 991.81 toks/s, output: 11027.11 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1711/4000 [03:00<08:40,  4.40it/s, est. speed input: 991.43 toks/s, output: 11036.10 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1712/4000 [03:00<08:19,  4.58it/s, est. speed input: 991.44 toks/s, output: 11033.59 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1716/4000 [03:00<05:27,  6.97it/s, est. speed input: 992.97 toks/s, output: 11053.32 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1722/4000 [03:01<03:10, 11.94it/s, est. speed input: 996.54 toks/s, output: 11061.46 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1725/4000 [03:01<03:21, 11.28it/s, est. speed input: 996.62 toks/s, output: 11055.53 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1727/4000 [03:01<03:07, 12.10it/s, est. speed input: 996.89 toks/s, output: 11055.36 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1730/4000 [03:01<03:43, 10.16it/s, est. speed input: 996.06 toks/s, output: 11041.96 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1732/4000 [03:02<04:12,  8.98it/s, est. speed input: 995.11 toks/s, output: 11026.23 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1734/4000 [03:02<03:40, 10.28it/s, est. speed input: 995.47 toks/s, output: 11023.29 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1736/4000 [03:02<03:14, 11.66it/s, est. speed input: 996.09 toks/s, output: 11022.97 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1744/4000 [03:02<02:02, 18.44it/s, est. speed input: 998.43 toks/s, output: 11037.03 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1746/4000 [03:02<02:06, 17.80it/s, est. speed input: 998.87 toks/s, output: 11033.06 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1752/4000 [03:02<01:33, 24.11it/s, est. speed input: 1000.17 toks/s, output: 11054.71 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1757/4000 [03:03<01:24, 26.48it/s, est. speed input: 1001.81 toks/s, output: 11059.80 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1762/4000 [03:03<01:12, 30.68it/s, est. speed input: 1003.46 toks/s, output: 11058.20 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1766/4000 [03:03<01:35, 23.49it/s, est. speed input: 1004.05 toks/s, output: 11047.68 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1770/4000 [03:03<01:29, 24.87it/s, est. speed input: 1005.53 toks/s, output: 11049.38 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1776/4000 [03:03<01:35, 23.38it/s, est. speed input: 1007.34 toks/s, output: 11056.73 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1779/4000 [03:04<01:36, 23.03it/s, est. speed input: 1008.19 toks/s, output: 11060.59 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1784/4000 [03:04<02:21, 15.66it/s, est. speed input: 1008.01 toks/s, output: 11049.45 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1787/4000 [03:05<04:01,  9.16it/s, est. speed input: 1004.92 toks/s, output: 11010.30 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1789/4000 [03:05<04:22,  8.42it/s, est. speed input: 1005.90 toks/s, output: 10996.60 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1793/4000 [03:05<03:15, 11.31it/s, est. speed input: 1010.81 toks/s, output: 11001.70 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1799/4000 [03:05<02:10, 16.85it/s, est. speed input: 1015.13 toks/s, output: 11023.98 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1802/4000 [03:06<02:37, 13.94it/s, est. speed input: 1014.79 toks/s, output: 11017.85 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1805/4000 [03:06<02:34, 14.19it/s, est. speed input: 1015.19 toks/s, output: 11018.77 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1808/4000 [03:06<03:00, 12.14it/s, est. speed input: 1014.77 toks/s, output: 11011.04 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1812/4000 [03:08<07:16,  5.01it/s, est. speed input: 1007.03 toks/s, output: 10923.16 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1815/4000 [03:08<05:53,  6.18it/s, est. speed input: 1007.08 toks/s, output: 10947.60 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1817/4000 [03:09<06:38,  5.48it/s, est. speed input: 1004.83 toks/s, output: 10949.40 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1821/4000 [03:09<04:48,  7.56it/s, est. speed input: 1005.47 toks/s, output: 10981.10 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1825/4000 [03:09<04:00,  9.05it/s, est. speed input: 1006.47 toks/s, output: 11001.38 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1827/4000 [03:10<04:11,  8.64it/s, est. speed input: 1005.67 toks/s, output: 11003.51 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1829/4000 [03:10<03:49,  9.48it/s, est. speed input: 1005.67 toks/s, output: 10999.37 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1833/4000 [03:10<04:06,  8.79it/s, est. speed input: 1004.55 toks/s, output: 10977.47 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1835/4000 [03:11<05:53,  6.12it/s, est. speed input: 1001.84 toks/s, output: 10941.29 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1836/4000 [03:11<07:11,  5.02it/s, est. speed input: 1000.33 toks/s, output: 10923.15 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1840/4000 [03:12<06:58,  5.16it/s, est. speed input: 999.47 toks/s, output: 10907.00 toks/s] [A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1842/4000 [03:13<07:34,  4.74it/s, est. speed input: 997.84 toks/s, output: 10888.32 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1846/4000 [03:13<04:53,  7.34it/s, est. speed input: 998.87 toks/s, output: 10912.46 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1851/4000 [03:13<03:08, 11.39it/s, est. speed input: 1001.21 toks/s, output: 10923.74 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1859/4000 [03:13<01:50, 19.45it/s, est. speed input: 1004.72 toks/s, output: 10938.43 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1864/4000 [03:13<01:39, 21.38it/s, est. speed input: 1006.18 toks/s, output: 10958.69 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1868/4000 [03:13<01:41, 20.95it/s, est. speed input: 1006.10 toks/s, output: 11010.69 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1872/4000 [03:14<02:13, 15.96it/s, est. speed input: 1005.22 toks/s, output: 11036.64 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1875/4000 [03:14<02:21, 15.07it/s, est. speed input: 1005.55 toks/s, output: 11029.94 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1878/4000 [03:14<02:03, 17.12it/s, est. speed input: 1006.55 toks/s, output: 11033.08 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1884/4000 [03:14<01:27, 24.14it/s, est. speed input: 1008.78 toks/s, output: 11045.85 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1888/4000 [03:14<01:52, 18.73it/s, est. speed input: 1008.59 toks/s, output: 11044.91 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1891/4000 [03:15<01:49, 19.32it/s, est. speed input: 1008.95 toks/s, output: 11047.22 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1894/4000 [03:15<03:48,  9.22it/s, est. speed input: 1006.18 toks/s, output: 11005.49 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1896/4000 [03:16<04:16,  8.19it/s, est. speed input: 1005.36 toks/s, output: 10990.85 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1898/4000 [03:16<04:28,  7.83it/s, est. speed input: 1004.67 toks/s, output: 10993.49 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1902/4000 [03:16<03:06, 11.23it/s, est. speed input: 1005.60 toks/s, output: 11036.39 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1907/4000 [03:17<04:27,  7.82it/s, est. speed input: 1002.84 toks/s, output: 11050.56 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1909/4000 [03:19<08:54,  3.91it/s, est. speed input: 995.52 toks/s, output: 10974.20 toks/s] [A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1911/4000 [03:19<09:28,  3.68it/s, est. speed input: 992.92 toks/s, output: 10959.73 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1914/4000 [03:20<07:00,  4.96it/s, est. speed input: 993.18 toks/s, output: 10985.17 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1917/4000 [03:20<06:02,  5.74it/s, est. speed input: 992.52 toks/s, output: 10986.49 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1919/4000 [03:20<06:22,  5.45it/s, est. speed input: 990.98 toks/s, output: 10993.46 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1923/4000 [03:20<04:20,  7.98it/s, est. speed input: 992.21 toks/s, output: 11020.82 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1928/4000 [03:21<03:06, 11.13it/s, est. speed input: 993.34 toks/s, output: 11051.87 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1930/4000 [03:21<03:16, 10.52it/s, est. speed input: 992.89 toks/s, output: 11043.74 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1933/4000 [03:21<03:53,  8.85it/s, est. speed input: 991.68 toks/s, output: 11029.78 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1935/4000 [03:22<03:43,  9.25it/s, est. speed input: 991.96 toks/s, output: 11030.47 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1937/4000 [03:22<05:00,  6.85it/s, est. speed input: 990.26 toks/s, output: 11008.87 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1938/4000 [03:22<05:04,  6.78it/s, est. speed input: 990.07 toks/s, output: 11005.60 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1939/4000 [03:22<05:28,  6.27it/s, est. speed input: 989.58 toks/s, output: 10999.20 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1940/4000 [03:23<06:23,  5.37it/s, est. speed input: 989.17 toks/s, output: 10985.23 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1941/4000 [03:23<10:09,  3.38it/s, est. speed input: 986.86 toks/s, output: 10950.47 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1944/4000 [03:24<06:00,  5.70it/s, est. speed input: 989.25 toks/s, output: 10949.57 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1946/4000 [03:24<04:39,  7.35it/s, est. speed input: 990.80 toks/s, output: 10948.62 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1948/4000 [03:26<15:19,  2.23it/s, est. speed input: 982.21 toks/s, output: 10833.04 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1952/4000 [03:26<10:02,  3.40it/s, est. speed input: 982.47 toks/s, output: 10830.25 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1954/4000 [03:27<08:22,  4.07it/s, est. speed input: 982.08 toks/s, output: 10849.32 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1967/4000 [03:27<02:42, 12.54it/s, est. speed input: 985.28 toks/s, output: 11036.10 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1972/4000 [03:27<02:21, 14.31it/s, est. speed input: 986.12 toks/s, output: 11072.51 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1980/4000 [03:27<01:42, 19.71it/s, est. speed input: 988.51 toks/s, output: 11110.26 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1985/4000 [03:27<01:36, 20.91it/s, est. speed input: 989.33 toks/s, output: 11120.55 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1989/4000 [03:28<02:06, 15.93it/s, est. speed input: 989.40 toks/s, output: 11144.01 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1992/4000 [03:28<02:27, 13.59it/s, est. speed input: 989.23 toks/s, output: 11129.79 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1995/4000 [03:28<02:13, 15.04it/s, est. speed input: 990.08 toks/s, output: 11129.31 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1998/4000 [03:29<03:08, 10.63it/s, est. speed input: 988.88 toks/s, output: 11106.92 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2000/4000 [03:29<03:49,  8.72it/s, est. speed input: 989.57 toks/s, output: 11092.83 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2002/4000 [03:30<05:12,  6.40it/s, est. speed input: 988.24 toks/s, output: 11065.11 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2004/4000 [03:30<05:51,  5.68it/s, est. speed input: 986.83 toks/s, output: 11055.69 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2006/4000 [03:32<12:26,  2.67it/s, est. speed input: 978.45 toks/s, output: 10958.25 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2008/4000 [03:32<09:42,  3.42it/s, est. speed input: 978.66 toks/s, output: 10957.52 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2015/4000 [03:33<04:35,  7.21it/s, est. speed input: 980.15 toks/s, output: 10963.75 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2022/4000 [03:33<02:45, 11.98it/s, est. speed input: 982.84 toks/s, output: 10991.74 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2032/4000 [03:33<01:54, 17.22it/s, est. speed input: 985.46 toks/s, output: 11020.89 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2036/4000 [03:33<01:47, 18.34it/s, est. speed input: 986.31 toks/s, output: 11020.38 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2040/4000 [03:33<01:36, 20.38it/s, est. speed input: 986.88 toks/s, output: 11071.42 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2045/4000 [03:33<01:26, 22.71it/s, est. speed input: 987.86 toks/s, output: 11111.39 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2049/4000 [03:34<03:19,  9.80it/s, est. speed input: 983.84 toks/s, output: 11111.90 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2052/4000 [03:35<02:58, 10.90it/s, est. speed input: 984.01 toks/s, output: 11134.84 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2055/4000 [03:35<03:10, 10.19it/s, est. speed input: 983.24 toks/s, output: 11148.22 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2057/4000 [03:35<02:57, 10.97it/s, est. speed input: 983.31 toks/s, output: 11159.57 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2059/4000 [03:36<06:04,  5.33it/s, est. speed input: 980.23 toks/s, output: 11108.73 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2061/4000 [03:36<05:11,  6.22it/s, est. speed input: 981.60 toks/s, output: 11108.38 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2063/4000 [03:37<04:23,  7.36it/s, est. speed input: 982.52 toks/s, output: 11105.24 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2065/4000 [03:38<07:35,  4.25it/s, est. speed input: 978.82 toks/s, output: 11056.34 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2067/4000 [03:38<06:03,  5.32it/s, est. speed input: 978.77 toks/s, output: 11055.17 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2073/4000 [03:38<03:32,  9.07it/s, est. speed input: 979.79 toks/s, output: 11057.02 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2076/4000 [03:38<02:54, 11.00it/s, est. speed input: 981.46 toks/s, output: 11058.23 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2080/4000 [03:38<02:11, 14.61it/s, est. speed input: 983.73 toks/s, output: 11062.51 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2083/4000 [03:38<02:13, 14.36it/s, est. speed input: 987.08 toks/s, output: 11058.46 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2088/4000 [03:39<01:44, 18.25it/s, est. speed input: 991.81 toks/s, output: 11062.92 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2091/4000 [03:39<01:37, 19.52it/s, est. speed input: 993.04 toks/s, output: 11062.15 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2094/4000 [03:39<02:02, 15.61it/s, est. speed input: 993.09 toks/s, output: 11053.37 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2097/4000 [03:39<01:56, 16.39it/s, est. speed input: 996.10 toks/s, output: 11052.43 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2099/4000 [03:43<12:44,  2.49it/s, est. speed input: 981.27 toks/s, output: 10910.51 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2101/4000 [03:43<10:15,  3.08it/s, est. speed input: 981.17 toks/s, output: 10932.13 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2103/4000 [03:43<08:21,  3.78it/s, est. speed input: 980.90 toks/s, output: 10951.70 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2108/4000 [03:43<04:52,  6.48it/s, est. speed input: 982.01 toks/s, output: 10978.61 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2111/4000 [03:43<04:03,  7.76it/s, est. speed input: 982.37 toks/s, output: 10976.04 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2113/4000 [03:43<03:58,  7.92it/s, est. speed input: 982.22 toks/s, output: 10969.04 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2115/4000 [03:44<03:33,  8.82it/s, est. speed input: 982.47 toks/s, output: 10966.60 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2120/4000 [03:44<02:17, 13.64it/s, est. speed input: 983.95 toks/s, output: 10972.29 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2123/4000 [03:45<04:45,  6.57it/s, est. speed input: 980.59 toks/s, output: 10941.63 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2125/4000 [03:45<04:24,  7.08it/s, est. speed input: 980.60 toks/s, output: 10950.67 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2127/4000 [03:45<03:49,  8.17it/s, est. speed input: 981.72 toks/s, output: 10950.24 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2129/4000 [03:45<04:05,  7.62it/s, est. speed input: 981.83 toks/s, output: 10939.98 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2132/4000 [03:46<04:23,  7.10it/s, est. speed input: 981.50 toks/s, output: 10924.28 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2135/4000 [03:46<03:33,  8.74it/s, est. speed input: 982.07 toks/s, output: 10934.02 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2137/4000 [03:47<05:03,  6.14it/s, est. speed input: 980.10 toks/s, output: 10908.28 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2144/4000 [03:47<02:36, 11.83it/s, est. speed input: 982.04 toks/s, output: 10974.89 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2149/4000 [03:47<02:07, 14.52it/s, est. speed input: 982.49 toks/s, output: 11032.58 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2152/4000 [03:47<01:52, 16.41it/s, est. speed input: 983.22 toks/s, output: 11056.30 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2159/4000 [03:47<01:18, 23.53it/s, est. speed input: 984.80 toks/s, output: 11098.12 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2163/4000 [03:48<01:36, 19.05it/s, est. speed input: 985.47 toks/s, output: 11090.46 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2166/4000 [03:48<01:41, 18.02it/s, est. speed input: 985.79 toks/s, output: 11089.15 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2173/4000 [03:48<02:03, 14.79it/s, est. speed input: 987.50 toks/s, output: 11076.58 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2175/4000 [03:49<03:07,  9.74it/s, est. speed input: 985.61 toks/s, output: 11052.30 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2177/4000 [03:49<02:54, 10.46it/s, est. speed input: 985.67 toks/s, output: 11051.21 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2183/4000 [03:49<02:30, 12.04it/s, est. speed input: 985.87 toks/s, output: 11047.08 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2187/4000 [03:50<02:08, 14.16it/s, est. speed input: 986.84 toks/s, output: 11048.04 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2190/4000 [03:51<05:12,  5.79it/s, est. speed input: 981.64 toks/s, output: 10984.39 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2192/4000 [03:51<04:34,  6.59it/s, est. speed input: 981.86 toks/s, output: 10983.33 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2194/4000 [03:52<05:02,  5.97it/s, est. speed input: 980.42 toks/s, output: 10964.02 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2197/4000 [03:52<03:58,  7.56it/s, est. speed input: 980.45 toks/s, output: 10959.66 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2200/4000 [03:52<03:04,  9.75it/s, est. speed input: 981.09 toks/s, output: 10962.90 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2203/4000 [03:52<03:09,  9.47it/s, est. speed input: 980.42 toks/s, output: 10962.29 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2208/4000 [03:52<02:05, 14.25it/s, est. speed input: 981.34 toks/s, output: 11023.26 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2211/4000 [03:53<02:16, 13.15it/s, est. speed input: 982.57 toks/s, output: 11022.94 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2214/4000 [03:53<02:50, 10.50it/s, est. speed input: 982.59 toks/s, output: 11023.89 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2216/4000 [03:54<03:24,  8.71it/s, est. speed input: 981.61 toks/s, output: 11008.98 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2223/4000 [03:54<01:54, 15.49it/s, est. speed input: 983.23 toks/s, output: 11025.61 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2226/4000 [03:55<04:12,  7.04it/s, est. speed input: 979.36 toks/s, output: 10979.63 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2229/4000 [03:55<03:56,  7.49it/s, est. speed input: 979.66 toks/s, output: 10971.92 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2231/4000 [03:55<03:41,  7.97it/s, est. speed input: 979.54 toks/s, output: 10989.41 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2234/4000 [03:56<03:12,  9.17it/s, est. speed input: 980.26 toks/s, output: 11001.25 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2236/4000 [03:56<03:09,  9.29it/s, est. speed input: 980.05 toks/s, output: 11017.71 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2240/4000 [03:56<02:44, 10.72it/s, est. speed input: 980.17 toks/s, output: 11047.11 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2242/4000 [03:56<02:28, 11.80it/s, est. speed input: 980.86 toks/s, output: 11057.84 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2246/4000 [03:57<03:07,  9.37it/s, est. speed input: 980.63 toks/s, output: 11041.32 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 2250/4000 [03:57<02:16, 12.82it/s, est. speed input: 982.22 toks/s, output: 11043.86 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 2253/4000 [03:58<03:54,  7.46it/s, est. speed input: 980.07 toks/s, output: 11012.88 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 2255/4000 [03:58<03:34,  8.14it/s, est. speed input: 980.07 toks/s, output: 11013.07 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 2257/4000 [03:58<03:21,  8.64it/s, est. speed input: 986.21 toks/s, output: 11008.96 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 2263/4000 [03:58<01:57, 14.82it/s, est. speed input: 1006.40 toks/s, output: 11017.01 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 2266/4000 [03:58<02:02, 14.17it/s, est. speed input: 1006.96 toks/s, output: 11014.28 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 2269/4000 [03:59<02:25, 11.92it/s, est. speed input: 1007.40 toks/s, output: 11006.62 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 2271/4000 [03:59<03:15,  8.84it/s, est. speed input: 1006.53 toks/s, output: 10991.52 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 2273/4000 [04:00<04:35,  6.27it/s, est. speed input: 1004.61 toks/s, output: 10966.49 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 2276/4000 [04:00<03:47,  7.59it/s, est. speed input: 1004.49 toks/s, output: 10962.45 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 2278/4000 [04:00<03:13,  8.88it/s, est. speed input: 1004.60 toks/s, output: 10961.92 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 2280/4000 [04:01<05:19,  5.38it/s, est. speed input: 1001.77 toks/s, output: 10950.84 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 2282/4000 [04:01<04:18,  6.66it/s, est. speed input: 1002.31 toks/s, output: 10962.41 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 2287/4000 [04:01<03:08,  9.06it/s, est. speed input: 1003.51 toks/s, output: 10971.52 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 2290/4000 [04:02<02:43, 10.47it/s, est. speed input: 1003.55 toks/s, output: 10990.80 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 2292/4000 [04:02<02:29, 11.39it/s, est. speed input: 1003.58 toks/s, output: 10989.41 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 2294/4000 [04:02<04:30,  6.31it/s, est. speed input: 1000.87 toks/s, output: 10957.11 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 2296/4000 [04:03<05:04,  5.60it/s, est. speed input: 1000.32 toks/s, output: 10943.53 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 2299/4000 [04:03<03:39,  7.77it/s, est. speed input: 1001.06 toks/s, output: 10945.30 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 2308/4000 [04:03<01:50, 15.30it/s, est. speed input: 1003.96 toks/s, output: 10956.80 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 2312/4000 [04:03<01:31, 18.41it/s, est. speed input: 1004.43 toks/s, output: 10959.26 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 2315/4000 [04:03<01:28, 18.98it/s, est. speed input: 1004.95 toks/s, output: 10958.61 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 2318/4000 [04:04<01:31, 18.36it/s, est. speed input: 1004.97 toks/s, output: 10954.74 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 2321/4000 [04:04<01:31, 18.32it/s, est. speed input: 1005.15 toks/s, output: 10953.11 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 2325/4000 [04:04<01:23, 19.94it/s, est. speed input: 1005.71 toks/s, output: 10964.90 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 2329/4000 [04:04<01:15, 22.04it/s, est. speed input: 1006.21 toks/s, output: 10967.70 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 2332/4000 [04:04<01:22, 20.22it/s, est. speed input: 1006.42 toks/s, output: 10968.38 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 2335/4000 [04:05<01:55, 14.41it/s, est. speed input: 1005.64 toks/s, output: 10959.19 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 2341/4000 [04:05<01:20, 20.58it/s, est. speed input: 1006.79 toks/s, output: 10972.43 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 2345/4000 [04:05<01:26, 19.19it/s, est. speed input: 1007.09 toks/s, output: 10978.35 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 2348/4000 [04:05<01:32, 17.78it/s, est. speed input: 1007.42 toks/s, output: 10977.28 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 2351/4000 [04:05<01:37, 16.99it/s, est. speed input: 1007.92 toks/s, output: 10978.36 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 2353/4000 [04:06<01:50, 14.88it/s, est. speed input: 1007.53 toks/s, output: 10984.06 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 2356/4000 [04:06<01:51, 14.77it/s, est. speed input: 1007.74 toks/s, output: 10991.55 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 2364/4000 [04:06<01:04, 25.28it/s, est. speed input: 1009.03 toks/s, output: 11086.11 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 2371/4000 [04:06<00:59, 27.39it/s, est. speed input: 1009.94 toks/s, output: 11142.57 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 2375/4000 [04:06<01:01, 26.58it/s, est. speed input: 1010.67 toks/s, output: 11164.28 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 2378/4000 [04:06<01:02, 26.05it/s, est. speed input: 1011.37 toks/s, output: 11175.35 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 2384/4000 [04:07<01:08, 23.51it/s, est. speed input: 1012.43 toks/s, output: 11236.47 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 2387/4000 [04:08<03:12,  8.38it/s, est. speed input: 1008.75 toks/s, output: 11198.88 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 2395/4000 [04:08<01:57, 13.66it/s, est. speed input: 1011.38 toks/s, output: 11266.64 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 2399/4000 [04:08<01:40, 15.90it/s, est. speed input: 1012.23 toks/s, output: 11279.47 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 2405/4000 [04:08<01:15, 21.08it/s, est. speed input: 1013.99 toks/s, output: 11292.63 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 2410/4000 [04:08<01:03, 25.19it/s, est. speed input: 1016.48 toks/s, output: 11325.78 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 2416/4000 [04:09<00:51, 31.05it/s, est. speed input: 1017.80 toks/s, output: 11347.35 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 2427/4000 [04:09<00:34, 46.01it/s, est. speed input: 1020.98 toks/s, output: 11394.47 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 2434/4000 [04:09<00:30, 51.17it/s, est. speed input: 1022.96 toks/s, output: 11421.07 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 2441/4000 [04:09<01:00, 25.81it/s, est. speed input: 1023.56 toks/s, output: 11425.52 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 2446/4000 [04:10<01:45, 14.69it/s, est. speed input: 1022.18 toks/s, output: 11401.05 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2450/4000 [04:10<01:44, 14.78it/s, est. speed input: 1022.61 toks/s, output: 11401.36 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2454/4000 [04:11<02:02, 12.67it/s, est. speed input: 1022.00 toks/s, output: 11392.57 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2460/4000 [04:11<01:34, 16.32it/s, est. speed input: 1022.66 toks/s, output: 11390.84 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2463/4000 [04:12<02:25, 10.57it/s, est. speed input: 1020.40 toks/s, output: 11384.18 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2468/4000 [04:12<01:57, 13.05it/s, est. speed input: 1020.79 toks/s, output: 11417.38 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2472/4000 [04:12<01:44, 14.67it/s, est. speed input: 1020.98 toks/s, output: 11449.37 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2475/4000 [04:13<03:18,  7.69it/s, est. speed input: 1017.58 toks/s, output: 11407.15 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2477/4000 [04:13<03:00,  8.44it/s, est. speed input: 1017.62 toks/s, output: 11404.91 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2481/4000 [04:14<02:48,  9.02it/s, est. speed input: 1017.31 toks/s, output: 11394.30 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2483/4000 [04:14<02:45,  9.18it/s, est. speed input: 1017.10 toks/s, output: 11387.61 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2486/4000 [04:14<02:16, 11.09it/s, est. speed input: 1017.37 toks/s, output: 11384.89 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2488/4000 [04:14<02:10, 11.56it/s, est. speed input: 1017.59 toks/s, output: 11381.25 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2494/4000 [04:15<02:20, 10.72it/s, est. speed input: 1016.76 toks/s, output: 11361.02 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2497/4000 [04:15<02:00, 12.45it/s, est. speed input: 1017.78 toks/s, output: 11361.68 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2503/4000 [04:15<01:50, 13.61it/s, est. speed input: 1019.57 toks/s, output: 11357.31 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2507/4000 [04:16<01:44, 14.34it/s, est. speed input: 1019.72 toks/s, output: 11366.71 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2509/4000 [04:16<02:01, 12.28it/s, est. speed input: 1019.11 toks/s, output: 11369.54 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2516/4000 [04:16<01:16, 19.45it/s, est. speed input: 1020.31 toks/s, output: 11418.62 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2521/4000 [04:16<01:01, 24.17it/s, est. speed input: 1021.07 toks/s, output: 11474.05 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2527/4000 [04:16<01:03, 23.24it/s, est. speed input: 1021.47 toks/s, output: 11524.59 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2531/4000 [04:16<01:00, 24.08it/s, est. speed input: 1021.96 toks/s, output: 11547.93 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2536/4000 [04:17<00:53, 27.46it/s, est. speed input: 1023.04 toks/s, output: 11570.52 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2546/4000 [04:17<00:58, 24.74it/s, est. speed input: 1024.13 toks/s, output: 11612.08 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2549/4000 [04:17<01:01, 23.54it/s, est. speed input: 1024.22 toks/s, output: 11640.72 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2555/4000 [04:17<00:54, 26.50it/s, est. speed input: 1025.06 toks/s, output: 11695.80 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2558/4000 [04:18<01:22, 17.47it/s, est. speed input: 1024.15 toks/s, output: 11703.39 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2561/4000 [04:18<01:15, 19.05it/s, est. speed input: 1024.55 toks/s, output: 11715.57 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2564/4000 [04:18<01:44, 13.73it/s, est. speed input: 1023.68 toks/s, output: 11702.83 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2569/4000 [04:19<01:33, 15.32it/s, est. speed input: 1024.21 toks/s, output: 11711.31 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2573/4000 [04:19<01:18, 18.21it/s, est. speed input: 1024.77 toks/s, output: 11723.70 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2576/4000 [04:19<01:17, 18.39it/s, est. speed input: 1024.95 toks/s, output: 11743.09 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2580/4000 [04:19<01:17, 18.31it/s, est. speed input: 1025.29 toks/s, output: 11753.42 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2583/4000 [04:19<01:13, 19.21it/s, est. speed input: 1025.61 toks/s, output: 11755.55 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2586/4000 [04:19<01:06, 21.20it/s, est. speed input: 1025.93 toks/s, output: 11756.95 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2598/4000 [04:19<00:38, 36.70it/s, est. speed input: 1028.38 toks/s, output: 11832.94 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2602/4000 [04:20<00:48, 28.99it/s, est. speed input: 1028.66 toks/s, output: 11850.99 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2606/4000 [04:22<04:11,  5.55it/s, est. speed input: 1020.01 toks/s, output: 11747.07 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2609/4000 [04:22<03:35,  6.44it/s, est. speed input: 1020.17 toks/s, output: 11757.65 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2614/4000 [04:23<02:40,  8.63it/s, est. speed input: 1020.80 toks/s, output: 11790.11 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2617/4000 [04:24<03:39,  6.30it/s, est. speed input: 1017.95 toks/s, output: 11774.53 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2621/4000 [04:24<03:29,  6.58it/s, est. speed input: 1016.79 toks/s, output: 11777.84 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2624/4000 [04:24<02:51,  8.02it/s, est. speed input: 1017.19 toks/s, output: 11778.85 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2634/4000 [04:24<01:29, 15.26it/s, est. speed input: 1019.48 toks/s, output: 11793.82 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2638/4000 [04:24<01:20, 16.84it/s, est. speed input: 1019.97 toks/s, output: 11796.89 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2649/4000 [04:25<00:49, 27.12it/s, est. speed input: 1023.17 toks/s, output: 11817.81 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2656/4000 [04:25<01:11, 18.92it/s, est. speed input: 1024.68 toks/s, output: 11807.42 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2661/4000 [04:26<01:11, 18.75it/s, est. speed input: 1025.82 toks/s, output: 11812.95 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2665/4000 [04:26<01:31, 14.67it/s, est. speed input: 1025.52 toks/s, output: 11803.81 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2668/4000 [04:26<01:33, 14.28it/s, est. speed input: 1025.60 toks/s, output: 11802.79 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2671/4000 [04:27<02:28,  8.96it/s, est. speed input: 1023.56 toks/s, output: 11774.83 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2684/4000 [04:27<01:16, 17.31it/s, est. speed input: 1026.05 toks/s, output: 11780.59 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2692/4000 [04:27<01:02, 20.82it/s, est. speed input: 1027.52 toks/s, output: 11783.10 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2696/4000 [04:29<02:42,  8.04it/s, est. speed input: 1022.02 toks/s, output: 11715.10 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2699/4000 [04:30<03:09,  6.86it/s, est. speed input: 1020.23 toks/s, output: 11693.93 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2704/4000 [04:30<02:24,  8.94it/s, est. speed input: 1021.14 toks/s, output: 11722.07 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2707/4000 [04:30<02:09, 10.02it/s, est. speed input: 1021.12 toks/s, output: 11749.43 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2719/4000 [04:31<01:14, 17.28it/s, est. speed input: 1024.46 toks/s, output: 11785.45 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2722/4000 [04:33<03:17,  6.46it/s, est. speed input: 1019.77 toks/s, output: 11717.12 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2725/4000 [04:34<04:39,  4.57it/s, est. speed input: 1016.86 toks/s, output: 11667.45 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2729/4000 [04:35<04:46,  4.43it/s, est. speed input: 1014.52 toks/s, output: 11635.08 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2732/4000 [04:35<03:56,  5.37it/s, est. speed input: 1015.04 toks/s, output: 11633.36 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2737/4000 [04:35<02:53,  7.29it/s, est. speed input: 1015.86 toks/s, output: 11631.07 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2739/4000 [04:36<02:51,  7.35it/s, est. speed input: 1015.39 toks/s, output: 11622.86 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2741/4000 [04:36<02:41,  7.80it/s, est. speed input: 1015.18 toks/s, output: 11627.37 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2749/4000 [04:36<01:28, 14.16it/s, est. speed input: 1018.71 toks/s, output: 11683.13 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2753/4000 [04:36<01:22, 15.05it/s, est. speed input: 1019.56 toks/s, output: 11700.93 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2756/4000 [04:36<01:16, 16.32it/s, est. speed input: 1019.77 toks/s, output: 11704.19 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2766/4000 [04:36<00:43, 28.33it/s, est. speed input: 1025.44 toks/s, output: 11718.05 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2771/4000 [04:37<00:40, 30.48it/s, est. speed input: 1027.94 toks/s, output: 11718.09 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2776/4000 [04:37<00:37, 32.46it/s, est. speed input: 1028.85 toks/s, output: 11725.92 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2782/4000 [04:37<00:32, 37.25it/s, est. speed input: 1030.95 toks/s, output: 11732.68 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2787/4000 [04:37<00:41, 29.16it/s, est. speed input: 1031.36 toks/s, output: 11733.07 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2791/4000 [04:37<01:02, 19.50it/s, est. speed input: 1032.17 toks/s, output: 11723.07 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2794/4000 [04:38<01:40, 11.97it/s, est. speed input: 1031.80 toks/s, output: 11706.08 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2799/4000 [04:39<01:38, 12.19it/s, est. speed input: 1035.12 toks/s, output: 11696.15 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2807/4000 [04:39<01:05, 18.24it/s, est. speed input: 1037.97 toks/s, output: 11707.43 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2810/4000 [04:39<01:02, 19.04it/s, est. speed input: 1038.43 toks/s, output: 11716.21 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2813/4000 [04:39<01:00, 19.49it/s, est. speed input: 1038.73 toks/s, output: 11725.99 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2816/4000 [04:39<00:58, 20.22it/s, est. speed input: 1039.29 toks/s, output: 11733.19 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2819/4000 [04:40<01:30, 12.98it/s, est. speed input: 1038.65 toks/s, output: 11724.12 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2821/4000 [04:41<03:53,  5.05it/s, est. speed input: 1033.97 toks/s, output: 11669.47 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2826/4000 [04:41<02:30,  7.80it/s, est. speed input: 1034.32 toks/s, output: 11667.54 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2829/4000 [04:44<07:18,  2.67it/s, est. speed input: 1023.14 toks/s, output: 11539.08 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2831/4000 [04:45<06:31,  2.99it/s, est. speed input: 1022.99 toks/s, output: 11532.72 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2833/4000 [04:45<05:51,  3.32it/s, est. speed input: 1023.62 toks/s, output: 11521.62 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2835/4000 [04:45<04:59,  3.89it/s, est. speed input: 1023.35 toks/s, output: 11519.00 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2838/4000 [04:45<03:35,  5.39it/s, est. speed input: 1023.72 toks/s, output: 11523.80 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2840/4000 [04:46<03:43,  5.19it/s, est. speed input: 1022.62 toks/s, output: 11509.70 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2843/4000 [04:46<02:42,  7.13it/s, est. speed input: 1022.85 toks/s, output: 11509.76 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2845/4000 [04:46<03:09,  6.10it/s, est. speed input: 1021.69 toks/s, output: 11495.74 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2847/4000 [04:47<02:43,  7.06it/s, est. speed input: 1021.65 toks/s, output: 11494.49 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2849/4000 [04:47<03:00,  6.39it/s, est. speed input: 1020.77 toks/s, output: 11483.93 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2851/4000 [04:47<02:28,  7.73it/s, est. speed input: 1021.09 toks/s, output: 11486.39 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2853/4000 [04:48<03:38,  5.26it/s, est. speed input: 1019.26 toks/s, output: 11465.94 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2855/4000 [04:48<03:29,  5.46it/s, est. speed input: 1018.82 toks/s, output: 11460.25 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2856/4000 [04:49<04:10,  4.57it/s, est. speed input: 1017.87 toks/s, output: 11448.83 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2858/4000 [04:49<03:43,  5.10it/s, est. speed input: 1017.57 toks/s, output: 11446.68 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2861/4000 [04:49<02:29,  7.61it/s, est. speed input: 1019.91 toks/s, output: 11447.94 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2864/4000 [04:49<02:09,  8.77it/s, est. speed input: 1021.19 toks/s, output: 11448.67 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2866/4000 [04:49<02:13,  8.48it/s, est. speed input: 1020.70 toks/s, output: 11442.53 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2870/4000 [04:50<01:38, 11.52it/s, est. speed input: 1020.89 toks/s, output: 11443.58 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2872/4000 [04:50<01:56,  9.66it/s, est. speed input: 1020.19 toks/s, output: 11435.16 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2874/4000 [04:50<02:21,  7.93it/s, est. speed input: 1019.70 toks/s, output: 11428.66 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2875/4000 [04:51<02:50,  6.59it/s, est. speed input: 1019.10 toks/s, output: 11421.40 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2876/4000 [04:51<03:26,  5.43it/s, est. speed input: 1018.31 toks/s, output: 11409.98 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2879/4000 [04:51<02:13,  8.41it/s, est. speed input: 1019.20 toks/s, output: 11416.36 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2882/4000 [04:51<02:04,  8.98it/s, est. speed input: 1019.44 toks/s, output: 11408.43 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2884/4000 [04:52<02:06,  8.84it/s, est. speed input: 1019.00 toks/s, output: 11401.10 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2890/4000 [04:52<01:12, 15.23it/s, est. speed input: 1020.99 toks/s, output: 11399.06 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2895/4000 [04:52<00:56, 19.57it/s, est. speed input: 1022.34 toks/s, output: 11401.09 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2898/4000 [04:52<01:24, 13.11it/s, est. speed input: 1021.80 toks/s, output: 11388.24 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2901/4000 [04:52<01:11, 15.35it/s, est. speed input: 1022.16 toks/s, output: 11389.70 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2904/4000 [04:53<01:07, 16.16it/s, est. speed input: 1022.25 toks/s, output: 11387.58 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2907/4000 [04:53<01:02, 17.37it/s, est. speed input: 1022.83 toks/s, output: 11396.30 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2910/4000 [04:53<02:00,  9.05it/s, est. speed input: 1021.36 toks/s, output: 11376.27 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2913/4000 [04:54<02:08,  8.46it/s, est. speed input: 1020.81 toks/s, output: 11367.26 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2915/4000 [04:54<02:11,  8.28it/s, est. speed input: 1020.26 toks/s, output: 11360.07 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2918/4000 [04:54<01:42, 10.51it/s, est. speed input: 1020.38 toks/s, output: 11359.73 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2921/4000 [04:54<01:22, 13.13it/s, est. speed input: 1021.12 toks/s, output: 11361.90 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2924/4000 [04:55<01:34, 11.45it/s, est. speed input: 1021.26 toks/s, output: 11359.01 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2926/4000 [04:55<01:29, 11.99it/s, est. speed input: 1021.65 toks/s, output: 11357.66 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2930/4000 [04:55<01:04, 16.50it/s, est. speed input: 1023.75 toks/s, output: 11363.21 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2933/4000 [04:56<02:36,  6.81it/s, est. speed input: 1021.51 toks/s, output: 11331.90 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2935/4000 [04:56<02:18,  7.68it/s, est. speed input: 1022.41 toks/s, output: 11332.07 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2938/4000 [04:56<01:52,  9.45it/s, est. speed input: 1023.92 toks/s, output: 11334.40 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2941/4000 [04:56<01:36, 10.95it/s, est. speed input: 1025.02 toks/s, output: 11338.25 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2943/4000 [04:57<01:53,  9.32it/s, est. speed input: 1025.99 toks/s, output: 11327.61 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2945/4000 [04:57<02:44,  6.41it/s, est. speed input: 1024.58 toks/s, output: 11314.60 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2947/4000 [04:58<03:17,  5.32it/s, est. speed input: 1023.09 toks/s, output: 11297.13 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2950/4000 [04:58<02:29,  7.03it/s, est. speed input: 1023.13 toks/s, output: 11299.42 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2953/4000 [04:58<01:52,  9.28it/s, est. speed input: 1023.38 toks/s, output: 11304.05 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2955/4000 [04:59<02:05,  8.33it/s, est. speed input: 1023.41 toks/s, output: 11298.65 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2957/4000 [05:01<07:41,  2.26it/s, est. speed input: 1014.82 toks/s, output: 11207.61 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2958/4000 [05:02<07:20,  2.36it/s, est. speed input: 1014.24 toks/s, output: 11196.93 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2960/4000 [05:02<05:21,  3.24it/s, est. speed input: 1014.71 toks/s, output: 11198.14 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2962/4000 [05:02<04:12,  4.11it/s, est. speed input: 1014.82 toks/s, output: 11194.48 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2967/4000 [05:02<02:16,  7.59it/s, est. speed input: 1016.18 toks/s, output: 11197.32 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2969/4000 [05:02<02:08,  8.03it/s, est. speed input: 1016.15 toks/s, output: 11197.54 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2971/4000 [05:03<02:44,  6.24it/s, est. speed input: 1015.32 toks/s, output: 11179.91 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2973/4000 [05:03<02:20,  7.30it/s, est. speed input: 1015.82 toks/s, output: 11176.94 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2975/4000 [05:03<02:43,  6.26it/s, est. speed input: 1014.96 toks/s, output: 11171.03 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2977/4000 [05:04<02:29,  6.85it/s, est. speed input: 1014.84 toks/s, output: 11173.39 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2981/4000 [05:04<01:59,  8.54it/s, est. speed input: 1016.31 toks/s, output: 11176.52 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2983/4000 [05:05<04:34,  3.70it/s, est. speed input: 1011.70 toks/s, output: 11141.61 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2985/4000 [05:06<03:40,  4.61it/s, est. speed input: 1011.69 toks/s, output: 11157.20 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2987/4000 [05:06<04:26,  3.80it/s, est. speed input: 1010.13 toks/s, output: 11140.65 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2989/4000 [05:07<04:33,  3.70it/s, est. speed input: 1008.63 toks/s, output: 11139.81 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2991/4000 [05:07<04:13,  3.98it/s, est. speed input: 1008.30 toks/s, output: 11137.18 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2992/4000 [05:08<05:56,  2.83it/s, est. speed input: 1006.31 toks/s, output: 11108.45 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2996/4000 [05:08<03:16,  5.10it/s, est. speed input: 1007.61 toks/s, output: 11132.33 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2998/4000 [05:09<02:54,  5.74it/s, est. speed input: 1008.86 toks/s, output: 11144.22 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3000/4000 [05:09<02:51,  5.84it/s, est. speed input: 1009.00 toks/s, output: 11152.32 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3004/4000 [05:09<01:51,  8.91it/s, est. speed input: 1009.67 toks/s, output: 11174.95 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3009/4000 [05:09<01:25, 11.57it/s, est. speed input: 1009.91 toks/s, output: 11214.92 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3011/4000 [05:10<01:38, 10.04it/s, est. speed input: 1009.95 toks/s, output: 11216.27 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3014/4000 [05:10<01:18, 12.50it/s, est. speed input: 1011.71 toks/s, output: 11220.23 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3016/4000 [05:11<03:08,  5.21it/s, est. speed input: 1008.60 toks/s, output: 11182.31 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3020/4000 [05:11<02:05,  7.81it/s, est. speed input: 1009.20 toks/s, output: 11184.01 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3023/4000 [05:11<01:38,  9.91it/s, est. speed input: 1009.54 toks/s, output: 11184.37 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3026/4000 [05:12<01:51,  8.74it/s, est. speed input: 1008.87 toks/s, output: 11172.71 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3028/4000 [05:12<01:43,  9.38it/s, est. speed input: 1009.08 toks/s, output: 11173.99 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3031/4000 [05:12<01:24, 11.47it/s, est. speed input: 1009.61 toks/s, output: 11177.31 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3035/4000 [05:12<01:18, 12.33it/s, est. speed input: 1009.84 toks/s, output: 11174.73 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3037/4000 [05:13<02:45,  5.82it/s, est. speed input: 1007.29 toks/s, output: 11143.21 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3039/4000 [05:13<02:19,  6.91it/s, est. speed input: 1007.61 toks/s, output: 11152.39 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3041/4000 [05:13<02:05,  7.62it/s, est. speed input: 1007.95 toks/s, output: 11152.54 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3046/4000 [05:14<01:28, 10.80it/s, est. speed input: 1008.71 toks/s, output: 11179.72 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3048/4000 [05:14<01:47,  8.84it/s, est. speed input: 1007.92 toks/s, output: 11185.79 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3052/4000 [05:14<01:26, 10.90it/s, est. speed input: 1007.92 toks/s, output: 11216.81 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3054/4000 [05:14<01:25, 11.13it/s, est. speed input: 1008.03 toks/s, output: 11216.22 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3056/4000 [05:15<01:20, 11.70it/s, est. speed input: 1007.87 toks/s, output: 11230.67 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3058/4000 [05:15<01:13, 12.90it/s, est. speed input: 1007.81 toks/s, output: 11246.33 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3061/4000 [05:15<01:24, 11.09it/s, est. speed input: 1007.34 toks/s, output: 11256.30 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3063/4000 [05:15<01:15, 12.43it/s, est. speed input: 1007.65 toks/s, output: 11257.95 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3066/4000 [05:16<01:36,  9.67it/s, est. speed input: 1007.24 toks/s, output: 11251.51 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3068/4000 [05:16<01:24, 11.05it/s, est. speed input: 1007.52 toks/s, output: 11267.29 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3070/4000 [05:16<01:41,  9.18it/s, est. speed input: 1007.22 toks/s, output: 11268.31 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3072/4000 [05:17<02:26,  6.33it/s, est. speed input: 1006.14 toks/s, output: 11258.16 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3073/4000 [05:17<02:36,  5.93it/s, est. speed input: 1005.78 toks/s, output: 11254.37 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3074/4000 [05:17<03:06,  4.96it/s, est. speed input: 1004.83 toks/s, output: 11251.93 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3078/4000 [05:17<01:49,  8.42it/s, est. speed input: 1004.85 toks/s, output: 11284.62 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3082/4000 [05:18<01:35,  9.60it/s, est. speed input: 1004.38 toks/s, output: 11311.27 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3084/4000 [05:18<01:28, 10.38it/s, est. speed input: 1004.46 toks/s, output: 11320.08 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3088/4000 [05:18<01:04, 14.13it/s, est. speed input: 1004.77 toks/s, output: 11354.07 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3090/4000 [05:18<01:02, 14.48it/s, est. speed input: 1004.73 toks/s, output: 11368.85 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3096/4000 [05:18<00:41, 21.99it/s, est. speed input: 1005.71 toks/s, output: 11413.33 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3099/4000 [05:19<01:10, 12.86it/s, est. speed input: 1004.99 toks/s, output: 11406.06 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 3102/4000 [05:19<01:33,  9.58it/s, est. speed input: 1003.94 toks/s, output: 11416.00 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 3104/4000 [05:19<01:40,  8.96it/s, est. speed input: 1003.46 toks/s, output: 11425.22 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 3106/4000 [05:20<01:29, 10.00it/s, est. speed input: 1003.49 toks/s, output: 11432.11 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 3109/4000 [05:20<01:13, 12.13it/s, est. speed input: 1003.70 toks/s, output: 11431.91 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 3118/4000 [05:20<00:51, 17.27it/s, est. speed input: 1004.55 toks/s, output: 11464.78 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 3120/4000 [05:20<01:06, 13.30it/s, est. speed input: 1003.98 toks/s, output: 11463.54 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 3128/4000 [05:21<00:40, 21.65it/s, est. speed input: 1005.23 toks/s, output: 11536.18 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 3132/4000 [05:21<00:41, 20.69it/s, est. speed input: 1005.43 toks/s, output: 11550.05 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 3135/4000 [05:21<00:43, 19.72it/s, est. speed input: 1005.25 toks/s, output: 11572.30 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 3138/4000 [05:21<00:50, 16.98it/s, est. speed input: 1005.05 toks/s, output: 11583.30 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 3141/4000 [05:22<01:20, 10.74it/s, est. speed input: 1003.67 toks/s, output: 11582.73 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 3143/4000 [05:22<01:17, 11.06it/s, est. speed input: 1003.58 toks/s, output: 11580.06 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 3146/4000 [05:22<01:06, 12.88it/s, est. speed input: 1003.75 toks/s, output: 11579.56 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 3148/4000 [05:23<01:58,  7.17it/s, est. speed input: 1001.86 toks/s, output: 11564.62 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 3153/4000 [05:23<01:19, 10.59it/s, est. speed input: 1002.21 toks/s, output: 11593.98 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 3155/4000 [05:23<01:19, 10.67it/s, est. speed input: 1001.95 toks/s, output: 11606.45 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 3159/4000 [05:24<01:21, 10.28it/s, est. speed input: 1001.50 toks/s, output: 11623.73 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 3161/4000 [05:24<01:20, 10.45it/s, est. speed input: 1001.54 toks/s, output: 11636.27 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 3163/4000 [05:25<02:56,  4.75it/s, est. speed input: 998.42 toks/s, output: 11612.21 toks/s] [A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 3164/4000 [05:26<03:36,  3.87it/s, est. speed input: 996.95 toks/s, output: 11596.15 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 3165/4000 [05:26<04:38,  3.00it/s, est. speed input: 995.01 toks/s, output: 11574.60 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 3168/4000 [05:26<03:00,  4.60it/s, est. speed input: 995.39 toks/s, output: 11597.05 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 3169/4000 [05:28<05:54,  2.35it/s, est. speed input: 991.84 toks/s, output: 11550.14 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 3171/4000 [05:30<08:36,  1.60it/s, est. speed input: 986.72 toks/s, output: 11484.63 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 3178/4000 [05:30<03:25,  3.99it/s, est. speed input: 987.72 toks/s, output: 11492.92 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 3180/4000 [05:31<03:31,  3.88it/s, est. speed input: 986.48 toks/s, output: 11475.19 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 3182/4000 [05:31<03:00,  4.54it/s, est. speed input: 986.33 toks/s, output: 11487.42 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 3189/4000 [05:32<02:11,  6.17it/s, est. speed input: 985.49 toks/s, output: 11518.18 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 3192/4000 [05:32<01:47,  7.54it/s, est. speed input: 986.08 toks/s, output: 11527.95 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 3195/4000 [05:32<01:27,  9.21it/s, est. speed input: 986.48 toks/s, output: 11528.53 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3200/4000 [05:32<01:01, 13.02it/s, est. speed input: 987.51 toks/s, output: 11537.67 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3203/4000 [05:32<00:56, 14.07it/s, est. speed input: 987.93 toks/s, output: 11544.32 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3207/4000 [05:32<00:46, 17.19it/s, est. speed input: 988.67 toks/s, output: 11552.58 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3210/4000 [05:32<00:44, 17.59it/s, est. speed input: 989.18 toks/s, output: 11562.38 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3214/4000 [05:33<01:11, 10.94it/s, est. speed input: 988.31 toks/s, output: 11553.37 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3218/4000 [05:33<00:55, 14.17it/s, est. speed input: 988.73 toks/s, output: 11552.53 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3221/4000 [05:34<01:28,  8.75it/s, est. speed input: 987.18 toks/s, output: 11529.83 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3224/4000 [05:34<01:24,  9.22it/s, est. speed input: 986.91 toks/s, output: 11524.55 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3226/4000 [05:34<01:16, 10.13it/s, est. speed input: 987.12 toks/s, output: 11527.70 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3229/4000 [05:34<01:00, 12.66it/s, est. speed input: 987.68 toks/s, output: 11535.13 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3233/4000 [05:35<00:46, 16.42it/s, est. speed input: 988.39 toks/s, output: 11540.96 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3236/4000 [05:35<00:52, 14.66it/s, est. speed input: 988.53 toks/s, output: 11536.43 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3239/4000 [05:35<00:48, 15.61it/s, est. speed input: 989.59 toks/s, output: 11536.20 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3241/4000 [05:35<01:18,  9.71it/s, est. speed input: 988.78 toks/s, output: 11521.67 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3243/4000 [05:36<01:12, 10.42it/s, est. speed input: 989.15 toks/s, output: 11522.05 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3245/4000 [05:36<01:13, 10.28it/s, est. speed input: 989.34 toks/s, output: 11520.55 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3247/4000 [05:38<04:23,  2.86it/s, est. speed input: 984.60 toks/s, output: 11457.54 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3249/4000 [05:38<03:53,  3.22it/s, est. speed input: 984.59 toks/s, output: 11459.20 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 3252/4000 [05:38<02:37,  4.74it/s, est. speed input: 985.11 toks/s, output: 11482.26 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 3256/4000 [05:39<01:54,  6.49it/s, est. speed input: 985.43 toks/s, output: 11508.58 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 3258/4000 [05:39<01:55,  6.44it/s, est. speed input: 984.81 toks/s, output: 11515.86 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 3261/4000 [05:39<01:35,  7.78it/s, est. speed input: 984.62 toks/s, output: 11535.47 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 3263/4000 [05:39<01:21,  9.06it/s, est. speed input: 984.63 toks/s, output: 11550.03 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 3265/4000 [05:40<01:48,  6.78it/s, est. speed input: 983.57 toks/s, output: 11550.66 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 3270/4000 [05:40<01:03, 11.42it/s, est. speed input: 984.62 toks/s, output: 11592.12 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 3273/4000 [05:40<01:14,  9.79it/s, est. speed input: 984.23 toks/s, output: 11598.91 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 3276/4000 [05:41<01:43,  6.98it/s, est. speed input: 982.95 toks/s, output: 11583.74 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 3279/4000 [05:41<01:21,  8.87it/s, est. speed input: 983.41 toks/s, output: 11589.18 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 3281/4000 [05:41<01:11, 10.09it/s, est. speed input: 983.62 toks/s, output: 11591.26 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 3283/4000 [05:42<01:36,  7.45it/s, est. speed input: 982.79 toks/s, output: 11579.23 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 3285/4000 [05:42<01:24,  8.50it/s, est. speed input: 983.00 toks/s, output: 11582.47 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 3287/4000 [05:42<01:40,  7.07it/s, est. speed input: 982.42 toks/s, output: 11572.65 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 3289/4000 [05:43<01:42,  6.97it/s, est. speed input: 981.89 toks/s, output: 11580.50 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 3292/4000 [05:43<01:12,  9.74it/s, est. speed input: 982.39 toks/s, output: 11591.77 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 3294/4000 [05:43<01:24,  8.31it/s, est. speed input: 981.77 toks/s, output: 11590.63 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 3297/4000 [05:43<01:07, 10.35it/s, est. speed input: 981.88 toks/s, output: 11589.35 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 3299/4000 [05:44<01:52,  6.21it/s, est. speed input: 980.16 toks/s, output: 11569.03 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 3305/4000 [05:44<01:03, 11.00it/s, est. speed input: 980.68 toks/s, output: 11572.58 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 3307/4000 [05:44<01:01, 11.25it/s, est. speed input: 980.54 toks/s, output: 11584.98 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 3310/4000 [05:44<00:52, 13.11it/s, est. speed input: 980.65 toks/s, output: 11599.48 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 3312/4000 [05:45<01:04, 10.61it/s, est. speed input: 980.35 toks/s, output: 11593.01 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 3319/4000 [05:45<00:41, 16.29it/s, est. speed input: 981.49 toks/s, output: 11600.91 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 3321/4000 [05:45<01:05, 10.44it/s, est. speed input: 980.72 toks/s, output: 11589.48 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 3323/4000 [05:46<01:02, 10.81it/s, est. speed input: 980.70 toks/s, output: 11588.04 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 3326/4000 [05:46<01:29,  7.53it/s, est. speed input: 979.38 toks/s, output: 11572.82 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 3328/4000 [05:47<02:11,  5.13it/s, est. speed input: 978.00 toks/s, output: 11549.82 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 3331/4000 [05:47<01:44,  6.42it/s, est. speed input: 978.47 toks/s, output: 11547.97 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 3333/4000 [05:47<01:28,  7.51it/s, est. speed input: 978.80 toks/s, output: 11552.12 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 3336/4000 [05:48<01:07,  9.79it/s, est. speed input: 978.90 toks/s, output: 11551.29 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 3339/4000 [05:48<00:57, 11.56it/s, est. speed input: 978.90 toks/s, output: 11549.17 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 3341/4000 [05:48<01:02, 10.60it/s, est. speed input: 978.56 toks/s, output: 11544.75 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 3343/4000 [05:48<00:56, 11.61it/s, est. speed input: 978.79 toks/s, output: 11545.81 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 3346/4000 [05:49<01:14,  8.81it/s, est. speed input: 978.49 toks/s, output: 11532.43 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 3348/4000 [05:49<01:21,  8.02it/s, est. speed input: 978.33 toks/s, output: 11525.60 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 3350/4000 [05:49<01:10,  9.24it/s, est. speed input: 978.83 toks/s, output: 11523.32 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 3355/4000 [05:49<00:44, 14.41it/s, est. speed input: 981.17 toks/s, output: 11525.92 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 3357/4000 [05:50<01:17,  8.28it/s, est. speed input: 979.88 toks/s, output: 11509.02 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 3361/4000 [05:50<00:56, 11.35it/s, est. speed input: 980.51 toks/s, output: 11510.79 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 3365/4000 [05:50<00:53, 11.88it/s, est. speed input: 980.74 toks/s, output: 11509.87 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 3373/4000 [05:50<00:32, 19.07it/s, est. speed input: 981.91 toks/s, output: 11543.20 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 3376/4000 [05:51<00:53, 11.61it/s, est. speed input: 980.87 toks/s, output: 11535.33 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 3378/4000 [05:51<00:54, 11.35it/s, est. speed input: 980.88 toks/s, output: 11539.60 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 3380/4000 [05:52<01:04,  9.64it/s, est. speed input: 980.50 toks/s, output: 11539.06 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 3383/4000 [05:52<00:54, 11.29it/s, est. speed input: 980.76 toks/s, output: 11546.17 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 3385/4000 [05:52<01:00, 10.16it/s, est. speed input: 980.31 toks/s, output: 11540.80 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 3387/4000 [05:52<00:58, 10.52it/s, est. speed input: 980.17 toks/s, output: 11545.76 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 3390/4000 [05:52<00:48, 12.65it/s, est. speed input: 980.28 toks/s, output: 11542.81 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 3392/4000 [05:52<00:44, 13.51it/s, est. speed input: 980.24 toks/s, output: 11542.54 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 3394/4000 [05:53<00:41, 14.72it/s, est. speed input: 980.30 toks/s, output: 11540.37 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 3396/4000 [05:53<00:41, 14.56it/s, est. speed input: 980.24 toks/s, output: 11536.89 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3400/4000 [05:53<00:54, 11.04it/s, est. speed input: 979.58 toks/s, output: 11526.43 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3403/4000 [05:55<02:28,  4.03it/s, est. speed input: 975.46 toks/s, output: 11475.83 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3405/4000 [05:55<02:30,  3.96it/s, est. speed input: 974.49 toks/s, output: 11463.89 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3408/4000 [05:56<02:03,  4.79it/s, est. speed input: 974.30 toks/s, output: 11469.74 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3410/4000 [05:56<01:43,  5.68it/s, est. speed input: 974.41 toks/s, output: 11478.63 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3413/4000 [05:56<01:36,  6.06it/s, est. speed input: 973.88 toks/s, output: 11475.66 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3415/4000 [05:57<01:35,  6.11it/s, est. speed input: 973.43 toks/s, output: 11475.19 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3420/4000 [05:57<01:09,  8.37it/s, est. speed input: 973.50 toks/s, output: 11499.52 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3422/4000 [05:57<01:00,  9.53it/s, est. speed input: 973.78 toks/s, output: 11498.35 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3424/4000 [05:58<01:12,  7.99it/s, est. speed input: 973.71 toks/s, output: 11495.60 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3428/4000 [05:58<00:55, 10.22it/s, est. speed input: 974.41 toks/s, output: 11515.12 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3432/4000 [05:58<00:45, 12.38it/s, est. speed input: 974.86 toks/s, output: 11520.28 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3435/4000 [05:58<00:40, 13.93it/s, est. speed input: 975.03 toks/s, output: 11534.15 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3439/4000 [05:58<00:33, 16.86it/s, est. speed input: 975.40 toks/s, output: 11551.59 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3443/4000 [05:58<00:27, 20.08it/s, est. speed input: 975.97 toks/s, output: 11555.40 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3446/4000 [05:59<00:26, 20.96it/s, est. speed input: 976.21 toks/s, output: 11561.95 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 3450/4000 [05:59<00:22, 24.72it/s, est. speed input: 976.70 toks/s, output: 11570.56 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 3457/4000 [05:59<00:15, 34.48it/s, est. speed input: 978.25 toks/s, output: 11581.71 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 3461/4000 [05:59<00:33, 15.96it/s, est. speed input: 977.38 toks/s, output: 11567.84 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 3464/4000 [05:59<00:30, 17.81it/s, est. speed input: 977.96 toks/s, output: 11573.67 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 3469/4000 [06:00<00:25, 20.76it/s, est. speed input: 978.35 toks/s, output: 11589.44 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 3474/4000 [06:00<00:23, 22.65it/s, est. speed input: 978.88 toks/s, output: 11616.50 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 3477/4000 [06:00<00:41, 12.48it/s, est. speed input: 977.70 toks/s, output: 11614.98 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 3480/4000 [06:01<00:43, 12.07it/s, est. speed input: 977.60 toks/s, output: 11610.29 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 3482/4000 [06:01<00:45, 11.38it/s, est. speed input: 977.36 toks/s, output: 11612.88 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 3484/4000 [06:01<00:42, 12.18it/s, est. speed input: 977.62 toks/s, output: 11615.59 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 3494/4000 [06:01<00:29, 16.88it/s, est. speed input: 978.52 toks/s, output: 11614.00 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 3496/4000 [06:04<01:43,  4.89it/s, est. speed input: 973.21 toks/s, output: 11549.28 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 3499/4000 [06:04<01:22,  6.09it/s, est. speed input: 973.76 toks/s, output: 11551.70 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 3508/4000 [06:04<00:43, 11.33it/s, est. speed input: 975.33 toks/s, output: 11560.87 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 3512/4000 [06:04<00:44, 10.86it/s, est. speed input: 975.75 toks/s, output: 11551.80 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 3515/4000 [06:05<00:59,  8.20it/s, est. speed input: 974.81 toks/s, output: 11539.83 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 3517/4000 [06:05<01:05,  7.33it/s, est. speed input: 974.09 toks/s, output: 11543.39 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 3519/4000 [06:06<01:05,  7.29it/s, est. speed input: 974.52 toks/s, output: 11535.75 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 3521/4000 [06:06<00:57,  8.26it/s, est. speed input: 975.37 toks/s, output: 11533.08 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 3526/4000 [06:06<00:54,  8.67it/s, est. speed input: 976.42 toks/s, output: 11518.91 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 3529/4000 [06:07<00:56,  8.28it/s, est. speed input: 975.71 toks/s, output: 11507.30 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 3534/4000 [06:07<00:41, 11.16it/s, est. speed input: 976.04 toks/s, output: 11503.64 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 3537/4000 [06:07<00:35, 12.89it/s, est. speed input: 977.12 toks/s, output: 11503.34 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 3540/4000 [06:07<00:32, 13.99it/s, est. speed input: 978.09 toks/s, output: 11501.83 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 3546/4000 [06:07<00:22, 20.60it/s, est. speed input: 979.94 toks/s, output: 11527.19 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 3551/4000 [06:07<00:18, 24.57it/s, est. speed input: 980.83 toks/s, output: 11535.26 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 3555/4000 [06:08<00:24, 18.32it/s, est. speed input: 980.57 toks/s, output: 11534.72 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 3558/4000 [06:08<00:33, 13.25it/s, est. speed input: 981.01 toks/s, output: 11528.15 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 3561/4000 [06:08<00:30, 14.57it/s, est. speed input: 981.63 toks/s, output: 11529.08 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 3564/4000 [06:09<00:42, 10.33it/s, est. speed input: 980.70 toks/s, output: 11523.18 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 3566/4000 [06:09<00:41, 10.46it/s, est. speed input: 980.60 toks/s, output: 11534.13 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 3569/4000 [06:09<00:34, 12.57it/s, est. speed input: 981.16 toks/s, output: 11541.34 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 3574/4000 [06:09<00:26, 16.21it/s, est. speed input: 982.06 toks/s, output: 11542.41 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 3577/4000 [06:10<00:41, 10.23it/s, est. speed input: 980.98 toks/s, output: 11541.23 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 3579/4000 [06:10<00:54,  7.77it/s, est. speed input: 980.15 toks/s, output: 11535.42 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 3581/4000 [06:11<00:48,  8.61it/s, est. speed input: 980.46 toks/s, output: 11534.12 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 3585/4000 [06:11<00:34, 11.98it/s, est. speed input: 981.32 toks/s, output: 11543.25 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 3589/4000 [06:11<00:33, 12.15it/s, est. speed input: 981.49 toks/s, output: 11553.02 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 3591/4000 [06:12<00:51,  7.92it/s, est. speed input: 980.50 toks/s, output: 11538.34 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 3593/4000 [06:12<00:52,  7.76it/s, est. speed input: 980.23 toks/s, output: 11539.94 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 3598/4000 [06:12<00:32, 12.37it/s, est. speed input: 980.91 toks/s, output: 11565.26 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3601/4000 [06:12<00:28, 13.96it/s, est. speed input: 981.18 toks/s, output: 11571.97 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3604/4000 [06:12<00:24, 16.36it/s, est. speed input: 981.55 toks/s, output: 11579.89 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3607/4000 [06:12<00:22, 17.52it/s, est. speed input: 981.72 toks/s, output: 11593.89 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3610/4000 [06:13<00:33, 11.72it/s, est. speed input: 981.08 toks/s, output: 11589.74 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3612/4000 [06:13<00:33, 11.47it/s, est. speed input: 981.04 toks/s, output: 11585.86 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3614/4000 [06:13<00:43,  8.92it/s, est. speed input: 980.49 toks/s, output: 11575.91 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3616/4000 [06:14<00:59,  6.45it/s, est. speed input: 979.61 toks/s, output: 11562.05 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3617/4000 [06:14<01:08,  5.62it/s, est. speed input: 978.96 toks/s, output: 11554.56 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3626/4000 [06:15<00:31, 11.86it/s, est. speed input: 979.99 toks/s, output: 11557.05 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3632/4000 [06:15<00:25, 14.32it/s, est. speed input: 980.58 toks/s, output: 11555.40 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3637/4000 [06:15<00:22, 16.19it/s, est. speed input: 981.14 toks/s, output: 11554.44 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3639/4000 [06:15<00:22, 16.00it/s, est. speed input: 981.23 toks/s, output: 11552.04 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3641/4000 [06:16<00:24, 14.45it/s, est. speed input: 981.07 toks/s, output: 11547.45 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3644/4000 [06:16<00:25, 13.75it/s, est. speed input: 981.04 toks/s, output: 11542.39 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3648/4000 [06:16<00:20, 17.56it/s, est. speed input: 981.75 toks/s, output: 11542.76 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3651/4000 [06:16<00:26, 13.26it/s, est. speed input: 981.41 toks/s, output: 11535.97 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3654/4000 [06:16<00:22, 15.22it/s, est. speed input: 981.73 toks/s, output: 11536.95 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3656/4000 [06:17<00:43,  7.87it/s, est. speed input: 980.67 toks/s, output: 11521.52 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3658/4000 [06:17<00:48,  7.04it/s, est. speed input: 980.48 toks/s, output: 11516.31 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3661/4000 [06:18<00:38,  8.90it/s, est. speed input: 981.28 toks/s, output: 11521.21 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3664/4000 [06:18<00:34,  9.79it/s, est. speed input: 981.60 toks/s, output: 11533.32 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3666/4000 [06:18<00:33, 10.09it/s, est. speed input: 981.54 toks/s, output: 11529.78 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3668/4000 [06:18<00:37,  8.85it/s, est. speed input: 981.07 toks/s, output: 11529.43 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3671/4000 [06:18<00:28, 11.52it/s, est. speed input: 981.26 toks/s, output: 11543.13 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3673/4000 [06:19<00:31, 10.42it/s, est. speed input: 980.89 toks/s, output: 11551.79 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3678/4000 [06:19<00:22, 14.40it/s, est. speed input: 981.29 toks/s, output: 11559.28 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3682/4000 [06:19<00:18, 17.43it/s, est. speed input: 981.57 toks/s, output: 11587.40 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3686/4000 [06:19<00:16, 19.60it/s, est. speed input: 981.89 toks/s, output: 11603.89 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3689/4000 [06:20<00:21, 14.63it/s, est. speed input: 981.52 toks/s, output: 11617.44 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3694/4000 [06:20<00:18, 16.64it/s, est. speed input: 981.78 toks/s, output: 11638.11 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3696/4000 [06:20<00:18, 16.86it/s, est. speed input: 981.82 toks/s, output: 11645.28 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3701/4000 [06:20<00:15, 19.25it/s, est. speed input: 982.14 toks/s, output: 11662.73 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3704/4000 [06:21<00:28, 10.24it/s, est. speed input: 980.86 toks/s, output: 11659.02 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3707/4000 [06:21<00:25, 11.63it/s, est. speed input: 981.06 toks/s, output: 11665.46 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3709/4000 [06:21<00:27, 10.77it/s, est. speed input: 980.80 toks/s, output: 11667.79 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3712/4000 [06:21<00:23, 12.40it/s, est. speed input: 980.80 toks/s, output: 11687.13 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3714/4000 [06:21<00:21, 13.37it/s, est. speed input: 980.79 toks/s, output: 11699.89 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3718/4000 [06:22<00:21, 13.22it/s, est. speed input: 980.67 toks/s, output: 11715.21 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3725/4000 [06:22<00:12, 21.69it/s, est. speed input: 981.75 toks/s, output: 11731.06 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3728/4000 [06:22<00:12, 21.73it/s, est. speed input: 982.09 toks/s, output: 11750.95 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3731/4000 [06:23<00:22, 12.12it/s, est. speed input: 981.25 toks/s, output: 11749.89 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3734/4000 [06:23<00:19, 13.40it/s, est. speed input: 981.44 toks/s, output: 11750.14 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3737/4000 [06:24<00:50,  5.23it/s, est. speed input: 978.65 toks/s, output: 11728.03 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3740/4000 [06:24<00:39,  6.57it/s, est. speed input: 979.14 toks/s, output: 11740.31 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3742/4000 [06:25<00:39,  6.52it/s, est. speed input: 978.70 toks/s, output: 11732.88 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3744/4000 [06:25<00:35,  7.20it/s, est. speed input: 979.60 toks/s, output: 11731.66 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3748/4000 [06:25<00:24, 10.18it/s, est. speed input: 981.63 toks/s, output: 11741.56 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3755/4000 [06:26<00:21, 11.40it/s, est. speed input: 982.61 toks/s, output: 11774.06 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3761/4000 [06:26<00:15, 15.91it/s, est. speed input: 984.39 toks/s, output: 11784.06 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3768/4000 [06:26<00:15, 15.04it/s, est. speed input: 984.48 toks/s, output: 11805.16 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3771/4000 [06:27<00:16, 13.73it/s, est. speed input: 984.26 toks/s, output: 11819.87 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3773/4000 [06:27<00:23,  9.73it/s, est. speed input: 983.31 toks/s, output: 11813.85 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3783/4000 [06:27<00:13, 16.17it/s, est. speed input: 985.15 toks/s, output: 11825.55 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3788/4000 [06:28<00:13, 15.85it/s, est. speed input: 986.23 toks/s, output: 11821.34 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3790/4000 [06:28<00:13, 15.74it/s, est. speed input: 986.55 toks/s, output: 11820.25 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3792/4000 [06:28<00:18, 11.16it/s, est. speed input: 985.88 toks/s, output: 11810.40 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3794/4000 [06:28<00:19, 10.47it/s, est. speed input: 985.69 toks/s, output: 11806.78 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3796/4000 [06:30<00:40,  5.07it/s, est. speed input: 983.37 toks/s, output: 11774.41 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3800/4000 [06:30<00:27,  7.39it/s, est. speed input: 984.22 toks/s, output: 11775.48 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3802/4000 [06:30<00:25,  7.91it/s, est. speed input: 984.34 toks/s, output: 11772.35 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3804/4000 [06:31<00:34,  5.60it/s, est. speed input: 983.46 toks/s, output: 11758.96 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3806/4000 [06:32<00:49,  3.94it/s, est. speed input: 981.39 toks/s, output: 11734.26 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3813/4000 [06:32<00:24,  7.50it/s, est. speed input: 981.92 toks/s, output: 11740.20 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3817/4000 [06:32<00:20,  8.96it/s, est. speed input: 981.92 toks/s, output: 11737.75 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3820/4000 [06:32<00:18,  9.67it/s, est. speed input: 981.92 toks/s, output: 11736.01 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3825/4000 [06:33<00:13, 13.01it/s, est. speed input: 982.73 toks/s, output: 11742.30 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3831/4000 [06:33<00:09, 18.51it/s, est. speed input: 983.96 toks/s, output: 11749.54 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3834/4000 [06:33<00:09, 17.22it/s, est. speed input: 984.04 toks/s, output: 11747.37 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3837/4000 [06:34<00:24,  6.78it/s, est. speed input: 981.73 toks/s, output: 11715.06 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3841/4000 [06:34<00:18,  8.76it/s, est. speed input: 982.32 toks/s, output: 11717.44 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3846/4000 [06:34<00:12, 12.34it/s, est. speed input: 983.51 toks/s, output: 11724.76 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3849/4000 [06:35<00:15,  9.63it/s, est. speed input: 983.19 toks/s, output: 11717.22 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3852/4000 [06:35<00:15,  9.69it/s, est. speed input: 983.23 toks/s, output: 11717.57 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3854/4000 [06:35<00:14,  9.80it/s, est. speed input: 983.22 toks/s, output: 11717.61 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3856/4000 [06:36<00:25,  5.57it/s, est. speed input: 982.10 toks/s, output: 11695.76 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3858/4000 [06:37<00:21,  6.67it/s, est. speed input: 982.62 toks/s, output: 11698.09 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3860/4000 [06:37<00:18,  7.69it/s, est. speed input: 983.18 toks/s, output: 11699.62 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3863/4000 [06:37<00:13, 10.11it/s, est. speed input: 983.86 toks/s, output: 11704.26 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3867/4000 [06:37<00:12, 10.82it/s, est. speed input: 984.94 toks/s, output: 11704.66 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3869/4000 [06:37<00:11, 11.44it/s, est. speed input: 985.21 toks/s, output: 11705.29 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3871/4000 [06:38<00:14,  9.07it/s, est. speed input: 984.71 toks/s, output: 11698.60 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3873/4000 [06:38<00:24,  5.27it/s, est. speed input: 983.02 toks/s, output: 11683.76 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3875/4000 [06:39<00:19,  6.54it/s, est. speed input: 983.12 toks/s, output: 11696.09 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3877/4000 [06:39<00:15,  7.84it/s, est. speed input: 983.17 toks/s, output: 11707.90 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3881/4000 [06:40<00:26,  4.52it/s, est. speed input: 980.63 toks/s, output: 11693.83 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3888/4000 [06:40<00:15,  7.23it/s, est. speed input: 981.13 toks/s, output: 11698.12 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3890/4000 [06:42<00:23,  4.69it/s, est. speed input: 978.83 toks/s, output: 11675.79 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3893/4000 [06:42<00:17,  6.08it/s, est. speed input: 979.03 toks/s, output: 11695.68 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3898/4000 [06:43<00:20,  4.91it/s, est. speed input: 976.62 toks/s, output: 11691.63 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3900/4000 [06:44<00:24,  4.05it/s, est. speed input: 974.85 toks/s, output: 11676.68 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3902/4000 [06:44<00:21,  4.62it/s, est. speed input: 974.80 toks/s, output: 11681.80 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3904/4000 [06:44<00:17,  5.43it/s, est. speed input: 974.87 toks/s, output: 11688.39 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3906/4000 [06:44<00:14,  6.53it/s, est. speed input: 975.03 toks/s, output: 11695.93 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3909/4000 [06:45<00:12,  7.12it/s, est. speed input: 974.65 toks/s, output: 11704.92 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3911/4000 [06:45<00:11,  8.05it/s, est. speed input: 974.56 toks/s, output: 11715.76 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3915/4000 [06:45<00:07, 10.91it/s, est. speed input: 974.67 toks/s, output: 11740.77 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3917/4000 [06:45<00:07, 10.51it/s, est. speed input: 974.49 toks/s, output: 11746.18 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3921/4000 [06:46<00:11,  7.11it/s, est. speed input: 973.54 toks/s, output: 11752.11 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3923/4000 [06:46<00:09,  7.93it/s, est. speed input: 974.05 toks/s, output: 11758.54 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3925/4000 [06:47<00:10,  7.03it/s, est. speed input: 974.42 toks/s, output: 11762.46 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3927/4000 [06:47<00:09,  7.99it/s, est. speed input: 974.49 toks/s, output: 11764.50 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3929/4000 [06:47<00:09,  7.19it/s, est. speed input: 974.08 toks/s, output: 11760.55 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3933/4000 [06:48<00:10,  6.17it/s, est. speed input: 972.99 toks/s, output: 11764.00 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3935/4000 [06:49<00:17,  3.71it/s, est. speed input: 970.49 toks/s, output: 11739.87 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3936/4000 [06:51<00:30,  2.09it/s, est. speed input: 966.98 toks/s, output: 11695.30 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3941/4000 [06:51<00:14,  3.96it/s, est. speed input: 967.72 toks/s, output: 11727.92 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3943/4000 [06:51<00:12,  4.48it/s, est. speed input: 967.60 toks/s, output: 11735.89 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3945/4000 [06:52<00:15,  3.66it/s, est. speed input: 965.93 toks/s, output: 11726.35 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3947/4000 [06:52<00:11,  4.59it/s, est. speed input: 965.90 toks/s, output: 11737.97 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3951/4000 [06:52<00:07,  6.93it/s, est. speed input: 965.96 toks/s, output: 11762.68 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3953/4000 [06:53<00:07,  6.01it/s, est. speed input: 965.06 toks/s, output: 11763.89 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3955/4000 [06:54<00:12,  3.69it/s, est. speed input: 962.55 toks/s, output: 11745.51 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3957/4000 [06:55<00:12,  3.44it/s, est. speed input: 961.15 toks/s, output: 11740.79 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3960/4000 [06:55<00:08,  4.66it/s, est. speed input: 961.05 toks/s, output: 11753.48 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3962/4000 [06:59<00:24,  1.57it/s, est. speed input: 952.81 toks/s, output: 11660.90 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3963/4000 [07:03<00:46,  1.27s/it, est. speed input: 942.79 toks/s, output: 11537.94 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3965/4000 [07:04<00:32,  1.08it/s, est. speed input: 943.20 toks/s, output: 11544.37 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3971/4000 [07:08<00:22,  1.30it/s, est. speed input: 936.98 toks/s, output: 11481.99 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3972/4000 [07:09<00:21,  1.28it/s, est. speed input: 935.32 toks/s, output: 11466.56 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3973/4000 [07:09<00:18,  1.46it/s, est. speed input: 935.24 toks/s, output: 11470.37 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3974/4000 [07:09<00:18,  1.44it/s, est. speed input: 933.80 toks/s, output: 11457.97 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3975/4000 [07:10<00:15,  1.60it/s, est. speed input: 933.22 toks/s, output: 11455.97 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3979/4000 [07:10<00:06,  3.16it/s, est. speed input: 933.62 toks/s, output: 11479.93 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3984/4000 [07:11<00:04,  3.99it/s, est. speed input: 932.64 toks/s, output: 11491.35 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3985/4000 [07:11<00:03,  4.03it/s, est. speed input: 932.36 toks/s, output: 11492.35 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3988/4000 [07:11<00:02,  5.70it/s, est. speed input: 932.78 toks/s, output: 11510.83 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3991/4000 [07:11<00:01,  7.34it/s, est. speed input: 933.07 toks/s, output: 11527.68 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3993/4000 [07:16<00:04,  1.62it/s, est. speed input: 924.37 toks/s, output: 11428.26 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3996/4000 [07:16<00:01,  2.38it/s, est. speed input: 924.75 toks/s, output: 11446.61 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3998/4000 [07:16<00:00,  2.91it/s, est. speed input: 924.70 toks/s, output: 11455.13 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4000/4000 [07:16<00:00,  3.70it/s, est. speed input: 924.85 toks/s, output: 11466.02 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4000/4000 [07:16<00:00,  9.16it/s, est. speed input: 924.85 toks/s, output: 11466.02 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/4000 [00:00<?, ?it/s][A
Evaluate:  36%|‚ñà‚ñà‚ñà‚ñå      | 1433/4000 [00:00<00:00, 7147.98it/s][A
Evaluate:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2148/4000 [00:00<00:00, 1968.00it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4000/4000 [00:00<00:00, 4162.34it/s]
{'num_samples': 500, 'num_scores': 4000, 'timeout_samples': 0, 'empty_samples': 5, 'acc': 48.2, 'total_acc': 47.525, 'pass_at_k_percent': {'1': 47.5, '8': 52.6}, 'pass_at_k_valid_counts': {'1': 500, '8': 500}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_noise_rlvr_1_5b_128batchsize_deepscaler_noise_robust_qwen25-math-cot/base__Qwen2.5-math-1.5B/g2/math500/test_qwen25-math-cot_-1_seed0_t0.0_s0_e-1.jsonl
[2025-09-23 15:52:06] ‚úì base__Qwen2.5-math-1.5B/g2/math500  acc=48.2 pass_at_k={'1': 47.5, '8': 52.6}
base__Qwen2.5-math-1.5B/g2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [23:44<00:00, 482.03s/ds]base__Qwen2.5-math-1.5B/g2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [23:44<00:00, 474.80s/ds]
[2025-09-23 15:52:06] ‚úÖ ÂÆåÊàêÔºöbase__Qwen2.5-math-1.5BÔºàg1+g2 Áº∫Â§±Êï∞ÊçÆÈõÜÂ∑≤Ë°•ÂÖ®Ôºâ
[2025-09-23 15:52:06] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_200
INFO 09-23 15:52:06 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 15:52:06 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 15:52:06 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 15:52:06 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 15:52:12 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:52:17 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 15:52:17 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 15:52:17 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_762ec74c'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/dda726a3-42c0-4cc9-aef9-8b657d5c21c7', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 15:52:23 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:52:23 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:52:23 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:52:23 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 15:52:34 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fe1aa6b0f10>
[1;36m(VllmWorker rank=0 pid=1188)[0;0m INFO 09-23 15:52:34 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_2191feaa'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/ecf80191-7925-4175-8d6a-e8d2269b8338', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 15:52:34 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fd032ee4f70>
WARNING 09-23 15:52:34 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f09d68b9060>
WARNING 09-23 15:52:34 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fc8ccbb0e50>
[1;36m(VllmWorker rank=3 pid=1191)[0;0m INFO 09-23 15:52:34 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_c56f7fe6'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/b5e21c20-7ad3-48e5-a4d3-a9c59829a4a6', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=1189)[0;0m INFO 09-23 15:52:34 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_1651fc61'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/c6c1219d-1ac8-407e-a780-fc0516b3bfd5', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=1190)[0;0m INFO 09-23 15:52:34 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_3b3541ad'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/b1682f6c-3917-412c-a0e1-881c528a2500', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=1191)[0;0m [1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=1 pid=1189)[0;0m INFO 09-23 15:53:10 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 15:53:10 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 15:53:10 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=1189)[0;0m [1;36m(VllmWorker rank=0 pid=1188)[0;0m INFO 09-23 15:53:10 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=1191)[0;0m INFO 09-23 15:53:10 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 15:53:10 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=1190)[0;0m INFO 09-23 15:53:10 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=1190)[0;0m INFO 09-23 15:53:10 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=1190)[0;0m INFO 09-23 15:53:12 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=3 pid=1191)[0;0m [1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=1 pid=1189)[0;0m INFO 09-23 15:53:12 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 15:53:12 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 15:53:12 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=1188)[0;0m INFO 09-23 15:53:12 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_dfcc0585'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/adabd1ce-1d32-47fb-9398-336e3bd30ba0', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=1191)[0;0m INFO 09-23 15:53:12 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=1190)[0;0m INFO 09-23 15:53:12 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=1 pid=1189)[0;0m [1;36m(VllmWorker rank=0 pid=1188)[0;0m INFO 09-23 15:53:12 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
INFO 09-23 15:53:12 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=3 pid=1191)[0;0m INFO 09-23 15:53:12 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=1188)[0;0m INFO 09-23 15:53:12 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=1190)[0;0m INFO 09-23 15:53:12 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=1189)[0;0m INFO 09-23 15:53:12 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=1191)[0;0m INFO 09-23 15:53:12 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=1188)[0;0m INFO 09-23 15:53:12 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=1190)[0;0m INFO 09-23 15:53:12 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=1189)[0;0m INFO 09-23 15:53:12 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=1191)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m INFO 09-23 15:53:12 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_200...
INFO 09-23 15:53:12 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=1 pid=1189)[0;0m INFO 09-23 15:53:12 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=0 pid=1188)[0;0m INFO 09-23 15:53:12 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435] WorkerProc failed to start.
ERROR 09-23 15:53:15 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435] Traceback (most recent call last):
ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m [1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
ERROR 09-23 15:53:15 [multiproc_executor.py:435] WorkerProc failed to start.
ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m [1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
ERROR 09-23 15:53:15 [multiproc_executor.py:435] Traceback (most recent call last):
ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m [1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.worker.load_model()
ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m [1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 09-23 15:53:15 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
ERROR 09-23 15:53:15 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m [1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.model_runner.load_model()
ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m [1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.worker.load_model()
ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m [1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m [1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.model_runner.load_model()
ERROR 09-23 15:53:15 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m [1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m [1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 09-23 15:53:15 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m [1;36m(VllmWorker rank=1 pid=1189)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 09-23 15:53:15 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 1 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088947 has 37.62 GiB memory in use. Process 2121414 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 09-23 15:53:15 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
ERROR 09-23 15:53:15 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 09-23 15:53:15 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 09-23 15:53:15 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
ERROR 09-23 15:53:15 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
ERROR 09-23 15:53:15 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
ERROR 09-23 15:53:15 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.quant_method.create_weights(
ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 09-23 15:53:15 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     return func(*args, **kwargs)
ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=0 pid=1188)[0;0m [1;36m(VllmWorker rank=2 pid=1190)[0;0m [1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088946 has 37.61 GiB memory in use. Process 2121413 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 15:53:15 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 09-23 15:53:15 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=1190)[0;0m [1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 09-23 15:53:15 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=1190)[0;0m [1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     return func(*args, **kwargs)
ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=1190)[0;0m [1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2121415 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 15:53:15 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=1191)[0;0m ERROR 09-23 15:53:15 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 3 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088949 has 37.61 GiB memory in use. Process 2121416 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f0b2816c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f0b28115b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f0ad908e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f0b2856bb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f0b2856c20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39afa (0x7f0b28582afa in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f0b2856e329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f0b206864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f0b1fda5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f0b1fda64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x556e6091fc04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x556e608ac2a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x556e608acbbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x556e608acc83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x556e6091fb85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x556e6098bc3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x556e6098ef1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x556e608adc98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x556e609ecc30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x556e60a12407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x556e60a12634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x556e60a12718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x556e60a1275b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x556e60a12972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x556e60a18f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x556e60a191ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x556e60a19469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f0b2937ad90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f0b2937ae40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x556e609842d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

ERROR 09-23 15:53:17 [core.py:396] EngineCore failed to start.
ERROR 09-23 15:53:17 [core.py:396] Traceback (most recent call last):
ERROR 09-23 15:53:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 15:53:17 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 15:53:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 15:53:17 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 15:53:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 15:53:17 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 15:53:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 15:53:17 [core.py:396]     self._init_executor()
ERROR 09-23 15:53:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 15:53:17 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 15:53:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 15:53:17 [core.py:396]     raise e from None
ERROR 09-23 15:53:17 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 15:53:21] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_313
INFO 09-23 15:53:21 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 15:53:21 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 15:53:21 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 15:53:21 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 15:53:27 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:53:32 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 15:53:32 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 15:53:32 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_34bf3387'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/54d87c82-4b7a-48ba-8757-799c1dfe00c1', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 15:53:37 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:53:37 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:53:37 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:53:37 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 15:53:43 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fb5c4a24d30>
[1;36m(VllmWorker rank=3 pid=1442)[0;0m INFO 09-23 15:53:43 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_a9d84871'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/fbd298ac-661b-4c06-9bac-70df9dec8ff0', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 15:53:43 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fb7bab78e20>
[1;36m(VllmWorker rank=2 pid=1441)[0;0m INFO 09-23 15:53:43 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_ca15b967'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/051e4b3b-f112-45e6-83b8-fe6c54a8b509', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 15:53:43 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f9033ac9120>
[1;36m(VllmWorker rank=1 pid=1440)[0;0m INFO 09-23 15:53:43 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_d248c570'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/f517e501-1714-4b4e-bbe2-d4eb22da1992', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 15:53:43 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f81994d8f10>
[1;36m(VllmWorker rank=0 pid=1439)[0;0m INFO 09-23 15:53:43 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_36faca02'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/060d1297-5715-4be1-aaef-fb46abf80391', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=1440)[0;0m INFO 09-23 15:54:19 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=1442)[0;0m INFO 09-23 15:54:19 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=1440)[0;0m INFO 09-23 15:54:19 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=1442)[0;0m INFO 09-23 15:54:19 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=1439)[0;0m INFO 09-23 15:54:19 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=1439)[0;0m INFO 09-23 15:54:19 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=1441)[0;0m INFO 09-23 15:54:19 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=1441)[0;0m INFO 09-23 15:54:19 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=1439)[0;0m INFO 09-23 15:54:20 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=1441)[0;0m [1;36m(VllmWorker rank=3 pid=1442)[0;0m INFO 09-23 15:54:20 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 15:54:20 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=1 pid=1440)[0;0m INFO 09-23 15:54:20 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=1439)[0;0m INFO 09-23 15:54:20 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_6adf50de'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/cef67919-f2b7-4d45-b038-edcf1985a8c4', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=1442)[0;0m INFO 09-23 15:54:20 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=1441)[0;0m INFO 09-23 15:54:20 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=1 pid=1440)[0;0m INFO 09-23 15:54:20 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=0 pid=1439)[0;0m INFO 09-23 15:54:20 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=3 pid=1442)[0;0m INFO 09-23 15:54:20 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=1439)[0;0m INFO 09-23 15:54:20 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=1440)[0;0m INFO 09-23 15:54:20 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=1441)[0;0m INFO 09-23 15:54:20 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=1442)[0;0m INFO 09-23 15:54:20 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=1439)[0;0m INFO 09-23 15:54:20 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=1440)[0;0m INFO 09-23 15:54:20 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=1441)[0;0m INFO 09-23 15:54:20 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=1442)[0;0m INFO 09-23 15:54:20 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=1 pid=1440)[0;0m INFO 09-23 15:54:20 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=2 pid=1441)[0;0m INFO 09-23 15:54:20 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=0 pid=1439)[0;0m INFO 09-23 15:54:20 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=1 pid=1440)[0;0m ERROR 09-23 15:54:20 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 1 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088947 has 37.62 GiB memory in use. Process 2122426 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 15:54:22 [core.py:396] EngineCore failed to start.
ERROR 09-23 15:54:22 [core.py:396] Traceback (most recent call last):
ERROR 09-23 15:54:22 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 15:54:22 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 15:54:22 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 15:54:22 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 15:54:22 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 15:54:22 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 15:54:22 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 15:54:22 [core.py:396]     self._init_executor()
ERROR 09-23 15:54:22 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 15:54:22 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 15:54:22 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 15:54:22 [core.py:396]     raise e from None
ERROR 09-23 15:54:22 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 15:54:23] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B/global_step_200
INFO 09-23 15:54:23 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 15:54:23 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 15:54:23 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 15:54:23 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 15:54:29 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:54:34 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 15:54:34 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 15:54:34 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_96aca64f'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/0d7d9377-0598-4868-b413-6b1f83a5a827', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 15:54:39 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:54:39 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:54:39 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:54:39 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 15:54:45 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f989f64d000>
WARNING 09-23 15:54:45 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f259a26cf40>
[1;36m(VllmWorker rank=2 pid=1692)[0;0m INFO 09-23 15:54:45 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_8eb4b453'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/002ba49b-76e1-4ef3-92bb-37ba7a1a3166', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=1693)[0;0m INFO 09-23 15:54:45 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_1901e1dc'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/53195ede-f2f6-447a-9e76-e83dc8ccdc92', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 15:54:45 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f0d0ac4d000>
[1;36m(VllmWorker rank=1 pid=1691)[0;0m INFO 09-23 15:54:45 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_a7132114'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/019bdb40-d0ad-4e3e-aa86-0926edd29dfd', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 15:54:45 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f63a61a0f10>
[1;36m(VllmWorker rank=0 pid=1690)[0;0m INFO 09-23 15:54:45 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_5c2f5672'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/5af99a22-0e24-449e-882f-cef801272d55', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=1690)[0;0m INFO 09-23 15:55:21 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=1692)[0;0m INFO 09-23 15:55:21 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=1691)[0;0m INFO 09-23 15:55:21 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=1690)[0;0m INFO 09-23 15:55:21 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=1692)[0;0m INFO 09-23 15:55:21 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=1693)[0;0m INFO 09-23 15:55:21 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=1691)[0;0m INFO 09-23 15:55:21 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=1693)[0;0m INFO 09-23 15:55:21 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=1690)[0;0m [1;36m(VllmWorker rank=1 pid=1691)[0;0m INFO 09-23 15:55:22 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 15:55:22 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=3 pid=1693)[0;0m [1;36m(VllmWorker rank=2 pid=1692)[0;0m INFO 09-23 15:55:22 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 15:55:22 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=1690)[0;0m INFO 09-23 15:55:22 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_dee457e5'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/870d2f30-e658-4500-a164-9fd118d7a37c', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=1693)[0;0m INFO 09-23 15:55:22 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=1692)[0;0m INFO 09-23 15:55:22 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=0 pid=1690)[0;0m INFO 09-23 15:55:22 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=1 pid=1691)[0;0m INFO 09-23 15:55:22 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=0 pid=1690)[0;0m [1;36m(VllmWorker rank=3 pid=1693)[0;0m INFO 09-23 15:55:22 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 09-23 15:55:22 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=1692)[0;0m INFO 09-23 15:55:22 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=1691)[0;0m INFO 09-23 15:55:22 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=1690)[0;0m INFO 09-23 15:55:22 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=1693)[0;0m INFO 09-23 15:55:22 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=1692)[0;0m INFO 09-23 15:55:22 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=1691)[0;0m INFO 09-23 15:55:22 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=1692)[0;0m INFO 09-23 15:55:22 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=1 pid=1691)[0;0m INFO 09-23 15:55:22 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=3 pid=1693)[0;0m INFO 09-23 15:55:22 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=0 pid=1690)[0;0m INFO 09-23 15:55:22 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=1690)[0;0m ERROR 09-23 15:55:22 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088946 has 37.61 GiB memory in use. Process 2123470 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f26ebb6c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f26ebb15b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f269ca8e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f26ebf6bb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f26ebf6c20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39afa (0x7f26ebf82afa in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f26ebf6e329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f26e40864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f26e37a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f26e37a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x55f316765c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x55f3166f22a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x55f3166f2bbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x55f3166f2c83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x55f316765b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x55f3167d1c3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x55f3167d4f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x55f3166f3c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x55f316832c30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x55f316858407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x55f316858634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x55f316858718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x55f31685875b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x55f316858972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x55f31685ef60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x55f31685f1ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x55f31685f469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f26ecd85d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f26ecd85e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x55f3167ca2d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

ERROR 09-23 15:55:24 [core.py:396] EngineCore failed to start.
ERROR 09-23 15:55:24 [core.py:396] Traceback (most recent call last):
ERROR 09-23 15:55:24 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 15:55:24 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 15:55:24 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 15:55:24 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 15:55:24 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 15:55:24 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 15:55:24 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 15:55:24 [core.py:396]     self._init_executor()
ERROR 09-23 15:55:24 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 15:55:24 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 15:55:24 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 15:55:24 [core.py:396]     raise e from None
ERROR 09-23 15:55:24 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 15:55:26] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B/global_step_100
INFO 09-23 15:55:27 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 15:55:27 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 15:55:27 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 15:55:27 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[2025-09-23 15:55:32] [WARN] ÂØºÂá∫Â§±Ë¥•ÔºöB_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B__global_step_313 -> 
INFO 09-23 15:55:32 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:55:37 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B/global_step_100', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B/global_step_100', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B/global_step_100, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 15:55:37 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 15:55:37 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_356dff26'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/692bdddd-c529-4c6d-ae37-2694339b61e9', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 15:55:43 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:55:43 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:55:43 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:55:43 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 15:55:49 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f46bad39150>
[1;36m(VllmWorker rank=1 pid=1942)[0;0m INFO 09-23 15:55:49 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_d37ed041'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/bc0879f8-9db9-4373-91c2-e2ed9847976c', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 15:55:51 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7ff178b09150>
[1;36m(VllmWorker rank=0 pid=1941)[0;0m INFO 09-23 15:55:51 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_2c56886e'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/c6b6cdf8-290c-4a1f-9d56-3b8eb633c5f4', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 15:55:51 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7efb54fecd00>
[1;36m(VllmWorker rank=3 pid=1944)[0;0m INFO 09-23 15:55:51 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_a7ec6ee6'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/9af0998c-cdce-4183-8034-1618b8aca782', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 15:55:51 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7ff328fad000>
[1;36m(VllmWorker rank=2 pid=1943)[0;0m INFO 09-23 15:55:51 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_1b85d703'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/39b773d2-cd67-45dc-971b-0cbb164e8e08', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=1941)[0;0m INFO 09-23 15:56:29 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=1944)[0;0m INFO 09-23 15:56:29 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=1943)[0;0m INFO 09-23 15:56:29 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=1944)[0;0m INFO 09-23 15:56:29 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=1941)[0;0m INFO 09-23 15:56:29 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=1943)[0;0m INFO 09-23 15:56:29 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=1942)[0;0m INFO 09-23 15:56:29 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=1942)[0;0m INFO 09-23 15:56:29 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=1943)[0;0m [1;36m(VllmWorker rank=3 pid=1944)[0;0m INFO 09-23 15:56:30 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 15:56:30 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=1 pid=1942)[0;0m INFO 09-23 15:56:30 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=1941)[0;0m INFO 09-23 15:56:30 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=1941)[0;0m INFO 09-23 15:56:30 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_fad244ea'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/b1ab14d2-6b0f-454b-b961-8b284e1b6cd0', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=1944)[0;0m INFO 09-23 15:56:30 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=1943)[0;0m INFO 09-23 15:56:30 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=1 pid=1942)[0;0m INFO 09-23 15:56:30 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=0 pid=1941)[0;0m INFO 09-23 15:56:30 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=3 pid=1944)[0;0m INFO 09-23 15:56:30 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=1943)[0;0m INFO 09-23 15:56:30 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=1942)[0;0m INFO 09-23 15:56:30 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=1941)[0;0m INFO 09-23 15:56:30 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=1944)[0;0m INFO 09-23 15:56:30 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=1943)[0;0m INFO 09-23 15:56:30 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=1942)[0;0m INFO 09-23 15:56:30 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=1941)[0;0m INFO 09-23 15:56:30 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=1944)[0;0m INFO 09-23 15:56:30 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=2 pid=1943)[0;0m INFO 09-23 15:56:30 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=1 pid=1942)[0;0m INFO 09-23 15:56:30 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=0 pid=1941)[0;0m INFO 09-23 15:56:30 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B/global_step_100...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=1 pid=1942)[0;0m ERROR 09-23 15:56:31 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 1 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088947 has 37.62 GiB memory in use. Process 2124471 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 15:56:33 [core.py:396] EngineCore failed to start.
ERROR 09-23 15:56:33 [core.py:396] Traceback (most recent call last):
ERROR 09-23 15:56:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 15:56:33 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 15:56:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 15:56:33 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 15:56:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 15:56:33 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 15:56:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 15:56:33 [core.py:396]     self._init_executor()
ERROR 09-23 15:56:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 15:56:33 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 15:56:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 15:56:33 [core.py:396]     raise e from None
ERROR 09-23 15:56:33 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 15:56:34] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_200
INFO 09-23 15:56:34 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 15:56:34 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 15:56:34 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 15:56:34 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 15:56:39 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:56:44 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 15:56:44 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 15:56:44 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_6521c562'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/515c33e2-318a-4897-8c1b-c022edb71f62', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 15:56:49 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:56:50 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:56:50 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:56:50 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 15:56:55 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7ff6543fcd90>
[1;36m(VllmWorker rank=2 pid=2194)[0;0m INFO 09-23 15:56:55 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_ac672901'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/aae3f86d-fa83-4ef6-bbfa-b576931bfca8', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 15:56:55 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fdb21818d60>
[1;36m(VllmWorker rank=3 pid=2195)[0;0m INFO 09-23 15:56:55 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_52415010'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/7d307e1e-ebe6-4cf7-a813-a30d268fd269', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 15:56:55 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f7427f60df0>
[1;36m(VllmWorker rank=1 pid=2193)[0;0m INFO 09-23 15:56:55 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_6a9f06de'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/9bd1618b-07f0-496d-908c-3c952eba856f', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 15:56:55 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f4a6e8c0e80>
[1;36m(VllmWorker rank=0 pid=2192)[0;0m INFO 09-23 15:56:55 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_48a06055'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/a761eb77-8fee-42b1-ac75-e06ab40cff16', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=2192)[0;0m INFO 09-23 15:57:31 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=2195)[0;0m [1;36m(VllmWorker rank=0 pid=2192)[0;0m INFO 09-23 15:57:31 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 15:57:31 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=2193)[0;0m INFO 09-23 15:57:31 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=2195)[0;0m INFO 09-23 15:57:31 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=2193)[0;0m INFO 09-23 15:57:31 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=2194)[0;0m INFO 09-23 15:57:31 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=2194)[0;0m INFO 09-23 15:57:31 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=2192)[0;0m [1;36m(VllmWorker rank=1 pid=2193)[0;0m INFO 09-23 15:57:32 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 15:57:32 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=3 pid=2195)[0;0m INFO 09-23 15:57:32 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=2194)[0;0m INFO 09-23 15:57:32 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=2192)[0;0m INFO 09-23 15:57:33 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_c3195e02'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/a307ad10-a43e-4f75-bb87-0e1a1153a2f9', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=2192)[0;0m INFO 09-23 15:57:33 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=0 pid=2192)[0;0m INFO 09-23 15:57:33 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=2192)[0;0m INFO 09-23 15:57:33 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=2193)[0;0m INFO 09-23 15:57:33 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=1 pid=2193)[0;0m INFO 09-23 15:57:33 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=2193)[0;0m INFO 09-23 15:57:33 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=2194)[0;0m INFO 09-23 15:57:33 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=3 pid=2195)[0;0m INFO 09-23 15:57:33 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=3 pid=2195)[0;0m INFO 09-23 15:57:33 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=2195)[0;0m INFO 09-23 15:57:33 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=2194)[0;0m INFO 09-23 15:57:33 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=2194)[0;0m INFO 09-23 15:57:33 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=2193)[0;0m INFO 09-23 15:57:33 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=0 pid=2192)[0;0m INFO 09-23 15:57:33 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=3 pid=2195)[0;0m INFO 09-23 15:57:33 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=2 pid=2194)[0;0m INFO 09-23 15:57:33 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=2192)[0;0m ERROR 09-23 15:57:33 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088946 has 37.61 GiB memory in use. Process 2125561 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 15:57:35 [core.py:396] EngineCore failed to start.
ERROR 09-23 15:57:35 [core.py:396] Traceback (most recent call last):
ERROR 09-23 15:57:35 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 15:57:35 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 15:57:35 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 15:57:35 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 15:57:35 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 15:57:35 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 15:57:35 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 15:57:35 [core.py:396]     self._init_executor()
ERROR 09-23 15:57:35 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 15:57:35 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 15:57:35 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 15:57:35 [core.py:396]     raise e from None
ERROR 09-23 15:57:35 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 15:57:36] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_313
INFO 09-23 15:57:36 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 15:57:36 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 15:57:36 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 15:57:36 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 15:57:42 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:57:47 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 15:57:47 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 15:57:47 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_0313d47b'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/2ef4d8b9-a63f-4b92-9295-7dd679cfb2ed', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 15:57:52 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:57:52 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:57:52 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:57:52 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 15:57:58 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f89b1834f40>
[1;36m(VllmWorker rank=1 pid=2444)[0;0m INFO 09-23 15:57:58 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_cfd36e5f'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/d6b2040e-a183-4984-8929-55b346a2a22e', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 15:57:58 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f1fc6a48dc0>
[1;36m(VllmWorker rank=2 pid=2445)[0;0m INFO 09-23 15:57:58 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_0696a1fb'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/140b7f51-4bdd-43ea-abcd-e16a911d6700', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 15:57:58 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f7922004f40>
[1;36m(VllmWorker rank=0 pid=2443)[0;0m INFO 09-23 15:57:58 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_5c347fd4'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/51616ed8-0bc7-461b-8a3c-f53561b9b91f', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 15:57:58 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f1fe89c1150>
[1;36m(VllmWorker rank=3 pid=2446)[0;0m INFO 09-23 15:57:58 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_18ba911f'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/5dff5c0f-dde8-40c5-82f2-fae87cb3adc5', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=2444)[0;0m INFO 09-23 15:58:34 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=2444)[0;0m INFO 09-23 15:58:34 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=2443)[0;0m INFO 09-23 15:58:34 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=2443)[0;0m INFO 09-23 15:58:34 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=2445)[0;0m INFO 09-23 15:58:34 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=2445)[0;0m INFO 09-23 15:58:34 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=2446)[0;0m INFO 09-23 15:58:34 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=2446)[0;0m INFO 09-23 15:58:34 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=2446)[0;0m INFO 09-23 15:58:36 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=1 pid=2444)[0;0m INFO 09-23 15:58:36 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=2445)[0;0m [1;36m(VllmWorker rank=0 pid=2443)[0;0m INFO 09-23 15:58:36 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 15:58:36 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=2443)[0;0m INFO 09-23 15:58:36 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_f4d9fb87'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/b49e2dfe-f047-45d4-95d3-49ec2cb92741', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=2446)[0;0m INFO 09-23 15:58:36 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=2445)[0;0m INFO 09-23 15:58:36 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=1 pid=2444)[0;0m INFO 09-23 15:58:36 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=2 pid=2445)[0;0m [1;36m(VllmWorker rank=0 pid=2443)[0;0m INFO 09-23 15:58:36 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 09-23 15:58:36 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=1 pid=2444)[0;0m INFO 09-23 15:58:36 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=2446)[0;0m INFO 09-23 15:58:36 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=2445)[0;0m INFO 09-23 15:58:36 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=2444)[0;0m INFO 09-23 15:58:36 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=2443)[0;0m INFO 09-23 15:58:36 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=2446)[0;0m INFO 09-23 15:58:36 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=2443)[0;0m INFO 09-23 15:58:36 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=2445)[0;0m INFO 09-23 15:58:36 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=1 pid=2444)[0;0m INFO 09-23 15:58:36 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=3 pid=2446)[0;0m INFO 09-23 15:58:36 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=0 pid=2443)[0;0m INFO 09-23 15:58:36 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=2445)[0;0m ERROR 09-23 15:58:36 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2126623 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 15:58:38 [core.py:396] EngineCore failed to start.
ERROR 09-23 15:58:38 [core.py:396] Traceback (most recent call last):
ERROR 09-23 15:58:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 15:58:38 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 15:58:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 15:58:38 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 15:58:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 15:58:38 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 15:58:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 15:58:38 [core.py:396]     self._init_executor()
ERROR 09-23 15:58:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 15:58:38 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 15:58:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 15:58:38 [core.py:396]     raise e from None
ERROR 09-23 15:58:38 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 15:58:40] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_200
INFO 09-23 15:58:40 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 15:58:40 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 15:58:40 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 15:58:40 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 15:58:46 [__init__.py:239] Automatically detected platform cuda.
[2025-09-23 15:58:50] [WARN] ÂØºÂá∫Â§±Ë¥•ÔºöB_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B__global_step_313 -> 
INFO 09-23 15:58:51 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 15:58:51 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 15:58:51 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_e279d6a8'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/4a466129-498c-4e4f-ba65-714d4e0ea45a', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 15:58:57 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:58:57 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:58:57 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:58:57 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 15:59:03 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fdac1f80dc0>
[1;36m(VllmWorker rank=0 pid=2694)[0;0m INFO 09-23 15:59:03 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_40f7b9f8'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/a6e7fddc-0acc-465b-82e1-924984892de9', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 15:59:04 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fab232d50f0>
[1;36m(VllmWorker rank=2 pid=2696)[0;0m INFO 09-23 15:59:04 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_ebf9dd40'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/60ed35e5-49db-4cbf-a1c1-4cd8d25e2812', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 15:59:04 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f3bc67dd180>
[1;36m(VllmWorker rank=3 pid=2697)[0;0m INFO 09-23 15:59:04 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_0b43091a'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/82f1f14d-089b-4c94-af10-0693a4bdd880', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 15:59:04 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f2f4d668e50>
[1;36m(VllmWorker rank=1 pid=2695)[0;0m INFO 09-23 15:59:04 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_ee37754c'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/3beaaaf4-5839-439f-8d45-ac16e7389595', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=2696)[0;0m [1;36m(VllmWorker rank=0 pid=2694)[0;0m INFO 09-23 15:59:40 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 15:59:40 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=2694)[0;0m [1;36m(VllmWorker rank=2 pid=2696)[0;0m INFO 09-23 15:59:40 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 15:59:40 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=2697)[0;0m INFO 09-23 15:59:40 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=2695)[0;0m INFO 09-23 15:59:40 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=2697)[0;0m INFO 09-23 15:59:40 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=2695)[0;0m INFO 09-23 15:59:40 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=2696)[0;0m [1;36m(VllmWorker rank=1 pid=2695)[0;0m [1;36m(VllmWorker rank=0 pid=2694)[0;0m INFO 09-23 15:59:41 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 15:59:41 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 15:59:41 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=3 pid=2697)[0;0m INFO 09-23 15:59:41 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=2694)[0;0m INFO 09-23 15:59:41 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_0d56710c'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/35487944-aca3-4574-acec-606f6125c397', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=2697)[0;0m INFO 09-23 15:59:41 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=2696)[0;0m INFO 09-23 15:59:41 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=0 pid=2694)[0;0m INFO 09-23 15:59:41 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=1 pid=2695)[0;0m INFO 09-23 15:59:41 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=2 pid=2696)[0;0m INFO 09-23 15:59:41 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=2697)[0;0m INFO 09-23 15:59:41 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=2694)[0;0m INFO 09-23 15:59:41 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=2695)[0;0m INFO 09-23 15:59:41 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=2696)[0;0m INFO 09-23 15:59:41 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=2694)[0;0m INFO 09-23 15:59:41 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=2697)[0;0m INFO 09-23 15:59:41 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=2695)[0;0m INFO 09-23 15:59:41 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=2696)[0;0m INFO 09-23 15:59:41 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=3 pid=2697)[0;0m INFO 09-23 15:59:41 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=1 pid=2695)[0;0m INFO 09-23 15:59:41 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=0 pid=2694)[0;0m INFO 09-23 15:59:41 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62

[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=2696)[0;0m ERROR 09-23 15:59:41 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2127745 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 15:59:43 [core.py:396] EngineCore failed to start.
ERROR 09-23 15:59:43 [core.py:396] Traceback (most recent call last):
ERROR 09-23 15:59:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 15:59:43 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 15:59:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 15:59:43 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 15:59:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 15:59:43 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 15:59:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 15:59:43 [core.py:396]     self._init_executor()
ERROR 09-23 15:59:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 15:59:43 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 15:59:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 15:59:43 [core.py:396]     raise e from None
ERROR 09-23 15:59:43 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 15:59:45] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_313
INFO 09-23 15:59:45 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 15:59:45 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 15:59:45 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 15:59:45 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 15:59:50 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 15:59:56 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 15:59:56 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 15:59:56 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_c1396351'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/79f2e5a9-bdc9-4a6e-95b8-a057527e7d39', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:00:01 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:00:01 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:00:01 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:00:01 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:00:07 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f7dc4a70d90>
[1;36m(VllmWorker rank=2 pid=2947)[0;0m INFO 09-23 16:00:07 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_804da590'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/f91cc6b5-3aaf-4487-aebd-4280a62d5934', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:00:07 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7faa17808fa0>
[1;36m(VllmWorker rank=0 pid=2945)[0;0m INFO 09-23 16:00:07 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_b3e25f1d'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/5bf164d4-ba2b-4d22-9f1e-e0639f46623f', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:00:07 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f5a7f7a9030>
WARNING 09-23 16:00:07 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f37b6c68e80>
[1;36m(VllmWorker rank=1 pid=2946)[0;0m [1;36m(VllmWorker rank=3 pid=2948)[0;0m INFO 09-23 16:00:07 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_a241bc7c'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/e738ce74-cff0-42cd-b83c-8639542f1019', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:00:07 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_e97d1aab'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/c05485b8-c6c9-4956-935f-ad9d9d1bd990', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=2947)[0;0m INFO 09-23 16:00:42 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=2947)[0;0m INFO 09-23 16:00:42 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=2946)[0;0m INFO 09-23 16:00:42 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=2946)[0;0m INFO 09-23 16:00:42 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=2948)[0;0m INFO 09-23 16:00:42 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=2948)[0;0m INFO 09-23 16:00:42 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=2945)[0;0m INFO 09-23 16:00:42 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=2945)[0;0m INFO 09-23 16:00:42 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=2947)[0;0m INFO 09-23 16:00:45 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=1 pid=2946)[0;0m [1;36m(VllmWorker rank=3 pid=2948)[0;0m INFO 09-23 16:00:45 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:00:45 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=2945)[0;0m INFO 09-23 16:00:45 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=2945)[0;0m INFO 09-23 16:00:45 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_e530aae8'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/4f2a695b-dab8-4af9-b6f8-5ce9e32b2289', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=2947)[0;0m [1;36m(VllmWorker rank=1 pid=2946)[0;0m INFO 09-23 16:00:45 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
INFO 09-23 16:00:45 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=3 pid=2948)[0;0m INFO 09-23 16:00:45 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=1 pid=2946)[0;0m INFO 09-23 16:00:45 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=2947)[0;0m INFO 09-23 16:00:45 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=2945)[0;0m INFO 09-23 16:00:45 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=1 pid=2946)[0;0m INFO 09-23 16:00:45 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=2947)[0;0m INFO 09-23 16:00:45 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=2948)[0;0m INFO 09-23 16:00:45 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=2945)[0;0m INFO 09-23 16:00:45 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=2948)[0;0m INFO 09-23 16:00:45 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=2945)[0;0m INFO 09-23 16:00:45 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=2946)[0;0m INFO 09-23 16:00:45 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=2 pid=2947)[0;0m INFO 09-23 16:00:45 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=3 pid=2948)[0;0m INFO 09-23 16:00:45 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=0 pid=2945)[0;0m INFO 09-23 16:00:45 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=2947)[0;0m ERROR 09-23 16:00:45 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2128765 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:00:47 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:00:47 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:00:47 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:00:47 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:00:47 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:00:47 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:00:47 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:00:47 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:00:47 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:00:47 [core.py:396]     self._init_executor()
ERROR 09-23 16:00:47 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:00:47 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:00:47 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:00:47 [core.py:396]     raise e from None
ERROR 09-23 16:00:47 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:00:49] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_200
INFO 09-23 16:00:49 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:00:49 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:00:49 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:00:49 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:00:55 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:01:00 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:01:00 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:01:00 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_ab9d28f9'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/ba720dd4-ee3a-4a49-bac1-0535dc1b959c', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:01:05 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:01:05 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:01:05 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:01:05 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:01:11 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f0d86d25000>
[1;36m(VllmWorker rank=3 pid=3199)[0;0m INFO 09-23 16:01:11 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_b831b201'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/cadcb9be-c759-4701-a7e8-7e7741feb55b', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:01:11 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fae432f8f40>
[1;36m(VllmWorker rank=1 pid=3197)[0;0m INFO 09-23 16:01:11 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_9ae47a16'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/d0117f75-60b9-4d22-8f0d-fa668a6b84b8', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:01:11 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f29c9ec90c0>
[1;36m(VllmWorker rank=0 pid=3196)[0;0m INFO 09-23 16:01:11 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_26e2caee'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/1684d783-b612-4fbb-9889-6ac51d44d3d7', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:01:11 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fd3371fd120>
[1;36m(VllmWorker rank=2 pid=3198)[0;0m INFO 09-23 16:01:11 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_d8693875'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/0eb59dff-e54f-4e50-92f5-00af7ff0144a', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=3198)[0;0m INFO 09-23 16:01:46 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=3198)[0;0m INFO 09-23 16:01:46 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=3199)[0;0m INFO 09-23 16:01:46 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=3196)[0;0m INFO 09-23 16:01:46 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=3199)[0;0m INFO 09-23 16:01:46 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=3197)[0;0m INFO 09-23 16:01:46 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=3196)[0;0m INFO 09-23 16:01:46 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=3197)[0;0m INFO 09-23 16:01:46 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=3198)[0;0m [1;36m(VllmWorker rank=0 pid=3196)[0;0m INFO 09-23 16:01:47 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:01:47 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=3 pid=3199)[0;0m [1;36m(VllmWorker rank=1 pid=3197)[0;0m INFO 09-23 16:01:47 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:01:47 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=3196)[0;0m INFO 09-23 16:01:48 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_c64df24f'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/07de4053-b0d7-4ed6-9cc1-e41dcc1f6a14', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=3199)[0;0m INFO 09-23 16:01:48 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=3198)[0;0m INFO 09-23 16:01:48 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=0 pid=3196)[0;0m INFO 09-23 16:01:48 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=1 pid=3197)[0;0m INFO 09-23 16:01:48 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=3 pid=3199)[0;0m INFO 09-23 16:01:48 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=3198)[0;0m INFO 09-23 16:01:48 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=3196)[0;0m INFO 09-23 16:01:48 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=3197)[0;0m INFO 09-23 16:01:48 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=3199)[0;0m [1;36m(VllmWorker rank=2 pid=3198)[0;0m INFO 09-23 16:01:48 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 09-23 16:01:48 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=3196)[0;0m INFO 09-23 16:01:48 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=3197)[0;0m INFO 09-23 16:01:48 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=3198)[0;0m INFO 09-23 16:01:48 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=3 pid=3199)[0;0m INFO 09-23 16:01:48 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=1 pid=3197)[0;0m INFO 09-23 16:01:48 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=0 pid=3196)[0;0m INFO 09-23 16:01:48 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=3198)[0;0m ERROR 09-23 16:01:48 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2130088 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:01:50 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:01:50 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:01:50 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:01:50 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:01:50 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:01:50 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:01:50 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:01:50 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:01:50 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:01:50 [core.py:396]     self._init_executor()
ERROR 09-23 16:01:50 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:01:50 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:01:50 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:01:50 [core.py:396]     raise e from None
ERROR 09-23 16:01:50 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:01:51] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_313
INFO 09-23 16:01:51 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:01:51 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:01:51 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:01:51 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:01:59 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:02:04 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:02:04 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:02:04 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_1758f1d9'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/da0ffec8-aba7-484e-bf37-db3e60364039', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:02:09 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:02:09 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:02:09 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:02:09 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:02:14 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f1dd0abce80>
[1;36m(VllmWorker rank=2 pid=3449)[0;0m INFO 09-23 16:02:14 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_776a6ce2'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/0099c9fd-bb9f-4594-bc78-8acac56b5926', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:02:15 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fe95d8d8d60>
[1;36m(VllmWorker rank=0 pid=3447)[0;0m INFO 09-23 16:02:15 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_76580f66'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/bcfd6385-77ec-4ce3-96c3-1a39607b672c', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:02:15 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f77a8be5030>
[1;36m(VllmWorker rank=3 pid=3450)[0;0m INFO 09-23 16:02:15 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_36465576'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/0a26ef9c-3354-41f0-ac50-64121f4f6869', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:02:15 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fd578c30f70>
[1;36m(VllmWorker rank=1 pid=3448)[0;0m INFO 09-23 16:02:15 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_bcb73172'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/90b56046-9d8f-4593-9c5b-58331310c34d', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=3448)[0;0m INFO 09-23 16:02:50 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=3448)[0;0m INFO 09-23 16:02:50 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=3450)[0;0m INFO 09-23 16:02:50 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=3449)[0;0m INFO 09-23 16:02:50 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=3447)[0;0m INFO 09-23 16:02:50 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=3450)[0;0m INFO 09-23 16:02:50 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=3449)[0;0m INFO 09-23 16:02:50 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=3447)[0;0m INFO 09-23 16:02:50 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=3448)[0;0m [1;36m(VllmWorker rank=3 pid=3450)[0;0m INFO 09-23 16:02:51 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:02:51 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=3449)[0;0m INFO 09-23 16:02:51 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=3447)[0;0m INFO 09-23 16:02:51 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=3447)[0;0m INFO 09-23 16:02:51 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_916528a0'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/49966390-b0d6-409b-96d2-51d00f823f0a', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=3450)[0;0m INFO 09-23 16:02:51 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=3449)[0;0m INFO 09-23 16:02:51 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=1 pid=3448)[0;0m [1;36m(VllmWorker rank=0 pid=3447)[0;0m INFO 09-23 16:02:51 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
INFO 09-23 16:02:51 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=3 pid=3450)[0;0m INFO 09-23 16:02:51 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=3449)[0;0m INFO 09-23 16:02:51 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=3448)[0;0m INFO 09-23 16:02:51 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=3447)[0;0m INFO 09-23 16:02:51 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=3450)[0;0m INFO 09-23 16:02:51 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=3449)[0;0m INFO 09-23 16:02:51 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=3448)[0;0m INFO 09-23 16:02:51 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=3447)[0;0m INFO 09-23 16:02:51 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=3450)[0;0m INFO 09-23 16:02:51 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=2 pid=3449)[0;0m INFO 09-23 16:02:51 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=1 pid=3448)[0;0m INFO 09-23 16:02:51 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=0 pid=3447)[0;0m INFO 09-23 16:02:51 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=3449)[0;0m ERROR 09-23 16:02:52 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2131139 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:02:54 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:02:54 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:02:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:02:54 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:02:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:02:54 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:02:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:02:54 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:02:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:02:54 [core.py:396]     self._init_executor()
ERROR 09-23 16:02:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:02:54 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:02:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:02:54 [core.py:396]     raise e from None
ERROR 09-23 16:02:54 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:02:55] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_100
INFO 09-23 16:02:55 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:02:55 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:02:55 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:02:55 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:03:00 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:03:05 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_100', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_100', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_100, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:03:05 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:03:05 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_a5e386a2'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/ae324c19-1aff-4008-bd49-05b7c223d6f5', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:03:11 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:03:11 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:03:11 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:03:11 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:03:16 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fdb25a35120>
[1;36m(VllmWorker rank=0 pid=3698)[0;0m INFO 09-23 16:03:16 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_cfc3ba74'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/9a765907-664f-4df4-9764-5df751ce7c13', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:03:16 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fa84ad20fd0>
[1;36m(VllmWorker rank=3 pid=3701)[0;0m INFO 09-23 16:03:16 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_0016608b'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/671a72b6-bfe3-40b2-8301-c3740803d279', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:03:16 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fc164cf2fe0>
[1;36m(VllmWorker rank=1 pid=3699)[0;0m INFO 09-23 16:03:16 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_a68ec869'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/63c4b78a-467f-4760-9493-aba1b92ef66f', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:03:16 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f18130ab550>
[1;36m(VllmWorker rank=2 pid=3700)[0;0m INFO 09-23 16:03:16 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_877db62d'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/53b3da52-7a2f-455f-8be0-b5ed9993fbcc', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=3699)[0;0m INFO 09-23 16:03:57 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=3699)[0;0m INFO 09-23 16:03:57 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=3701)[0;0m INFO 09-23 16:03:57 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=3701)[0;0m INFO 09-23 16:03:57 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=3698)[0;0m INFO 09-23 16:03:57 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=3700)[0;0m INFO 09-23 16:03:57 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=3698)[0;0m INFO 09-23 16:03:57 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=3700)[0;0m INFO 09-23 16:03:57 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=3700)[0;0m INFO 09-23 16:03:59 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=1 pid=3699)[0;0m INFO 09-23 16:03:59 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=3 pid=3701)[0;0m INFO 09-23 16:03:59 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=3698)[0;0m INFO 09-23 16:03:59 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=3698)[0;0m INFO 09-23 16:03:59 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_534dedce'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/222e3f2d-f2b3-46ea-bc59-c7d07666e9f1', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=3700)[0;0m [1;36m(VllmWorker rank=1 pid=3699)[0;0m INFO 09-23 16:03:59 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
INFO 09-23 16:03:59 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=3 pid=3701)[0;0m INFO 09-23 16:03:59 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=3700)[0;0m INFO 09-23 16:03:59 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=3699)[0;0m INFO 09-23 16:03:59 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=3700)[0;0m INFO 09-23 16:03:59 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=3701)[0;0m INFO 09-23 16:03:59 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=3699)[0;0m INFO 09-23 16:03:59 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=3698)[0;0m INFO 09-23 16:03:59 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=3 pid=3701)[0;0m INFO 09-23 16:03:59 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=3698)[0;0m INFO 09-23 16:03:59 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=3698)[0;0m INFO 09-23 16:03:59 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=3700)[0;0m INFO 09-23 16:03:59 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=1 pid=3699)[0;0m INFO 09-23 16:03:59 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=3 pid=3701)[0;0m INFO 09-23 16:03:59 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=0 pid=3698)[0;0m INFO 09-23 16:03:59 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_100...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=1 pid=3699)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 1 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088947 has 37.62 GiB memory in use. Process 2132097 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=3700)[0;0m ERROR 09-23 16:04:00 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2132098 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:04:01 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:04:01 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:04:01 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:04:01 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:04:01 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:04:01 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:04:01 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:04:01 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:04:01 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:04:01 [core.py:396]     self._init_executor()
ERROR 09-23 16:04:01 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:04:01 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:04:01 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:04:01 [core.py:396]     raise e from None
ERROR 09-23 16:04:01 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:04:03] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_200
INFO 09-23 16:04:03 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:04:03 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:04:03 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:04:03 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:04:09 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:04:14 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:04:14 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:04:14 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_b1396134'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/08e0c919-4fcb-4186-941b-71385833e2c5', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:04:19 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:04:19 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:04:19 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:04:19 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:04:24 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fac9f6c4d60>
[1;36m(VllmWorker rank=2 pid=3951)[0;0m INFO 09-23 16:04:24 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_99790f92'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/03fef9cd-83b9-40c4-8917-ba13528dae05', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:04:25 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fa3d64c8d90>
[1;36m(VllmWorker rank=3 pid=3952)[0;0m INFO 09-23 16:04:25 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_39b0857a'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/e45e729e-955e-4d96-9036-091bcf500293', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:04:25 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f22f20c0fd0>
[1;36m(VllmWorker rank=1 pid=3950)[0;0m INFO 09-23 16:04:25 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_9bc2be0a'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/7bdbf67a-010a-417e-bb10-b92ff9d7121f', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:04:25 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f73218a9000>
[1;36m(VllmWorker rank=0 pid=3949)[0;0m INFO 09-23 16:04:25 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_6d0e3a43'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/42d076da-f946-4e54-a552-c875bf23cb06', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=3950)[0;0m INFO 09-23 16:05:00 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=3949)[0;0m INFO 09-23 16:05:00 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=3951)[0;0m INFO 09-23 16:05:00 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=3952)[0;0m INFO 09-23 16:05:00 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=3950)[0;0m INFO 09-23 16:05:00 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=3949)[0;0m INFO 09-23 16:05:00 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=3951)[0;0m INFO 09-23 16:05:00 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=3952)[0;0m INFO 09-23 16:05:00 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=3951)[0;0m [1;36m(VllmWorker rank=1 pid=3950)[0;0m [1;36m(VllmWorker rank=3 pid=3952)[0;0m [1;36m(VllmWorker rank=0 pid=3949)[0;0m INFO 09-23 16:05:01 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:05:01 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:05:01 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:05:01 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=3949)[0;0m INFO 09-23 16:05:02 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_5c7e718a'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/94b90e54-15c4-4f82-a4c6-1e82f160725b', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=3950)[0;0m INFO 09-23 16:05:02 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=2 pid=3951)[0;0m INFO 09-23 16:05:02 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=1 pid=3950)[0;0m INFO 09-23 16:05:02 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=3952)[0;0m INFO 09-23 16:05:02 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=0 pid=3949)[0;0m INFO 09-23 16:05:02 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=2 pid=3951)[0;0m INFO 09-23 16:05:02 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=3950)[0;0m INFO 09-23 16:05:02 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=3952)[0;0m INFO 09-23 16:05:02 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=3949)[0;0m INFO 09-23 16:05:02 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=3951)[0;0m INFO 09-23 16:05:02 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=3952)[0;0m INFO 09-23 16:05:02 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=3949)[0;0m INFO 09-23 16:05:02 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=3950)[0;0m INFO 09-23 16:05:02 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=2 pid=3951)[0;0m INFO 09-23 16:05:02 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=3 pid=3952)[0;0m INFO 09-23 16:05:02 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=0 pid=3949)[0;0m INFO 09-23 16:05:02 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=3951)[0;0m ERROR 09-23 16:05:02 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2133087 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fa527d6c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7fa527d15b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7fa4d8c8e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7fa52816bb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7fa52816c20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39afa (0x7fa528182afa in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7fa52816e329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7fa5202864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7fa51f9a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7fa51f9a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x55a501f40c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x55a501ecd2a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x55a501ecdbbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x55a501ecdc83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x55a501f40b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x55a501facc3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x55a501faff1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x55a501ecec98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x55a50200dc30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x55a502033407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x55a502033634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x55a502033718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x55a50203375b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x55a502033972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x55a502039f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x55a50203a1ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x55a50203a469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7fa528fa6d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7fa528fa6e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x55a501fa52d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

ERROR 09-23 16:05:04 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:05:04 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:05:04 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:05:04 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:05:04 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:05:04 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:05:04 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:05:04 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:05:04 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:05:04 [core.py:396]     self._init_executor()
ERROR 09-23 16:05:04 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:05:04 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:05:04 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:05:04 [core.py:396]     raise e from None
ERROR 09-23 16:05:04 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:05:05] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_313
INFO 09-23 16:05:05 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:05:05 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:05:05 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:05:05 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:05:12 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:05:17 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:05:17 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:05:17 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_dda95c64'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/fef17e24-5a7f-45c2-acff-08aa559220f6', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:05:22 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:05:22 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:05:22 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:05:23 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:05:28 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f0d46069030>
[1;36m(VllmWorker rank=0 pid=4200)[0;0m INFO 09-23 16:05:28 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_635c5e11'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/488ffba8-17d8-4a4b-8e7f-cd87b06b7e27', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:05:28 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f264eaa90c0>
[1;36m(VllmWorker rank=2 pid=4202)[0;0m INFO 09-23 16:05:28 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_8ce84342'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/0fb53665-1e9f-4dff-b412-5af304c8f48a', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:05:28 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7ff675e89120>
[1;36m(VllmWorker rank=3 pid=4203)[0;0m INFO 09-23 16:05:28 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_d3135123'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/b48f6bbc-2661-47a1-b351-6ecc1793e5ca', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:05:28 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f7a56d61000>
[1;36m(VllmWorker rank=1 pid=4201)[0;0m INFO 09-23 16:05:28 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_850868dd'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/17295dee-630d-496b-9bb7-ea1251c55fde', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=4200)[0;0m INFO 09-23 16:06:04 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=4200)[0;0m [1;36m(VllmWorker rank=3 pid=4203)[0;0m INFO 09-23 16:06:04 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 16:06:04 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=4202)[0;0m INFO 09-23 16:06:04 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=4203)[0;0m INFO 09-23 16:06:04 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=4201)[0;0m INFO 09-23 16:06:04 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=4202)[0;0m INFO 09-23 16:06:04 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=4201)[0;0m INFO 09-23 16:06:04 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=4202)[0;0m INFO 09-23 16:06:05 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=4200)[0;0m INFO 09-23 16:06:05 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=1 pid=4201)[0;0m INFO 09-23 16:06:05 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=3 pid=4203)[0;0m INFO 09-23 16:06:05 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=4200)[0;0m INFO 09-23 16:06:05 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_1ef76534'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/581bf0b8-6e4a-461e-8220-026428525a20', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=4203)[0;0m INFO 09-23 16:06:05 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=4202)[0;0m [1;36m(VllmWorker rank=0 pid=4200)[0;0m INFO 09-23 16:06:05 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
INFO 09-23 16:06:05 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=1 pid=4201)[0;0m INFO 09-23 16:06:05 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=3 pid=4203)[0;0m INFO 09-23 16:06:05 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=4200)[0;0m [1;36m(VllmWorker rank=2 pid=4202)[0;0m INFO 09-23 16:06:05 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 09-23 16:06:05 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=4201)[0;0m INFO 09-23 16:06:05 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=4202)[0;0m [1;36m(VllmWorker rank=0 pid=4200)[0;0m [1;36m(VllmWorker rank=3 pid=4203)[0;0m INFO 09-23 16:06:05 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 09-23 16:06:05 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 09-23 16:06:05 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=4201)[0;0m INFO 09-23 16:06:05 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=4203)[0;0m INFO 09-23 16:06:05 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=2 pid=4202)[0;0m INFO 09-23 16:06:05 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=1 pid=4201)[0;0m INFO 09-23 16:06:05 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=0 pid=4200)[0;0m INFO 09-23 16:06:05 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=4202)[0;0m ERROR 09-23 16:06:06 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2134095 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7ff7c776c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7ff7c7715b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7ff77868e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7ff7c7b6bb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7ff7c7b6c20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39afa (0x7ff7c7b82afa in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7ff7c7b6e329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7ff7bfc864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7ff7bf3a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7ff7bf3a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x56118b9afc04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x56118b93c2a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x56118b93cbbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x56118b93cc83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x56118b9afb85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x56118ba1bc3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x56118ba1ef1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x56118b93dc98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x56118ba7cc30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x56118baa2407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x56118baa2634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x56118baa2718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x56118baa275b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x56118baa2972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x56118baa8f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x56118baa91ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x56118baa9469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7ff7c8983d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7ff7c8983e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x56118ba142d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

ERROR 09-23 16:06:08 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:06:08 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:06:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:06:08 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:06:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:06:08 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:06:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:06:08 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:06:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:06:08 [core.py:396]     self._init_executor()
ERROR 09-23 16:06:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:06:08 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:06:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:06:08 [core.py:396]     raise e from None
ERROR 09-23 16:06:08 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:06:09] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_100
INFO 09-23 16:06:09 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:06:09 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:06:09 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:06:09 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:06:14 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:06:19 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_100', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_100', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_100, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:06:19 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:06:19 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_6a776a61'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/87ed6800-9879-478e-a6d6-6d9bdf59a460', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:06:24 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:06:25 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:06:25 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:06:25 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:06:30 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f39f51ccf70>
[1;36m(VllmWorker rank=0 pid=4451)[0;0m INFO 09-23 16:06:30 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_30d90609'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/e080857e-662a-4e23-aa34-d1a0a9a77972', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:06:30 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fae0e2d8f40>
[1;36m(VllmWorker rank=2 pid=4453)[0;0m INFO 09-23 16:06:30 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_b5896b3e'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/e9325aea-7be2-4d89-be9f-3341aa975235', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:06:30 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f3ee07bd060>
[1;36m(VllmWorker rank=3 pid=4454)[0;0m INFO 09-23 16:06:30 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_b2a4eab4'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/8d7434c2-5569-44e6-99a6-05d2c41c8d33', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:06:30 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fec7c588f40>
[1;36m(VllmWorker rank=1 pid=4452)[0;0m INFO 09-23 16:06:30 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_1792969d'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/576e3fb9-8405-45a8-943c-85dafe2f84ea', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=4452)[0;0m INFO 09-23 16:07:06 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=4452)[0;0m INFO 09-23 16:07:06 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=4454)[0;0m INFO 09-23 16:07:06 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=4453)[0;0m INFO 09-23 16:07:06 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=4454)[0;0m INFO 09-23 16:07:06 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=4451)[0;0m INFO 09-23 16:07:06 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=4453)[0;0m INFO 09-23 16:07:06 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=4451)[0;0m INFO 09-23 16:07:06 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=4454)[0;0m INFO 09-23 16:07:09 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=1 pid=4452)[0;0m INFO 09-23 16:07:09 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=4451)[0;0m INFO 09-23 16:07:09 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=4453)[0;0m INFO 09-23 16:07:09 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=4451)[0;0m INFO 09-23 16:07:09 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_f2cf951b'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/75edb707-3c73-43c9-80ab-a417f300f5e0', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=4454)[0;0m INFO 09-23 16:07:09 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=3 pid=4454)[0;0m INFO 09-23 16:07:09 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=4453)[0;0m INFO 09-23 16:07:09 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=1 pid=4452)[0;0m INFO 09-23 16:07:09 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=3 pid=4454)[0;0m INFO 09-23 16:07:09 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=4453)[0;0m INFO 09-23 16:07:09 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=4452)[0;0m INFO 09-23 16:07:09 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=4451)[0;0m [1;36m(VllmWorker rank=2 pid=4453)[0;0m INFO 09-23 16:07:09 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 09-23 16:07:09 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=4452)[0;0m INFO 09-23 16:07:09 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=4451)[0;0m INFO 09-23 16:07:09 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=4451)[0;0m INFO 09-23 16:07:09 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=4454)[0;0m INFO 09-23 16:07:09 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=2 pid=4453)[0;0m INFO 09-23 16:07:09 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=1 pid=4452)[0;0m INFO 09-23 16:07:09 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=0 pid=4451)[0;0m INFO 09-23 16:07:09 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_100...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=4454)[0;0m ERROR 09-23 16:07:09 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 3 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088949 has 37.61 GiB memory in use. Process 2135070 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:07:11 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:07:11 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:07:11 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:07:11 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:07:11 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:07:11 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:07:11 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:07:11 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:07:11 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:07:11 [core.py:396]     self._init_executor()
ERROR 09-23 16:07:11 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:07:11 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:07:11 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:07:11 [core.py:396]     raise e from None
ERROR 09-23 16:07:11 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:07:13] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_200
INFO 09-23 16:07:13 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:07:13 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:07:13 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:07:13 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:07:20 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:07:24 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:07:24 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:07:24 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_a0af6cda'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/bb7a59aa-605a-4199-b6d3-c262117d572e', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:07:30 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:07:30 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:07:30 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:07:30 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:07:35 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f4a74731090>
[1;36m(VllmWorker rank=2 pid=4704)[0;0m INFO 09-23 16:07:35 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_c2390b73'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/3681b225-05c8-4e70-8540-5eabef2f0e33', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:07:35 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f1b362d4f10>
[1;36m(VllmWorker rank=0 pid=4702)[0;0m INFO 09-23 16:07:35 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_510bb68d'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/69f49bc3-76da-425e-a73c-81bae7877939', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:07:35 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f18703c0df0>
[1;36m(VllmWorker rank=3 pid=4705)[0;0m INFO 09-23 16:07:35 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_92aa3e00'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/176fe336-21b7-4a0c-a465-19ff0e106363', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:07:35 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f859e23d000>
[1;36m(VllmWorker rank=1 pid=4703)[0;0m INFO 09-23 16:07:35 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_1c88b2ec'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/559f52d9-b8f7-4226-891d-41bd067a8423', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=4702)[0;0m [1;36m(VllmWorker rank=2 pid=4704)[0;0m INFO 09-23 16:08:11 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 16:08:11 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=4703)[0;0m INFO 09-23 16:08:11 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=4702)[0;0m INFO 09-23 16:08:11 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=4704)[0;0m INFO 09-23 16:08:11 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=4703)[0;0m INFO 09-23 16:08:11 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=4705)[0;0m INFO 09-23 16:08:11 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=4705)[0;0m INFO 09-23 16:08:11 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=4702)[0;0m INFO 09-23 16:08:13 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=1 pid=4703)[0;0m INFO 09-23 16:08:13 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=3 pid=4705)[0;0m [1;36m(VllmWorker rank=2 pid=4704)[0;0m INFO 09-23 16:08:13 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:08:13 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=4702)[0;0m INFO 09-23 16:08:13 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_9d505af8'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/8d7c16ee-d2cb-492f-be64-7b30248dfc43', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=4704)[0;0m INFO 09-23 16:08:13 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=0 pid=4702)[0;0m INFO 09-23 16:08:13 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=0 pid=4702)[0;0m INFO 09-23 16:08:13 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=4704)[0;0m INFO 09-23 16:08:13 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=4705)[0;0m INFO 09-23 16:08:13 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=0 pid=4702)[0;0m INFO 09-23 16:08:13 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=4703)[0;0m INFO 09-23 16:08:13 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=2 pid=4704)[0;0m INFO 09-23 16:08:13 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=4705)[0;0m INFO 09-23 16:08:13 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=4703)[0;0m INFO 09-23 16:08:13 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=4703)[0;0m [1;36m(VllmWorker rank=3 pid=4705)[0;0m INFO 09-23 16:08:13 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 09-23 16:08:13 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=4704)[0;0m INFO 09-23 16:08:13 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=1 pid=4703)[0;0m [1;36m(VllmWorker rank=3 pid=4705)[0;0m INFO 09-23 16:08:13 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_200...
INFO 09-23 16:08:13 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=0 pid=4702)[0;0m INFO 09-23 16:08:13 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=4702)[0;0m ERROR 09-23 16:08:13 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088946 has 37.61 GiB memory in use. Process 2136222 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f19bdf6c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f19bdf15b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f196ea8e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f19be3bbb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f19be3bc20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39afa (0x7f19be3d2afa in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f19be3be329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f19b60864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f19b57a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f19b57a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x55b8560fbc04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x55b8560882a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x55b856088bbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x55b856088c83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x55b8560fbb85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x55b856167c3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x55b85616af1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x55b856089c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x55b8561c8c30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x55b8561ee407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x55b8561ee634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x55b8561ee718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x55b8561ee75b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x55b8561ee972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x55b8561f4f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x55b8561f51ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x55b8561f5469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f19beeb7d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f19beeb7e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x55b8561602d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

ERROR 09-23 16:08:15 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:08:15 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:08:15 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:08:15 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:08:15 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:08:15 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:08:15 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:08:15 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:08:15 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:08:15 [core.py:396]     self._init_executor()
ERROR 09-23 16:08:15 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:08:15 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:08:15 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:08:15 [core.py:396]     raise e from None
ERROR 09-23 16:08:15 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:08:16] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_313
INFO 09-23 16:08:16 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:08:16 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:08:16 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:08:16 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:08:22 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:08:28 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:08:28 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:08:28 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_871cbcac'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/dc749f6b-734a-4642-8c76-01312fd41c74', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:08:33 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:08:33 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:08:33 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:08:33 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:08:39 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f2f166d4eb0>
[1;36m(VllmWorker rank=2 pid=4955)[0;0m INFO 09-23 16:08:39 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_8e5f86c2'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/356aaec5-09a1-4a5e-acec-69ed0ff088f0', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:08:39 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f10ce145000>
[1;36m(VllmWorker rank=0 pid=4953)[0;0m INFO 09-23 16:08:39 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_1ab8b296'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/b8021a23-568f-4094-8e4c-694ee47bbbbc', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:08:39 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7ff5d7129030>
[1;36m(VllmWorker rank=3 pid=4956)[0;0m INFO 09-23 16:08:39 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_3dff818f'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/a0f6ab97-9a94-4c26-a968-7e4aabc48e46', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:08:39 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7ff404ed8eb0>
[1;36m(VllmWorker rank=1 pid=4954)[0;0m INFO 09-23 16:08:39 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_a1e27863'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/e7eab78e-9ed6-4803-92d9-831fd492c9f0', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=4956)[0;0m [1;36m(VllmWorker rank=2 pid=4955)[0;0m INFO 09-23 16:09:15 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 16:09:15 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=4953)[0;0m INFO 09-23 16:09:15 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=4955)[0;0m [1;36m(VllmWorker rank=3 pid=4956)[0;0m INFO 09-23 16:09:15 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=4953)[0;0m INFO 09-23 16:09:15 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 16:09:15 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=4954)[0;0m INFO 09-23 16:09:15 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=4954)[0;0m INFO 09-23 16:09:15 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=4956)[0;0m [1;36m(VllmWorker rank=0 pid=4953)[0;0m [1;36m(VllmWorker rank=2 pid=4955)[0;0m INFO 09-23 16:09:16 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:09:16 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:09:16 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=1 pid=4954)[0;0m INFO 09-23 16:09:16 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=4953)[0;0m INFO 09-23 16:09:16 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_83768c07'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/e956d8dc-25f9-4c01-99a8-84925e106e38', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=4956)[0;0m INFO 09-23 16:09:16 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=4955)[0;0m [1;36m(VllmWorker rank=1 pid=4954)[0;0m INFO 09-23 16:09:16 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
INFO 09-23 16:09:16 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=0 pid=4953)[0;0m INFO 09-23 16:09:16 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=3 pid=4956)[0;0m INFO 09-23 16:09:16 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=4955)[0;0m INFO 09-23 16:09:16 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=4953)[0;0m INFO 09-23 16:09:16 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=4954)[0;0m INFO 09-23 16:09:16 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=4956)[0;0m INFO 09-23 16:09:16 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=4955)[0;0m INFO 09-23 16:09:16 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=4953)[0;0m INFO 09-23 16:09:16 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=4954)[0;0m INFO 09-23 16:09:16 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=4956)[0;0m INFO 09-23 16:09:16 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=2 pid=4955)[0;0m INFO 09-23 16:09:16 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=1 pid=4954)[0;0m INFO 09-23 16:09:16 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=0 pid=4953)[0;0m INFO 09-23 16:09:16 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=4955)[0;0m ERROR 09-23 16:09:16 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2137249 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:09:18 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:09:18 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:09:18 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:09:18 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:09:18 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:09:18 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:09:18 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:09:18 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:09:18 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:09:18 [core.py:396]     self._init_executor()
ERROR 09-23 16:09:18 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:09:18 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:09:18 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:09:18 [core.py:396]     raise e from None
ERROR 09-23 16:09:18 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:09:19] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_200
INFO 09-23 16:09:19 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:09:19 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:09:19 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:09:19 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:09:25 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:09:30 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:09:30 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:09:30 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_9949c2f9'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/6f491bab-f706-4a12-881d-1c54034653d1', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:09:35 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:09:35 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:09:35 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:09:35 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:09:41 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fae50eed0c0>
WARNING 09-23 16:09:41 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f75ac1ecf70>
[1;36m(VllmWorker rank=1 pid=5205)[0;0m INFO 09-23 16:09:41 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_88a1f3f4'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/b623628f-8ff6-42d0-a9b9-68f0af6f7c2b', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=5207)[0;0m INFO 09-23 16:09:41 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_57a4c31f'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/a36f9de5-8346-4e57-a422-32109d1942a1', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:09:41 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7ff6de52ce20>
[1;36m(VllmWorker rank=0 pid=5204)[0;0m INFO 09-23 16:09:41 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_8d8e606a'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/a6577308-491c-4ff0-8acf-2f47357941db', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:09:41 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fbebf67cdf0>
[1;36m(VllmWorker rank=2 pid=5206)[0;0m INFO 09-23 16:09:41 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_3efb3bc2'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/77a96cf5-a449-4290-a79a-1fe10fb5c212', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=5204)[0;0m INFO 09-23 16:10:17 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=5206)[0;0m INFO 09-23 16:10:17 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=5207)[0;0m INFO 09-23 16:10:17 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=5204)[0;0m INFO 09-23 16:10:17 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=5206)[0;0m INFO 09-23 16:10:17 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=5207)[0;0m INFO 09-23 16:10:17 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=5205)[0;0m INFO 09-23 16:10:17 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=5205)[0;0m INFO 09-23 16:10:17 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=5207)[0;0m [1;36m(VllmWorker rank=1 pid=5205)[0;0m INFO 09-23 16:10:18 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:10:18 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=5206)[0;0m INFO 09-23 16:10:18 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=5204)[0;0m INFO 09-23 16:10:18 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=5204)[0;0m INFO 09-23 16:10:18 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_94d8a1ca'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/776bc124-070c-4d40-a463-6d60c86620c3', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=5207)[0;0m [1;36m(VllmWorker rank=2 pid=5206)[0;0m INFO 09-23 16:10:18 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
INFO 09-23 16:10:18 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=0 pid=5204)[0;0m INFO 09-23 16:10:18 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=1 pid=5205)[0;0m INFO 09-23 16:10:18 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=3 pid=5207)[0;0m INFO 09-23 16:10:18 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=5206)[0;0m INFO 09-23 16:10:18 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=5205)[0;0m INFO 09-23 16:10:18 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=5204)[0;0m INFO 09-23 16:10:18 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=5207)[0;0m INFO 09-23 16:10:18 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=5206)[0;0m INFO 09-23 16:10:18 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=5205)[0;0m INFO 09-23 16:10:18 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=5204)[0;0m INFO 09-23 16:10:18 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=5207)[0;0m INFO 09-23 16:10:18 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=2 pid=5206)[0;0m INFO 09-23 16:10:18 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=1 pid=5205)[0;0m INFO 09-23 16:10:18 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=0 pid=5204)[0;0m INFO 09-23 16:10:18 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=5207)[0;0m ERROR 09-23 16:10:19 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 3 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088949 has 37.61 GiB memory in use. Process 2138254 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:10:20 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:10:20 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:10:20 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:10:20 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:10:20 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:10:20 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:10:20 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:10:20 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:10:20 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:10:20 [core.py:396]     self._init_executor()
ERROR 09-23 16:10:20 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:10:20 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:10:20 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:10:20 [core.py:396]     raise e from None
ERROR 09-23 16:10:20 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:10:22] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_313
INFO 09-23 16:10:22 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:10:22 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:10:22 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:10:22 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:10:31 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:10:36 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:10:36 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:10:36 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_1455a620'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/54d7e1b1-9d2d-46c1-ad9f-abc51d2f0e19', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:10:42 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:10:42 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:10:42 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:10:42 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:10:47 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f4dbc28d180>
[1;36m(VllmWorker rank=2 pid=5457)[0;0m INFO 09-23 16:10:47 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_91049a66'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/8cd5b2b4-d3b5-4928-bb91-298e1c43c88b', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:10:47 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f0a515d4f70>
[1;36m(VllmWorker rank=0 pid=5455)[0;0m INFO 09-23 16:10:47 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_a2a581e5'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/7e249571-d709-42ac-8e7e-d86f0e90bd9c', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:10:47 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f5bc9001030>
[1;36m(VllmWorker rank=1 pid=5456)[0;0m INFO 09-23 16:10:47 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_5c719618'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/e5354ab9-c027-4719-9d22-c86b1e35ac9c', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:10:47 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fd3f2dd4e50>
[1;36m(VllmWorker rank=3 pid=5458)[0;0m INFO 09-23 16:10:47 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_f048c931'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/d12d9e85-9e34-4fac-be86-3a95d12ddbf4', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=5458)[0;0m INFO 09-23 16:11:23 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=5456)[0;0m [1;36m(VllmWorker rank=2 pid=5457)[0;0m INFO 09-23 16:11:23 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 16:11:23 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=5458)[0;0m INFO 09-23 16:11:23 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=5457)[0;0m INFO 09-23 16:11:23 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=5456)[0;0m INFO 09-23 16:11:23 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=5455)[0;0m INFO 09-23 16:11:23 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=5455)[0;0m INFO 09-23 16:11:23 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=5458)[0;0m [1;36m(VllmWorker rank=1 pid=5456)[0;0m [1;36m(VllmWorker rank=0 pid=5455)[0;0m INFO 09-23 16:11:24 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:11:24 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=5457)[0;0m INFO 09-23 16:11:24 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:11:24 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=5455)[0;0m INFO 09-23 16:11:24 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_8185b81f'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/a6cacb32-fe0d-46cf-be8d-7b030f436ce6', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=5458)[0;0m INFO 09-23 16:11:24 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=5457)[0;0m INFO 09-23 16:11:24 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=1 pid=5456)[0;0m [1;36m(VllmWorker rank=0 pid=5455)[0;0m INFO 09-23 16:11:24 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
INFO 09-23 16:11:24 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=3 pid=5458)[0;0m INFO 09-23 16:11:24 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=5457)[0;0m INFO 09-23 16:11:24 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=5455)[0;0m INFO 09-23 16:11:24 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=5456)[0;0m INFO 09-23 16:11:24 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=5458)[0;0m INFO 09-23 16:11:24 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=5457)[0;0m INFO 09-23 16:11:24 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=5455)[0;0m INFO 09-23 16:11:24 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=5456)[0;0m INFO 09-23 16:11:24 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=5458)[0;0m INFO 09-23 16:11:24 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=2 pid=5457)[0;0m INFO 09-23 16:11:24 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=1 pid=5456)[0;0m INFO 09-23 16:11:24 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=0 pid=5455)[0;0m INFO 09-23 16:11:24 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=5458)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 3 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088949 has 37.61 GiB memory in use. Process 2139377 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=5455)[0;0m ERROR 09-23 16:11:24 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088946 has 37.61 GiB memory in use. Process 2139374 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:11:26 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:11:26 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:11:26 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:11:26 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:11:26 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:11:26 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:11:26 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:11:26 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:11:26 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:11:26 [core.py:396]     self._init_executor()
ERROR 09-23 16:11:26 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:11:26 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:11:26 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:11:26 [core.py:396]     raise e from None
ERROR 09-23 16:11:26 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:11:28] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_200
INFO 09-23 16:11:28 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:11:28 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:11:28 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:11:28 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:11:33 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:11:40 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:11:40 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:11:40 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_c68f4031'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/bcc5aa62-a21c-4809-95d9-7f572d720b21', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:11:45 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:11:45 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:11:45 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:11:45 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:11:51 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f3345d90eb0>
WARNING 09-23 16:11:51 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f3c15f01060>
[1;36m(VllmWorker rank=1 pid=5707)[0;0m INFO 09-23 16:11:51 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_707492cc'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/61d6b0b5-59a7-4b33-891e-d524899c1aa9', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=5706)[0;0m INFO 09-23 16:11:51 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_4228076e'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/73901358-8695-43c9-aeae-fa17e70badc2', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:11:51 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f2c3dcc0eb0>
[1;36m(VllmWorker rank=3 pid=5709)[0;0m INFO 09-23 16:11:51 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_b19671f6'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/85ed492c-3710-4ee2-b3b5-6c6190899cb1', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:11:51 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f5813eccf40>
[1;36m(VllmWorker rank=2 pid=5708)[0;0m INFO 09-23 16:11:51 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_97f84d2c'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/ad062941-f227-49e0-88ad-41e40391bd2a', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=5707)[0;0m INFO 09-23 16:12:27 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=5706)[0;0m INFO 09-23 16:12:27 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=5707)[0;0m INFO 09-23 16:12:27 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=5706)[0;0m INFO 09-23 16:12:27 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=5709)[0;0m INFO 09-23 16:12:27 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=5708)[0;0m INFO 09-23 16:12:27 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=5709)[0;0m INFO 09-23 16:12:27 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=5708)[0;0m INFO 09-23 16:12:27 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=5707)[0;0m [1;36m(VllmWorker rank=3 pid=5709)[0;0m INFO 09-23 16:12:28 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:12:28 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=5706)[0;0m INFO 09-23 16:12:28 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=5708)[0;0m INFO 09-23 16:12:28 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=5706)[0;0m INFO 09-23 16:12:28 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_729827f2'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/928ae96a-7138-423b-8834-9193273b08b4', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=5709)[0;0m INFO 09-23 16:12:28 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=5708)[0;0m INFO 09-23 16:12:28 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=1 pid=5707)[0;0m INFO 09-23 16:12:28 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=0 pid=5706)[0;0m INFO 09-23 16:12:28 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=3 pid=5709)[0;0m INFO 09-23 16:12:28 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=5708)[0;0m INFO 09-23 16:12:28 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=5707)[0;0m INFO 09-23 16:12:28 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=5706)[0;0m INFO 09-23 16:12:28 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=5709)[0;0m INFO 09-23 16:12:28 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=5708)[0;0m INFO 09-23 16:12:28 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=5707)[0;0m INFO 09-23 16:12:28 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=5706)[0;0m INFO 09-23 16:12:28 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=5707)[0;0m INFO 09-23 16:12:28 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=3 pid=5709)[0;0m [1;36m(VllmWorker rank=2 pid=5708)[0;0m INFO 09-23 16:12:28 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_200...
INFO 09-23 16:12:28 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=0 pid=5706)[0;0m INFO 09-23 16:12:28 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=5709)[0;0m ERROR 09-23 16:12:28 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 3 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088949 has 37.61 GiB memory in use. Process 2140424 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:12:30 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:12:30 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:12:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:12:30 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:12:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:12:30 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:12:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:12:30 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:12:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:12:30 [core.py:396]     self._init_executor()
ERROR 09-23 16:12:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:12:30 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:12:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:12:30 [core.py:396]     raise e from None
ERROR 09-23 16:12:30 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:12:32] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_313
INFO 09-23 16:12:32 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:12:32 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:12:32 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:12:32 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:12:37 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:12:43 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:12:43 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:12:43 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_aa108167'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/9e9ad57b-235f-436a-8f3d-f04354fea51a', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:12:48 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:12:48 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:12:48 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:12:48 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:12:53 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fc5574ecf70>
[1;36m(VllmWorker rank=3 pid=5960)[0;0m INFO 09-23 16:12:53 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_f66a3640'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/8cfaa279-c5d6-498b-9903-4d8ce2e2ee11', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:12:53 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f5ee4504f40>
[1;36m(VllmWorker rank=1 pid=5958)[0;0m INFO 09-23 16:12:53 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_441e15ea'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/c89fd29c-1489-4dc9-a299-670b44d7df3b', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:12:53 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fbba1919030>
[1;36m(VllmWorker rank=2 pid=5959)[0;0m INFO 09-23 16:12:53 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_95816cc5'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/718c61a4-00c2-4b14-9c72-d2dc80a07517', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:12:54 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f84e49c8ee0>
[1;36m(VllmWorker rank=0 pid=5957)[0;0m INFO 09-23 16:12:54 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_bea4e637'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/bb61a9b2-1128-4e91-9100-8b4c0e569efe', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=5958)[0;0m [1;36m(VllmWorker rank=3 pid=5960)[0;0m INFO 09-23 16:13:34 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 16:13:34 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=5960)[0;0m INFO 09-23 16:13:34 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=5958)[0;0m INFO 09-23 16:13:34 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=5959)[0;0m INFO 09-23 16:13:34 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=5959)[0;0m INFO 09-23 16:13:34 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=5957)[0;0m INFO 09-23 16:13:34 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=5957)[0;0m INFO 09-23 16:13:34 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=5958)[0;0m INFO 09-23 16:13:36 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=5959)[0;0m INFO 09-23 16:13:36 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=5957)[0;0m [1;36m(VllmWorker rank=3 pid=5960)[0;0m INFO 09-23 16:13:36 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:13:36 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=5957)[0;0m INFO 09-23 16:13:36 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_51b613f2'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/b9388f37-8f31-4edc-924b-84b22c85002a', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=5959)[0;0m INFO 09-23 16:13:36 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=3 pid=5960)[0;0m INFO 09-23 16:13:36 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=5959)[0;0m INFO 09-23 16:13:36 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=5960)[0;0m INFO 09-23 16:13:36 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=5959)[0;0m INFO 09-23 16:13:36 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=5960)[0;0m INFO 09-23 16:13:36 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=5958)[0;0m INFO 09-23 16:13:36 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=1 pid=5958)[0;0m INFO 09-23 16:13:36 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=5957)[0;0m INFO 09-23 16:13:36 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=1 pid=5958)[0;0m INFO 09-23 16:13:36 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=5957)[0;0m INFO 09-23 16:13:36 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=5957)[0;0m INFO 09-23 16:13:36 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=5960)[0;0m INFO 09-23 16:13:36 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=1 pid=5958)[0;0m INFO 09-23 16:13:36 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=2 pid=5959)[0;0m INFO 09-23 16:13:36 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=0 pid=5957)[0;0m INFO 09-23 16:13:36 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=5959)[0;0m ERROR 09-23 16:13:37 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2141394 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:13:39 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:13:39 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:13:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:13:39 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:13:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:13:39 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:13:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:13:39 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:13:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:13:39 [core.py:396]     self._init_executor()
ERROR 09-23 16:13:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:13:39 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:13:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:13:39 [core.py:396]     raise e from None
ERROR 09-23 16:13:39 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:13:40] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_100
INFO 09-23 16:13:40 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:13:40 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:13:40 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:13:40 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:13:47 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:13:53 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_100', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_100', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_100, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:13:53 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:13:53 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_05f1ed05'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/c58a854a-5856-49c9-947e-d018c6e5d028', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:13:58 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:13:58 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:13:58 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:13:58 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:14:04 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f59ca59ceb0>
WARNING 09-23 16:14:04 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fb60bba0e50>
[1;36m(VllmWorker rank=1 pid=6209)[0;0m INFO 09-23 16:14:04 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_2145fd35'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/f695bc2e-97b0-4ddb-b560-99e9062e9430', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=6211)[0;0m INFO 09-23 16:14:04 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_96fcdbaa'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/c7cbf36b-9569-4bf3-9683-a2888be2aaa8', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:14:04 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f390d824ee0>
WARNING 09-23 16:14:04 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f9d8def4d90>
[1;36m(VllmWorker rank=2 pid=6210)[0;0m INFO 09-23 16:14:04 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_4c880c2d'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/dff4d8ce-b43d-4e9d-812b-8640a273f819', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=6208)[0;0m INFO 09-23 16:14:04 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_dd3c4522'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/25eddef7-f1a8-4d68-b94c-4956339c6480', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=6211)[0;0m INFO 09-23 16:14:40 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=6211)[0;0m INFO 09-23 16:14:40 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=6208)[0;0m INFO 09-23 16:14:40 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=6208)[0;0m INFO 09-23 16:14:40 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=6210)[0;0m INFO 09-23 16:14:40 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=6210)[0;0m INFO 09-23 16:14:40 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=6209)[0;0m INFO 09-23 16:14:40 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=6209)[0;0m INFO 09-23 16:14:40 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=6209)[0;0m [1;36m(VllmWorker rank=0 pid=6208)[0;0m INFO 09-23 16:14:41 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=3 pid=6211)[0;0m INFO 09-23 16:14:41 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:14:41 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=6210)[0;0m INFO 09-23 16:14:41 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=6208)[0;0m INFO 09-23 16:14:41 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_e7fb48bf'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/95a81e29-f78f-4388-bd3e-f882ebde55a3', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=6210)[0;0m [1;36m(VllmWorker rank=3 pid=6211)[0;0m INFO 09-23 16:14:41 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
INFO 09-23 16:14:41 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=0 pid=6208)[0;0m INFO 09-23 16:14:41 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=1 pid=6209)[0;0m INFO 09-23 16:14:41 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=0 pid=6208)[0;0m [1;36m(VllmWorker rank=3 pid=6211)[0;0m INFO 09-23 16:14:41 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 09-23 16:14:41 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=6210)[0;0m INFO 09-23 16:14:41 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=6209)[0;0m INFO 09-23 16:14:41 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=6208)[0;0m INFO 09-23 16:14:41 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=6211)[0;0m INFO 09-23 16:14:41 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=6210)[0;0m INFO 09-23 16:14:41 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=6209)[0;0m INFO 09-23 16:14:41 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=6210)[0;0m INFO 09-23 16:14:41 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=1 pid=6209)[0;0m INFO 09-23 16:14:41 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=3 pid=6211)[0;0m INFO 09-23 16:14:41 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=0 pid=6208)[0;0m INFO 09-23 16:14:41 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_100...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=6210)[0;0m ERROR 09-23 16:14:41 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2142377 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:14:43 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:14:43 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:14:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:14:43 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:14:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:14:43 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:14:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:14:43 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:14:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:14:43 [core.py:396]     self._init_executor()
ERROR 09-23 16:14:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:14:43 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:14:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:14:43 [core.py:396]     raise e from None
ERROR 09-23 16:14:43 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:14:44] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_200
INFO 09-23 16:14:44 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:14:44 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:14:44 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:14:44 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:14:50 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:14:57 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:14:57 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:14:57 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_410d38aa'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/5e7d97f7-3ca0-4d39-8342-6efd46ad852a', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:15:03 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:15:03 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:15:03 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:15:03 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:15:24 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7efba88bcf10>
WARNING 09-23 16:15:24 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fb676e51000>
WARNING 09-23 16:15:24 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f41805f5000>
WARNING 09-23 16:15:24 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fa131cf8cd0>
[1;36m(VllmWorker rank=2 pid=6461)[0;0m [1;36m(VllmWorker rank=0 pid=6459)[0;0m INFO 09-23 16:15:24 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_a4c0a62f'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/be748aef-99ab-4ae4-928d-d8ed27070f48', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:15:24 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_3e42981e'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/59131870-6777-4ba4-97cc-6140f37cff62', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=6460)[0;0m [1;36m(VllmWorker rank=3 pid=6462)[0;0m INFO 09-23 16:15:24 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_1db0bac3'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/c28e7371-c5c2-4ebc-b4f9-f2079f17c44c', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:15:24 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_6025f3e5'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/e7e54065-94d9-4e39-940d-7b82bbf6cfd6', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=6460)[0;0m INFO 09-23 16:16:01 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=6462)[0;0m INFO 09-23 16:16:01 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=6461)[0;0m INFO 09-23 16:16:01 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=6459)[0;0m INFO 09-23 16:16:01 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=6460)[0;0m INFO 09-23 16:16:01 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=6461)[0;0m [1;36m(VllmWorker rank=0 pid=6459)[0;0m INFO 09-23 16:16:01 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 16:16:01 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=6462)[0;0m INFO 09-23 16:16:01 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=6459)[0;0m INFO 09-23 16:16:03 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=1 pid=6460)[0;0m INFO 09-23 16:16:03 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=3 pid=6462)[0;0m INFO 09-23 16:16:03 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=6461)[0;0m INFO 09-23 16:16:03 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=6459)[0;0m INFO 09-23 16:16:03 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_046ec2b3'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/7bbd6628-b897-4658-ae8b-f5302a9f4c31', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=6462)[0;0m INFO 09-23 16:16:03 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=1 pid=6460)[0;0m INFO 09-23 16:16:03 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=2 pid=6461)[0;0m [1;36m(VllmWorker rank=0 pid=6459)[0;0m INFO 09-23 16:16:03 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
INFO 09-23 16:16:03 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=3 pid=6462)[0;0m INFO 09-23 16:16:03 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=6460)[0;0m INFO 09-23 16:16:03 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=6459)[0;0m INFO 09-23 16:16:03 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=6461)[0;0m INFO 09-23 16:16:03 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=6462)[0;0m INFO 09-23 16:16:03 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=6460)[0;0m INFO 09-23 16:16:03 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=6459)[0;0m INFO 09-23 16:16:03 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=6461)[0;0m INFO 09-23 16:16:03 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=6460)[0;0m [1;36m(VllmWorker rank=2 pid=6461)[0;0m INFO 09-23 16:16:04 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=0 pid=6459)[0;0m INFO 09-23 16:16:04 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=3 pid=6462)[0;0m INFO 09-23 16:16:04 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_200...
INFO 09-23 16:16:04 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=6462)[0;0m ERROR 09-23 16:16:05 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 3 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088949 has 37.61 GiB memory in use. Process 2143377 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:16:09 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:16:09 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:16:09 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:16:09 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:16:09 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:16:09 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:16:09 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:16:09 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:16:09 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:16:09 [core.py:396]     self._init_executor()
ERROR 09-23 16:16:09 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:16:09 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:16:09 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:16:09 [core.py:396]     raise e from None
ERROR 09-23 16:16:09 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:16:25] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_313
INFO 09-23 16:16:25 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:16:25 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:16:25 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:16:25 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:18:28 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:19:33 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:19:33 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:19:33 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_5cf6805d'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/db5d21fc-d27e-4f6d-8343-ea5114c7b28d', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:19:38 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:19:38 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:19:38 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:19:39 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:19:52 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fceca8533a0>
WARNING 09-23 16:19:52 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f9ddeb64f40>
[1;36m(VllmWorker rank=1 pid=6711)[0;0m INFO 09-23 16:19:52 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_17f67a81'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/59de1030-c641-4201-94e4-84b5fd050fe9', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=6712)[0;0m INFO 09-23 16:19:52 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_e93c339f'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/80b9a6fa-9824-4586-b0c9-d8790fc0a4ac', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:19:52 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f1d36aa4f70>
WARNING 09-23 16:19:52 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f6ba34ecdf0>
[1;36m(VllmWorker rank=3 pid=6713)[0;0m INFO 09-23 16:19:52 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_6ce32237'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/408035b2-4d33-4464-b85c-10f3d48ca75b', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=6710)[0;0m INFO 09-23 16:19:52 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_25670667'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/d71bddd0-832e-42c0-b0f8-fc0b07eac5b9', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=6711)[0;0m INFO 09-23 16:20:28 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=6711)[0;0m INFO 09-23 16:20:28 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=6713)[0;0m INFO 09-23 16:20:28 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=6710)[0;0m INFO 09-23 16:20:28 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=6712)[0;0m INFO 09-23 16:20:28 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=6713)[0;0m INFO 09-23 16:20:28 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=6710)[0;0m INFO 09-23 16:20:28 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=6712)[0;0m INFO 09-23 16:20:28 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=6713)[0;0m INFO 09-23 16:20:30 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=1 pid=6711)[0;0m [1;36m(VllmWorker rank=0 pid=6710)[0;0m INFO 09-23 16:20:30 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:20:30 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=6712)[0;0m INFO 09-23 16:20:30 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=6710)[0;0m INFO 09-23 16:20:30 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_1e7a2520'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/48702464-0da6-4db5-af3d-90e283fa41a3', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=6713)[0;0m INFO 09-23 16:20:30 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=6712)[0;0m INFO 09-23 16:20:30 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=0 pid=6710)[0;0m INFO 09-23 16:20:30 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=1 pid=6711)[0;0m INFO 09-23 16:20:30 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=3 pid=6713)[0;0m INFO 09-23 16:20:30 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=6710)[0;0m INFO 09-23 16:20:30 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=6712)[0;0m INFO 09-23 16:20:30 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=6713)[0;0m INFO 09-23 16:20:30 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=6710)[0;0m INFO 09-23 16:20:30 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=6711)[0;0m INFO 09-23 16:20:30 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=6712)[0;0m INFO 09-23 16:20:30 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=6711)[0;0m INFO 09-23 16:20:30 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=6713)[0;0m INFO 09-23 16:20:30 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=2 pid=6712)[0;0m [1;36m(VllmWorker rank=1 pid=6711)[0;0m INFO 09-23 16:20:30 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_313...
INFO 09-23 16:20:30 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=0 pid=6710)[0;0m INFO 09-23 16:20:30 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=6710)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088946 has 37.61 GiB memory in use. Process 2147076 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=6713)[0;0m ERROR 09-23 16:20:31 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 3 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088949 has 37.61 GiB memory in use. Process 2147079 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:20:32 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:20:32 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:20:32 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:20:32 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:20:32 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:20:32 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:20:32 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:20:32 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:20:32 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:20:32 [core.py:396]     self._init_executor()
ERROR 09-23 16:20:32 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:20:32 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:20:32 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:20:32 [core.py:396]     raise e from None
ERROR 09-23 16:20:32 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:20:35] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_100
INFO 09-23 16:20:35 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:20:35 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:20:35 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:20:35 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:20:41 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:20:46 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_100', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_100', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_100, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:20:46 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:20:46 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_fe8ded4b'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/37c32fe3-4126-4c5e-983f-cca1899ad304', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:20:51 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:20:51 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:20:51 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:20:51 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:20:57 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fd546a78f40>
WARNING 09-23 16:20:57 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f3accfbd000>
[1;36m(VllmWorker rank=0 pid=6961)[0;0m INFO 09-23 16:20:57 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_eb41aa5d'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/2a9aa9b2-7436-48de-ae9c-817c8096f1c4', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=6964)[0;0m INFO 09-23 16:20:57 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_4d1aac66'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/40fc3981-c724-47ef-8677-8caba953ed0c', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:20:57 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f4da22ace80>
[1;36m(VllmWorker rank=2 pid=6963)[0;0m INFO 09-23 16:20:57 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_73a08780'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/9bc8d351-5c8e-4e4e-bf25-f171d761daf7', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:20:57 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f6de9df0df0>
[1;36m(VllmWorker rank=1 pid=6962)[0;0m INFO 09-23 16:20:57 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_d1e36675'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/43b658f8-4359-458f-8380-350968d6249f', remote_subscribe_addr=None, remote_addr_ipv6=False)
[2025-09-23 16:21:31] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:21:31] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:21:31] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:21:31] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B__global_step_100 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:21:31] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:21:31] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:21:31] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:21:31] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:21:31] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:21:31] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:21:31] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B__global_step_100 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:21:31] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:21:31] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:21:31] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B__global_step_100 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:21:31] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:21:31] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:21:31] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:21:31] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:21:31] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:21:31] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:21:31] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B__global_step_100 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:21:31] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:21:31] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[1;36m(VllmWorker rank=3 pid=6964)[0;0m INFO 09-23 16:21:33 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=6963)[0;0m INFO 09-23 16:21:33 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=6964)[0;0m INFO 09-23 16:21:33 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=6963)[0;0m INFO 09-23 16:21:33 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=6961)[0;0m INFO 09-23 16:21:33 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=6961)[0;0m INFO 09-23 16:21:33 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=6962)[0;0m INFO 09-23 16:21:33 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=6962)[0;0m INFO 09-23 16:21:33 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=6961)[0;0m [1;36m(VllmWorker rank=2 pid=6963)[0;0m INFO 09-23 16:21:34 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:21:34 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=3 pid=6964)[0;0m INFO 09-23 16:21:34 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=1 pid=6962)[0;0m INFO 09-23 16:21:34 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=6961)[0;0m INFO 09-23 16:21:34 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_9180d60a'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/73319468-7686-444d-b4c4-aab479536fcd', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=6964)[0;0m INFO 09-23 16:21:34 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=6963)[0;0m INFO 09-23 16:21:34 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=0 pid=6961)[0;0m INFO 09-23 16:21:34 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=1 pid=6962)[0;0m INFO 09-23 16:21:34 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=3 pid=6964)[0;0m INFO 09-23 16:21:34 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=6963)[0;0m INFO 09-23 16:21:34 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=6961)[0;0m INFO 09-23 16:21:34 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=6964)[0;0m INFO 09-23 16:21:34 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=6963)[0;0m INFO 09-23 16:21:34 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=6961)[0;0m INFO 09-23 16:21:34 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=6962)[0;0m INFO 09-23 16:21:34 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=6962)[0;0m INFO 09-23 16:21:34 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=6964)[0;0m INFO 09-23 16:21:34 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=2 pid=6963)[0;0m INFO 09-23 16:21:34 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=1 pid=6962)[0;0m INFO 09-23 16:21:34 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=0 pid=6961)[0;0m INFO 09-23 16:21:34 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_100...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=6963)[0;0m ERROR 09-23 16:21:34 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2148299 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:21:36 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:21:36 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:21:36 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:21:36 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:21:36 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:21:36 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:21:36 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:21:36 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:21:36 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:21:36 [core.py:396]     self._init_executor()
ERROR 09-23 16:21:36 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:21:36 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:21:36 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:21:36 [core.py:396]     raise e from None
ERROR 09-23 16:21:36 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:21:37] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B__global_step_100 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:21:37] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_200
INFO 09-23 16:21:37 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:21:37 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:21:37 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:21:37 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:21:43 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:21:48 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:21:48 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:21:48 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_2088ae0f'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/6cfdf31d-4ba0-4526-aadb-e0ec2cd87549', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:21:53 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:21:53 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:21:54 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:21:54 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:21:59 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f48ba6acfa0>
[1;36m(VllmWorker rank=1 pid=7213)[0;0m INFO 09-23 16:21:59 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_48bfa96c'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/125f1106-18ef-4990-9933-be0e5d1af34d', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:21:59 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fc28dfdcfd0>
[1;36m(VllmWorker rank=0 pid=7212)[0;0m INFO 09-23 16:21:59 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_9f109ae2'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/7ca2cce6-bdd1-4cd1-9f9c-e6b2031b2ea1', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:21:59 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f3f96e3cf40>
[1;36m(VllmWorker rank=2 pid=7214)[0;0m INFO 09-23 16:21:59 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_ec863d8a'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/f8b02736-6abb-483f-a62a-3f0c9d2eabbe', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:21:59 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7ff18b768f10>
[1;36m(VllmWorker rank=3 pid=7215)[0;0m INFO 09-23 16:21:59 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_adb70ae8'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/f7c185dc-4d5e-4ea3-8314-5da526e632a6', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=7213)[0;0m [1;36m(VllmWorker rank=3 pid=7215)[0;0m INFO 09-23 16:22:35 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 16:22:35 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=7214)[0;0m INFO 09-23 16:22:35 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=7212)[0;0m INFO 09-23 16:22:35 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=7213)[0;0m [1;36m(VllmWorker rank=3 pid=7215)[0;0m INFO 09-23 16:22:35 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 16:22:35 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=7214)[0;0m INFO 09-23 16:22:35 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=7212)[0;0m INFO 09-23 16:22:35 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=7213)[0;0m [1;36m(VllmWorker rank=2 pid=7214)[0;0m INFO 09-23 16:22:36 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:22:36 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=7212)[0;0m INFO 09-23 16:22:36 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=3 pid=7215)[0;0m INFO 09-23 16:22:36 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=7212)[0;0m INFO 09-23 16:22:36 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_84439dc0'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/454301f3-cd9b-4974-9de2-6cdfe8247181', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=7215)[0;0m INFO 09-23 16:22:36 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=7214)[0;0m INFO 09-23 16:22:36 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=0 pid=7212)[0;0m [1;36m(VllmWorker rank=1 pid=7213)[0;0m INFO 09-23 16:22:36 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 09-23 16:22:36 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=2 pid=7214)[0;0m INFO 09-23 16:22:36 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=7212)[0;0m INFO 09-23 16:22:36 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=7215)[0;0m INFO 09-23 16:22:36 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=7213)[0;0m INFO 09-23 16:22:36 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=7214)[0;0m INFO 09-23 16:22:36 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=7212)[0;0m INFO 09-23 16:22:36 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=7215)[0;0m INFO 09-23 16:22:36 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=7213)[0;0m INFO 09-23 16:22:36 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=7214)[0;0m INFO 09-23 16:22:36 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=3 pid=7215)[0;0m INFO 09-23 16:22:36 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=1 pid=7213)[0;0m INFO 09-23 16:22:36 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=0 pid=7212)[0;0m INFO 09-23 16:22:36 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=7214)[0;0m ERROR 09-23 16:22:37 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2149202 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7ff2dd36c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7ff2dd315b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7ff28de8e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7ff2dd7b8b78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7ff2dd7b920e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39afa (0x7ff2dd7cfafa in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7ff2dd7bb329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7ff2d54864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7ff2d4ba5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7ff2d4ba64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x55a82628fc04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x55a82621c2a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x55a82621cbbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x55a82621cc83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x55a82628fb85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x55a8262fbc3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x55a8262fef1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x55a82621dc98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x55a82635cc30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x55a826382407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x55a826382634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x55a826382718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x55a82638275b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x55a826382972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x55a826388f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x55a8263891ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x55a826389469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7ff2de2b4d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7ff2de2b4e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x55a8262f42d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

ERROR 09-23 16:22:39 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:22:39 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:22:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:22:39 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:22:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:22:39 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:22:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:22:39 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:22:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:22:39 [core.py:396]     self._init_executor()
ERROR 09-23 16:22:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:22:39 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:22:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:22:39 [core.py:396]     raise e from None
ERROR 09-23 16:22:39 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:22:40] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:22:40] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_313
INFO 09-23 16:22:40 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:22:40 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:22:40 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:22:40 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:22:45 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:22:50 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:22:50 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:22:50 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_61e5b13b'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/71ebbb95-69c9-4927-93c9-782c2f22985d', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:22:56 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:22:56 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:22:56 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:22:56 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:23:01 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fc806c68dc0>
[1;36m(VllmWorker rank=3 pid=7466)[0;0m INFO 09-23 16:23:01 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_2b3612e7'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/9a89da99-6a99-4fa1-972b-aebf7e97f2db', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:23:01 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fbc3999f430>
[1;36m(VllmWorker rank=1 pid=7464)[0;0m INFO 09-23 16:23:01 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_1d7e07a5'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/63cff5c8-9ef7-4a63-9e51-b7a56363aeb8', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:23:02 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f68a1095060>
[1;36m(VllmWorker rank=2 pid=7465)[0;0m INFO 09-23 16:23:02 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_dd05b5f3'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/4ea585a8-d66b-41e0-b959-278437c9bdd5', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:23:02 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f5666a08f10>
[1;36m(VllmWorker rank=0 pid=7463)[0;0m INFO 09-23 16:23:02 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_ad731d07'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/0b4ec120-756d-4aaf-bdca-d1e5484871ab', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=7463)[0;0m INFO 09-23 16:23:42 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=7463)[0;0m INFO 09-23 16:23:42 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=7466)[0;0m INFO 09-23 16:23:42 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=7466)[0;0m INFO 09-23 16:23:42 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=7465)[0;0m INFO 09-23 16:23:42 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=7464)[0;0m INFO 09-23 16:23:42 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=7465)[0;0m INFO 09-23 16:23:42 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=7464)[0;0m INFO 09-23 16:23:42 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=7463)[0;0m INFO 09-23 16:23:44 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=7465)[0;0m INFO 09-23 16:23:44 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=3 pid=7466)[0;0m [1;36m(VllmWorker rank=1 pid=7464)[0;0m INFO 09-23 16:23:44 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:23:44 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=7463)[0;0m INFO 09-23 16:23:44 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_475dc1a5'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/4d29015d-b8f9-4e89-af17-65b9e7ffc768', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=7466)[0;0m INFO 09-23 16:23:44 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=0 pid=7463)[0;0m INFO 09-23 16:23:44 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=2 pid=7465)[0;0m INFO 09-23 16:23:44 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=1 pid=7464)[0;0m INFO 09-23 16:23:44 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=0 pid=7463)[0;0m INFO 09-23 16:23:44 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=7465)[0;0m INFO 09-23 16:23:44 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=7466)[0;0m INFO 09-23 16:23:44 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=7464)[0;0m INFO 09-23 16:23:44 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=7463)[0;0m INFO 09-23 16:23:44 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=7465)[0;0m INFO 09-23 16:23:44 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=7466)[0;0m INFO 09-23 16:23:44 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=7464)[0;0m INFO 09-23 16:23:44 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=7464)[0;0m INFO 09-23 16:23:44 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=2 pid=7465)[0;0m INFO 09-23 16:23:44 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=3 pid=7466)[0;0m INFO 09-23 16:23:44 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=0 pid=7463)[0;0m INFO 09-23 16:23:44 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=7463)[0;0m ERROR 09-23 16:23:44 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088946 has 37.61 GiB memory in use. Process 2150159 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:23:46 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:23:46 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:23:46 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:23:46 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:23:46 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:23:46 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:23:46 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:23:46 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:23:46 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:23:46 [core.py:396]     self._init_executor()
ERROR 09-23 16:23:46 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:23:46 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:23:46 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:23:46 [core.py:396]     raise e from None
ERROR 09-23 16:23:46 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:23:47] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:23:47] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_200
INFO 09-23 16:23:47 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:23:47 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:23:47 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:23:47 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:23:53 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:23:58 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:23:58 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:23:58 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_19f9d815'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/61190b8f-41cc-42ea-aed1-1fc40b1e7818', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:24:03 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:24:03 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:24:03 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:24:03 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:24:09 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f5c5c0d8f40>
[1;36m(VllmWorker rank=3 pid=7717)[0;0m INFO 09-23 16:24:09 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_1785a337'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/0e780c42-b7e8-4de5-9ba6-1c96f2b6fe3e', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:24:09 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f8ca38c8e80>
[1;36m(VllmWorker rank=1 pid=7715)[0;0m INFO 09-23 16:24:09 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_6033b3ae'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/63af85b8-4dcc-4df7-a451-d12dfe1af7a1', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:24:09 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f92d0698fd0>
[1;36m(VllmWorker rank=0 pid=7714)[0;0m INFO 09-23 16:24:09 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_1505f4ed'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/44510e84-4658-46a8-be5e-8bb7d65adaf1', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:24:09 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f528c155030>
[1;36m(VllmWorker rank=2 pid=7716)[0;0m INFO 09-23 16:24:09 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_713a7310'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/2c3e2c11-4c30-4f21-82df-fcde25152594', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=7714)[0;0m [1;36m(VllmWorker rank=3 pid=7717)[0;0m INFO 09-23 16:24:45 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 16:24:45 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=7715)[0;0m INFO 09-23 16:24:45 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=7716)[0;0m INFO 09-23 16:24:45 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=7714)[0;0m INFO 09-23 16:24:45 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=7717)[0;0m [1;36m(VllmWorker rank=1 pid=7715)[0;0m INFO 09-23 16:24:45 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 16:24:45 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=7716)[0;0m INFO 09-23 16:24:45 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=7717)[0;0m [1;36m(VllmWorker rank=1 pid=7715)[0;0m INFO 09-23 16:24:46 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:24:46 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=7714)[0;0m INFO 09-23 16:24:46 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=7716)[0;0m INFO 09-23 16:24:46 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=7714)[0;0m INFO 09-23 16:24:46 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_9b47a8fb'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/83438331-6068-4909-b141-6e1bea48315f', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=7717)[0;0m INFO 09-23 16:24:46 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=7716)[0;0m INFO 09-23 16:24:46 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=1 pid=7715)[0;0m INFO 09-23 16:24:46 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=0 pid=7714)[0;0m INFO 09-23 16:24:46 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=3 pid=7717)[0;0m INFO 09-23 16:24:46 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=7716)[0;0m INFO 09-23 16:24:46 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=7715)[0;0m INFO 09-23 16:24:46 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=7714)[0;0m INFO 09-23 16:24:46 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=7717)[0;0m INFO 09-23 16:24:46 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=7716)[0;0m INFO 09-23 16:24:46 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=7715)[0;0m INFO 09-23 16:24:46 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=7714)[0;0m INFO 09-23 16:24:46 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=7716)[0;0m INFO 09-23 16:24:46 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=1 pid=7715)[0;0m INFO 09-23 16:24:46 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=3 pid=7717)[0;0m INFO 09-23 16:24:46 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=0 pid=7714)[0;0m INFO 09-23 16:24:46 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=7716)[0;0m ERROR 09-23 16:24:47 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2151239 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f5da996c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f5da9915b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f5d5a88e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f5da9d6bb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f5da9d6c20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39afa (0x7f5da9d82afa in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f5da9d6e329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f5da1e864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f5da15a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f5da15a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x561321fe3c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x561321f702a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x561321f70bbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x561321f70c83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x561321fe3b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x56132204fc3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x561322052f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x561321f71c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x5613220b0c30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x5613220d6407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x5613220d6634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x5613220d6718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x5613220d675b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x5613220d6972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x5613220dcf60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x5613220dd1ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x5613220dd469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f5daabb9d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f5daabb9e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x5613220482d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f941df6c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f941df15b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f93cee8e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f941e36bb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f941e36c20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39afa (0x7f941e382afa in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f941e36e329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f94164864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f9415ba5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f9415ba64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x5601fdfa9c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x5601fdf362a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x5601fdf36bbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x5601fdf36c83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x5601fdfa9b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x5601fe015c3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x5601fe018f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x5601fdf37c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x5601fe076c30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x5601fe09c407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x5601fe09c634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x5601fe09c718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x5601fe09c75b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x5601fe09c972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x5601fe0a2f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x5601fe0a31ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x5601fe0a3469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f941f17ed90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f941f17ee40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x5601fe00e2d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

ERROR 09-23 16:24:49 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:24:49 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:24:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:24:49 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:24:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:24:49 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:24:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:24:49 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:24:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:24:49 [core.py:396]     self._init_executor()
ERROR 09-23 16:24:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:24:49 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:24:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:24:49 [core.py:396]     raise e from None
ERROR 09-23 16:24:49 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:24:50] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:24:50] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_313
INFO 09-23 16:24:50 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:24:50 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:24:50 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:24:50 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:24:56 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:25:01 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:25:01 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:25:01 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_d2ba6168'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/3860ad11-0142-4cef-8e24-9a9b9edef55d', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:25:06 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:25:06 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:25:06 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:25:06 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:25:11 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f8ed25f4df0>
[1;36m(VllmWorker rank=2 pid=7967)[0;0m INFO 09-23 16:25:11 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_235a9af1'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/11d1cdb9-5e0b-40a6-b115-e413fb90f53f', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:25:11 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f3251c7cd00>
[1;36m(VllmWorker rank=1 pid=7966)[0;0m INFO 09-23 16:25:11 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_36926e50'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/a06460a6-509b-49ef-b9cd-0db003bd99b9', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:25:12 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7efead100f10>
[1;36m(VllmWorker rank=3 pid=7968)[0;0m INFO 09-23 16:25:12 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_a396388c'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/2125cedd-2862-487c-9a75-958440a453ec', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:25:12 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f448d608e50>
[1;36m(VllmWorker rank=0 pid=7965)[0;0m INFO 09-23 16:25:12 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_f6c8204c'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/e50d5c97-14ae-4d80-b39c-de0128a0ba95', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=7965)[0;0m INFO 09-23 16:25:47 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=7965)[0;0m INFO 09-23 16:25:47 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=7968)[0;0m INFO 09-23 16:25:47 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=7968)[0;0m INFO 09-23 16:25:47 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=7967)[0;0m INFO 09-23 16:25:47 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=7966)[0;0m INFO 09-23 16:25:47 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=7967)[0;0m INFO 09-23 16:25:47 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=7966)[0;0m INFO 09-23 16:25:47 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=7965)[0;0m [1;36m(VllmWorker rank=3 pid=7968)[0;0m INFO 09-23 16:25:48 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:25:48 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=7967)[0;0m INFO 09-23 16:25:48 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=1 pid=7966)[0;0m INFO 09-23 16:25:48 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=7965)[0;0m INFO 09-23 16:25:48 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_20d0718b'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/ff197b69-20c7-4712-ac36-b4944d0152c7', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=7968)[0;0m INFO 09-23 16:25:48 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=7967)[0;0m INFO 09-23 16:25:48 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=0 pid=7965)[0;0m INFO 09-23 16:25:48 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=1 pid=7966)[0;0m INFO 09-23 16:25:48 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=3 pid=7968)[0;0m INFO 09-23 16:25:48 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=7965)[0;0m INFO 09-23 16:25:48 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=7967)[0;0m INFO 09-23 16:25:48 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=7968)[0;0m INFO 09-23 16:25:48 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=7965)[0;0m INFO 09-23 16:25:48 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=7967)[0;0m INFO 09-23 16:25:48 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=7966)[0;0m INFO 09-23 16:25:48 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=7966)[0;0m INFO 09-23 16:25:48 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=7968)[0;0m INFO 09-23 16:25:48 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=2 pid=7967)[0;0m INFO 09-23 16:25:48 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=1 pid=7966)[0;0m INFO 09-23 16:25:48 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=0 pid=7965)[0;0m INFO 09-23 16:25:48 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=7965)[0;0m ERROR 09-23 16:25:49 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088946 has 37.61 GiB memory in use. Process 2152281 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7efffed6c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7efffed15b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7effaf88e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7effff120b78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7effff12120e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39afa (0x7effff137afa in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7effff123329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7efff6e864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7efff65a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7efff65a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x562135fd2c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x562135f5f2a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x562135f5fbbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x562135f5fc83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x562135fd2b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x56213603ec3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x562136041f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x562135f60c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x56213609fc30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x5621360c5407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x5621360c5634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x5621360c5718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x5621360c575b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x5621360c5972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x5621360cbf60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x5621360cc1ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x5621360cc469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7effffc1cd90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7effffc1ce40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x5621360372d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

ERROR 09-23 16:25:51 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:25:51 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:25:51 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:25:51 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:25:51 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:25:51 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:25:51 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:25:51 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:25:51 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:25:51 [core.py:396]     self._init_executor()
ERROR 09-23 16:25:51 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:25:51 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:25:51 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:25:51 [core.py:396]     raise e from None
ERROR 09-23 16:25:51 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:25:52] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:25:52] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_200
INFO 09-23 16:25:52 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:25:52 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:25:52 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:25:52 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:25:58 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:26:03 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:26:03 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:26:03 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_9cc98cd5'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/1c8adc8f-da77-403f-a218-882a0cbd4570', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:26:08 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:26:08 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:26:08 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:26:08 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:26:13 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fc10ed38f10>
WARNING 09-23 16:26:13 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f61d7e98eb0>
[1;36m(VllmWorker rank=0 pid=8216)[0;0m INFO 09-23 16:26:13 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_8e9682cd'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/9ec1fab6-cd5c-48b8-b9bd-837e90e635d6', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=8218)[0;0m INFO 09-23 16:26:13 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_f583d736'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/e6d8b44d-df62-410b-b338-e94f73c09488', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:26:13 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fc9d0ac0f70>
[1;36m(VllmWorker rank=3 pid=8219)[0;0m INFO 09-23 16:26:13 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_f2e361bc'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/b72d4015-9cec-45a7-9486-8f03742755b3', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:26:14 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f69799b1000>
[1;36m(VllmWorker rank=1 pid=8217)[0;0m INFO 09-23 16:26:14 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_0f3f04e7'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/60fbc188-85af-4830-80a1-c273df5cca49', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=8216)[0;0m INFO 09-23 16:26:49 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=8219)[0;0m INFO 09-23 16:26:49 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=8216)[0;0m INFO 09-23 16:26:49 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=8219)[0;0m INFO 09-23 16:26:49 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=8218)[0;0m INFO 09-23 16:26:49 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=8217)[0;0m INFO 09-23 16:26:49 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=8218)[0;0m INFO 09-23 16:26:49 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=8217)[0;0m INFO 09-23 16:26:49 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=8216)[0;0m [1;36m(VllmWorker rank=3 pid=8219)[0;0m INFO 09-23 16:26:50 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=1 pid=8217)[0;0m [1;36m(VllmWorker rank=2 pid=8218)[0;0m INFO 09-23 16:26:50 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:26:50 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:26:50 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=8216)[0;0m INFO 09-23 16:26:50 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_807204a5'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/be08d546-ba03-4a96-b7da-48ae8a26d93f', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=8219)[0;0m INFO 09-23 16:26:50 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=8218)[0;0m INFO 09-23 16:26:50 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=3 pid=8219)[0;0m INFO 09-23 16:26:50 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=8218)[0;0m INFO 09-23 16:26:50 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=8217)[0;0m INFO 09-23 16:26:50 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=0 pid=8216)[0;0m [1;36m(VllmWorker rank=3 pid=8219)[0;0m INFO 09-23 16:26:50 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 09-23 16:26:50 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=8218)[0;0m INFO 09-23 16:26:50 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=8216)[0;0m [1;36m(VllmWorker rank=1 pid=8217)[0;0m INFO 09-23 16:26:50 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 09-23 16:26:50 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=8216)[0;0m INFO 09-23 16:26:50 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=8217)[0;0m INFO 09-23 16:26:50 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=8218)[0;0m INFO 09-23 16:26:50 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=3 pid=8219)[0;0m INFO 09-23 16:26:50 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=1 pid=8217)[0;0m INFO 09-23 16:26:50 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=0 pid=8216)[0;0m INFO 09-23 16:26:50 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=8218)[0;0m ERROR 09-23 16:26:51 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2153576 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:26:53 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:26:53 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:26:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:26:53 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:26:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:26:53 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:26:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:26:53 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:26:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:26:53 [core.py:396]     self._init_executor()
ERROR 09-23 16:26:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:26:53 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:26:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:26:53 [core.py:396]     raise e from None
ERROR 09-23 16:26:53 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:26:54] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:26:54] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_313
INFO 09-23 16:26:54 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:26:54 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:26:54 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:26:54 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:26:59 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:27:04 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:27:04 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:27:04 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_329c43b3'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/97c8e9a3-1d9b-4255-910f-c98902255945', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:27:10 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:27:10 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:27:10 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:27:10 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:27:15 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f0ce94dcfd0>
WARNING 09-23 16:27:15 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f1732d14f70>
[1;36m(VllmWorker rank=0 pid=8467)[0;0m INFO 09-23 16:27:15 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_f67e6b27'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/5b1a3079-9026-40ab-8b81-3a4486a70673', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=8468)[0;0m INFO 09-23 16:27:15 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_269bad91'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/9769ed96-ba76-4120-b91a-ad806edda992', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:27:15 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fca226c5030>
[1;36m(VllmWorker rank=2 pid=8469)[0;0m INFO 09-23 16:27:15 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_f9706f80'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/475e4868-50de-4f9e-86a6-045ee7e4e694', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:27:15 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f5838b7b550>
[1;36m(VllmWorker rank=3 pid=8470)[0;0m INFO 09-23 16:27:15 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_13ee4119'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/ed373fe3-f90c-446d-90ee-21467a27233d', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=8467)[0;0m [1;36m(VllmWorker rank=1 pid=8468)[0;0m INFO 09-23 16:27:51 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 16:27:51 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=8468)[0;0m [1;36m(VllmWorker rank=0 pid=8467)[0;0m INFO 09-23 16:27:51 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 16:27:51 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=8470)[0;0m INFO 09-23 16:27:51 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=8470)[0;0m INFO 09-23 16:27:51 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=8469)[0;0m INFO 09-23 16:27:51 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=8469)[0;0m INFO 09-23 16:27:51 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=8470)[0;0m [1;36m(VllmWorker rank=1 pid=8468)[0;0m [1;36m(VllmWorker rank=0 pid=8467)[0;0m [1;36m(VllmWorker rank=2 pid=8469)[0;0m INFO 09-23 16:27:52 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:27:52 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:27:52 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:27:52 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=8467)[0;0m INFO 09-23 16:27:52 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_2aa1e413'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/fc8768d2-fc83-49bf-9f26-f5980179ca2b', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=8470)[0;0m INFO 09-23 16:27:52 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=8469)[0;0m INFO 09-23 16:27:52 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=0 pid=8467)[0;0m INFO 09-23 16:27:52 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=1 pid=8468)[0;0m INFO 09-23 16:27:52 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=3 pid=8470)[0;0m INFO 09-23 16:27:52 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=8469)[0;0m INFO 09-23 16:27:52 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=8467)[0;0m INFO 09-23 16:27:52 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=8468)[0;0m INFO 09-23 16:27:52 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=8470)[0;0m INFO 09-23 16:27:52 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=8467)[0;0m [1;36m(VllmWorker rank=2 pid=8469)[0;0m INFO 09-23 16:27:52 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 09-23 16:27:52 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=8468)[0;0m INFO 09-23 16:27:52 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=8470)[0;0m INFO 09-23 16:27:52 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=2 pid=8469)[0;0m INFO 09-23 16:27:52 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=1 pid=8468)[0;0m INFO 09-23 16:27:52 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=0 pid=8467)[0;0m INFO 09-23 16:27:52 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo1_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=8469)[0;0m ERROR 09-23 16:27:53 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2154603 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:27:54 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:27:54 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:27:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:27:54 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:27:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:27:54 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:27:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:27:54 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:27:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:27:54 [core.py:396]     self._init_executor()
ERROR 09-23 16:27:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:27:54 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:27:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:27:54 [core.py:396]     raise e from None
ERROR 09-23 16:27:54 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:27:56] ‚ö† Ê®°Âûã B_rb_manual_algo1_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:27:56] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_200
INFO 09-23 16:27:56 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:27:56 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:27:56 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:27:56 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:28:01 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:28:06 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:28:06 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:28:06 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_abe61ae0'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/c2524ca8-0680-479f-817c-45ecab3a33f1', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:28:12 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:28:12 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:28:12 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:28:12 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:28:17 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f97fcd00eb0>
[1;36m(VllmWorker rank=1 pid=8719)[0;0m INFO 09-23 16:28:17 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_92fd1925'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/1d351118-b68c-48ef-a51a-4461607d5bdb', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:28:17 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f79b6aa4f70>
[1;36m(VllmWorker rank=0 pid=8718)[0;0m INFO 09-23 16:28:17 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_b39302eb'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/3379f37c-8686-48c3-b685-2072e9a777c2', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:28:17 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f24d3cecf10>
[1;36m(VllmWorker rank=3 pid=8721)[0;0m INFO 09-23 16:28:17 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_3a08485f'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/d57b5eb5-4b1a-4d04-a461-0b5373d3ddc3', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:28:17 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f2913270e50>
[1;36m(VllmWorker rank=2 pid=8720)[0;0m INFO 09-23 16:28:17 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_4029f493'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/fa3c8e00-bb19-4d62-859a-3ec97c359977', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=8720)[0;0m [1;36m(VllmWorker rank=0 pid=8718)[0;0m INFO 09-23 16:28:53 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 16:28:53 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=8718)[0;0m INFO 09-23 16:28:53 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=8720)[0;0m INFO 09-23 16:28:53 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=8719)[0;0m INFO 09-23 16:28:53 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=8719)[0;0m INFO 09-23 16:28:53 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=8721)[0;0m INFO 09-23 16:28:53 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=8721)[0;0m INFO 09-23 16:28:53 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=8718)[0;0m [1;36m(VllmWorker rank=2 pid=8720)[0;0m [1;36m(VllmWorker rank=1 pid=8719)[0;0m INFO 09-23 16:28:54 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:28:54 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=3 pid=8721)[0;0m INFO 09-23 16:28:54 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:28:54 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=8718)[0;0m INFO 09-23 16:28:54 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_da78038f'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/dbc7c0b3-6532-409a-b4d6-0f30e8a1ee41', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=8721)[0;0m INFO 09-23 16:28:54 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=8720)[0;0m [1;36m(VllmWorker rank=1 pid=8719)[0;0m INFO 09-23 16:28:54 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
INFO 09-23 16:28:54 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=0 pid=8718)[0;0m INFO 09-23 16:28:54 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=3 pid=8721)[0;0m INFO 09-23 16:28:54 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=8720)[0;0m INFO 09-23 16:28:54 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=8719)[0;0m INFO 09-23 16:28:54 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=8718)[0;0m INFO 09-23 16:28:54 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=8721)[0;0m INFO 09-23 16:28:54 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=8720)[0;0m INFO 09-23 16:28:54 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=8719)[0;0m [1;36m(VllmWorker rank=0 pid=8718)[0;0m INFO 09-23 16:28:54 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 09-23 16:28:54 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=8721)[0;0m INFO 09-23 16:28:54 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=2 pid=8720)[0;0m INFO 09-23 16:28:54 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=1 pid=8719)[0;0m INFO 09-23 16:28:54 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=0 pid=8718)[0;0m INFO 09-23 16:28:54 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=8720)[0;0m ERROR 09-23 16:28:54 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2155582 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f262596c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f2625915b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f25d648e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f2625cd9b78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f2625cda20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39afa (0x7f2625cf0afa in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f2625cdc329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f261da864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f261d1a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f261d1a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x563a95942c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x563a958cf2a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x563a958cfbbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x563a958cfc83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x563a95942b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x563a959aec3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x563a959b1f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x563a958d0c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x563a95a0fc30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x563a95a35407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x563a95a35634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x563a95a35718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x563a95a3575b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x563a95a35972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x563a95a3bf60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x563a95a3c1ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x563a95a3c469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f26267d5d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f26267d5e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x563a959a72d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

ERROR 09-23 16:28:56 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:28:56 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:28:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:28:56 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:28:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:28:56 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:28:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:28:56 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:28:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:28:56 [core.py:396]     self._init_executor()
ERROR 09-23 16:28:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:28:56 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:28:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:28:56 [core.py:396]     raise e from None
ERROR 09-23 16:28:56 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:28:57] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:28:57] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_313
INFO 09-23 16:28:58 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:28:58 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:28:58 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:28:58 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:29:03 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:29:08 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:29:08 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:29:08 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_a2d635c3'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/68e20606-f0cd-4a2d-9736-1c62b2f31c15', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:29:13 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:29:13 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:29:13 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:29:14 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:29:19 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7ff958cf4f70>
[1;36m(VllmWorker rank=3 pid=8972)[0;0m INFO 09-23 16:29:19 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_ba956cb4'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/2ac1d6ee-068c-4ffd-9bc6-6023885af0b9', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:29:19 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f5fe0708fa0>
[1;36m(VllmWorker rank=2 pid=8971)[0;0m INFO 09-23 16:29:19 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_fe08250f'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/9324a9d6-bcc4-4a7f-9abb-7e3e4246cd96', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:29:19 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f9b49bc8eb0>
[1;36m(VllmWorker rank=0 pid=8969)[0;0m INFO 09-23 16:29:19 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_5d31dc77'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/ccc6eb1e-5c49-4439-9cd2-0425146ec6a0', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:29:19 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f6535da8e50>
[1;36m(VllmWorker rank=1 pid=8970)[0;0m INFO 09-23 16:29:19 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_c6d369bc'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/543b862e-ebdc-4584-b082-65365827c491', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=8971)[0;0m INFO 09-23 16:29:55 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=8969)[0;0m INFO 09-23 16:29:55 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=8972)[0;0m INFO 09-23 16:29:55 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=8970)[0;0m INFO 09-23 16:29:55 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=8971)[0;0m INFO 09-23 16:29:55 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=8972)[0;0m [1;36m(VllmWorker rank=0 pid=8969)[0;0m INFO 09-23 16:29:55 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 16:29:55 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=8970)[0;0m INFO 09-23 16:29:55 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=8972)[0;0m INFO 09-23 16:29:56 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=8969)[0;0m INFO 09-23 16:29:56 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=8971)[0;0m INFO 09-23 16:29:56 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=1 pid=8970)[0;0m INFO 09-23 16:29:56 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=8969)[0;0m INFO 09-23 16:29:56 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_41a0d941'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/3e1e9f50-79f5-4759-b637-02bb91574ced', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=8972)[0;0m INFO 09-23 16:29:56 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=0 pid=8969)[0;0m INFO 09-23 16:29:56 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=1 pid=8970)[0;0m INFO 09-23 16:29:56 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=3 pid=8972)[0;0m INFO 09-23 16:29:56 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=8971)[0;0m INFO 09-23 16:29:56 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=0 pid=8969)[0;0m INFO 09-23 16:29:56 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=8972)[0;0m INFO 09-23 16:29:56 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=8969)[0;0m INFO 09-23 16:29:56 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=8971)[0;0m INFO 09-23 16:29:56 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=8971)[0;0m INFO 09-23 16:29:56 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=8970)[0;0m INFO 09-23 16:29:56 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=8970)[0;0m INFO 09-23 16:29:56 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=8972)[0;0m INFO 09-23 16:29:56 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=2 pid=8971)[0;0m INFO 09-23 16:29:56 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=1 pid=8970)[0;0m INFO 09-23 16:29:56 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=0 pid=8969)[0;0m INFO 09-23 16:29:56 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=8972)[0;0m ERROR 09-23 16:29:56 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 3 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088949 has 37.61 GiB memory in use. Process 2156544 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f668776c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f6687715b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f663868e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f6687b39b78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f6687b3a20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39afa (0x7f6687b50afa in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f6687b3c329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f667fc864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f667f3a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f667f3a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x5563c65b2c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x5563c653f2a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x5563c653fbbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x5563c653fc83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x5563c65b2b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x5563c661ec3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x5563c6621f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x5563c6540c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x5563c667fc30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x5563c66a5407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x5563c66a5634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x5563c66a5718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x5563c66a575b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x5563c66a5972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x5563c66abf60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x5563c66ac1ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x5563c66ac469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f66888e4d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f66888e4e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x5563c66172d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

ERROR 09-23 16:29:58 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:29:58 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:29:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:29:58 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:29:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:29:58 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:29:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:29:58 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:29:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:29:58 [core.py:396]     self._init_executor()
ERROR 09-23 16:29:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:29:58 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:29:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:29:58 [core.py:396]     raise e from None
ERROR 09-23 16:29:58 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:29:59] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.00_0.20_Qwen2.5-math-1.5B__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:29:59] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B/global_step_200
INFO 09-23 16:29:59 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:29:59 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:29:59 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:29:59 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:30:05 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:30:10 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:30:10 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:30:10 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_34bca10d'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/ab7c2029-d93e-400c-ac7c-2fce2fb4bf35', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:30:15 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:30:15 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:30:15 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:30:15 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:30:21 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7faff67c5060>
WARNING 09-23 16:30:21 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f5e6d0e4d30>
[1;36m(VllmWorker rank=0 pid=9220)[0;0m INFO 09-23 16:30:21 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_ab3bcb8c'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/4e6c74ea-080b-40f1-9ba3-3c213766d863', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=9221)[0;0m INFO 09-23 16:30:21 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_1b4981ca'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/f583ef81-9940-43b0-9f7a-f7d1b2703675', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:30:21 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f2f4b640fa0>
[1;36m(VllmWorker rank=3 pid=9223)[0;0m INFO 09-23 16:30:21 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_0608cc40'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/c76191b2-947f-4c80-9e47-8239386da975', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:30:21 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f9dd33dcd00>
[1;36m(VllmWorker rank=2 pid=9222)[0;0m INFO 09-23 16:30:21 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_e148e3b7'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/b2b021d5-4e49-4f68-9b16-25ff8434d669', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=3 pid=9223)[0;0m INFO 09-23 16:30:57 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 16:30:57 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=9221)[0;0m INFO 09-23 16:30:57 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=9223)[0;0m [1;36m(VllmWorker rank=2 pid=9222)[0;0m INFO 09-23 16:30:57 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 16:30:57 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=9221)[0;0m INFO 09-23 16:30:57 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=9220)[0;0m INFO 09-23 16:30:57 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=9220)[0;0m INFO 09-23 16:30:57 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=9221)[0;0m INFO 09-23 16:30:59 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=3 pid=9223)[0;0m INFO 09-23 16:30:59 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m INFO 09-23 16:30:59 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:30:59 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=9220)[0;0m INFO 09-23 16:31:00 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_6526ef24'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/33ea3f34-5135-4995-a36f-0e57b8fe3d52', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=9222)[0;0m INFO 09-23 16:31:00 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=0 pid=9220)[0;0m INFO 09-23 16:31:00 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=2 pid=9222)[0;0m INFO 09-23 16:31:00 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=9220)[0;0m INFO 09-23 16:31:00 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=9222)[0;0m INFO 09-23 16:31:00 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=9220)[0;0m INFO 09-23 16:31:00 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=9223)[0;0m [1;36m(VllmWorker rank=1 pid=9221)[0;0m INFO 09-23 16:31:00 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
INFO 09-23 16:31:00 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=3 pid=9223)[0;0m INFO 09-23 16:31:00 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=9221)[0;0m INFO 09-23 16:31:00 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=9223)[0;0m INFO 09-23 16:31:00 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=9221)[0;0m INFO 09-23 16:31:00 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=9222)[0;0m INFO 09-23 16:31:00 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=3 pid=9223)[0;0m INFO 09-23 16:31:00 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=1 pid=9221)[0;0m INFO 09-23 16:31:00 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=0 pid=9220)[0;0m INFO 09-23 16:31:00 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=9222)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=9222)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=9222)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=9222)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=9222)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=9222)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=9222)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=9222)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=9222)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=9222)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=9222)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 09-23 16:31:00 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
ERROR 09-23 16:31:00 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 09-23 16:31:00 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 09-23 16:31:00 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 09-23 16:31:00 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
ERROR 09-23 16:31:00 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=3 pid=9223)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
ERROR 09-23 16:31:00 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=3 pid=9223)[0;0m [1;36m(VllmWorker rank=1 pid=9221)[0;0m [1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=3 pid=9223)[0;0m [1;36m(VllmWorker rank=1 pid=9221)[0;0m [1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=3 pid=9223)[0;0m [1;36m(VllmWorker rank=1 pid=9221)[0;0m [1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
ERROR 09-23 16:31:00 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=3 pid=9223)[0;0m [1;36m(VllmWorker rank=1 pid=9221)[0;0m [1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=3 pid=9223)[0;0m [1;36m(VllmWorker rank=1 pid=9221)[0;0m [1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
ERROR 09-23 16:31:00 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=3 pid=9223)[0;0m [1;36m(VllmWorker rank=1 pid=9221)[0;0m [1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.quant_method.create_weights(
ERROR 09-23 16:31:00 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=3 pid=9223)[0;0m [1;36m(VllmWorker rank=1 pid=9221)[0;0m [1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.quant_method.create_weights(
ERROR 09-23 16:31:00 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=3 pid=9223)[0;0m [1;36m(VllmWorker rank=1 pid=9221)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=1 pid=9221)[0;0m [1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m [1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 09-23 16:31:00 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 09-23 16:31:00 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 09-23 16:31:00 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=1 pid=9221)[0;0m [1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m [1;36m(VllmWorker rank=3 pid=9223)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
ERROR 09-23 16:31:00 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 3 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088949 has 37.61 GiB memory in use. Process 2157748 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(VllmWorker rank=1 pid=9221)[0;0m [1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 09-23 16:31:00 [multiproc_executor.py:435]     return func(*args, **kwargs)
ERROR 09-23 16:31:00 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=1 pid=9221)[0;0m [1;36m(VllmWorker rank=2 pid=9222)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     return func(*args, **kwargs)
ERROR 09-23 16:31:00 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2157747 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=1 pid=9221)[0;0m [1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 1 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088947 has 37.62 GiB memory in use. Process 2157746 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=9220)[0;0m ERROR 09-23 16:31:00 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088946 has 37.61 GiB memory in use. Process 2157745 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:31:03 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:31:03 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:31:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:31:03 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:31:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:31:03 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:31:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:31:03 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:31:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:31:03 [core.py:396]     self._init_executor()
ERROR 09-23 16:31:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:31:03 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:31:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:31:03 [core.py:396]     raise e from None
ERROR 09-23 16:31:03 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:31:09] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:31:09] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B/global_step_313
INFO 09-23 16:31:09 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:31:09 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:31:09 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:31:09 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:31:15 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:31:20 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:31:20 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:31:20 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_41b5d940'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/173f39eb-f521-4aca-9728-9504c60553a3', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:31:26 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:31:26 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:31:26 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:31:26 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:31:36 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f2e01798e80>
WARNING 09-23 16:31:36 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f691e654f10>
WARNING 09-23 16:31:36 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f3442a44fd0>
WARNING 09-23 16:31:36 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f54ed9dd060>
[1;36m(VllmWorker rank=1 pid=9472)[0;0m INFO 09-23 16:31:36 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_83e399ee'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/fce00cac-bb58-4a3a-bb6d-94699f57265e', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=9473)[0;0m INFO 09-23 16:31:36 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_02fa1b3f'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/1f4f0aff-9b3a-4c73-9693-e9957b60768c', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=9471)[0;0m INFO 09-23 16:31:36 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_156a25bd'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/30d307ed-2a8c-4c3e-95bb-9ad3c00387eb', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=9474)[0;0m INFO 09-23 16:31:36 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_415a82b1'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/e722934f-22f3-4615-9133-0a717e377a8d', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=9474)[0;0m INFO 09-23 16:32:14 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=9471)[0;0m INFO 09-23 16:32:14 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=9472)[0;0m INFO 09-23 16:32:14 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=9474)[0;0m INFO 09-23 16:32:14 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=9473)[0;0m INFO 09-23 16:32:14 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=9471)[0;0m INFO 09-23 16:32:14 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=9472)[0;0m INFO 09-23 16:32:14 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=9473)[0;0m INFO 09-23 16:32:14 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=9474)[0;0m INFO 09-23 16:32:16 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=9471)[0;0m INFO 09-23 16:32:16 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=9473)[0;0m INFO 09-23 16:32:16 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=1 pid=9472)[0;0m INFO 09-23 16:32:16 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=9471)[0;0m INFO 09-23 16:32:16 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_1461329c'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/523782ef-c915-40a1-ba21-7d5db66e2d6f', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=9474)[0;0m INFO 09-23 16:32:16 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=9473)[0;0m INFO 09-23 16:32:16 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=0 pid=9471)[0;0m INFO 09-23 16:32:16 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=1 pid=9472)[0;0m INFO 09-23 16:32:16 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=3 pid=9474)[0;0m INFO 09-23 16:32:16 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=9471)[0;0m INFO 09-23 16:32:16 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=9473)[0;0m INFO 09-23 16:32:16 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=9474)[0;0m INFO 09-23 16:32:16 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=9471)[0;0m INFO 09-23 16:32:16 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=9473)[0;0m INFO 09-23 16:32:16 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=9472)[0;0m INFO 09-23 16:32:16 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=9472)[0;0m INFO 09-23 16:32:16 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=9474)[0;0m INFO 09-23 16:32:16 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=1 pid=9472)[0;0m INFO 09-23 16:32:16 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=2 pid=9473)[0;0m INFO 09-23 16:32:16 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=0 pid=9471)[0;0m INFO 09-23 16:32:16 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62

CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435] WorkerProc failed to start.
ERROR 09-23 16:32:21 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435] Traceback (most recent call last):
ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
ERROR 09-23 16:32:21 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
ERROR 09-23 16:32:21 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     self.worker.load_model()
ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 09-23 16:32:21 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     self.model_runner.load_model()
ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 09-23 16:32:21 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 09-23 16:32:21 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 09-23 16:32:21 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 09-23 16:32:21 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
ERROR 09-23 16:32:21 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 09-23 16:32:21 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=0 pid=9471)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 09-23 16:32:21 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088946 has 37.61 GiB memory in use. Process 2159049 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(VllmWorker rank=3 pid=9474)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=3 pid=9474)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=3 pid=9474)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=3 pid=9474)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=3 pid=9474)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=3 pid=9474)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=3 pid=9474)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=3 pid=9474)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=3 pid=9474)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=3 pid=9474)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=3 pid=9474)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=3 pid=9474)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=3 pid=9474)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
ERROR 09-23 16:32:21 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
ERROR 09-23 16:32:21 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     self.quant_method.create_weights(
ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 09-23 16:32:21 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 09-23 16:32:21 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     return func(*args, **kwargs)
ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=3 pid=9474)[0;0m [1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 3 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088949 has 37.61 GiB memory in use. Process 2159052 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:32:21 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=9473)[0;0m ERROR 09-23 16:32:21 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2159051 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:32:23 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:32:23 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:32:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:32:23 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:32:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:32:23 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:32:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:32:23 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:32:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:32:23 [core.py:396]     self._init_executor()
ERROR 09-23 16:32:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:32:23 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:32:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:32:23 [core.py:396]     raise e from None
ERROR 09-23 16:32:23 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:32:31] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.05_0.20_Qwen2.5-math-1.5B__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:32:31] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B/global_step_100
INFO 09-23 16:32:31 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:32:31 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:32:31 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:32:31 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:32:37 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:32:43 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B/global_step_100', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B/global_step_100', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B/global_step_100, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:32:43 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:32:43 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_4c91a68b'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/bcb82aa5-d71e-4ba6-a372-074c67e85485', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:32:48 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:32:48 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:32:48 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:32:48 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:32:54 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f8263a8cdf0>
[1;36m(VllmWorker rank=1 pid=9723)[0;0m INFO 09-23 16:32:54 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_45b076c3'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/4b6c4a67-8b12-4467-b7e2-e9294b3e1060', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:32:54 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f6b42fccfa0>
WARNING 09-23 16:32:54 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f2ff3574df0>
[1;36m(VllmWorker rank=3 pid=9725)[0;0m INFO 09-23 16:32:54 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_359d61bc'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/c702a6e8-724a-49ff-9045-f80074fc0398', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=9722)[0;0m INFO 09-23 16:32:54 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_ae37364f'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/c90bfcbb-b51e-41cf-9a38-ac14bdb01024', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:32:54 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f40e04d0f40>
[1;36m(VllmWorker rank=2 pid=9724)[0;0m INFO 09-23 16:32:54 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_1d7363c5'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/2adebd29-2147-4b73-b3d4-5da757126fad', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=9725)[0;0m [1;36m(VllmWorker rank=1 pid=9723)[0;0m INFO 09-23 16:33:30 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=9722)[0;0m INFO 09-23 16:33:30 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 16:33:30 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=9724)[0;0m INFO 09-23 16:33:30 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=9722)[0;0m [1;36m(VllmWorker rank=3 pid=9725)[0;0m [1;36m(VllmWorker rank=1 pid=9723)[0;0m INFO 09-23 16:33:30 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 16:33:30 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 16:33:30 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=9724)[0;0m INFO 09-23 16:33:30 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=9725)[0;0m INFO 09-23 16:33:31 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=9724)[0;0m [1;36m(VllmWorker rank=0 pid=9722)[0;0m [1;36m(VllmWorker rank=1 pid=9723)[0;0m INFO 09-23 16:33:31 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:33:31 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:33:31 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=9722)[0;0m INFO 09-23 16:33:31 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_ad2b58ea'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/91abada4-30d3-4f31-816e-ca0c6794bc05', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=9725)[0;0m INFO 09-23 16:33:31 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=9724)[0;0m INFO 09-23 16:33:31 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=1 pid=9723)[0;0m INFO 09-23 16:33:31 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=0 pid=9722)[0;0m INFO 09-23 16:33:31 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=3 pid=9725)[0;0m INFO 09-23 16:33:31 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=9724)[0;0m INFO 09-23 16:33:31 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=9723)[0;0m INFO 09-23 16:33:31 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=9722)[0;0m INFO 09-23 16:33:31 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=9725)[0;0m INFO 09-23 16:33:31 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=9724)[0;0m INFO 09-23 16:33:31 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=9722)[0;0m INFO 09-23 16:33:31 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=9723)[0;0m INFO 09-23 16:33:31 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=9725)[0;0m INFO 09-23 16:33:31 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=2 pid=9724)[0;0m INFO 09-23 16:33:31 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=1 pid=9723)[0;0m INFO 09-23 16:33:31 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=0 pid=9722)[0;0m INFO 09-23 16:33:31 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B/global_step_100...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=9724)[0;0m ERROR 09-23 16:33:31 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2160576 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:33:33 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:33:33 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:33:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:33:33 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:33:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:33:33 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:33:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:33:33 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:33:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:33:33 [core.py:396]     self._init_executor()
ERROR 09-23 16:33:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:33:33 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:33:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:33:33 [core.py:396]     raise e from None
ERROR 09-23 16:33:33 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:33:35] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B__global_step_100 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:33:35] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B/global_step_200
INFO 09-23 16:33:35 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:33:35 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:33:35 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:33:35 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:33:40 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:33:45 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:33:45 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:33:45 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_0d1c038b'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/ffca7f39-38fb-4f4e-b0dc-9111160c9cc2', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:33:50 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:33:51 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:33:51 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:33:51 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:33:56 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f7d9e318fd0>
[1;36m(VllmWorker rank=0 pid=9973)[0;0m INFO 09-23 16:33:56 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_28796b7a'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/26ba9cf0-1ca5-4dee-8ef1-0cb0da780788', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:33:56 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f13f311d150>
[1;36m(VllmWorker rank=2 pid=9975)[0;0m INFO 09-23 16:33:56 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_0b2b39ac'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/bd2e00ac-8a8b-45d2-b1f0-71420f10bac6', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:33:56 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f4c38a74e20>
[1;36m(VllmWorker rank=1 pid=9974)[0;0m INFO 09-23 16:33:56 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_f9aba1be'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/d9d5cb8d-0baf-4805-aa52-96aa42cd6d3e', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:33:56 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f67a0a68ee0>
[1;36m(VllmWorker rank=3 pid=9976)[0;0m INFO 09-23 16:33:56 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_50a229e1'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/1441eaa7-f2d3-47b8-91d6-ff5216a803ba', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=9973)[0;0m [1;36m(VllmWorker rank=2 pid=9975)[0;0m INFO 09-23 16:34:32 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 16:34:32 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=9974)[0;0m INFO 09-23 16:34:32 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=9976)[0;0m INFO 09-23 16:34:32 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=9975)[0;0m [1;36m(VllmWorker rank=0 pid=9973)[0;0m INFO 09-23 16:34:32 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 16:34:32 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=9974)[0;0m INFO 09-23 16:34:32 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=9976)[0;0m INFO 09-23 16:34:32 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=9973)[0;0m [1;36m(VllmWorker rank=2 pid=9975)[0;0m INFO 09-23 16:34:33 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:34:33 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=1 pid=9974)[0;0m INFO 09-23 16:34:33 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=3 pid=9976)[0;0m INFO 09-23 16:34:33 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=9973)[0;0m INFO 09-23 16:34:33 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_5f986e7f'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/47c9a7df-6700-4d58-a929-4035eae7134e', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=9976)[0;0m INFO 09-23 16:34:33 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=9975)[0;0m INFO 09-23 16:34:33 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=1 pid=9974)[0;0m INFO 09-23 16:34:33 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=0 pid=9973)[0;0m INFO 09-23 16:34:33 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=0 pid=9973)[0;0m INFO 09-23 16:34:33 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=9974)[0;0m [1;36m(VllmWorker rank=2 pid=9975)[0;0m INFO 09-23 16:34:33 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 09-23 16:34:33 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=9976)[0;0m INFO 09-23 16:34:33 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=9973)[0;0m INFO 09-23 16:34:33 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=9974)[0;0m INFO 09-23 16:34:33 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=9975)[0;0m INFO 09-23 16:34:33 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=9976)[0;0m INFO 09-23 16:34:33 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=9974)[0;0m INFO 09-23 16:34:33 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=2 pid=9975)[0;0m INFO 09-23 16:34:33 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=3 pid=9976)[0;0m INFO 09-23 16:34:33 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=0 pid=9973)[0;0m INFO 09-23 16:34:33 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=1 pid=9974)[0;0m ERROR 09-23 16:34:33 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 1 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088947 has 37.62 GiB memory in use. Process 2161578 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:34:35 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:34:35 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:34:35 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:34:35 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:34:35 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:34:35 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:34:35 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:34:35 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:34:35 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:34:35 [core.py:396]     self._init_executor()
ERROR 09-23 16:34:35 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:34:35 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:34:35 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:34:35 [core.py:396]     raise e from None
ERROR 09-23 16:34:35 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:34:36] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.20_Qwen2.5-math-1.5B__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:34:36] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_100
INFO 09-23 16:34:36 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:34:36 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:34:36 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:34:36 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:34:43 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:34:49 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_100', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_100', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_100, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:34:49 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:34:49 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_6405839a'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/40c11ce8-4378-4931-90e3-d5215712f532', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:34:54 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:34:54 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:34:54 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:34:54 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:35:00 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fb4c175cee0>
[1;36m(VllmWorker rank=0 pid=10224)[0;0m INFO 09-23 16:35:00 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_43f06a1b'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/4b60962c-bcc8-4f46-8e43-866ce9da6183', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:35:00 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f8394f34f40>
[1;36m(VllmWorker rank=3 pid=10227)[0;0m INFO 09-23 16:35:00 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_27a828d5'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/bfcd4505-c8ab-49ed-b203-27e61fe0a462', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:35:00 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fa5bc0c8e20>
WARNING 09-23 16:35:00 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f65663d9150>
[1;36m(VllmWorker rank=2 pid=10226)[0;0m INFO 09-23 16:35:00 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_cf953882'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/74e4d989-cc89-4950-8d15-677752cf79cd', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=10225)[0;0m INFO 09-23 16:35:00 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_8a29254d'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/14267902-a75c-4e10-9536-f4dd12ed6801', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=10227)[0;0m [1;36m(VllmWorker rank=0 pid=10224)[0;0m INFO 09-23 16:35:36 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 16:35:36 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=10224)[0;0m [1;36m(VllmWorker rank=3 pid=10227)[0;0m INFO 09-23 16:35:36 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 16:35:36 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=10225)[0;0m INFO 09-23 16:35:36 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=10226)[0;0m INFO 09-23 16:35:36 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=10225)[0;0m INFO 09-23 16:35:36 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=10226)[0;0m INFO 09-23 16:35:36 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=10227)[0;0m [1;36m(VllmWorker rank=2 pid=10226)[0;0m [1;36m(VllmWorker rank=0 pid=10224)[0;0m INFO 09-23 16:35:37 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=1 pid=10225)[0;0m INFO 09-23 16:35:37 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:35:37 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:35:37 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=10224)[0;0m INFO 09-23 16:35:37 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_f41e7d64'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/779f47b4-7f79-44cf-866f-250dd3a2d1a0', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=10226)[0;0m INFO 09-23 16:35:37 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=3 pid=10227)[0;0m INFO 09-23 16:35:37 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=1 pid=10225)[0;0m [1;36m(VllmWorker rank=0 pid=10224)[0;0m INFO 09-23 16:35:37 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
INFO 09-23 16:35:37 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=2 pid=10226)[0;0m INFO 09-23 16:35:37 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=10227)[0;0m INFO 09-23 16:35:37 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=10224)[0;0m INFO 09-23 16:35:37 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=10225)[0;0m INFO 09-23 16:35:37 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=10226)[0;0m INFO 09-23 16:35:37 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=10227)[0;0m INFO 09-23 16:35:37 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=10224)[0;0m INFO 09-23 16:35:37 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=10225)[0;0m INFO 09-23 16:35:37 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=10226)[0;0m INFO 09-23 16:35:37 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=3 pid=10227)[0;0m INFO 09-23 16:35:37 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=1 pid=10225)[0;0m INFO 09-23 16:35:37 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=0 pid=10224)[0;0m INFO 09-23 16:35:37 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_100...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=10226)[0;0m ERROR 09-23 16:35:37 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2162648 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f84e2b6c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f84e2b15b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f849368e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f84e2efcb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f84e2efd20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39afa (0x7f84e2f13afa in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f84e2eff329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f84dac864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f84da3a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f84da3a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x55d5195a8c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x55d5195352a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x55d519535bbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x55d519535c83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x55d5195a8b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x55d519614c3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x55d519617f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x55d519536c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x55d519675c30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x55d51969b407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x55d51969b634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x55d51969b718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x55d51969b75b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x55d51969b972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x55d5196a1f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x55d5196a21ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x55d5196a2469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f84e39f8d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f84e39f8e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x55d51960d2d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

ERROR 09-23 16:35:39 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:35:39 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:35:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:35:39 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:35:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:35:39 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:35:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:35:39 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:35:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:35:39 [core.py:396]     self._init_executor()
ERROR 09-23 16:35:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:35:39 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:35:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:35:39 [core.py:396]     raise e from None
ERROR 09-23 16:35:39 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:35:41] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B__global_step_100 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:35:41] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_200
INFO 09-23 16:35:41 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:35:41 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:35:41 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:35:41 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:35:46 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:35:51 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:35:51 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:35:51 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_c299a714'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/40fe4e07-5a07-4f30-9839-81749a042957', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:35:57 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:35:57 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:35:57 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:35:57 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:36:02 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fa1c1159000>
[1;36m(VllmWorker rank=0 pid=10475)[0;0m INFO 09-23 16:36:02 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_2c655e77'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/9904cdba-e1d0-4234-8722-7fa9f7edaaf8', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:36:02 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fea6cbc8fa0>
[1;36m(VllmWorker rank=3 pid=10478)[0;0m INFO 09-23 16:36:02 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_62606eac'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/35ecde61-84c6-4b3a-9120-94c8f09c8e05', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:36:02 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f95eb6b0fd0>
[1;36m(VllmWorker rank=2 pid=10477)[0;0m INFO 09-23 16:36:02 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_9ca8dbb6'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/d7f542b0-ff57-4d43-81c0-eda373357597', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:36:02 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f9412dd8e50>
[1;36m(VllmWorker rank=1 pid=10476)[0;0m INFO 09-23 16:36:02 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_765f22a0'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/2ac2578b-7125-44a7-91f9-c69c713e5c24', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=10475)[0;0m INFO 09-23 16:36:38 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=10478)[0;0m INFO 09-23 16:36:38 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=10478)[0;0m [1;36m(VllmWorker rank=0 pid=10475)[0;0m INFO 09-23 16:36:38 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 16:36:38 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=10476)[0;0m INFO 09-23 16:36:38 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=10477)[0;0m INFO 09-23 16:36:38 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=10476)[0;0m INFO 09-23 16:36:38 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=10477)[0;0m INFO 09-23 16:36:38 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=10475)[0;0m INFO 09-23 16:36:39 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=3 pid=10478)[0;0m [1;36m(VllmWorker rank=1 pid=10476)[0;0m INFO 09-23 16:36:39 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:36:39 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=10477)[0;0m INFO 09-23 16:36:39 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=10475)[0;0m INFO 09-23 16:36:39 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_36600e49'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/7ff92d67-6c0d-4126-977d-9af1529d8514', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=10478)[0;0m INFO 09-23 16:36:39 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=0 pid=10475)[0;0m [1;36m(VllmWorker rank=2 pid=10477)[0;0m INFO 09-23 16:36:39 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 09-23 16:36:39 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=1 pid=10476)[0;0m INFO 09-23 16:36:39 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=3 pid=10478)[0;0m INFO 09-23 16:36:39 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=10475)[0;0m INFO 09-23 16:36:39 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=10476)[0;0m INFO 09-23 16:36:39 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=10478)[0;0m INFO 09-23 16:36:39 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=10475)[0;0m INFO 09-23 16:36:39 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=10476)[0;0m INFO 09-23 16:36:39 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=10477)[0;0m INFO 09-23 16:36:39 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=10477)[0;0m INFO 09-23 16:36:39 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=10478)[0;0m INFO 09-23 16:36:39 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=1 pid=10476)[0;0m INFO 09-23 16:36:39 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=2 pid=10477)[0;0m INFO 09-23 16:36:39 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=0 pid=10475)[0;0m INFO 09-23 16:36:39 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=10475)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088946 has 37.61 GiB memory in use. Process 2163591 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=10478)[0;0m ERROR 09-23 16:36:39 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 3 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088949 has 37.61 GiB memory in use. Process 2163594 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:36:41 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:36:41 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:36:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:36:41 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:36:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:36:41 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:36:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:36:41 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:36:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:36:41 [core.py:396]     self._init_executor()
ERROR 09-23 16:36:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:36:41 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:36:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:36:41 [core.py:396]     raise e from None
ERROR 09-23 16:36:41 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:36:42] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:36:42] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_313
INFO 09-23 16:36:42 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:36:42 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:36:42 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:36:42 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:36:48 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:36:53 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:36:53 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:36:53 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_f936edc6'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/ce41b819-4a09-4316-ae66-08e979e8d5ed', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:36:58 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:36:58 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:36:58 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:36:58 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:37:04 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7ff3adb78dc0>
[1;36m(VllmWorker rank=3 pid=10729)[0;0m INFO 09-23 16:37:04 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_1dabc9dc'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/23ec95d1-e6bd-4e24-90f1-904cb5a5b63a', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:37:04 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fd1b3c88f40>
[1;36m(VllmWorker rank=2 pid=10728)[0;0m INFO 09-23 16:37:04 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_03b219fe'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/8f170891-bec7-4964-9940-ce65b18c3a2a', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:37:04 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f37d31e0f40>
[1;36m(VllmWorker rank=0 pid=10726)[0;0m INFO 09-23 16:37:04 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_ab564bce'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/3361eaa9-0325-47e4-a1b1-52d1f40e45cc', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:37:04 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fa202419060>
[1;36m(VllmWorker rank=1 pid=10727)[0;0m INFO 09-23 16:37:04 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_1b814add'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/20beb4de-7a8c-47a7-aded-ce7d814f99e0', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=10726)[0;0m INFO 09-23 16:37:40 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=10729)[0;0m INFO 09-23 16:37:40 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=10726)[0;0m INFO 09-23 16:37:40 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=10729)[0;0m INFO 09-23 16:37:40 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=10727)[0;0m INFO 09-23 16:37:40 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=10728)[0;0m INFO 09-23 16:37:40 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=10727)[0;0m INFO 09-23 16:37:40 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=10728)[0;0m INFO 09-23 16:37:40 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=10729)[0;0m INFO 09-23 16:37:41 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=10726)[0;0m [1;36m(VllmWorker rank=2 pid=10728)[0;0m INFO 09-23 16:37:41 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=1 pid=10727)[0;0m INFO 09-23 16:37:41 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:37:41 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=10726)[0;0m INFO 09-23 16:37:41 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_8d14c14e'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/422c6eae-d1a9-44b6-b4bb-f09dc5dc13c2', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=10729)[0;0m INFO 09-23 16:37:41 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=0 pid=10726)[0;0m [1;36m(VllmWorker rank=2 pid=10728)[0;0m INFO 09-23 16:37:41 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=1 pid=10727)[0;0m INFO 09-23 16:37:41 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
INFO 09-23 16:37:41 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=3 pid=10729)[0;0m INFO 09-23 16:37:41 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=10726)[0;0m INFO 09-23 16:37:41 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=10727)[0;0m INFO 09-23 16:37:41 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=10728)[0;0m INFO 09-23 16:37:41 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=10729)[0;0m INFO 09-23 16:37:41 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=10726)[0;0m INFO 09-23 16:37:41 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=10727)[0;0m INFO 09-23 16:37:41 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=10728)[0;0m INFO 09-23 16:37:41 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=10729)[0;0m INFO 09-23 16:37:41 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=2 pid=10728)[0;0m INFO 09-23 16:37:41 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=1 pid=10727)[0;0m INFO 09-23 16:37:41 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=0 pid=10726)[0;0m INFO 09-23 16:37:41 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=1 pid=10727)[0;0m ERROR 09-23 16:37:41 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 1 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088947 has 37.62 GiB memory in use. Process 2164603 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:37:43 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:37:43 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:37:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:37:43 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:37:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:37:43 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:37:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:37:43 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:37:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:37:43 [core.py:396]     self._init_executor()
ERROR 09-23 16:37:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:37:43 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:37:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:37:43 [core.py:396]     raise e from None
ERROR 09-23 16:37:43 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:37:44] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.09_0.21_Qwen2.5-math-1.5B__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:37:44] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_200
INFO 09-23 16:37:44 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:37:44 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:37:44 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:37:44 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:37:50 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:37:55 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:37:55 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:37:55 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_f5f3bc2f'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/18118c59-57b3-49e3-af1a-48e2a749d691', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:38:00 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:38:00 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:38:00 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:38:00 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:38:06 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fabd45c0eb0>
[1;36m(VllmWorker rank=3 pid=10980)[0;0m INFO 09-23 16:38:06 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_7ea71372'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/a6ff5d71-72b6-4985-8713-218af3165205', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:38:06 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f91c31d50c0>
[1;36m(VllmWorker rank=1 pid=10978)[0;0m INFO 09-23 16:38:06 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_2df64e1c'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/362dbb50-ccf2-4850-9ce9-ccd839bb768a', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:38:06 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7ff95f984f70>
[1;36m(VllmWorker rank=0 pid=10977)[0;0m INFO 09-23 16:38:06 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_33a6bb8f'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/e5388874-b599-4ed6-a0cf-e7b5293e6207', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:38:06 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fd8d9bd50f0>
[1;36m(VllmWorker rank=2 pid=10979)[0;0m INFO 09-23 16:38:06 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_9b3260b1'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/3ff218a0-e1d0-43d1-8cf7-d66242c4cc5c', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=10980)[0;0m [1;36m(VllmWorker rank=1 pid=10978)[0;0m INFO 09-23 16:38:42 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 16:38:42 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=10980)[0;0m [1;36m(VllmWorker rank=1 pid=10978)[0;0m INFO 09-23 16:38:42 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 16:38:42 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=10977)[0;0m INFO 09-23 16:38:42 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=10977)[0;0m INFO 09-23 16:38:42 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=10979)[0;0m INFO 09-23 16:38:42 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=10979)[0;0m INFO 09-23 16:38:42 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=10980)[0;0m INFO 09-23 16:38:43 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=10977)[0;0m [1;36m(VllmWorker rank=1 pid=10978)[0;0m [1;36m(VllmWorker rank=2 pid=10979)[0;0m INFO 09-23 16:38:43 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:38:43 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:38:43 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=10977)[0;0m INFO 09-23 16:38:43 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_44956f36'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/5bfc60e6-cb38-4685-a0c7-a4199b696a5e', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=10980)[0;0m INFO 09-23 16:38:43 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=10979)[0;0m [1;36m(VllmWorker rank=1 pid=10978)[0;0m [1;36m(VllmWorker rank=0 pid=10977)[0;0m INFO 09-23 16:38:43 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
INFO 09-23 16:38:43 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
INFO 09-23 16:38:43 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=3 pid=10980)[0;0m INFO 09-23 16:38:43 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=10977)[0;0m INFO 09-23 16:38:43 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=10979)[0;0m INFO 09-23 16:38:43 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=10980)[0;0m INFO 09-23 16:38:43 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=10978)[0;0m [1;36m(VllmWorker rank=0 pid=10977)[0;0m INFO 09-23 16:38:43 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 09-23 16:38:43 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=10979)[0;0m INFO 09-23 16:38:43 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=10978)[0;0m INFO 09-23 16:38:43 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=10980)[0;0m INFO 09-23 16:38:43 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=2 pid=10979)[0;0m INFO 09-23 16:38:43 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=1 pid=10978)[0;0m INFO 09-23 16:38:43 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=0 pid=10977)[0;0m INFO 09-23 16:38:43 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=10979)[0;0m ERROR 09-23 16:38:43 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2165668 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:38:45 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:38:45 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:38:45 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:38:45 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:38:45 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:38:45 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:38:45 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:38:45 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:38:45 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:38:45 [core.py:396]     self._init_executor()
ERROR 09-23 16:38:45 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:38:45 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:38:45 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:38:45 [core.py:396]     raise e from None
ERROR 09-23 16:38:45 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:38:46] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:38:46] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_313
INFO 09-23 16:38:46 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:38:46 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:38:46 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:38:46 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:38:52 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:38:57 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:38:57 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:38:57 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_6f67bd6d'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/1a511afe-6707-42f1-b971-8a8734321a8d', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:39:02 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:39:02 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:39:02 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:39:02 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:39:08 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fd6bc0cd030>
[1;36m(VllmWorker rank=3 pid=11231)[0;0m INFO 09-23 16:39:08 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_b4e8d8b5'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/83424cbb-6c8b-4644-b4c5-b15ee1fd5d35', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:39:08 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fc1fe3d0f70>
[1;36m(VllmWorker rank=1 pid=11229)[0;0m INFO 09-23 16:39:08 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_6e9dfff1'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/062a8295-54a6-4623-9b2e-00b995b0080f', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:39:08 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f55011ecd30>
WARNING 09-23 16:39:08 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f3544490eb0>
[1;36m(VllmWorker rank=0 pid=11228)[0;0m INFO 09-23 16:39:08 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_61a6453e'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/e68d773a-e1c1-4c6d-8c82-4f992eeebcac', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=11230)[0;0m INFO 09-23 16:39:08 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_5a9b59ea'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/576418d0-828f-499b-b022-6cad1c1548cb', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=11230)[0;0m INFO 09-23 16:39:44 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=11231)[0;0m INFO 09-23 16:39:44 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=11228)[0;0m INFO 09-23 16:39:44 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=11230)[0;0m INFO 09-23 16:39:44 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=11231)[0;0m INFO 09-23 16:39:44 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=11228)[0;0m INFO 09-23 16:39:44 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=11229)[0;0m INFO 09-23 16:39:44 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=11229)[0;0m INFO 09-23 16:39:44 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=11228)[0;0m [1;36m(VllmWorker rank=3 pid=11231)[0;0m [1;36m(VllmWorker rank=2 pid=11230)[0;0m INFO 09-23 16:39:45 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=1 pid=11229)[0;0m INFO 09-23 16:39:45 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:39:45 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:39:45 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=11228)[0;0m INFO 09-23 16:39:45 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_bb4594af'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/53144f3f-ea93-4602-a222-e2e9bc5adb30', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=11231)[0;0m INFO 09-23 16:39:45 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=11230)[0;0m INFO 09-23 16:39:45 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=1 pid=11229)[0;0m [1;36m(VllmWorker rank=0 pid=11228)[0;0m INFO 09-23 16:39:45 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
INFO 09-23 16:39:45 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=3 pid=11231)[0;0m INFO 09-23 16:39:45 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=11228)[0;0m INFO 09-23 16:39:45 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=11230)[0;0m INFO 09-23 16:39:45 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=11229)[0;0m INFO 09-23 16:39:45 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=11231)[0;0m INFO 09-23 16:39:45 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=11228)[0;0m INFO 09-23 16:39:45 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=11230)[0;0m INFO 09-23 16:39:45 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=11229)[0;0m INFO 09-23 16:39:45 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=11231)[0;0m INFO 09-23 16:39:45 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=2 pid=11230)[0;0m INFO 09-23 16:39:45 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=1 pid=11229)[0;0m INFO 09-23 16:39:45 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=0 pid=11228)[0;0m INFO 09-23 16:39:45 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=11231)[0;0m ERROR 09-23 16:39:45 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 3 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088949 has 37.61 GiB memory in use. Process 2166698 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:39:47 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:39:47 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:39:47 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:39:47 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:39:47 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:39:47 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:39:47 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:39:47 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:39:47 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:39:47 [core.py:396]     self._init_executor()
ERROR 09-23 16:39:47 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:39:47 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:39:47 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:39:47 [core.py:396]     raise e from None
ERROR 09-23 16:39:47 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:39:48] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.10_Qwen2.5-math-1.5B__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:39:48] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_200
INFO 09-23 16:39:48 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:39:48 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:39:48 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:39:48 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:39:54 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:39:59 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:39:59 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:39:59 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_568e1374'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/8e33598e-e978-4b2e-8536-aac0089dc49c', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:40:04 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:40:04 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:40:04 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:40:04 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:40:10 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f1bfd26ce20>
[1;36m(VllmWorker rank=1 pid=11480)[0;0m INFO 09-23 16:40:10 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_9bff1a9d'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/c4542138-6a69-4d40-be0b-5360f85824a7', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:40:10 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f04d74e8fa0>
[1;36m(VllmWorker rank=2 pid=11481)[0;0m INFO 09-23 16:40:10 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_e7bbb34d'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/ae8dbd28-930f-4aa2-94c5-74ff210014b8', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:40:10 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f6c3b4f1000>
[1;36m(VllmWorker rank=0 pid=11479)[0;0m INFO 09-23 16:40:10 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_6b82da17'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/f4905710-2775-4a14-9574-700f115b3ac2', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:40:10 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f4bd150d060>
[1;36m(VllmWorker rank=3 pid=11482)[0;0m INFO 09-23 16:40:10 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_f9fe007e'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/0fd3f94f-fd47-414e-891d-16589351b2ed', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=11480)[0;0m [1;36m(VllmWorker rank=0 pid=11479)[0;0m INFO 09-23 16:40:46 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 16:40:46 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=11481)[0;0m INFO 09-23 16:40:46 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=11482)[0;0m INFO 09-23 16:40:46 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=11480)[0;0m [1;36m(VllmWorker rank=0 pid=11479)[0;0m INFO 09-23 16:40:46 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 16:40:46 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=11481)[0;0m INFO 09-23 16:40:46 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=11482)[0;0m INFO 09-23 16:40:46 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=11480)[0;0m INFO 09-23 16:40:47 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=3 pid=11482)[0;0m INFO 09-23 16:40:47 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=11481)[0;0m [1;36m(VllmWorker rank=0 pid=11479)[0;0m INFO 09-23 16:40:47 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:40:47 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=11479)[0;0m INFO 09-23 16:40:47 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_778c2ed0'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/eedb4f14-f62b-45f9-bc60-2318d4644e8a', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=11479)[0;0m INFO 09-23 16:40:47 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=3 pid=11482)[0;0m INFO 09-23 16:40:47 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=1 pid=11480)[0;0m INFO 09-23 16:40:47 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=0 pid=11479)[0;0m INFO 09-23 16:40:47 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=11482)[0;0m INFO 09-23 16:40:47 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=11479)[0;0m INFO 09-23 16:40:47 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=11480)[0;0m INFO 09-23 16:40:47 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=11482)[0;0m INFO 09-23 16:40:47 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=11480)[0;0m INFO 09-23 16:40:47 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=11480)[0;0m INFO 09-23 16:40:47 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=3 pid=11482)[0;0m INFO 09-23 16:40:47 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=2 pid=11481)[0;0m INFO 09-23 16:40:47 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=0 pid=11479)[0;0m INFO 09-23 16:40:47 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=2 pid=11481)[0;0m INFO 09-23 16:40:47 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=11481)[0;0m INFO 09-23 16:40:47 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=11481)[0;0m INFO 09-23 16:40:47 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=11479)[0;0m ERROR 09-23 16:40:47 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088946 has 37.61 GiB memory in use. Process 2167762 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:40:49 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:40:49 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:40:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:40:49 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:40:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:40:49 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:40:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:40:49 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:40:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:40:49 [core.py:396]     self._init_executor()
ERROR 09-23 16:40:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:40:49 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:40:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:40:49 [core.py:396]     raise e from None
ERROR 09-23 16:40:49 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:40:50] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:40:50] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_313
INFO 09-23 16:40:50 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:40:50 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:40:50 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:40:50 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:40:56 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:41:01 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:41:01 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:41:01 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_168d0d95'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/85873fb3-c9b8-412d-96bb-04a01929d063', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:41:06 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:41:06 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:41:06 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:41:06 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:41:12 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7faa2ba49150>
[1;36m(VllmWorker rank=1 pid=11731)[0;0m INFO 09-23 16:41:12 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_7878d29e'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/104df819-ec6c-4059-a60c-94dd3413a7d4', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:41:12 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f592a0ecee0>
[1;36m(VllmWorker rank=2 pid=11732)[0;0m INFO 09-23 16:41:12 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_a9a8739e'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/e8041f1d-4271-41aa-a0a8-0b5a2302adb3', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:41:12 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f454e424f10>
[1;36m(VllmWorker rank=0 pid=11730)[0;0m INFO 09-23 16:41:12 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_7782aa81'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/f9c65126-a326-46c7-a7c6-08dc97512484', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:41:12 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fc348cf0d30>
[1;36m(VllmWorker rank=3 pid=11733)[0;0m INFO 09-23 16:41:12 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_cc73f711'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/6da4432c-734a-4005-abd0-b522dd45f3e9', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=11731)[0;0m [1;36m(VllmWorker rank=2 pid=11732)[0;0m INFO 09-23 16:41:48 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 16:41:48 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=11730)[0;0m INFO 09-23 16:41:48 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=11732)[0;0m [1;36m(VllmWorker rank=1 pid=11731)[0;0m INFO 09-23 16:41:48 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 16:41:48 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=11730)[0;0m INFO 09-23 16:41:48 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=11733)[0;0m INFO 09-23 16:41:48 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=11733)[0;0m INFO 09-23 16:41:48 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=11731)[0;0m [1;36m(VllmWorker rank=0 pid=11730)[0;0m INFO 09-23 16:41:49 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:41:49 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=3 pid=11733)[0;0m INFO 09-23 16:41:49 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=11732)[0;0m INFO 09-23 16:41:49 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=11730)[0;0m INFO 09-23 16:41:49 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_7e5476a5'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/d325d5fe-5767-4f47-9ab1-f279297d8f43', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=11733)[0;0m INFO 09-23 16:41:49 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=11732)[0;0m INFO 09-23 16:41:49 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=0 pid=11730)[0;0m INFO 09-23 16:41:49 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=1 pid=11731)[0;0m INFO 09-23 16:41:49 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=2 pid=11732)[0;0m INFO 09-23 16:41:49 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=11733)[0;0m INFO 09-23 16:41:49 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=11730)[0;0m INFO 09-23 16:41:49 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=11731)[0;0m INFO 09-23 16:41:49 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=11732)[0;0m INFO 09-23 16:41:49 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=11730)[0;0m INFO 09-23 16:41:49 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=11733)[0;0m INFO 09-23 16:41:49 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=11731)[0;0m INFO 09-23 16:41:49 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=11732)[0;0m INFO 09-23 16:41:49 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=1 pid=11731)[0;0m INFO 09-23 16:41:49 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=3 pid=11733)[0;0m INFO 09-23 16:41:49 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=0 pid=11730)[0;0m INFO 09-23 16:41:49 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=11732)[0;0m ERROR 09-23 16:41:49 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2168790 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fc49696c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7fc496915b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7fc44748e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7fc496d20b78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7fc496d2120e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39afa (0x7fc496d37afa in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7fc496d23329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7fc48ea864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7fc48e1a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7fc48e1a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x5619c1703c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x5619c16902a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x5619c1690bbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x5619c1690c83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x5619c1703b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x5619c176fc3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x5619c1772f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x5619c1691c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x5619c17d0c30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x5619c17f6407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x5619c17f6634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x5619c17f6718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x5619c17f675b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x5619c17f6972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x5619c17fcf60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x5619c17fd1ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x5619c17fd469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7fc49781cd90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7fc49781ce40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x5619c17682d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

ERROR 09-23 16:41:51 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:41:51 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:41:51 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:41:51 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:41:51 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:41:51 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:41:51 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:41:51 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:41:51 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:41:51 [core.py:396]     self._init_executor()
ERROR 09-23 16:41:51 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:41:51 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:41:51 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:41:51 [core.py:396]     raise e from None
ERROR 09-23 16:41:51 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:41:52] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.15_Qwen2.5-math-1.5B__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:41:52] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_100
INFO 09-23 16:41:52 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:41:52 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:41:52 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:41:52 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:41:58 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:42:03 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_100', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_100', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_100, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:42:03 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:42:03 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_85b05034'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/2bf81b3d-18bd-4eec-b058-0347b2f9adb5', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:42:08 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:42:08 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:42:08 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:42:08 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:42:14 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f76724d0e80>
[1;36m(VllmWorker rank=2 pid=11983)[0;0m INFO 09-23 16:42:14 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_c1c181b4'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/ab821573-252b-4918-b48f-702da733d43c', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:42:14 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fb876971090>
WARNING 09-23 16:42:14 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f0034d59000>
[1;36m(VllmWorker rank=3 pid=11984)[0;0m INFO 09-23 16:42:14 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_14fc3709'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/bf5d1abd-8698-4a10-b22f-1f4a31e29f80', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=11981)[0;0m INFO 09-23 16:42:14 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_62e5d3ca'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/afbdb0ba-8eee-4a96-8ef6-858ac934411a', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:42:14 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f9ed69f8d30>
[1;36m(VllmWorker rank=1 pid=11982)[0;0m INFO 09-23 16:42:14 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_c0e740ee'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/2ee84da4-972f-4340-9ab9-90946ab0de88', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=11983)[0;0m [1;36m(VllmWorker rank=3 pid=11984)[0;0m INFO 09-23 16:42:50 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 16:42:50 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=11981)[0;0m INFO 09-23 16:42:50 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=11984)[0;0m [1;36m(VllmWorker rank=2 pid=11983)[0;0m INFO 09-23 16:42:50 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 16:42:50 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=11981)[0;0m INFO 09-23 16:42:50 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=11982)[0;0m INFO 09-23 16:42:50 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=11982)[0;0m INFO 09-23 16:42:50 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=11981)[0;0m [1;36m(VllmWorker rank=2 pid=11983)[0;0m [1;36m(VllmWorker rank=3 pid=11984)[0;0m INFO 09-23 16:42:51 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:42:51 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=1 pid=11982)[0;0m INFO 09-23 16:42:51 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:42:51 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=11981)[0;0m INFO 09-23 16:42:51 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_4966d7f7'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/19a88c0d-a824-4601-8af6-abccf0027b39', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=11984)[0;0m INFO 09-23 16:42:51 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=11983)[0;0m INFO 09-23 16:42:51 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=1 pid=11982)[0;0m INFO 09-23 16:42:51 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=0 pid=11981)[0;0m INFO 09-23 16:42:51 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=3 pid=11984)[0;0m INFO 09-23 16:42:51 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=11983)[0;0m INFO 09-23 16:42:51 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=11982)[0;0m INFO 09-23 16:42:51 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=11984)[0;0m INFO 09-23 16:42:51 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=11981)[0;0m INFO 09-23 16:42:51 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=11983)[0;0m INFO 09-23 16:42:51 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=11982)[0;0m INFO 09-23 16:42:51 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=11981)[0;0m INFO 09-23 16:42:51 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=11984)[0;0m INFO 09-23 16:42:51 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=2 pid=11983)[0;0m INFO 09-23 16:42:51 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=1 pid=11982)[0;0m INFO 09-23 16:42:51 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=0 pid=11981)[0;0m INFO 09-23 16:42:51 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_100...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=11983)[0;0m ERROR 09-23 16:42:51 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2169756 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:42:53 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:42:53 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:42:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:42:53 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:42:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:42:53 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:42:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:42:53 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:42:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:42:53 [core.py:396]     self._init_executor()
ERROR 09-23 16:42:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:42:53 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:42:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:42:53 [core.py:396]     raise e from None
ERROR 09-23 16:42:53 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:42:54] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B__global_step_100 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:42:54] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_200
INFO 09-23 16:42:54 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:42:54 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:42:54 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:42:54 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:43:00 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:43:05 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:43:05 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:43:05 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_d649ece9'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/b7c0ea50-90e6-4e1a-8321-b8c671ce5fcf', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:43:10 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:43:10 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:43:10 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:43:10 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:43:15 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f9b85fc4f10>
[1;36m(VllmWorker rank=0 pid=12232)[0;0m INFO 09-23 16:43:15 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_a314d524'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/d63068ed-c1f5-49af-9b03-3148ea04f217', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:43:16 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fd3042d4e80>
[1;36m(VllmWorker rank=1 pid=12233)[0;0m INFO 09-23 16:43:16 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_44f100a9'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/0b91cb24-4670-4258-b71a-41d356469581', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:43:16 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fd805fb8f10>
[1;36m(VllmWorker rank=3 pid=12235)[0;0m INFO 09-23 16:43:16 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_a07bd12a'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/9303165c-ce99-4130-afa7-404aaadf48f7', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:43:16 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f998af08eb0>
[1;36m(VllmWorker rank=2 pid=12234)[0;0m INFO 09-23 16:43:16 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_df9953aa'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/73e4493f-b756-403e-a747-63326e8c6bcd', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=12233)[0;0m INFO 09-23 16:43:52 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=12235)[0;0m INFO 09-23 16:43:52 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=12232)[0;0m INFO 09-23 16:43:52 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=12233)[0;0m INFO 09-23 16:43:52 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=12235)[0;0m INFO 09-23 16:43:52 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=12232)[0;0m INFO 09-23 16:43:52 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=12234)[0;0m INFO 09-23 16:43:52 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=12234)[0;0m INFO 09-23 16:43:52 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=12235)[0;0m [1;36m(VllmWorker rank=0 pid=12232)[0;0m [1;36m(VllmWorker rank=2 pid=12234)[0;0m INFO 09-23 16:43:53 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:43:53 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:43:53 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=1 pid=12233)[0;0m INFO 09-23 16:43:53 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=12232)[0;0m INFO 09-23 16:43:53 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_393b0bf9'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/c61d191a-ce64-4b45-978f-4b56d4c3cb26', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=12235)[0;0m INFO 09-23 16:43:53 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=12234)[0;0m INFO 09-23 16:43:53 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=0 pid=12232)[0;0m INFO 09-23 16:43:53 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=1 pid=12233)[0;0m INFO 09-23 16:43:53 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=3 pid=12235)[0;0m INFO 09-23 16:43:53 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=12232)[0;0m INFO 09-23 16:43:53 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=12234)[0;0m INFO 09-23 16:43:53 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=12233)[0;0m INFO 09-23 16:43:53 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=12232)[0;0m INFO 09-23 16:43:53 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=12235)[0;0m INFO 09-23 16:43:53 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=12234)[0;0m INFO 09-23 16:43:53 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=12233)[0;0m INFO 09-23 16:43:53 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=12234)[0;0m INFO 09-23 16:43:53 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=3 pid=12235)[0;0m INFO 09-23 16:43:53 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=1 pid=12233)[0;0m INFO 09-23 16:43:53 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=0 pid=12232)[0;0m INFO 09-23 16:43:53 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=12234)[0;0m ERROR 09-23 16:43:53 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2170684 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:43:55 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:43:55 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:43:55 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:43:55 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:43:55 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:43:55 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:43:55 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:43:55 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:43:55 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:43:55 [core.py:396]     self._init_executor()
ERROR 09-23 16:43:55 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:43:55 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:43:55 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:43:55 [core.py:396]     raise e from None
ERROR 09-23 16:43:55 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:43:56] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.19_Qwen2.5-math-1.5B__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:43:56] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_100
INFO 09-23 16:43:56 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:43:56 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:43:56 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:43:56 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:44:02 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:44:07 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_100', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_100', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_100, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:44:07 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:44:07 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_6d60ad93'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/48eaff17-fbe2-4349-af20-18abece9099c', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:44:12 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:44:12 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:44:12 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:44:12 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:44:18 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f40ab2390f0>
WARNING 09-23 16:44:18 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f3ed9aeceb0>
[1;36m(VllmWorker rank=0 pid=12483)[0;0m INFO 09-23 16:44:18 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_81fa2b4f'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/56d5c04c-3b90-4f66-beca-d58ed42d84ba', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=12486)[0;0m INFO 09-23 16:44:18 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_3207d3e8'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/505bb8c0-ece4-4b17-a05d-c63f012a4bab', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:44:18 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f6229d78e50>
[1;36m(VllmWorker rank=1 pid=12484)[0;0m INFO 09-23 16:44:18 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_35d11247'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/02a1c59b-9334-444d-b579-171fddb38ced', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:44:18 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f50b8dd8e50>
[1;36m(VllmWorker rank=2 pid=12485)[0;0m INFO 09-23 16:44:18 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_0d1e30fd'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/eab176e0-ebf2-4d35-8bc8-f4d08301d571', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=12483)[0;0m [1;36m(VllmWorker rank=3 pid=12486)[0;0m INFO 09-23 16:44:54 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 16:44:54 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=12486)[0;0m [1;36m(VllmWorker rank=0 pid=12483)[0;0m INFO 09-23 16:44:54 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 16:44:54 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=12485)[0;0m INFO 09-23 16:44:54 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=12485)[0;0m INFO 09-23 16:44:54 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=12484)[0;0m INFO 09-23 16:44:54 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=12484)[0;0m INFO 09-23 16:44:54 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=12484)[0;0m [1;36m(VllmWorker rank=3 pid=12486)[0;0m [1;36m(VllmWorker rank=0 pid=12483)[0;0m [1;36m(VllmWorker rank=2 pid=12485)[0;0m INFO 09-23 16:44:55 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:44:55 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:44:55 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:44:55 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=12483)[0;0m INFO 09-23 16:44:55 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_83ff9cc4'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/bac4a476-45b9-4d02-b810-5fb018ae7652', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=12486)[0;0m INFO 09-23 16:44:55 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=12485)[0;0m INFO 09-23 16:44:55 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=1 pid=12484)[0;0m INFO 09-23 16:44:55 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=0 pid=12483)[0;0m INFO 09-23 16:44:55 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=3 pid=12486)[0;0m INFO 09-23 16:44:55 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=12485)[0;0m INFO 09-23 16:44:55 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=12484)[0;0m INFO 09-23 16:44:55 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=12483)[0;0m INFO 09-23 16:44:55 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=12486)[0;0m INFO 09-23 16:44:55 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=12485)[0;0m INFO 09-23 16:44:55 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=12484)[0;0m INFO 09-23 16:44:55 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=12483)[0;0m INFO 09-23 16:44:55 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=12485)[0;0m INFO 09-23 16:44:55 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=3 pid=12486)[0;0m INFO 09-23 16:44:55 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=1 pid=12484)[0;0m INFO 09-23 16:44:55 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=0 pid=12483)[0;0m INFO 09-23 16:44:55 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_100...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=12485)[0;0m ERROR 09-23 16:44:55 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2171665 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f402b76c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f402b715b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f3fdc28e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f402bae7b78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f402bae820e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39afa (0x7f402bafeafa in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f402baea329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f40238864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f4022fa5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f4022fa64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x55ad87402c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x55ad8738f2a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x55ad8738fbbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x55ad8738fc83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x55ad87402b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x55ad8746ec3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x55ad87471f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x55ad87390c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x55ad874cfc30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x55ad874f5407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x55ad874f5634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x55ad874f5718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x55ad874f575b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x55ad874f5972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x55ad874fbf60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x55ad874fc1ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x55ad874fc469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f402c5e3d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f402c5e3e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x55ad874672d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

ERROR 09-23 16:44:57 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:44:57 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:44:57 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:44:57 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:44:57 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:44:57 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:44:57 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:44:57 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:44:57 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:44:57 [core.py:396]     self._init_executor()
ERROR 09-23 16:44:57 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:44:57 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:44:57 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:44:57 [core.py:396]     raise e from None
ERROR 09-23 16:44:57 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:44:58] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B__global_step_100 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:44:58] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_200
INFO 09-23 16:44:58 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:44:58 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:44:58 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:44:58 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:45:04 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:45:10 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:45:10 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:45:10 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_f0021386'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/b11afabc-5383-48f3-bf04-61b8a62074e7', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:45:16 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:45:16 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:45:16 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:45:16 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:45:22 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f61460e8e20>
WARNING 09-23 16:45:22 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7faa01008d90>
WARNING 09-23 16:45:22 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f23cac38eb0>
[1;36m(VllmWorker rank=0 pid=12734)[0;0m INFO 09-23 16:45:22 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_bf096d18'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/cba0398d-3905-44c6-9746-f0cf249b5335', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=12735)[0;0m INFO 09-23 16:45:22 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_3f96ff66'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/8c7bc075-3a07-4a99-a2c8-e66b4df6d1e8', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=12737)[0;0m INFO 09-23 16:45:22 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_98216d3b'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/d96e1a20-3f54-4021-81ba-04c36ff02a3f', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:45:22 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f3bae5f0df0>
[1;36m(VllmWorker rank=2 pid=12736)[0;0m INFO 09-23 16:45:22 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_f3b8656c'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/8a06be02-75d1-409b-a8b3-68690fed7d1e', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=12734)[0;0m [1;36m(VllmWorker rank=1 pid=12735)[0;0m INFO 09-23 16:45:58 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 16:45:58 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=12734)[0;0m INFO 09-23 16:45:58 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=12735)[0;0m INFO 09-23 16:45:58 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=12736)[0;0m INFO 09-23 16:45:58 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=12737)[0;0m INFO 09-23 16:45:58 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=12736)[0;0m INFO 09-23 16:45:58 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=12737)[0;0m INFO 09-23 16:45:58 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=12737)[0;0m [1;36m(VllmWorker rank=1 pid=12735)[0;0m INFO 09-23 16:45:59 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:45:59 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=12736)[0;0m [1;36m(VllmWorker rank=0 pid=12734)[0;0m INFO 09-23 16:45:59 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:45:59 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=12734)[0;0m INFO 09-23 16:45:59 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_d2f73643'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/bdc157b7-80ab-4189-b657-a7cb2de24c05', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=12737)[0;0m INFO 09-23 16:45:59 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=12736)[0;0m [1;36m(VllmWorker rank=1 pid=12735)[0;0m INFO 09-23 16:45:59 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
INFO 09-23 16:45:59 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=0 pid=12734)[0;0m INFO 09-23 16:45:59 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=3 pid=12737)[0;0m INFO 09-23 16:45:59 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=12736)[0;0m INFO 09-23 16:45:59 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=12735)[0;0m INFO 09-23 16:45:59 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=12734)[0;0m INFO 09-23 16:45:59 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=12737)[0;0m INFO 09-23 16:45:59 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=12736)[0;0m INFO 09-23 16:45:59 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=12735)[0;0m INFO 09-23 16:45:59 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=12734)[0;0m INFO 09-23 16:45:59 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=12736)[0;0m INFO 09-23 16:45:59 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=3 pid=12737)[0;0m INFO 09-23 16:45:59 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=1 pid=12735)[0;0m INFO 09-23 16:45:59 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=0 pid=12734)[0;0m INFO 09-23 16:45:59 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=12736)[0;0m ERROR 09-23 16:45:59 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2172709 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:46:01 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:46:01 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:46:01 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:46:01 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:46:01 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:46:01 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:46:01 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:46:01 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:46:01 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:46:01 [core.py:396]     self._init_executor()
ERROR 09-23 16:46:01 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:46:01 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:46:01 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:46:01 [core.py:396]     raise e from None
ERROR 09-23 16:46:01 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:46:02] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.21_Qwen2.5-math-1.5B__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:46:02] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_200
INFO 09-23 16:46:02 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:46:02 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:46:02 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:46:02 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:46:08 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:46:13 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:46:13 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:46:13 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_cff01f46'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/8e07c9b8-a142-4ab1-93ce-1cbe9780c154', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:46:18 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:46:18 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:46:18 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:46:18 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:46:23 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f2ba7fa8fd0>
[1;36m(VllmWorker rank=3 pid=12988)[0;0m INFO 09-23 16:46:23 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_363dbed5'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/787d2519-d8be-491b-9e7c-fadf2544957d', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:46:24 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fbffce24e50>
[1;36m(VllmWorker rank=2 pid=12987)[0;0m INFO 09-23 16:46:24 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_dc941ad2'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/33253337-e7ca-45f1-8e2d-1289085d930e', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:46:24 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f7f6c09ce50>
[1;36m(VllmWorker rank=0 pid=12985)[0;0m INFO 09-23 16:46:24 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_b134d9fb'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/ab0bc9dc-81cd-4570-b435-6dc28d4d14e9', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:46:24 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f872c8c0d00>
[1;36m(VllmWorker rank=1 pid=12986)[0;0m INFO 09-23 16:46:24 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_88364ed2'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/88c6859c-61d0-4274-9a9e-00ef4f8329fb', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=12987)[0;0m [1;36m(VllmWorker rank=0 pid=12985)[0;0m INFO 09-23 16:46:59 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 16:46:59 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=12988)[0;0m INFO 09-23 16:46:59 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=12985)[0;0m INFO 09-23 16:46:59 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=12987)[0;0m INFO 09-23 16:46:59 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=12988)[0;0m INFO 09-23 16:46:59 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=12986)[0;0m INFO 09-23 16:46:59 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=12986)[0;0m INFO 09-23 16:46:59 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=12988)[0;0m INFO 09-23 16:47:00 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=12987)[0;0m [1;36m(VllmWorker rank=0 pid=12985)[0;0m INFO 09-23 16:47:00 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:47:00 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=1 pid=12986)[0;0m INFO 09-23 16:47:00 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=12985)[0;0m INFO 09-23 16:47:00 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_95254fa0'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/3a309759-36f2-42e0-869f-7806478a2fae', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=12988)[0;0m INFO 09-23 16:47:00 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=12987)[0;0m INFO 09-23 16:47:00 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=1 pid=12986)[0;0m INFO 09-23 16:47:00 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=0 pid=12985)[0;0m INFO 09-23 16:47:00 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=3 pid=12988)[0;0m INFO 09-23 16:47:00 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=12985)[0;0m INFO 09-23 16:47:00 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=12986)[0;0m INFO 09-23 16:47:00 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=12987)[0;0m INFO 09-23 16:47:00 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=12988)[0;0m INFO 09-23 16:47:00 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=12985)[0;0m INFO 09-23 16:47:00 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=12986)[0;0m INFO 09-23 16:47:00 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=12987)[0;0m INFO 09-23 16:47:00 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=12988)[0;0m INFO 09-23 16:47:00 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=1 pid=12986)[0;0m INFO 09-23 16:47:00 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=2 pid=12987)[0;0m INFO 09-23 16:47:00 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=0 pid=12985)[0;0m INFO 09-23 16:47:00 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=12988)[0;0m ERROR 09-23 16:47:01 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 3 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088949 has 37.61 GiB memory in use. Process 2173733 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:47:03 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:47:03 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:47:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:47:03 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:47:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:47:03 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:47:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:47:03 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:47:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:47:03 [core.py:396]     self._init_executor()
ERROR 09-23 16:47:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:47:03 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:47:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:47:03 [core.py:396]     raise e from None
ERROR 09-23 16:47:03 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:47:04] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:47:04] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_313
INFO 09-23 16:47:04 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:47:04 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:47:04 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:47:04 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:47:10 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:47:15 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:47:15 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:47:15 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_8d614b58'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/600f803e-280a-413e-acfa-5488048f6424', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:47:20 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:47:20 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:47:20 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:47:20 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:47:25 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f1bee698d90>
[1;36m(VllmWorker rank=3 pid=13239)[0;0m INFO 09-23 16:47:25 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_b65600bb'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/a27532fe-825b-49be-b468-5c45e432a94b', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:47:25 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f48c5ff9030>
[1;36m(VllmWorker rank=2 pid=13238)[0;0m INFO 09-23 16:47:25 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_94c8299b'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/744b6bce-5941-4042-bf9c-9dd34510a5e9', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:47:26 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f82e72d4e50>
[1;36m(VllmWorker rank=0 pid=13236)[0;0m INFO 09-23 16:47:26 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_32d689b0'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/d197220f-9cf8-4956-8558-21b7a5d78ec6', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:47:26 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f519ae34dc0>
[1;36m(VllmWorker rank=1 pid=13237)[0;0m INFO 09-23 16:47:26 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_b1405102'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/cb445c27-8686-4549-8e8e-b7463ac5faeb', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=13236)[0;0m [1;36m(VllmWorker rank=1 pid=13237)[0;0m INFO 09-23 16:48:01 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 16:48:01 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=13237)[0;0m [1;36m(VllmWorker rank=0 pid=13236)[0;0m INFO 09-23 16:48:01 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 16:48:01 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=13238)[0;0m INFO 09-23 16:48:01 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=13238)[0;0m INFO 09-23 16:48:01 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=13239)[0;0m INFO 09-23 16:48:01 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=13239)[0;0m INFO 09-23 16:48:01 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=13237)[0;0m [1;36m(VllmWorker rank=0 pid=13236)[0;0m [1;36m(VllmWorker rank=3 pid=13239)[0;0m [1;36m(VllmWorker rank=2 pid=13238)[0;0m INFO 09-23 16:48:02 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:48:02 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:48:02 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:48:02 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=13236)[0;0m INFO 09-23 16:48:03 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_0f05b529'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/aeb9474d-4661-40ed-a619-c48ffd40e8c3', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=13239)[0;0m INFO 09-23 16:48:03 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=13238)[0;0m INFO 09-23 16:48:03 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=1 pid=13237)[0;0m [1;36m(VllmWorker rank=0 pid=13236)[0;0m INFO 09-23 16:48:03 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
INFO 09-23 16:48:03 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=2 pid=13238)[0;0m INFO 09-23 16:48:03 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=13236)[0;0m INFO 09-23 16:48:03 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=13237)[0;0m INFO 09-23 16:48:03 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=13239)[0;0m INFO 09-23 16:48:03 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=13238)[0;0m INFO 09-23 16:48:03 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=13236)[0;0m [1;36m(VllmWorker rank=1 pid=13237)[0;0m INFO 09-23 16:48:03 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 09-23 16:48:03 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=13239)[0;0m INFO 09-23 16:48:03 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=13238)[0;0m INFO 09-23 16:48:03 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=3 pid=13239)[0;0m INFO 09-23 16:48:03 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=0 pid=13236)[0;0m INFO 09-23 16:48:03 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=1 pid=13237)[0;0m INFO 09-23 16:48:03 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=13238)[0;0m ERROR 09-23 16:48:03 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2174769 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:48:05 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:48:05 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:48:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:48:05 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:48:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:48:05 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:48:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:48:05 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:48:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:48:05 [core.py:396]     self._init_executor()
ERROR 09-23 16:48:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:48:05 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:48:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:48:05 [core.py:396]     raise e from None
ERROR 09-23 16:48:05 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:48:06] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_200
[2025-09-23 16:48:06] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.25_Qwen2.5-math-1.5B__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
INFO 09-23 16:48:06 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:48:06 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:48:06 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:48:06 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:48:12 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:48:17 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:48:17 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:48:17 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_3bdaa551'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/5d87650d-e2f7-48b7-af86-4c2a299ccf3b', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:48:22 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:48:22 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:48:22 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:48:22 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:48:27 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f4713ee4dc0>
[1;36m(VllmWorker rank=1 pid=13488)[0;0m INFO 09-23 16:48:27 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_4d44d8d9'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/f74d2442-56bf-4a28-8037-a037c58ee8d7', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:48:28 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7efae2208e20>
[1;36m(VllmWorker rank=0 pid=13487)[0;0m INFO 09-23 16:48:28 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_d6a570a4'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/eab2eaf3-a285-401a-8179-98a9b8805dec', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:48:28 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f569e498fd0>
[1;36m(VllmWorker rank=3 pid=13490)[0;0m INFO 09-23 16:48:28 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_e2cba3fe'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/b3157c1c-9fe5-467a-9366-27f2948e536e', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:48:28 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f6c0683cd60>
[1;36m(VllmWorker rank=2 pid=13489)[0;0m INFO 09-23 16:48:28 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_eed4bcdb'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/76e5bfb4-4e1f-44dd-8bae-3b4feaab39be', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=13488)[0;0m INFO 09-23 16:49:04 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=13489)[0;0m INFO 09-23 16:49:04 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=13487)[0;0m INFO 09-23 16:49:04 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=13488)[0;0m INFO 09-23 16:49:04 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=13490)[0;0m INFO 09-23 16:49:04 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=13489)[0;0m INFO 09-23 16:49:04 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=13487)[0;0m INFO 09-23 16:49:04 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=13490)[0;0m INFO 09-23 16:49:04 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=13487)[0;0m [1;36m(VllmWorker rank=1 pid=13488)[0;0m [1;36m(VllmWorker rank=2 pid=13489)[0;0m [1;36m(VllmWorker rank=3 pid=13490)[0;0m INFO 09-23 16:49:05 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:49:05 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:49:05 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:49:05 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=13487)[0;0m INFO 09-23 16:49:05 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_652f2cd4'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/f92bf1e7-d91f-4e4e-a9fb-635459f85543', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=13489)[0;0m INFO 09-23 16:49:05 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=3 pid=13490)[0;0m INFO 09-23 16:49:05 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=1 pid=13488)[0;0m INFO 09-23 16:49:05 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=0 pid=13487)[0;0m INFO 09-23 16:49:05 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=3 pid=13490)[0;0m INFO 09-23 16:49:05 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=13489)[0;0m INFO 09-23 16:49:05 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=13488)[0;0m INFO 09-23 16:49:05 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=13487)[0;0m INFO 09-23 16:49:05 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=13490)[0;0m INFO 09-23 16:49:05 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=13489)[0;0m INFO 09-23 16:49:05 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=13488)[0;0m INFO 09-23 16:49:05 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=13487)[0;0m INFO 09-23 16:49:05 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=13490)[0;0m INFO 09-23 16:49:05 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=2 pid=13489)[0;0m INFO 09-23 16:49:05 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=1 pid=13488)[0;0m INFO 09-23 16:49:05 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=0 pid=13487)[0;0m INFO 09-23 16:49:05 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=1 pid=13488)[0;0m ERROR 09-23 16:49:05 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 1 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088947 has 37.62 GiB memory in use. Process 2175789 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:49:07 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:49:07 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:49:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:49:07 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:49:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:49:07 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:49:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:49:07 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:49:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:49:07 [core.py:396]     self._init_executor()
ERROR 09-23 16:49:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:49:07 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:49:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:49:07 [core.py:396]     raise e from None
ERROR 09-23 16:49:07 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:49:08] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:49:08] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_313
INFO 09-23 16:49:08 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:49:08 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:49:08 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:49:08 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:49:14 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:49:19 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:49:19 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:49:19 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_17486c6b'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/80a67e5a-15cd-4817-b30d-cc48262bcd23', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:49:24 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:49:24 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:49:24 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:49:24 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:49:29 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7facea208f40>
[1;36m(VllmWorker rank=1 pid=13739)[0;0m INFO 09-23 16:49:29 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_5a440f06'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/bbdca650-4dfa-4742-bb1d-bcfcbee9e9d1', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:49:29 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f538e928f40>
[1;36m(VllmWorker rank=3 pid=13741)[0;0m INFO 09-23 16:49:29 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_24645212'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/8ab0faa4-9a81-46c0-86ad-7b8d4d072052', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:49:30 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f11c93c8d90>
[1;36m(VllmWorker rank=2 pid=13740)[0;0m INFO 09-23 16:49:30 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_a33ec6ab'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/af7e3347-5edb-4c91-ae63-2602ea5e606a', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:49:30 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f0943688d90>
[1;36m(VllmWorker rank=0 pid=13738)[0;0m INFO 09-23 16:49:30 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_03fdfefb'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/3325ac3c-9fca-43d1-b135-1b49b4d674d6', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=13741)[0;0m INFO 09-23 16:50:05 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=13740)[0;0m INFO 09-23 16:50:05 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=13739)[0;0m [1;36m(VllmWorker rank=3 pid=13741)[0;0m INFO 09-23 16:50:05 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 16:50:05 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=13738)[0;0m INFO 09-23 16:50:05 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=13740)[0;0m INFO 09-23 16:50:05 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=13739)[0;0m INFO 09-23 16:50:05 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=13738)[0;0m INFO 09-23 16:50:05 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=13741)[0;0m INFO 09-23 16:50:06 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=13738)[0;0m INFO 09-23 16:50:06 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=13740)[0;0m [1;36m(VllmWorker rank=1 pid=13739)[0;0m INFO 09-23 16:50:06 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:50:06 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=13738)[0;0m INFO 09-23 16:50:06 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_3004afe5'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/278a32ff-0461-4e1e-8f61-d9e54f1ec6f1', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=13741)[0;0m INFO 09-23 16:50:06 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=13740)[0;0m INFO 09-23 16:50:06 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=1 pid=13739)[0;0m INFO 09-23 16:50:06 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=0 pid=13738)[0;0m INFO 09-23 16:50:06 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=3 pid=13741)[0;0m INFO 09-23 16:50:06 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=13740)[0;0m INFO 09-23 16:50:06 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=13739)[0;0m [1;36m(VllmWorker rank=0 pid=13738)[0;0m INFO 09-23 16:50:06 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 09-23 16:50:06 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=13741)[0;0m INFO 09-23 16:50:06 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=13740)[0;0m INFO 09-23 16:50:06 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=13738)[0;0m [1;36m(VllmWorker rank=1 pid=13739)[0;0m INFO 09-23 16:50:06 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 09-23 16:50:06 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=13741)[0;0m INFO 09-23 16:50:06 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=2 pid=13740)[0;0m INFO 09-23 16:50:06 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=1 pid=13739)[0;0m INFO 09-23 16:50:06 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=0 pid=13738)[0;0m INFO 09-23 16:50:06 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=13740)[0;0m ERROR 09-23 16:50:07 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2176829 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:50:09 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:50:09 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:50:09 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:50:09 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:50:09 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:50:09 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:50:09 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:50:09 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:50:09 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:50:09 [core.py:396]     self._init_executor()
ERROR 09-23 16:50:09 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:50:09 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:50:09 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:50:09 [core.py:396]     raise e from None
ERROR 09-23 16:50:09 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:50:10] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.30_Qwen2.5-math-1.5B__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:50:10] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_100
INFO 09-23 16:50:10 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:50:10 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:50:10 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:50:10 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:50:15 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:50:20 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_100', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_100', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_100, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:50:20 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:50:20 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_1e694e0e'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/dbb05f48-19ab-442c-b4c2-ccebc706d885', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:50:26 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:50:26 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:50:26 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:50:26 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:50:31 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fc3aa675090>
[1;36m(VllmWorker rank=3 pid=13992)[0;0m INFO 09-23 16:50:31 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_310c619e'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/f9e89292-49a8-4045-93fb-ad7b6c212889', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:50:31 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fb7ece95030>
[1;36m(VllmWorker rank=0 pid=13989)[0;0m INFO 09-23 16:50:31 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_fc9b11bf'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/1c618f3d-fa75-4bec-8209-c1348b88fa81', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:50:31 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f8428c74d60>
[1;36m(VllmWorker rank=2 pid=13991)[0;0m INFO 09-23 16:50:31 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_93718dec'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/196aa5c0-3fea-40f6-bad1-d13a96ddf29b', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:50:31 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f9cb8b28fd0>
[1;36m(VllmWorker rank=1 pid=13990)[0;0m INFO 09-23 16:50:31 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_a1c03bb1'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/4c698fde-e5cb-43de-9d84-dd33b1ba74f3', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=13989)[0;0m [1;36m(VllmWorker rank=2 pid=13991)[0;0m [1;36m(VllmWorker rank=1 pid=13990)[0;0m INFO 09-23 16:51:07 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 16:51:07 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 16:51:07 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=13992)[0;0m INFO 09-23 16:51:07 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=13991)[0;0m [1;36m(VllmWorker rank=0 pid=13989)[0;0m [1;36m(VllmWorker rank=1 pid=13990)[0;0m INFO 09-23 16:51:07 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 16:51:07 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 16:51:07 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=13992)[0;0m INFO 09-23 16:51:07 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=13992)[0;0m [1;36m(VllmWorker rank=0 pid=13989)[0;0m [1;36m(VllmWorker rank=2 pid=13991)[0;0m INFO 09-23 16:51:08 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:51:08 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:51:08 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=1 pid=13990)[0;0m INFO 09-23 16:51:08 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=13989)[0;0m INFO 09-23 16:51:08 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_168ea3ba'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/1affbcf4-2eb7-4288-921c-2e43aa21531e', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=13992)[0;0m INFO 09-23 16:51:08 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=0 pid=13989)[0;0m INFO 09-23 16:51:08 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=3 pid=13992)[0;0m INFO 09-23 16:51:08 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=13989)[0;0m INFO 09-23 16:51:08 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=13991)[0;0m INFO 09-23 16:51:08 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=3 pid=13992)[0;0m INFO 09-23 16:51:08 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=13990)[0;0m INFO 09-23 16:51:08 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=0 pid=13989)[0;0m INFO 09-23 16:51:08 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=13991)[0;0m INFO 09-23 16:51:08 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=13991)[0;0m INFO 09-23 16:51:08 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=13990)[0;0m INFO 09-23 16:51:08 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=13990)[0;0m INFO 09-23 16:51:08 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=13992)[0;0m INFO 09-23 16:51:08 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=2 pid=13991)[0;0m INFO 09-23 16:51:08 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=1 pid=13990)[0;0m INFO 09-23 16:51:08 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=0 pid=13989)[0;0m INFO 09-23 16:51:08 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_100...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=13992)[0;0m ERROR 09-23 16:51:09 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 3 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088949 has 37.61 GiB memory in use. Process 2177786 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:51:11 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:51:11 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:51:11 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:51:11 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:51:11 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:51:11 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:51:11 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:51:11 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:51:11 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:51:11 [core.py:396]     self._init_executor()
ERROR 09-23 16:51:11 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:51:11 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:51:11 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:51:11 [core.py:396]     raise e from None
ERROR 09-23 16:51:11 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:51:12] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B__global_step_100 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:51:12] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_200
INFO 09-23 16:51:12 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:51:12 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:51:12 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:51:12 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:51:17 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:51:22 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:51:22 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:51:22 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_3f478626'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/f4a9a730-d5de-46e1-a037-f496e4f245e7', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:51:28 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:51:28 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:51:28 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:51:28 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:51:33 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fe444decf10>
[1;36m(VllmWorker rank=0 pid=14240)[0;0m INFO 09-23 16:51:33 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_8bf2b039'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/1e12b6a0-905e-486e-9d12-2c61b871acb2', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:51:33 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fe6e3e60eb0>
[1;36m(VllmWorker rank=3 pid=14243)[0;0m INFO 09-23 16:51:33 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_81ac91f4'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/8629a3cd-dcc5-4a41-915e-e39868efffba', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:51:33 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f02bcab8f10>
[1;36m(VllmWorker rank=2 pid=14242)[0;0m INFO 09-23 16:51:33 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_a2023d5c'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/2805ebe8-eaec-4e52-8e93-296ed1fd8760', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:51:34 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f5030125000>
[1;36m(VllmWorker rank=1 pid=14241)[0;0m INFO 09-23 16:51:34 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_e1209c79'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/ba6fb41d-3dfb-4bf0-94b9-db42412d9a5b', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=14242)[0;0m INFO 09-23 16:52:09 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=14240)[0;0m INFO 09-23 16:52:09 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=14243)[0;0m [1;36m(VllmWorker rank=2 pid=14242)[0;0m INFO 09-23 16:52:09 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 16:52:09 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=14241)[0;0m INFO 09-23 16:52:09 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=14240)[0;0m INFO 09-23 16:52:09 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=14243)[0;0m INFO 09-23 16:52:09 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=14241)[0;0m INFO 09-23 16:52:09 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=14240)[0;0m [1;36m(VllmWorker rank=2 pid=14242)[0;0m [1;36m(VllmWorker rank=3 pid=14243)[0;0m [1;36m(VllmWorker rank=1 pid=14241)[0;0m INFO 09-23 16:52:10 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:52:10 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:52:10 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:52:10 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=14240)[0;0m INFO 09-23 16:52:10 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_59ebdcbe'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/b5c00a54-43b2-487d-94c8-f37c4bf2c020', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=14243)[0;0m INFO 09-23 16:52:10 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=14242)[0;0m INFO 09-23 16:52:10 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=1 pid=14241)[0;0m INFO 09-23 16:52:10 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=0 pid=14240)[0;0m INFO 09-23 16:52:10 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=3 pid=14243)[0;0m INFO 09-23 16:52:10 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=14242)[0;0m [1;36m(VllmWorker rank=0 pid=14240)[0;0m INFO 09-23 16:52:10 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 09-23 16:52:10 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=14241)[0;0m INFO 09-23 16:52:10 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=14243)[0;0m INFO 09-23 16:52:10 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=14240)[0;0m INFO 09-23 16:52:10 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=14242)[0;0m INFO 09-23 16:52:10 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=14241)[0;0m INFO 09-23 16:52:10 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=14243)[0;0m INFO 09-23 16:52:10 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=2 pid=14242)[0;0m INFO 09-23 16:52:10 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=1 pid=14241)[0;0m INFO 09-23 16:52:10 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=0 pid=14240)[0;0m INFO 09-23 16:52:10 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=14240)[0;0m ERROR 09-23 16:52:11 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088946 has 37.61 GiB memory in use. Process 2178775 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fe83576c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7fe835715b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7fe7e668e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7fe835b6bb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7fe835b6c20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39afa (0x7fe835b82afa in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7fe835b6e329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7fe82dc864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7fe82d3a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7fe82d3a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x558274fd0c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x558274f5d2a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x558274f5dbbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x558274f5dc83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x558274fd0b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x55827503cc3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x55827503ff1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x558274f5ec98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x55827509dc30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x5582750c3407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x5582750c3634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x5582750c3718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x5582750c375b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x5582750c3972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x5582750c9f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x5582750ca1ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x5582750ca469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7fe836938d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7fe836938e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x5582750352d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

ERROR 09-23 16:52:13 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:52:13 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:52:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:52:13 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:52:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:52:13 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:52:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:52:13 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:52:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:52:13 [core.py:396]     self._init_executor()
ERROR 09-23 16:52:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:52:13 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:52:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:52:13 [core.py:396]     raise e from None
ERROR 09-23 16:52:13 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:52:14] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:52:14] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_313
INFO 09-23 16:52:14 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:52:14 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:52:14 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:52:14 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:52:19 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:52:24 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:52:24 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:52:24 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_c200d2c5'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/7deb5242-03e8-41e8-ae42-1b6b3080fdfe', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:52:30 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:52:30 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:52:30 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:52:30 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:52:35 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fb04199cfa0>
[1;36m(VllmWorker rank=0 pid=14491)[0;0m INFO 09-23 16:52:35 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_ca272a55'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/91deed66-b96f-4835-a1c4-c10fe1a4e897', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:52:35 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fc1b9f60eb0>
[1;36m(VllmWorker rank=1 pid=14492)[0;0m INFO 09-23 16:52:35 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_22237cf3'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/eade2065-e306-4f15-b7dc-85b3c1e9f6b4', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:52:35 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f21b492ce80>
[1;36m(VllmWorker rank=2 pid=14493)[0;0m INFO 09-23 16:52:35 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_b9b1b6cb'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/b85c9f2c-03e7-4050-ba02-944e6c5b2c39', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:52:36 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f770e8e4f40>
[1;36m(VllmWorker rank=3 pid=14494)[0;0m INFO 09-23 16:52:36 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_3f29fb6d'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/bad749de-7cca-480c-9ecf-58c15d503368', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=14492)[0;0m INFO 09-23 16:53:11 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=14494)[0;0m INFO 09-23 16:53:11 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=14491)[0;0m INFO 09-23 16:53:11 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=14492)[0;0m INFO 09-23 16:53:11 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=14493)[0;0m INFO 09-23 16:53:11 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=14491)[0;0m INFO 09-23 16:53:11 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=14494)[0;0m INFO 09-23 16:53:11 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=14493)[0;0m INFO 09-23 16:53:11 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=14492)[0;0m INFO 09-23 16:53:12 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=14493)[0;0m INFO 09-23 16:53:12 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=14491)[0;0m INFO 09-23 16:53:12 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=3 pid=14494)[0;0m INFO 09-23 16:53:12 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=14491)[0;0m INFO 09-23 16:53:12 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_93a8b234'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/447d56c4-0957-472d-a55a-d304898eb489', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=14492)[0;0m INFO 09-23 16:53:12 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=2 pid=14493)[0;0m [1;36m(VllmWorker rank=0 pid=14491)[0;0m [1;36m(VllmWorker rank=3 pid=14494)[0;0m INFO 09-23 16:53:12 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
INFO 09-23 16:53:12 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 09-23 16:53:12 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=1 pid=14492)[0;0m INFO 09-23 16:53:12 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=14493)[0;0m INFO 09-23 16:53:12 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=14491)[0;0m INFO 09-23 16:53:12 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=14493)[0;0m [1;36m(VllmWorker rank=1 pid=14492)[0;0m INFO 09-23 16:53:12 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 09-23 16:53:12 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=14491)[0;0m INFO 09-23 16:53:12 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=14494)[0;0m INFO 09-23 16:53:12 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=14494)[0;0m INFO 09-23 16:53:12 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=14493)[0;0m INFO 09-23 16:53:12 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=1 pid=14492)[0;0m INFO 09-23 16:53:12 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=3 pid=14494)[0;0m INFO 09-23 16:53:12 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=0 pid=14491)[0;0m INFO 09-23 16:53:12 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=14493)[0;0m ERROR 09-23 16:53:13 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2179743 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:53:14 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:53:14 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:53:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:53:14 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:53:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:53:14 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:53:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:53:14 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:53:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:53:14 [core.py:396]     self._init_executor()
ERROR 09-23 16:53:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:53:14 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:53:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:53:14 [core.py:396]     raise e from None
ERROR 09-23 16:53:14 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:53:16] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.19_Qwen2.5-math-1.5B__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')[2025-09-23 16:53:16] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_100

INFO 09-23 16:53:16 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:53:16 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:53:16 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:53:16 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:53:22 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:53:30 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_100', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_100', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_100, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:53:30 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:53:30 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_d0a056c7'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/41b789cf-22dd-4684-9d91-7d44791c1e59', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:53:36 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:53:36 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:53:36 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:53:36 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:53:49 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fe335e10f40>
WARNING 09-23 16:53:49 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f2168874df0>
WARNING 09-23 16:53:49 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f31ca794be0>
WARNING 09-23 16:53:49 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fe06fadcf40>
[1;36m(VllmWorker rank=3 pid=14745)[0;0m INFO 09-23 16:53:49 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_cfa7eb17'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/cd5a115e-eba2-4390-9960-e3745f08a6e3', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=14743)[0;0m INFO 09-23 16:53:49 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_739458c1'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/ee29c6ac-9a07-40cc-aead-9b0c3ed414b1', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=14744)[0;0m INFO 09-23 16:53:49 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_e550e5f3'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/0661e1f0-e4db-4063-bd3e-98e006cc6613', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=14742)[0;0m INFO 09-23 16:53:49 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_205137cd'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/6e80ad5a-c7e4-411c-9492-f6aff705b673', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=14742)[0;0m INFO 09-23 16:54:27 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=14743)[0;0m INFO 09-23 16:54:27 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=14745)[0;0m INFO 09-23 16:54:27 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=14744)[0;0m INFO 09-23 16:54:27 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=14742)[0;0m INFO 09-23 16:54:27 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=14744)[0;0m [1;36m(VllmWorker rank=1 pid=14743)[0;0m [1;36m(VllmWorker rank=3 pid=14745)[0;0m INFO 09-23 16:54:27 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 16:54:27 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 16:54:27 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=14742)[0;0m INFO 09-23 16:54:30 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=14744)[0;0m [1;36m(VllmWorker rank=1 pid=14743)[0;0m INFO 09-23 16:54:30 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:54:30 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=3 pid=14745)[0;0m INFO 09-23 16:54:30 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=14742)[0;0m INFO 09-23 16:54:30 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_a437eab6'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/8726e550-4199-4b47-b88a-c46e0181d555', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=14745)[0;0m INFO 09-23 16:54:30 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=1 pid=14743)[0;0m [1;36m(VllmWorker rank=2 pid=14744)[0;0m [1;36m(VllmWorker rank=0 pid=14742)[0;0m INFO 09-23 16:54:30 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
INFO 09-23 16:54:30 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 09-23 16:54:30 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=0 pid=14742)[0;0m INFO 09-23 16:54:30 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=14745)[0;0m INFO 09-23 16:54:30 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=14744)[0;0m [1;36m(VllmWorker rank=1 pid=14743)[0;0m INFO 09-23 16:54:30 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 09-23 16:54:30 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=14742)[0;0m INFO 09-23 16:54:30 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=14744)[0;0m INFO 09-23 16:54:30 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=14743)[0;0m INFO 09-23 16:54:30 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=14745)[0;0m INFO 09-23 16:54:30 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=14743)[0;0m INFO 09-23 16:54:31 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=2 pid=14744)[0;0m [1;36m(VllmWorker rank=3 pid=14745)[0;0m INFO 09-23 16:54:31 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_100...
INFO 09-23 16:54:31 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_100...
[1;36m(VllmWorker rank=0 pid=14742)[0;0m INFO 09-23 16:54:31 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_100...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=14742)[0;0m ERROR 09-23 16:54:32 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088946 has 37.61 GiB memory in use. Process 2180756 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:54:34 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:54:34 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:54:34 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:54:34 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:54:34 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:54:34 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:54:34 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:54:34 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:54:34 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:54:34 [core.py:396]     self._init_executor()
ERROR 09-23 16:54:34 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:54:34 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:54:34 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:54:34 [core.py:396]     raise e from None
ERROR 09-23 16:54:34 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:54:36] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B__global_step_100 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:54:36] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_200
INFO 09-23 16:54:36 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:54:36 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:54:36 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:54:36 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:54:45 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:54:53 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:54:53 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:54:53 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_997b28aa'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/d82c2925-7220-444d-8a05-29bb2163e2e0', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:54:59 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:54:59 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:54:59 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:54:59 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:55:10 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fe08473cee0>
WARNING 09-23 16:55:10 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f1eb7345030>
WARNING 09-23 16:55:10 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fcd6b000f40>
WARNING 09-23 16:55:10 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f10ec51d000>
[1;36m(VllmWorker rank=1 pid=14994)[0;0m INFO 09-23 16:55:10 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_6df4f11a'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/ef2534f9-3ade-470f-829e-d15c72fd82fc', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=14993)[0;0m INFO 09-23 16:55:10 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_10b11fc1'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/99ea5cfe-5f68-4053-a23e-a3f5819c11f8', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=14995)[0;0m INFO 09-23 16:55:10 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_bde5044d'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/f13fbb19-406d-4c30-84b0-67c389c58104', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=14996)[0;0m INFO 09-23 16:55:10 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_8e629f95'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/e4206e5f-6fc3-4c6e-bfc4-fb3cf5b45a2b', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=14995)[0;0m INFO 09-23 16:55:47 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=14993)[0;0m INFO 09-23 16:55:47 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=14994)[0;0m INFO 09-23 16:55:47 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=14996)[0;0m INFO 09-23 16:55:47 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=14995)[0;0m INFO 09-23 16:55:47 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=14996)[0;0m INFO 09-23 16:55:47 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=14994)[0;0m [1;36m(VllmWorker rank=0 pid=14993)[0;0m INFO 09-23 16:55:47 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 16:55:47 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=14993)[0;0m [1;36m(VllmWorker rank=2 pid=14995)[0;0m [1;36m(VllmWorker rank=1 pid=14994)[0;0m INFO 09-23 16:55:49 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:55:49 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:55:49 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=3 pid=14996)[0;0m INFO 09-23 16:55:49 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=14993)[0;0m INFO 09-23 16:55:50 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_5c4ea861'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/a004354b-fdc6-4513-9435-201a50b38604', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=14996)[0;0m INFO 09-23 16:55:50 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=14995)[0;0m [1;36m(VllmWorker rank=0 pid=14993)[0;0m INFO 09-23 16:55:50 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
INFO 09-23 16:55:50 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=1 pid=14994)[0;0m INFO 09-23 16:55:50 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=0 pid=14993)[0;0m INFO 09-23 16:55:50 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=14995)[0;0m INFO 09-23 16:55:50 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=14994)[0;0m INFO 09-23 16:55:50 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=14996)[0;0m INFO 09-23 16:55:50 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=14993)[0;0m [1;36m(VllmWorker rank=2 pid=14995)[0;0m INFO 09-23 16:55:50 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 09-23 16:55:50 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=14994)[0;0m INFO 09-23 16:55:50 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=14996)[0;0m INFO 09-23 16:55:50 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=14994)[0;0m [1;36m(VllmWorker rank=2 pid=14995)[0;0m INFO 09-23 16:55:50 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_200...
INFO 09-23 16:55:50 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=0 pid=14993)[0;0m [1;36m(VllmWorker rank=3 pid=14996)[0;0m INFO 09-23 16:55:50 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_200...
INFO 09-23 16:55:50 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=14993)[0;0m ERROR 09-23 16:55:51 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088946 has 37.61 GiB memory in use. Process 2182175 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:55:55 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:55:55 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:55:55 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:55:55 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:55:55 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:55:55 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:55:55 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:55:55 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:55:55 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:55:55 [core.py:396]     self._init_executor()
ERROR 09-23 16:55:55 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:55:55 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:55:55 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:55:55 [core.py:396]     raise e from None
ERROR 09-23 16:55:55 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:56:11] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')[2025-09-23 16:56:11] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_313

INFO 09-23 16:56:11 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:56:11 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:56:11 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:56:11 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:56:51 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:56:57 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:56:57 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:56:57 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_812c32fa'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/e61b4bd4-97ec-4be6-839f-09bea186858e', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 16:57:36 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:57:36 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:57:36 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:57:37 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 16:57:42 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f3c5c67cd00>
WARNING 09-23 16:57:42 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f6420f2ce80>
[1;36m(VllmWorker rank=1 pid=15245)[0;0m INFO 09-23 16:57:42 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_c6887629'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/47f37cc9-06a9-44e1-a514-ea3fcc58ca65', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=15244)[0;0m INFO 09-23 16:57:42 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_0d271d9d'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/8dc9a8cc-254b-46dc-8e89-0db8010f2168', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:57:42 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fcfbaf74f40>
[1;36m(VllmWorker rank=2 pid=15246)[0;0m INFO 09-23 16:57:42 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_b51bd4b0'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/71695485-b770-408c-b65c-a15541371376', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 16:57:42 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f686ced0f40>
[1;36m(VllmWorker rank=3 pid=15247)[0;0m INFO 09-23 16:57:42 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_d7006f6f'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/ee1b971d-d1ca-4b5a-9902-b71682054e94', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=15247)[0;0m INFO 09-23 16:58:18 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=15244)[0;0m INFO 09-23 16:58:18 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=15245)[0;0m INFO 09-23 16:58:18 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=15244)[0;0m INFO 09-23 16:58:18 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=15247)[0;0m INFO 09-23 16:58:18 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=15245)[0;0m INFO 09-23 16:58:18 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=15246)[0;0m INFO 09-23 16:58:18 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=15246)[0;0m INFO 09-23 16:58:18 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=15247)[0;0m [1;36m(VllmWorker rank=1 pid=15245)[0;0m INFO 09-23 16:58:20 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 16:58:20 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=15244)[0;0m INFO 09-23 16:58:20 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=15246)[0;0m INFO 09-23 16:58:20 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=15244)[0;0m INFO 09-23 16:58:20 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_d374eed0'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/e842b11d-2486-4221-8a01-11ddbadf2b2d', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=15247)[0;0m [1;36m(VllmWorker rank=2 pid=15246)[0;0m INFO 09-23 16:58:20 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
INFO 09-23 16:58:20 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=1 pid=15245)[0;0m [1;36m(VllmWorker rank=0 pid=15244)[0;0m INFO 09-23 16:58:20 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
INFO 09-23 16:58:20 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=0 pid=15244)[0;0m INFO 09-23 16:58:20 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=15247)[0;0m INFO 09-23 16:58:20 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=15246)[0;0m INFO 09-23 16:58:20 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=15245)[0;0m INFO 09-23 16:58:20 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=15244)[0;0m INFO 09-23 16:58:20 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=15247)[0;0m INFO 09-23 16:58:20 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=15246)[0;0m INFO 09-23 16:58:20 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=15245)[0;0m INFO 09-23 16:58:20 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=15247)[0;0m INFO 09-23 16:58:20 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=1 pid=15245)[0;0m INFO 09-23 16:58:20 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=2 pid=15246)[0;0m INFO 09-23 16:58:20 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=0 pid=15244)[0;0m INFO 09-23 16:58:20 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=1 pid=15245)[0;0m ERROR 09-23 16:58:20 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 1 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088947 has 37.62 GiB memory in use. Process 2183812 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 16:58:22 [core.py:396] EngineCore failed to start.
ERROR 09-23 16:58:22 [core.py:396] Traceback (most recent call last):
ERROR 09-23 16:58:22 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 16:58:22 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 16:58:22 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 16:58:22 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 16:58:22 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 16:58:22 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 16:58:22 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 16:58:22 [core.py:396]     self._init_executor()
ERROR 09-23 16:58:22 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 16:58:22 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 16:58:22 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 16:58:22 [core.py:396]     raise e from None
ERROR 09-23 16:58:22 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 16:58:23] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.11_0.20_Qwen2.5-math-1.5B__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 16:58:23] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_200
INFO 09-23 16:58:23 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 16:58:23 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 16:58:23 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 16:58:23 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 16:59:31 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 16:59:36 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 16:59:36 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 16:59:36 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_541d2829'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/5deaa198-0503-4d4b-abd4-e71f24526d3d', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 17:00:03 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 17:00:03 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 17:00:03 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 17:00:03 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 17:00:10 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fbae6400e80>
[1;36m(VllmWorker rank=0 pid=15495)[0;0m INFO 09-23 17:00:10 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_86b5c594'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/656ea9b3-ece9-4136-abac-2a5d128e70bc', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 17:00:10 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fa1793c0fa0>
WARNING 09-23 17:00:10 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fe8635b8e80>
[1;36m(VllmWorker rank=1 pid=15496)[0;0m INFO 09-23 17:00:10 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_ab8c3456'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/124bd17d-9764-4988-a349-1dd7c4dda85a', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=15497)[0;0m INFO 09-23 17:00:10 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_65bd4b22'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/e9b8d016-ef3c-4995-bdf1-e19c104ca385', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 17:00:10 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f2b78414d90>
[1;36m(VllmWorker rank=3 pid=15498)[0;0m INFO 09-23 17:00:10 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_a99a30b2'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/5dbaf822-a113-4979-b93b-6aacca54d1b2', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=15495)[0;0m INFO 09-23 17:00:46 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=15497)[0;0m INFO 09-23 17:00:46 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=15495)[0;0m INFO 09-23 17:00:46 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=15497)[0;0m INFO 09-23 17:00:46 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=15496)[0;0m INFO 09-23 17:00:46 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=15496)[0;0m [1;36m(VllmWorker rank=3 pid=15498)[0;0m INFO 09-23 17:00:46 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 17:00:46 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=15498)[0;0m INFO 09-23 17:00:46 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=15495)[0;0m [1;36m(VllmWorker rank=3 pid=15498)[0;0m [1;36m(VllmWorker rank=2 pid=15497)[0;0m INFO 09-23 17:00:47 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=1 pid=15496)[0;0m INFO 09-23 17:00:47 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 17:00:47 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 17:00:47 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=15495)[0;0m INFO 09-23 17:00:47 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_001e81a8'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/be988b4c-f15e-4b0f-86d1-ce5e4d362f18', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=15498)[0;0m [1;36m(VllmWorker rank=2 pid=15497)[0;0m INFO 09-23 17:00:47 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
INFO 09-23 17:00:47 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=1 pid=15496)[0;0m [1;36m(VllmWorker rank=0 pid=15495)[0;0m INFO 09-23 17:00:47 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
INFO 09-23 17:00:47 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=3 pid=15498)[0;0m [1;36m(VllmWorker rank=2 pid=15497)[0;0m INFO 09-23 17:00:47 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 09-23 17:00:47 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=15496)[0;0m INFO 09-23 17:00:47 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=15495)[0;0m INFO 09-23 17:00:47 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=15497)[0;0m [1;36m(VllmWorker rank=3 pid=15498)[0;0m INFO 09-23 17:00:47 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 09-23 17:00:47 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=15496)[0;0m INFO 09-23 17:00:47 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=15495)[0;0m INFO 09-23 17:00:47 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=15497)[0;0m [1;36m(VllmWorker rank=1 pid=15496)[0;0m INFO 09-23 17:00:47 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_200...
INFO 09-23 17:00:47 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=3 pid=15498)[0;0m INFO 09-23 17:00:47 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=0 pid=15495)[0;0m INFO 09-23 17:00:47 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=15495)[0;0m ERROR 09-23 17:00:48 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088946 has 37.61 GiB memory in use. Process 2186032 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 17:00:50 [core.py:396] EngineCore failed to start.
ERROR 09-23 17:00:50 [core.py:396] Traceback (most recent call last):
ERROR 09-23 17:00:50 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 17:00:50 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 17:00:50 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 17:00:50 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 17:00:50 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 17:00:50 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 17:00:50 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 17:00:50 [core.py:396]     self._init_executor()
ERROR 09-23 17:00:50 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 17:00:50 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 17:00:50 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 17:00:50 [core.py:396]     raise e from None
ERROR 09-23 17:00:50 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 17:00:51] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')[2025-09-23 17:00:51] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_313

INFO 09-23 17:00:51 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 17:00:51 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 17:00:51 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 17:00:51 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 17:01:05 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 17:01:14 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 17:01:14 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 17:01:14 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_0ba389c1'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/a23a7efa-a7cb-428e-9f20-231145cb4635', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 17:01:21 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 17:01:21 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 17:01:21 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 17:01:21 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 17:01:27 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f2114da8df0>
WARNING 09-23 17:01:27 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f4d5c221030>
[1;36m(VllmWorker rank=2 pid=15748)[0;0m INFO 09-23 17:01:27 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_8f72bd68'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/dba79dc1-2b6a-4960-8aa5-969227e084b4', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=15746)[0;0m INFO 09-23 17:01:27 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_322da818'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/5ab50a21-8ea8-43bf-b8f6-89c99b41c1ba', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 17:01:27 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f266720cee0>
[1;36m(VllmWorker rank=1 pid=15747)[0;0m INFO 09-23 17:01:27 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_fd758734'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/e0410911-da9d-4bdc-a419-664f94af4f12', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 17:01:27 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f57ded48f70>
[1;36m(VllmWorker rank=3 pid=15749)[0;0m INFO 09-23 17:01:27 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_58395701'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/fa23795e-d94a-4fae-98f2-85e687e2198c', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=15749)[0;0m [1;36m(VllmWorker rank=2 pid=15748)[0;0m INFO 09-23 17:02:03 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 17:02:03 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=15748)[0;0m INFO 09-23 17:02:03 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=15746)[0;0m [1;36m(VllmWorker rank=3 pid=15749)[0;0m INFO 09-23 17:02:03 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 17:02:03 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=15746)[0;0m INFO 09-23 17:02:03 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=15747)[0;0m INFO 09-23 17:02:03 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=15747)[0;0m INFO 09-23 17:02:03 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=15746)[0;0m INFO 09-23 17:02:04 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=1 pid=15747)[0;0m INFO 09-23 17:02:04 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=3 pid=15749)[0;0m INFO 09-23 17:02:04 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=15748)[0;0m INFO 09-23 17:02:04 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=15746)[0;0m INFO 09-23 17:02:04 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_7ebe0104'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/5601480b-baaa-4d6a-9db0-88139242f2c3', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=15748)[0;0m [1;36m(VllmWorker rank=1 pid=15747)[0;0m INFO 09-23 17:02:04 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
INFO 09-23 17:02:04 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=3 pid=15749)[0;0m INFO 09-23 17:02:04 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=1 pid=15747)[0;0m INFO 09-23 17:02:04 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=15746)[0;0m INFO 09-23 17:02:04 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=2 pid=15748)[0;0m INFO 09-23 17:02:04 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=15747)[0;0m INFO 09-23 17:02:04 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=15746)[0;0m INFO 09-23 17:02:04 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=15749)[0;0m INFO 09-23 17:02:04 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=15748)[0;0m INFO 09-23 17:02:04 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=15746)[0;0m INFO 09-23 17:02:04 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=15749)[0;0m INFO 09-23 17:02:04 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=15747)[0;0m INFO 09-23 17:02:04 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=2 pid=15748)[0;0m INFO 09-23 17:02:04 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=3 pid=15749)[0;0m INFO 09-23 17:02:04 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=0 pid=15746)[0;0m INFO 09-23 17:02:04 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=15746)[0;0m ERROR 09-23 17:02:05 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088946 has 37.61 GiB memory in use. Process 2187827 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 17:02:06 [core.py:396] EngineCore failed to start.
ERROR 09-23 17:02:06 [core.py:396] Traceback (most recent call last):
ERROR 09-23 17:02:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 17:02:06 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 17:02:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 17:02:06 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 17:02:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 17:02:06 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 17:02:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 17:02:06 [core.py:396]     self._init_executor()
ERROR 09-23 17:02:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 17:02:06 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 17:02:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 17:02:06 [core.py:396]     raise e from None
ERROR 09-23 17:02:06 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 17:02:08] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.15_0.20_Qwen2.5-math-1.5B__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 17:02:08] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_200
INFO 09-23 17:02:08 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 17:02:08 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 17:02:08 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 17:02:08 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 17:02:16 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 17:02:28 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 17:02:28 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 17:02:28 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_8c543003'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/2b46eebe-d845-442b-9f94-07f08da394bc', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 17:02:34 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 17:02:34 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 17:02:34 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 17:02:34 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 17:02:41 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f1480f54e20>
[1;36m(VllmWorker rank=0 pid=15997)[0;0m INFO 09-23 17:02:41 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_74b54b39'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/300cd60d-b676-40f9-9656-98f656b2ffc5', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 17:02:41 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f0f005c5000>
[1;36m(VllmWorker rank=1 pid=15998)[0;0m INFO 09-23 17:02:41 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_e9c0cedc'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/3d8d5bc0-9db5-4e35-bc07-6cc20285ff61', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 17:02:41 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fbf1f448f10>
[1;36m(VllmWorker rank=2 pid=15999)[0;0m INFO 09-23 17:02:41 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_6c311e21'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/a0109f20-2dee-474b-a0fe-03e22086a0c9', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 09-23 17:02:41 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fda085d8d00>
[1;36m(VllmWorker rank=3 pid=16000)[0;0m INFO 09-23 17:02:41 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_ba67e996'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/01bdcbee-03d0-480a-b4e9-badf891585ba', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=15997)[0;0m [1;36m(VllmWorker rank=2 pid=15999)[0;0m INFO 09-23 17:03:17 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 17:03:17 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=15998)[0;0m INFO 09-23 17:03:17 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=16000)[0;0m INFO 09-23 17:03:17 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=15999)[0;0m [1;36m(VllmWorker rank=0 pid=15997)[0;0m INFO 09-23 17:03:17 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 17:03:17 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=15998)[0;0m INFO 09-23 17:03:17 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=16000)[0;0m INFO 09-23 17:03:17 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=15999)[0;0m [1;36m(VllmWorker rank=0 pid=15997)[0;0m [1;36m(VllmWorker rank=1 pid=15998)[0;0m [1;36m(VllmWorker rank=3 pid=16000)[0;0m INFO 09-23 17:03:18 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 17:03:18 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 17:03:18 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 17:03:18 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=15997)[0;0m INFO 09-23 17:03:18 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_ae4bb013'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/67b885e2-7837-41c0-b276-dd41cbf06db2', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=16000)[0;0m INFO 09-23 17:03:18 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=15999)[0;0m INFO 09-23 17:03:18 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=1 pid=15998)[0;0m INFO 09-23 17:03:18 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=0 pid=15997)[0;0m INFO 09-23 17:03:18 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=2 pid=15999)[0;0m INFO 09-23 17:03:18 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=15997)[0;0m [1;36m(VllmWorker rank=1 pid=15998)[0;0m [1;36m(VllmWorker rank=3 pid=16000)[0;0m INFO 09-23 17:03:18 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 09-23 17:03:18 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 09-23 17:03:18 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=15999)[0;0m INFO 09-23 17:03:18 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=15998)[0;0m INFO 09-23 17:03:18 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=15997)[0;0m INFO 09-23 17:03:18 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=16000)[0;0m INFO 09-23 17:03:18 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=15999)[0;0m INFO 09-23 17:03:18 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=1 pid=15998)[0;0m [1;36m(VllmWorker rank=0 pid=15997)[0;0m INFO 09-23 17:03:18 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_200...
INFO 09-23 17:03:18 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_200...
[1;36m(VllmWorker rank=3 pid=16000)[0;0m INFO 09-23 17:03:18 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=15999)[0;0m ERROR 09-23 17:03:18 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2188865 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fdb5616c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7fdb56115b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7fdb06c8e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7fdb565adb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7fdb565ae20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39afa (0x7fdb565c4afa in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7fdb565b0329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7fdb4e2864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7fdb4d9a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7fdb4d9a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x55fd32d2bc04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x55fd32cb82a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x55fd32cb8bbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x55fd32cb8c83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x55fd32d2bb85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x55fd32d97c3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x55fd32d9af1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x55fd32cb9c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x55fd32df8c30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x55fd32e1e407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x55fd32e1e634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x55fd32e1e718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x55fd32e1e75b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x55fd32e1e972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x55fd32e24f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x55fd32e251ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x55fd32e25469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7fdb570a9d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7fdb570a9e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x55fd32d902d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

ERROR 09-23 17:03:20 [core.py:396] EngineCore failed to start.
ERROR 09-23 17:03:20 [core.py:396] Traceback (most recent call last):
ERROR 09-23 17:03:20 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 17:03:20 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 17:03:20 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 17:03:20 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 17:03:20 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 17:03:20 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 17:03:20 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 17:03:20 [core.py:396]     self._init_executor()
ERROR 09-23 17:03:20 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 17:03:20 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 17:03:20 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 17:03:20 [core.py:396]     raise e from None
ERROR 09-23 17:03:20 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 17:03:21] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-09-23 17:03:21] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_313
INFO 09-23 17:03:21 [config.py:717] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 09-23 17:03:21 [config.py:1770] Defaulting to use mp for distributed inference
INFO 09-23 17:03:21 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 09-23 17:03:21 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 09-23 17:03:32 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 17:03:39 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 09-23 17:03:39 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 09-23 17:03:39 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_01d27181'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/13ebc7f3-0256-46c4-aa40-64d0566b52f5', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-23 17:03:47 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 17:03:47 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 17:03:47 [__init__.py:239] Automatically detected platform cuda.
INFO 09-23 17:03:47 [__init__.py:239] Automatically detected platform cuda.
WARNING 09-23 17:03:55 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f056c484dc0>
WARNING 09-23 17:03:55 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f1781c80ee0>
WARNING 09-23 17:03:55 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fcd3d768f10>
WARNING 09-23 17:03:55 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f1b040a10f0>
[1;36m(VllmWorker rank=1 pid=16249)[0;0m INFO 09-23 17:03:55 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_bd79ed00'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/e8005734-5167-4db7-b6ce-68c3025cba8a', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=16248)[0;0m INFO 09-23 17:03:55 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_f4260cc5'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/6760d1ad-585c-490c-ae2e-274f80a7a7e6', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=16250)[0;0m INFO 09-23 17:03:55 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_52e84694'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/de042ec5-3a41-48e9-8821-200f070b06b7', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=16251)[0;0m INFO 09-23 17:03:55 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_8dd670c7'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/4b525f79-1c5b-4379-8c5c-54005096d23a', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=16250)[0;0m [1;36m(VllmWorker rank=1 pid=16249)[0;0m INFO 09-23 17:04:31 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 09-23 17:04:31 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=16251)[0;0m INFO 09-23 17:04:31 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=16250)[0;0m [1;36m(VllmWorker rank=1 pid=16249)[0;0m INFO 09-23 17:04:31 [pynccl.py:69] vLLM is using nccl==2.21.5
INFO 09-23 17:04:31 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=16251)[0;0m INFO 09-23 17:04:31 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=16248)[0;0m INFO 09-23 17:04:31 [utils.py:1055] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=16248)[0;0m INFO 09-23 17:04:31 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=16249)[0;0m [1;36m(VllmWorker rank=2 pid=16250)[0;0m [1;36m(VllmWorker rank=0 pid=16248)[0;0m INFO 09-23 17:04:33 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=3 pid=16251)[0;0m INFO 09-23 17:04:33 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 17:04:33 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
INFO 09-23 17:04:33 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /uge_mnt/home/caixq/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=16248)[0;0m INFO 09-23 17:04:33 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_4f113ff1'), local_subscribe_addr='ipc:///tmp/17611923.1.g3n/539e47bf-91b5-41da-80d0-37e76c75bd94', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=16251)[0;0m INFO 09-23 17:04:33 [parallel_state.py:1004] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=2 pid=16250)[0;0m [1;36m(VllmWorker rank=0 pid=16248)[0;0m INFO 09-23 17:04:33 [parallel_state.py:1004] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
INFO 09-23 17:04:33 [parallel_state.py:1004] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=1 pid=16249)[0;0m INFO 09-23 17:04:33 [parallel_state.py:1004] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=2 pid=16250)[0;0m INFO 09-23 17:04:33 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=16251)[0;0m INFO 09-23 17:04:33 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=16248)[0;0m INFO 09-23 17:04:33 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=16249)[0;0m INFO 09-23 17:04:33 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=16250)[0;0m INFO 09-23 17:04:33 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=16249)[0;0m INFO 09-23 17:04:33 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=3 pid=16251)[0;0m INFO 09-23 17:04:33 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=16248)[0;0m INFO 09-23 17:04:33 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker rank=2 pid=16250)[0;0m INFO 09-23 17:04:33 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=3 pid=16251)[0;0m INFO 09-23 17:04:33 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=1 pid=16249)[0;0m INFO 09-23 17:04:33 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_313...
[1;36m(VllmWorker rank=0 pid=16248)[0;0m INFO 09-23 17:04:33 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
[1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=2 pid=16250)[0;0m [1;36m(VllmWorker rank=1 pid=16249)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435] WorkerProc failed to start.
ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=1 pid=16249)[0;0m [1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435] Traceback (most recent call last):
ERROR 09-23 17:04:34 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=1 pid=16249)[0;0m [1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=1 pid=16249)[0;0m [1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=1 pid=16249)[0;0m [1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=1 pid=16249)[0;0m [1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.worker.load_model()
ERROR 09-23 17:04:34 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=1 pid=16249)[0;0m [1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=1 pid=16249)[0;0m [1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.model_runner.load_model()
ERROR 09-23 17:04:34 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=1 pid=16249)[0;0m [1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=1 pid=16249)[0;0m [1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 09-23 17:04:34 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=1 pid=16249)[0;0m [1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=1 pid=16249)[0;0m [1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=1 pid=16249)[0;0m [1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=1 pid=16249)[0;0m [1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=1 pid=16249)[0;0m [1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=1 pid=16249)[0;0m [1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 09-23 17:04:34 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=1 pid=16249)[0;0m [1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=1 pid=16249)[0;0m [1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=1 pid=16249)[0;0m [1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=1 pid=16249)[0;0m [1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 09-23 17:04:34 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=1 pid=16249)[0;0m [1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=1 pid=16249)[0;0m [1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 09-23 17:04:34 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=1 pid=16249)[0;0m [1;36m(VllmWorker rank=2 pid=16250)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 09-23 17:04:34 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088948 has 37.62 GiB memory in use. Process 2189944 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(VllmWorker rank=1 pid=16249)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=1 pid=16249)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=1 pid=16249)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=1 pid=16249)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=1 pid=16249)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=1 pid=16249)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=1 pid=16249)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=1 pid=16249)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=1 pid=16249)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=1 pid=16249)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=1 pid=16249)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=1 pid=16249)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=1 pid=16249)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=1 pid=16249)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=1 pid=16249)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=1 pid=16249)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=1 pid=16249)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=1 pid=16249)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 1 has a total capacity of 39.39 GiB of which 6.56 MiB is free. Process 2088947 has 37.62 GiB memory in use. Process 2189943 has 1.76 GiB memory in use. Of the allocated memory 352.35 MiB is allocated by PyTorch, with 13.35 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=3 pid=16251)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 3 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088949 has 37.61 GiB memory in use. Process 2189945 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435] WorkerProc failed to start.
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435] Traceback (most recent call last):
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 409, in worker_main
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 306, in __init__
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.worker.load_model()
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.model_runner.load_model()
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.model = get_model(vllm_config=self.vllm_config)
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     return loader.load_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     model = _initialize_model(vllm_config=vllm_config)
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 436, in __init__
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.model = Qwen2Model(vllm_config=vllm_config,
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 305, in __init__
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     [PPMissingLayer() for _ in range(start_layer)] + [
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 307, in <lambda>
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     lambda prefix: decoder_layer_type(config=config,
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 217, in __init__
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.mlp = Qwen2MLP(
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 74, in __init__
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 544, in __init__
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     super().__init__(input_size=input_size,
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     self.quant_method.create_weights(
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435]     return func(*args, **kwargs)
[1;36m(VllmWorker rank=0 pid=16248)[0;0m ERROR 09-23 17:04:34 [multiproc_executor.py:435] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.56 MiB is free. Process 2088946 has 37.61 GiB memory in use. Process 2189942 has 1.76 GiB memory in use. Of the allocated memory 496.35 MiB is allocated by PyTorch, with 13.28 MiB allocated in private pools (e.g., CUDA Graphs), and 13.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 09-23 17:04:36 [core.py:396] EngineCore failed to start.
ERROR 09-23 17:04:36 [core.py:396] Traceback (most recent call last):
ERROR 09-23 17:04:36 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 09-23 17:04:36 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 09-23 17:04:36 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 09-23 17:04:36 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 09-23 17:04:36 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 09-23 17:04:36 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 09-23 17:04:36 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 09-23 17:04:36 [core.py:396]     self._init_executor()
ERROR 09-23 17:04:36 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
ERROR 09-23 17:04:36 [core.py:396]     self.workers = WorkerProc.wait_for_ready(unready_workers)
ERROR 09-23 17:04:36 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
ERROR 09-23 17:04:36 [core.py:396]     raise e from None
ERROR 09-23 17:04:36 [core.py:396] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 91, in _init_executor
    self.workers = WorkerProc.wait_for_ready(unready_workers)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 370, in wait_for_ready
    raise e from None
Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/executor/multiproc_executor.py", line 228, in shutdown
    for w in self.workers:
AttributeError: 'MultiprocExecutor' object has no attribute 'workers'
[2025-09-23 17:04:38] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.20_0.20_Qwen2.5-math-1.5B__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
