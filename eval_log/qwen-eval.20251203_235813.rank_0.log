INFO 12-04 00:00:13 [__init__.py:239] Automatically detected platform cuda.
[2025-12-04 00:01:19] ÂèëÁé∞ 7 ‰∏™ run„ÄÇ
[2025-12-04 00:01:19] ‚è≠ Ë∑≥Ëøá base-onlyÔºöLlama-3.2-3B-Instruct
[2025-12-04 00:01:19] ‚è≠ Ë∑≥ËøáÔºöA_rb_oracle_grpo_Llama-3.2-3B-Instruct__global_step_100
[2025-12-04 00:01:19] ‚è≠ Ë∑≥ËøáÔºöA_rb_oracle_grpo_Llama-3.2-3B-Instruct__global_step_200
[2025-12-04 00:01:19] ‚è≠ Ë∑≥ËøáÔºöA_rb_oracle_grpo_Llama-3.2-3B-Instruct__global_step_300
[2025-12-04 00:01:19] ‚è≠ Ë∑≥ËøáÔºöA_rb_oracle_grpo_Llama-3.2-3B-Instruct__global_step_313
[2025-12-04 00:01:19] ‚è≠ Ë∑≥ËøáÔºöB_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100
[2025-12-04 00:01:19] ‚è≠ Ë∑≥ËøáÔºöB_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200
[2025-12-04 00:01:19] ‚è≠ Ë∑≥ËøáÔºöB_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300
[2025-12-04 00:01:19] ‚è≠ Ë∑≥ËøáÔºöB_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_313
[2025-12-04 00:01:19] ‚è≠ Ë∑≥ËøáÔºöB_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100
[2025-12-04 00:01:19] ‚è≠ Ë∑≥ËøáÔºöB_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200
INFO 12-04 00:01:25 [__init__.py:239] Automatically detected platform cuda.
[2025-12-04 00:01:33] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_300
INFO 12-04 00:01:56 [config.py:717] This model supports multiple tasks: {'classify', 'score', 'generate', 'reward', 'embed'}. Defaulting to 'generate'.
INFO 12-04 00:01:56 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-04 00:01:56 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-04 00:02:06 [__init__.py:239] Automatically detected platform cuda.
INFO 12-04 00:02:12 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_300', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_300', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_300, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-04 00:02:18 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f123b7a24a0>
INFO 12-04 00:02:55 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-04 00:02:55 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-04 00:02:55 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-04 00:02:56 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_300...
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.74s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.06s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.17s/it]

INFO 12-04 00:02:58 [loader.py:458] Loading weights took 2.37 seconds
INFO 12-04 00:02:58 [gpu_model_runner.py:1347] Model loading took 6.0160 GiB and 2.534214 seconds
INFO 12-04 00:02:59 [kv_cache_utils.py:634] GPU KV cache size: 239,808 tokens
INFO 12-04 00:02:59 [kv_cache_utils.py:637] Maximum concurrency for 131,072 tokens per request: 1.83x
INFO 12-04 00:02:59 [core.py:159] init engine (profile, create kv cache, warmup model) took 0.72 seconds
INFO 12-04 00:02:59 [core_client.py:439] Core engine process 0 ready.
[2025-12-04 00:02:59] ‚ÑπÔ∏è  ÂΩìÂâçÂ∑•‰ΩúËäÇÁÇπÂàÜÁâá: 0/8
[2025-12-04 00:02:59] ‚úì Ê®°ÂûãÂ∞±Áª™ÔºåÂºÄÂßãËØÑÊµã B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300ÔºàÂÖ±‰∫´Âêå‰∏Ä LLMÔºå‰ªÖË°•Áº∫Êï∞ÊçÆÈõÜÔºâ
[2025-12-04 00:02:59] ‚ñ∂ B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g1  ÂæÖËØÑÊµã=['aime25x8', 'amc23x8', 'aime24x8']  T=0.6  n=8
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g1:   0%|          | 0/3 [00:00<?, ?ds/s][Info] Sharding enabled: Process 0/8 handling range [0:30]
==================================================
data: aime25x8  ,remain samples: 30
{'idx': 0, 'problem': 'Find the sum of all integer bases $b>9$ for which $17_{b}$ is a divisor of $97_{b}$.', 'answer': '70'}

  0%|          | 0/30 [00:00<?, ?it/s][ALet's think step by step and enclose the reasoning process within <think> and </think> tags.
The final result in the answer MUST BE within \boxed{}.

Find the sum of all integer bases $b>9$ for which $17_{b}$ is a divisor of $97_{b}$.

100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 336.30it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/240 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 1/240 [00:04<16:50,  4.23s/it, est. speed input: 36.89 toks/s, output: 47.30 toks/s][A
Processed prompts:   1%|          | 2/240 [00:05<09:19,  2.35s/it, est. speed input: 48.09 toks/s, output: 84.58 toks/s][A
Processed prompts:   1%|‚ñè         | 3/240 [00:05<06:07,  1.55s/it, est. speed input: 59.87 toks/s, output: 122.13 toks/s][A
Processed prompts:   2%|‚ñè         | 4/240 [00:06<04:42,  1.20s/it, est. speed input: 77.74 toks/s, output: 155.94 toks/s][A
Processed prompts:   2%|‚ñè         | 5/240 [00:06<03:14,  1.21it/s, est. speed input: 88.65 toks/s, output: 197.78 toks/s][A
Processed prompts:   2%|‚ñé         | 6/240 [00:07<02:38,  1.48it/s, est. speed input: 106.19 toks/s, output: 232.74 toks/s][A
Processed prompts:   3%|‚ñé         | 8/240 [00:07<01:26,  2.68it/s, est. speed input: 133.61 toks/s, output: 319.49 toks/s][A
Processed prompts:   4%|‚ñç         | 9/240 [00:07<01:41,  2.27it/s, est. speed input: 142.66 toks/s, output: 338.32 toks/s][A
Processed prompts:   5%|‚ñç         | 11/240 [00:08<01:10,  3.25it/s, est. speed input: 162.79 toks/s, output: 415.63 toks/s][A
Processed prompts:   5%|‚ñå         | 13/240 [00:08<00:55,  4.05it/s, est. speed input: 185.84 toks/s, output: 488.66 toks/s][A
Processed prompts:   6%|‚ñå         | 14/240 [00:08<00:52,  4.33it/s, est. speed input: 193.43 toks/s, output: 522.99 toks/s][A
Processed prompts:   6%|‚ñã         | 15/240 [00:08<00:49,  4.58it/s, est. speed input: 197.99 toks/s, output: 556.50 toks/s][A
Processed prompts:   7%|‚ñã         | 16/240 [00:08<00:45,  4.98it/s, est. speed input: 201.99 toks/s, output: 591.44 toks/s][A
Processed prompts:   8%|‚ñä         | 18/240 [00:09<00:55,  3.99it/s, est. speed input: 216.63 toks/s, output: 636.86 toks/s][A
Processed prompts:   8%|‚ñä         | 19/240 [00:09<00:55,  3.99it/s, est. speed input: 232.90 toks/s, output: 664.31 toks/s][A
Processed prompts:   8%|‚ñä         | 20/240 [00:10<01:03,  3.47it/s, est. speed input: 239.24 toks/s, output: 681.74 toks/s][A
Processed prompts:   9%|‚ñâ         | 21/240 [00:10<00:53,  4.07it/s, est. speed input: 245.73 toks/s, output: 716.88 toks/s][A
Processed prompts:  10%|‚ñà         | 25/240 [00:10<00:25,  8.51it/s, est. speed input: 286.80 toks/s, output: 881.22 toks/s][A
Processed prompts:  11%|‚ñà‚ñè        | 27/240 [00:10<00:23,  8.91it/s, est. speed input: 320.21 toks/s, output: 951.60 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 29/240 [00:10<00:28,  7.43it/s, est. speed input: 329.96 toks/s, output: 1004.98 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 31/240 [00:11<00:23,  8.85it/s, est. speed input: 351.88 toks/s, output: 1080.27 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 33/240 [00:11<00:24,  8.58it/s, est. speed input: 364.04 toks/s, output: 1142.26 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 36/240 [00:11<00:18, 11.06it/s, est. speed input: 397.08 toks/s, output: 1256.10 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 38/240 [00:11<00:20, 10.04it/s, est. speed input: 407.98 toks/s, output: 1315.19 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 40/240 [00:12<00:24,  8.28it/s, est. speed input: 427.53 toks/s, output: 1362.95 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 42/240 [00:12<00:22,  8.97it/s, est. speed input: 447.09 toks/s, output: 1429.28 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 44/240 [00:12<00:20,  9.56it/s, est. speed input: 469.59 toks/s, output: 1494.80 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 46/240 [00:12<00:20,  9.67it/s, est. speed input: 478.01 toks/s, output: 1556.50 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 48/240 [00:13<00:24,  7.79it/s, est. speed input: 486.00 toks/s, output: 1596.34 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 49/240 [00:13<00:24,  7.82it/s, est. speed input: 493.37 toks/s, output: 1623.97 toks/s][A
Processed prompts:  21%|‚ñà‚ñà‚ñè       | 51/240 [00:13<00:19,  9.81it/s, est. speed input: 506.76 toks/s, output: 1697.17 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñé       | 54/240 [00:13<00:23,  7.97it/s, est. speed input: 535.06 toks/s, output: 1763.88 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 56/240 [00:13<00:21,  8.45it/s, est. speed input: 558.47 toks/s, output: 1823.52 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 58/240 [00:14<00:21,  8.32it/s, est. speed input: 576.81 toks/s, output: 1876.00 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñç       | 59/240 [00:14<00:24,  7.47it/s, est. speed input: 578.78 toks/s, output: 1892.53 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 62/240 [00:14<00:16, 10.54it/s, est. speed input: 601.01 toks/s, output: 2003.40 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 64/240 [00:14<00:17, 10.02it/s, est. speed input: 616.76 toks/s, output: 2057.90 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 66/240 [00:14<00:16, 10.40it/s, est. speed input: 632.54 toks/s, output: 2118.55 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 68/240 [00:15<00:28,  6.12it/s, est. speed input: 620.07 toks/s, output: 2114.36 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 69/240 [00:15<00:28,  6.04it/s, est. speed input: 617.27 toks/s, output: 2133.18 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 70/240 [00:15<00:25,  6.55it/s, est. speed input: 629.58 toks/s, output: 2161.94 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 71/240 [00:16<00:37,  4.54it/s, est. speed input: 620.24 toks/s, output: 2143.47 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 73/240 [00:16<00:27,  6.08it/s, est. speed input: 627.00 toks/s, output: 2207.80 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà‚ñè      | 75/240 [00:16<00:21,  7.53it/s, est. speed input: 641.16 toks/s, output: 2271.64 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 77/240 [00:16<00:21,  7.66it/s, est. speed input: 654.04 toks/s, output: 2321.97 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñé      | 78/240 [00:17<00:25,  6.30it/s, est. speed input: 647.32 toks/s, output: 2326.84 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 79/240 [00:17<00:28,  5.60it/s, est. speed input: 651.46 toks/s, output: 2335.43 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 80/240 [00:17<00:34,  4.68it/s, est. speed input: 645.83 toks/s, output: 2334.39 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 81/240 [00:17<00:36,  4.36it/s, est. speed input: 647.79 toks/s, output: 2340.63 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 82/240 [00:18<00:50,  3.10it/s, est. speed input: 641.30 toks/s, output: 2309.28 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 84/240 [00:18<00:41,  3.76it/s, est. speed input: 655.50 toks/s, output: 2345.79 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñã      | 87/240 [00:19<00:26,  5.86it/s, est. speed input: 677.15 toks/s, output: 2445.81 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 88/240 [00:19<00:32,  4.67it/s, est. speed input: 670.07 toks/s, output: 2436.97 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 90/240 [00:19<00:26,  5.71it/s, est. speed input: 676.23 toks/s, output: 2495.11 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 91/240 [00:19<00:26,  5.53it/s, est. speed input: 675.57 toks/s, output: 2511.48 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 92/240 [00:20<00:24,  6.13it/s, est. speed input: 678.43 toks/s, output: 2540.46 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 93/240 [00:20<00:21,  6.74it/s, est. speed input: 679.33 toks/s, output: 2569.48 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 94/240 [00:20<00:24,  5.93it/s, est. speed input: 677.28 toks/s, output: 2582.45 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 95/240 [00:20<00:30,  4.73it/s, est. speed input: 672.70 toks/s, output: 2583.06 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 96/240 [00:21<00:33,  4.34it/s, est. speed input: 671.94 toks/s, output: 2590.41 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 98/240 [00:21<00:24,  5.76it/s, est. speed input: 674.89 toks/s, output: 2648.53 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 99/240 [00:21<00:32,  4.36it/s, est. speed input: 675.07 toks/s, output: 2640.33 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 102/240 [00:21<00:19,  6.99it/s, est. speed input: 692.79 toks/s, output: 2742.88 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 104/240 [00:21<00:15,  8.55it/s, est. speed input: 700.54 toks/s, output: 2810.08 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 106/240 [00:22<00:16,  8.00it/s, est. speed input: 699.55 toks/s, output: 2856.87 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 107/240 [00:22<00:25,  5.15it/s, est. speed input: 695.45 toks/s, output: 2835.36 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 108/240 [00:23<00:28,  4.62it/s, est. speed input: 690.82 toks/s, output: 2839.75 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 110/240 [00:23<00:22,  5.90it/s, est. speed input: 695.84 toks/s, output: 2900.25 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 111/240 [00:23<00:28,  4.46it/s, est. speed input: 689.85 toks/s, output: 2888.77 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 112/240 [00:23<00:30,  4.23it/s, est. speed input: 693.49 toks/s, output: 2896.63 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 113/240 [00:24<00:37,  3.36it/s, est. speed input: 686.29 toks/s, output: 2880.88 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 115/240 [00:24<00:29,  4.24it/s, est. speed input: 688.85 toks/s, output: 2928.38 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 116/240 [00:25<00:49,  2.51it/s, est. speed input: 666.91 toks/s, output: 2862.22 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 117/240 [00:26<01:17,  1.58it/s, est. speed input: 638.21 toks/s, output: 2759.98 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 118/240 [00:27<01:07,  1.80it/s, est. speed input: 639.90 toks/s, output: 2768.13 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 119/240 [00:28<01:18,  1.54it/s, est. speed input: 627.00 toks/s, output: 2721.25 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 120/240 [00:29<01:56,  1.03it/s, est. speed input: 593.71 toks/s, output: 2600.11 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 121/240 [00:30<01:38,  1.21it/s, est. speed input: 589.12 toks/s, output: 2601.90 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 122/240 [00:30<01:15,  1.57it/s, est. speed input: 589.41 toks/s, output: 2628.79 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 123/240 [00:31<01:09,  1.68it/s, est. speed input: 584.21 toks/s, output: 2628.78 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 124/240 [00:31<00:59,  1.95it/s, est. speed input: 586.39 toks/s, output: 2643.35 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 126/240 [00:31<00:35,  3.19it/s, est. speed input: 594.29 toks/s, output: 2713.91 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 127/240 [00:33<01:08,  1.65it/s, est. speed input: 570.54 toks/s, output: 2632.75 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 129/240 [00:34<01:04,  1.71it/s, est. speed input: 558.28 toks/s, output: 2628.90 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 130/240 [00:35<01:20,  1.36it/s, est. speed input: 542.42 toks/s, output: 2577.54 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 131/240 [00:50<07:32,  4.15s/it, est. speed input: 386.49 toks/s, output: 1863.31 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 132/240 [00:51<06:10,  3.43s/it, est. speed input: 379.28 toks/s, output: 1853.16 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 133/240 [00:53<05:16,  2.96s/it, est. speed input: 369.78 toks/s, output: 1833.52 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 134/240 [01:05<09:38,  5.46s/it, est. speed input: 305.27 toks/s, output: 1535.47 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 135/240 [01:23<16:07,  9.21s/it, est. speed input: 238.13 toks/s, output: 1230.58 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 163/240 [01:24<00:58,  1.33it/s, est. speed input: 277.64 toks/s, output: 2248.76 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 197/240 [01:24<00:12,  3.38it/s, est. speed input: 342.48 toks/s, output: 3480.06 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 212/240 [01:26<00:07,  3.89it/s, est. speed input: 356.53 toks/s, output: 3915.96 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 217/240 [01:29<00:06,  3.42it/s, est. speed input: 360.97 toks/s, output: 3965.81 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 220/240 [01:30<00:06,  3.24it/s, est. speed input: 359.57 toks/s, output: 4006.05 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 223/240 [01:32<00:05,  3.09it/s, est. speed input: 359.13 toks/s, output: 4049.10 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 225/240 [01:33<00:04,  3.03it/s, est. speed input: 361.41 toks/s, output: 4080.90 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 227/240 [01:33<00:04,  3.01it/s, est. speed input: 363.98 toks/s, output: 4116.01 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 228/240 [01:34<00:04,  2.97it/s, est. speed input: 365.12 toks/s, output: 4131.89 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 229/240 [01:34<00:04,  2.72it/s, est. speed input: 365.26 toks/s, output: 4136.41 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 230/240 [01:35<00:03,  2.71it/s, est. speed input: 366.44 toks/s, output: 4152.64 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 231/240 [01:35<00:03,  2.79it/s, est. speed input: 366.93 toks/s, output: 4171.57 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 232/240 [01:35<00:02,  2.81it/s, est. speed input: 367.26 toks/s, output: 4188.74 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 233/240 [01:36<00:02,  2.92it/s, est. speed input: 367.80 toks/s, output: 4208.04 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 234/240 [01:36<00:02,  2.96it/s, est. speed input: 368.21 toks/s, output: 4225.88 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 235/240 [01:36<00:01,  3.12it/s, est. speed input: 368.51 toks/s, output: 4245.88 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 236/240 [01:36<00:01,  3.08it/s, est. speed input: 368.55 toks/s, output: 4262.82 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 237/240 [01:37<00:00,  3.27it/s, est. speed input: 368.89 toks/s, output: 4283.21 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 238/240 [01:37<00:00,  3.27it/s, est. speed input: 369.05 toks/s, output: 4301.26 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 239/240 [01:37<00:00,  3.31it/s, est. speed input: 369.11 toks/s, output: 4319.89 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [01:38<00:00,  3.43it/s, est. speed input: 369.26 toks/s, output: 4339.54 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [01:38<00:00,  2.45it/s, est. speed input: 369.26 toks/s, output: 4339.54 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/240 [00:00<?, ?it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<00:00, 24989.03it/s]
{'num_samples': 30, 'num_scores': 240, 'timeout_samples': 0, 'empty_samples': 1, 'acc': 3.3, 'total_acc': 0.4166666666666667, 'pass_at_k_percent': {'1': 0.4, '8': 3.3}, 'pass_at_k_valid_counts': {'1': 30, '8': 30}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_results/noise_rlvr_1_5b_128batchsize_deepscaler_v2_think-boxed/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g1/aime25x8/test_think-boxed_-1_seed0_t0.6_s0_e-1_part0.jsonl
[2025-12-04 00:04:38] ‚úì B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g1/aime25x8  acc=3.3 pass_at_k={'1': 0.4, '8': 3.3}
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g1:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [01:39<03:18, 99.06s/ds][Info] Sharding enabled: Process 0/8 handling range [0:40]
==================================================
data: amc23x8  ,remain samples: 40
{'idx': 0, 'id': 0, 'problem': 'Cities $A$ and $B$ are $45$ miles apart. Alicia lives in $A$ and Beth lives in $B$. Alicia bikes towards $B$ at 18 miles per hour. Leaving at the same time, Beth bikes toward $A$ at 12 miles per hour. How many miles from City $A$ will they be when they meet?', 'answer': 27.0, 'url': 'https://artofproblemsolving.com/wiki/index.php/2023_AMC_12A_Problems/Problem_1', 'question': 'Cities $A$ and $B$ are $45$ miles apart. Alicia lives in $A$ and Beth lives in $B$. Alicia bikes towards $B$ at 18 miles per hour. Leaving at the same time, Beth bikes toward $A$ at 12 miles per hour. How many miles from City $A$ will they be when they meet?'}

  0%|          | 0/40 [00:00<?, ?it/s][ALet's think step by step and enclose the reasoning process within <think> and </think> tags.
The final result in the answer MUST BE within \boxed{}.

Cities $A$ and $B$ are $45$ miles apart. Alicia lives in $A$ and Beth lives in $B$. Alicia bikes towards $B$ at 18 miles per hour. Leaving at the same time, Beth bikes toward $A$ at 12 miles per hour. How many miles from City $A$ will they be when they meet?

100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 452.33it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/320 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 1/320 [00:04<21:18,  4.01s/it, est. speed input: 17.71 toks/s, output: 46.90 toks/s][A
Processed prompts:   1%|          | 2/320 [00:04<09:13,  1.74s/it, est. speed input: 55.06 toks/s, output: 92.33 toks/s][A
Processed prompts:   2%|‚ñè         | 5/320 [00:04<02:50,  1.85it/s, est. speed input: 142.89 toks/s, output: 224.54 toks/s][A
Processed prompts:   2%|‚ñè         | 6/320 [00:04<02:35,  2.02it/s, est. speed input: 143.64 toks/s, output: 253.96 toks/s][A
Processed prompts:   2%|‚ñè         | 7/320 [00:04<02:05,  2.49it/s, est. speed input: 163.53 toks/s, output: 292.10 toks/s][A
Processed prompts:   2%|‚ñé         | 8/320 [00:05<01:45,  2.95it/s, est. speed input: 179.99 toks/s, output: 328.39 toks/s][A
Processed prompts:   3%|‚ñé         | 11/320 [00:05<01:03,  4.83it/s, est. speed input: 235.47 toks/s, output: 443.88 toks/s][A
Processed prompts:   4%|‚ñç         | 13/320 [00:05<00:52,  5.81it/s, est. speed input: 257.86 toks/s, output: 517.35 toks/s][A
Processed prompts:   5%|‚ñç         | 15/320 [00:05<00:48,  6.34it/s, est. speed input: 273.91 toks/s, output: 582.90 toks/s][A
Processed prompts:   5%|‚ñå         | 16/320 [00:05<00:46,  6.56it/s, est. speed input: 287.87 toks/s, output: 614.78 toks/s][A
Processed prompts:   5%|‚ñå         | 17/320 [00:06<01:01,  4.91it/s, est. speed input: 278.48 toks/s, output: 620.68 toks/s][A
Processed prompts:   6%|‚ñå         | 19/320 [00:06<00:44,  6.82it/s, est. speed input: 303.04 toks/s, output: 697.58 toks/s][A
Processed prompts:   7%|‚ñã         | 21/320 [00:06<00:36,  8.16it/s, est. speed input: 329.63 toks/s, output: 768.68 toks/s][A
Processed prompts:   7%|‚ñã         | 23/320 [00:06<00:34,  8.59it/s, est. speed input: 336.63 toks/s, output: 831.53 toks/s][A
Processed prompts:   8%|‚ñä         | 26/320 [00:06<00:24, 12.23it/s, est. speed input: 373.44 toks/s, output: 948.65 toks/s][A
Processed prompts:   9%|‚ñâ         | 28/320 [00:07<00:29, 10.00it/s, est. speed input: 390.17 toks/s, output: 995.78 toks/s][A
Processed prompts:   9%|‚ñâ         | 30/320 [00:07<00:34,  8.52it/s, est. speed input: 389.91 toks/s, output: 1038.25 toks/s][A
Processed prompts:  10%|‚ñà         | 32/320 [00:07<00:31,  9.21it/s, est. speed input: 405.71 toks/s, output: 1098.80 toks/s][A
Processed prompts:  11%|‚ñà         | 34/320 [00:07<00:29,  9.75it/s, est. speed input: 412.25 toks/s, output: 1158.45 toks/s][A
Processed prompts:  11%|‚ñà‚ñè        | 36/320 [00:08<00:33,  8.54it/s, est. speed input: 432.13 toks/s, output: 1199.03 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 39/320 [00:08<00:30,  9.27it/s, est. speed input: 445.92 toks/s, output: 1282.68 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 41/320 [00:08<00:26, 10.41it/s, est. speed input: 464.35 toks/s, output: 1346.76 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 43/320 [00:08<00:33,  8.18it/s, est. speed input: 463.94 toks/s, output: 1372.80 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 44/320 [00:09<00:35,  7.72it/s, est. speed input: 474.47 toks/s, output: 1389.12 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 46/320 [00:09<00:32,  8.55it/s, est. speed input: 488.61 toks/s, output: 1444.27 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 47/320 [00:09<00:38,  7.11it/s, est. speed input: 483.77 toks/s, output: 1448.57 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 49/320 [00:09<00:31,  8.72it/s, est. speed input: 502.42 toks/s, output: 1510.46 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 53/320 [00:09<00:21, 12.41it/s, est. speed input: 538.91 toks/s, output: 1644.45 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 55/320 [00:10<00:24, 10.69it/s, est. speed input: 554.42 toks/s, output: 1683.06 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 57/320 [00:10<00:26,  9.97it/s, est. speed input: 572.21 toks/s, output: 1725.35 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 59/320 [00:10<00:25, 10.19it/s, est. speed input: 589.30 toks/s, output: 1775.31 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 62/320 [00:10<00:19, 13.36it/s, est. speed input: 608.13 toks/s, output: 1877.71 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 64/320 [00:10<00:21, 12.04it/s, est. speed input: 625.94 toks/s, output: 1921.05 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 66/320 [00:11<00:25,  9.85it/s, est. speed input: 624.37 toks/s, output: 1948.82 toks/s][A
Processed prompts:  21%|‚ñà‚ñà‚ñè       | 68/320 [00:11<00:27,  9.11it/s, est. speed input: 637.76 toks/s, output: 1983.22 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 70/320 [00:11<00:40,  6.20it/s, est. speed input: 621.19 toks/s, output: 1966.45 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 73/320 [00:12<00:27,  8.82it/s, est. speed input: 641.32 toks/s, output: 2068.50 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 77/320 [00:12<00:20, 11.76it/s, est. speed input: 669.12 toks/s, output: 2172.64 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñç       | 79/320 [00:12<00:20, 11.97it/s, est. speed input: 679.71 toks/s, output: 2224.66 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 81/320 [00:12<00:18, 12.65it/s, est. speed input: 690.22 toks/s, output: 2280.93 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 83/320 [00:12<00:17, 13.88it/s, est. speed input: 713.96 toks/s, output: 2341.74 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 86/320 [00:12<00:13, 17.04it/s, est. speed input: 738.81 toks/s, output: 2418.96 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 92/320 [00:12<00:10, 21.55it/s, est. speed input: 780.67 toks/s, output: 2598.71 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 95/320 [00:13<00:09, 23.15it/s, est. speed input: 792.41 toks/s, output: 2675.86 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 98/320 [00:13<00:13, 16.22it/s, est. speed input: 802.23 toks/s, output: 2686.63 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 101/320 [00:13<00:14, 15.21it/s, est. speed input: 813.05 toks/s, output: 2743.28 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 103/320 [00:13<00:13, 15.98it/s, est. speed input: 827.41 toks/s, output: 2802.30 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 105/320 [00:13<00:14, 15.25it/s, est. speed input: 832.53 toks/s, output: 2833.11 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 107/320 [00:14<00:19, 11.11it/s, est. speed input: 828.86 toks/s, output: 2847.42 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 109/320 [00:14<00:18, 11.18it/s, est. speed input: 832.75 toks/s, output: 2871.28 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 111/320 [00:14<00:17, 12.16it/s, est. speed input: 839.51 toks/s, output: 2907.54 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 114/320 [00:14<00:13, 15.56it/s, est. speed input: 864.71 toks/s, output: 3006.51 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñã      | 116/320 [00:14<00:14, 14.23it/s, est. speed input: 869.77 toks/s, output: 3050.22 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 118/320 [00:15<00:22,  9.17it/s, est. speed input: 858.04 toks/s, output: 3024.12 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 120/320 [00:15<00:19, 10.41it/s, est. speed input: 873.59 toks/s, output: 3078.84 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 122/320 [00:15<00:16, 12.05it/s, est. speed input: 885.92 toks/s, output: 3138.21 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 125/320 [00:15<00:13, 14.87it/s, est. speed input: 901.12 toks/s, output: 3212.26 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 129/320 [00:15<00:10, 18.30it/s, est. speed input: 916.31 toks/s, output: 3314.59 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 132/320 [00:15<00:09, 19.84it/s, est. speed input: 930.21 toks/s, output: 3381.19 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 135/320 [00:16<00:09, 19.05it/s, est. speed input: 934.05 toks/s, output: 3437.51 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 140/320 [00:16<00:10, 17.59it/s, est. speed input: 959.67 toks/s, output: 3521.12 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 144/320 [00:16<00:09, 19.19it/s, est. speed input: 972.68 toks/s, output: 3643.48 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 147/320 [00:16<00:09, 18.81it/s, est. speed input: 983.96 toks/s, output: 3705.99 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 151/320 [00:16<00:10, 16.35it/s, est. speed input: 997.24 toks/s, output: 3756.15 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 154/320 [00:17<00:11, 13.86it/s, est. speed input: 1005.99 toks/s, output: 3770.28 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 156/320 [00:17<00:13, 12.27it/s, est. speed input: 1007.59 toks/s, output: 3780.25 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 158/320 [00:17<00:17,  9.22it/s, est. speed input: 996.35 toks/s, output: 3754.94 toks/s] [A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 161/320 [00:18<00:18,  8.54it/s, est. speed input: 996.10 toks/s, output: 3767.03 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 162/320 [00:18<00:19,  8.29it/s, est. speed input: 994.31 toks/s, output: 3777.79 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 164/320 [00:18<00:17,  8.79it/s, est. speed input: 995.85 toks/s, output: 3802.47 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 166/320 [00:18<00:15, 10.15it/s, est. speed input: 1000.60 toks/s, output: 3839.95 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 168/320 [00:18<00:14, 10.62it/s, est. speed input: 998.95 toks/s, output: 3886.44 toks/s] [A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 171/320 [00:19<00:11, 13.10it/s, est. speed input: 1011.47 toks/s, output: 3941.19 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 173/320 [00:19<00:20,  7.09it/s, est. speed input: 988.04 toks/s, output: 3893.05 toks/s] [A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 175/320 [00:19<00:18,  8.00it/s, est. speed input: 991.40 toks/s, output: 3940.92 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 177/320 [00:20<00:17,  8.35it/s, est. speed input: 994.48 toks/s, output: 3959.07 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 179/320 [00:20<00:15,  9.16it/s, est. speed input: 999.76 toks/s, output: 3991.24 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 181/320 [00:20<00:23,  5.84it/s, est. speed input: 977.69 toks/s, output: 3948.85 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 182/320 [00:21<00:22,  6.02it/s, est. speed input: 976.34 toks/s, output: 3962.60 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 185/320 [00:21<00:16,  8.19it/s, est. speed input: 982.90 toks/s, output: 4029.45 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 189/320 [00:21<00:12, 10.68it/s, est. speed input: 997.11 toks/s, output: 4146.09 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 191/320 [00:22<00:21,  5.90it/s, est. speed input: 976.06 toks/s, output: 4049.69 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 194/320 [00:22<00:16,  7.74it/s, est. speed input: 989.28 toks/s, output: 4108.49 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 196/320 [00:22<00:17,  7.08it/s, est. speed input: 986.51 toks/s, output: 4124.80 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 198/320 [00:23<00:20,  6.05it/s, est. speed input: 974.59 toks/s, output: 4123.06 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 199/320 [00:23<00:21,  5.69it/s, est. speed input: 968.81 toks/s, output: 4107.43 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 200/320 [00:23<00:24,  4.87it/s, est. speed input: 958.16 toks/s, output: 4090.07 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 201/320 [00:24<00:29,  3.99it/s, est. speed input: 945.96 toks/s, output: 4059.63 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 202/320 [00:24<00:27,  4.22it/s, est. speed input: 942.09 toks/s, output: 4069.04 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 203/320 [00:24<00:26,  4.43it/s, est. speed input: 941.80 toks/s, output: 4078.58 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 204/320 [00:24<00:25,  4.50it/s, est. speed input: 938.55 toks/s, output: 4084.92 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 206/320 [00:25<00:19,  5.95it/s, est. speed input: 942.86 toks/s, output: 4122.99 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 208/320 [00:25<00:21,  5.11it/s, est. speed input: 932.31 toks/s, output: 4110.89 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 211/320 [00:25<00:13,  8.08it/s, est. speed input: 942.19 toks/s, output: 4186.14 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 213/320 [00:25<00:14,  7.53it/s, est. speed input: 941.40 toks/s, output: 4203.42 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 215/320 [00:26<00:20,  5.13it/s, est. speed input: 924.99 toks/s, output: 4164.73 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 216/320 [00:29<01:02,  1.66it/s, est. speed input: 849.50 toks/s, output: 3848.70 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 217/320 [00:29<01:03,  1.62it/s, est. speed input: 834.73 toks/s, output: 3804.52 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 218/320 [00:30<00:58,  1.74it/s, est. speed input: 825.76 toks/s, output: 3780.09 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 219/320 [00:30<00:46,  2.16it/s, est. speed input: 826.89 toks/s, output: 3808.85 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 220/320 [00:32<01:19,  1.25it/s, est. speed input: 788.98 toks/s, output: 3634.37 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 221/320 [00:33<01:28,  1.12it/s, est. speed input: 764.19 toks/s, output: 3552.46 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 223/320 [00:34<01:10,  1.37it/s, est. speed input: 748.19 toks/s, output: 3529.14 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 224/320 [00:34<01:04,  1.48it/s, est. speed input: 740.49 toks/s, output: 3521.19 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 226/320 [00:38<01:55,  1.23s/it, est. speed input: 668.74 toks/s, output: 3229.73 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 227/320 [00:39<01:39,  1.07s/it, est. speed input: 662.46 toks/s, output: 3232.53 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 228/320 [00:45<03:29,  2.27s/it, est. speed input: 576.13 toks/s, output: 2844.16 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 229/320 [00:46<02:48,  1.85s/it, est. speed input: 571.83 toks/s, output: 2847.74 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 230/320 [00:46<02:21,  1.58s/it, est. speed input: 563.30 toks/s, output: 2839.09 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 233/320 [00:47<01:13,  1.18it/s, est. speed input: 563.81 toks/s, output: 2925.22 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 234/320 [00:50<01:53,  1.32s/it, est. speed input: 530.26 toks/s, output: 2783.35 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 235/320 [00:57<03:35,  2.53s/it, est. speed input: 472.86 toks/s, output: 2496.15 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 236/320 [00:57<02:44,  1.96s/it, est. speed input: 472.68 toks/s, output: 2529.73 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 237/320 [01:04<04:23,  3.18s/it, est. speed input: 424.68 toks/s, output: 2307.15 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 238/320 [01:18<08:33,  6.26s/it, est. speed input: 346.82 toks/s, output: 1917.95 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 247/320 [01:19<01:44,  1.43s/it, est. speed input: 355.90 toks/s, output: 2259.92 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 262/320 [01:19<00:29,  1.96it/s, est. speed input: 383.05 toks/s, output: 2834.57 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 304/320 [01:21<00:02,  5.44it/s, est. speed input: 438.54 toks/s, output: 4325.95 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 307/320 [01:22<00:02,  5.56it/s, est. speed input: 445.70 toks/s, output: 4418.25 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 310/320 [01:23<00:01,  5.18it/s, est. speed input: 444.25 toks/s, output: 4476.61 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 312/320 [01:23<00:01,  5.10it/s, est. speed input: 445.02 toks/s, output: 4525.50 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 314/320 [01:24<00:01,  5.20it/s, est. speed input: 446.06 toks/s, output: 4581.41 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 316/320 [01:24<00:00,  4.42it/s, est. speed input: 443.31 toks/s, output: 4603.76 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 317/320 [01:25<00:00,  3.73it/s, est. speed input: 440.39 toks/s, output: 4600.32 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 318/320 [01:26<00:00,  3.44it/s, est. speed input: 438.78 toks/s, output: 4610.14 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 319/320 [01:26<00:00,  3.22it/s, est. speed input: 437.38 toks/s, output: 4621.96 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 320/320 [01:27<00:00,  2.97it/s, est. speed input: 435.86 toks/s, output: 4632.19 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 320/320 [01:27<00:00,  3.68it/s, est. speed input: 435.86 toks/s, output: 4632.19 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/320 [00:00<?, ?it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 320/320 [00:00<00:00, 25022.88it/s]
{'num_samples': 40, 'num_scores': 320, 'timeout_samples': 0, 'empty_samples': 1, 'acc': 15.0, 'total_acc': 19.0625, 'pass_at_k_percent': {'1': 19.1, '8': 62.5}, 'pass_at_k_valid_counts': {'1': 40, '8': 40}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_results/noise_rlvr_1_5b_128batchsize_deepscaler_v2_think-boxed/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g1/amc23x8/test_think-boxed_-1_seed0_t0.6_s0_e-1_part0.jsonl
[2025-12-04 00:06:06] ‚úì B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g1/amc23x8  acc=15.0 pass_at_k={'1': 19.1, '8': 62.5}
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [03:07<01:32, 92.65s/ds][Info] Sharding enabled: Process 0/8 handling range [0:30]
==================================================
data: aime24x8  ,remain samples: 30
{'idx': 0, 'id': 60, 'problem': 'Every morning Aya goes for a $9$-kilometer-long walk and stops at a coffee shop afterwards. When she walks at a constant speed of $s$ kilometers per hour, the walk takes her 4 hours, including $t$ minutes spent in the coffee shop. When she walks $s+2$ kilometers per hour, the walk takes her 2 hours and 24 minutes, including $t$ minutes spent in the coffee shop. Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find the number of minutes the walk takes her, including the $t$ minutes spent in the coffee shop.', 'solution': '$\\frac{9}{s} + t = 4$ in hours and $\\frac{9}{s+2} + t = 2.4$ in hours.\nSubtracting the second equation from the first, we get, \n$\\frac{9}{s} - \\frac{9}{s+2} = 1.6$\nMultiplying by $(s)(s+2)$, we get \n$9s+18-9s=18=1.6s^{2} + 3.2s$\nMultiplying by 5/2 on both sides, we get\n$0 = 4s^{2} + 8s - 45$\nFactoring gives us \n$(2s-5)(2s+9) = 0$, of which the solution we want is $s=2.5$.\nSubstituting this back to the first equation, we can find that $t = 0.4$ hours.\nLastly, $s + \\frac{1}{2} = 3$ kilometers per hour, so\n$\\frac{9}{3} + 0.4 = 3.4$ hours, or $\\framebox{204}$ minutes\n-Failure.net\nThe amount of hours spent while walking on the first travel is $\\frac{240-t}{6}$. Thus, we have the equation $(240-t)(s) = 540$, and by the same logic, the second equation yields $(144-t)(s+2) = 540$. We have $240s-st = 540$, and $288+144s-2t-st = 540$. We subtract the two equations to get $96s+2t-288 = 0$, so we have $48s+t = 144$, so $t = 144-48s$, and now we have $(96+48s)(s) = 540$. The numerator of $s$ must evenly divide 540, however, $s$ must be less than 3. We can guess that $s = 2.5$. Now, $2.5+0.5 = 3$. Taking $\\frac{9}{3} = 3$, we find that it will take three hours for the 9 kilometers to be traveled. The t minutes spent at the coffeeshop can be written as $144-48(2.5)$, so t = 24. $180 + 24 = 204$. -sepehr2010', 'answer': '204', 'url': 'https://artofproblemsolving.com/wiki/index.php/2024_AIME_I_Problems/Problem_1', 'question': 'Every morning Aya goes for a $9$-kilometer-long walk and stops at a coffee shop afterwards. When she walks at a constant speed of $s$ kilometers per hour, the walk takes her 4 hours, including $t$ minutes spent in the coffee shop. When she walks $s+2$ kilometers per hour, the walk takes her 2 hours and 24 minutes, including $t$ minutes spent in the coffee shop. Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find the number of minutes the walk takes her, including the $t$ minutes spent in the coffee shop.'}

  0%|          | 0/30 [00:00<?, ?it/s][ALet's think step by step and enclose the reasoning process within <think> and </think> tags.
The final result in the answer MUST BE within \boxed{}.

Every morning Aya goes for a $9$-kilometer-long walk and stops at a coffee shop afterwards. When she walks at a constant speed of $s$ kilometers per hour, the walk takes her 4 hours, including $t$ minutes spent in the coffee shop. When she walks $s+2$ kilometers per hour, the walk takes her 2 hours and 24 minutes, including $t$ minutes spent in the coffee shop. Suppose Aya walks at $s+\frac{1}{2}$ kilometers per hour. Find the number of minutes the walk takes her, including the $t$ minutes spent in the coffee shop.

100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 466.05it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/240 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 1/240 [00:04<19:41,  4.94s/it, est. speed input: 19.22 toks/s, output: 46.12 toks/s][A
Processed prompts:   1%|          | 2/240 [00:05<09:02,  2.28s/it, est. speed input: 38.63 toks/s, output: 89.01 toks/s][A
Processed prompts:   1%|‚ñè         | 3/240 [00:06<06:04,  1.54s/it, est. speed input: 61.00 toks/s, output: 125.15 toks/s][A
Processed prompts:   2%|‚ñè         | 4/240 [00:06<04:13,  1.07s/it, est. speed input: 78.59 toks/s, output: 163.46 toks/s][A
Processed prompts:   2%|‚ñè         | 5/240 [00:06<02:51,  1.37it/s, est. speed input: 90.23 toks/s, output: 206.03 toks/s][A
Processed prompts:   2%|‚ñé         | 6/240 [00:06<02:25,  1.61it/s, est. speed input: 113.24 toks/s, output: 238.93 toks/s][A
Processed prompts:   3%|‚ñé         | 8/240 [00:07<01:31,  2.54it/s, est. speed input: 144.14 toks/s, output: 317.07 toks/s][A
Processed prompts:   4%|‚ñç         | 9/240 [00:07<01:15,  3.04it/s, est. speed input: 167.86 toks/s, output: 355.68 toks/s][A
Processed prompts:   4%|‚ñç         | 10/240 [00:07<01:08,  3.34it/s, est. speed input: 175.52 toks/s, output: 390.04 toks/s][A
Processed prompts:   5%|‚ñå         | 12/240 [00:07<00:51,  4.39it/s, est. speed input: 195.04 toks/s, output: 464.89 toks/s][A
Processed prompts:   6%|‚ñå         | 14/240 [00:08<00:54,  4.17it/s, est. speed input: 204.94 toks/s, output: 522.55 toks/s][A
Processed prompts:   6%|‚ñã         | 15/240 [00:08<00:49,  4.54it/s, est. speed input: 215.17 toks/s, output: 557.69 toks/s][A
Processed prompts:   7%|‚ñã         | 17/240 [00:08<00:36,  6.07it/s, est. speed input: 245.03 toks/s, output: 636.21 toks/s][A
Processed prompts:   8%|‚ñä         | 19/240 [00:09<00:44,  4.95it/s, est. speed input: 253.41 toks/s, output: 684.28 toks/s][A
Processed prompts:   9%|‚ñâ         | 21/240 [00:09<00:34,  6.43it/s, est. speed input: 270.35 toks/s, output: 763.11 toks/s][A
Processed prompts:  10%|‚ñâ         | 23/240 [00:09<00:28,  7.51it/s, est. speed input: 291.07 toks/s, output: 836.64 toks/s][A
Processed prompts:  11%|‚ñà         | 26/240 [00:09<00:22,  9.48it/s, est. speed input: 330.38 toks/s, output: 950.17 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 28/240 [00:09<00:21,  9.99it/s, est. speed input: 352.94 toks/s, output: 1021.18 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 31/240 [00:10<00:16, 12.84it/s, est. speed input: 377.98 toks/s, output: 1139.73 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 33/240 [00:10<00:19, 10.40it/s, est. speed input: 388.81 toks/s, output: 1193.79 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 35/240 [00:10<00:21,  9.67it/s, est. speed input: 397.11 toks/s, output: 1252.77 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 37/240 [00:11<00:31,  6.49it/s, est. speed input: 404.74 toks/s, output: 1275.48 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 40/240 [00:11<00:22,  8.95it/s, est. speed input: 438.18 toks/s, output: 1391.13 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 44/240 [00:11<00:15, 12.42it/s, est. speed input: 470.06 toks/s, output: 1545.41 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 47/240 [00:11<00:13, 14.66it/s, est. speed input: 494.02 toks/s, output: 1658.53 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 49/240 [00:11<00:13, 13.86it/s, est. speed input: 504.60 toks/s, output: 1720.88 toks/s][A
Processed prompts:  21%|‚ñà‚ñà‚ñè       | 51/240 [00:12<00:19,  9.50it/s, est. speed input: 510.45 toks/s, output: 1748.23 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 53/240 [00:12<00:19,  9.39it/s, est. speed input: 521.57 toks/s, output: 1802.87 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 55/240 [00:12<00:18, 10.25it/s, est. speed input: 540.12 toks/s, output: 1867.68 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 58/240 [00:12<00:17, 10.25it/s, est. speed input: 562.70 toks/s, output: 1952.86 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 60/240 [00:12<00:16, 10.95it/s, est. speed input: 581.09 toks/s, output: 2016.86 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 64/240 [00:13<00:12, 13.67it/s, est. speed input: 609.81 toks/s, output: 2157.78 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 67/240 [00:13<00:14, 12.03it/s, est. speed input: 627.40 toks/s, output: 2234.91 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 69/240 [00:13<00:16, 10.27it/s, est. speed input: 633.29 toks/s, output: 2273.34 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 71/240 [00:14<00:26,  6.36it/s, est. speed input: 616.53 toks/s, output: 2251.73 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 72/240 [00:14<00:30,  5.53it/s, est. speed input: 611.94 toks/s, output: 2246.28 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 73/240 [00:14<00:28,  5.86it/s, est. speed input: 612.15 toks/s, output: 2270.57 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 74/240 [00:15<00:30,  5.40it/s, est. speed input: 609.62 toks/s, output: 2276.69 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà‚ñè      | 75/240 [00:15<00:28,  5.83it/s, est. speed input: 612.38 toks/s, output: 2301.15 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 79/240 [00:15<00:15, 10.09it/s, est. speed input: 640.12 toks/s, output: 2446.37 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 82/240 [00:15<00:16,  9.32it/s, est. speed input: 645.37 toks/s, output: 2516.72 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 84/240 [00:15<00:15,  9.87it/s, est. speed input: 661.29 toks/s, output: 2575.18 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 86/240 [00:16<00:16,  9.08it/s, est. speed input: 667.33 toks/s, output: 2617.92 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 88/240 [00:16<00:15,  9.72it/s, est. speed input: 678.43 toks/s, output: 2675.92 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 90/240 [00:16<00:21,  7.01it/s, est. speed input: 672.10 toks/s, output: 2684.01 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 93/240 [00:16<00:15,  9.37it/s, est. speed input: 693.35 toks/s, output: 2788.84 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 95/240 [00:17<00:17,  8.13it/s, est. speed input: 689.70 toks/s, output: 2819.69 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 97/240 [00:17<00:22,  6.44it/s, est. speed input: 682.35 toks/s, output: 2828.72 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 98/240 [00:18<00:24,  5.77it/s, est. speed input: 682.29 toks/s, output: 2829.68 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 100/240 [00:18<00:23,  5.95it/s, est. speed input: 687.49 toks/s, output: 2866.10 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 103/240 [00:18<00:16,  8.17it/s, est. speed input: 698.97 toks/s, output: 2967.39 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 105/240 [00:19<00:28,  4.78it/s, est. speed input: 685.00 toks/s, output: 2919.63 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 107/240 [00:19<00:23,  5.66it/s, est. speed input: 690.62 toks/s, output: 2975.69 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 109/240 [00:20<00:30,  4.26it/s, est. speed input: 675.33 toks/s, output: 2948.60 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 110/240 [00:20<00:35,  3.63it/s, est. speed input: 665.07 toks/s, output: 2923.97 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 111/240 [00:20<00:31,  4.08it/s, est. speed input: 668.02 toks/s, output: 2949.45 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 112/240 [00:21<00:27,  4.59it/s, est. speed input: 669.74 toks/s, output: 2974.87 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 114/240 [00:21<00:20,  6.29it/s, est. speed input: 675.93 toks/s, output: 3040.69 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 115/240 [00:22<00:39,  3.19it/s, est. speed input: 655.22 toks/s, output: 2962.60 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 120/240 [00:22<00:19,  6.04it/s, est. speed input: 681.35 toks/s, output: 3126.43 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 121/240 [00:22<00:23,  5.10it/s, est. speed input: 674.87 toks/s, output: 3118.03 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 122/240 [00:23<00:33,  3.52it/s, est. speed input: 660.29 toks/s, output: 3067.53 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 125/240 [00:23<00:21,  5.42it/s, est. speed input: 671.33 toks/s, output: 3175.03 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 126/240 [00:23<00:21,  5.25it/s, est. speed input: 668.46 toks/s, output: 3188.62 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 128/240 [00:24<00:19,  5.62it/s, est. speed input: 666.88 toks/s, output: 3233.13 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 129/240 [00:24<00:19,  5.77it/s, est. speed input: 668.10 toks/s, output: 3255.48 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 130/240 [00:24<00:19,  5.61it/s, est. speed input: 670.03 toks/s, output: 3272.20 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 131/240 [00:24<00:19,  5.64it/s, est. speed input: 670.73 toks/s, output: 3291.81 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 132/240 [00:24<00:17,  6.06it/s, est. speed input: 672.66 toks/s, output: 3317.57 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 133/240 [00:26<01:03,  1.70it/s, est. speed input: 633.93 toks/s, output: 3138.54 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 134/240 [00:26<00:51,  2.05it/s, est. speed input: 632.69 toks/s, output: 3156.04 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 135/240 [00:27<01:07,  1.56it/s, est. speed input: 613.48 toks/s, output: 3082.58 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 136/240 [00:27<00:51,  2.02it/s, est. speed input: 613.62 toks/s, output: 3111.20 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 138/240 [00:28<00:44,  2.27it/s, est. speed input: 609.96 toks/s, output: 3115.78 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 139/240 [00:29<00:50,  1.98it/s, est. speed input: 598.30 toks/s, output: 3084.23 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 141/240 [00:30<00:51,  1.94it/s, est. speed input: 587.13 toks/s, output: 3061.70 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 142/240 [00:31<00:56,  1.75it/s, est. speed input: 580.26 toks/s, output: 3030.36 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 143/240 [00:32<01:02,  1.54it/s, est. speed input: 568.52 toks/s, output: 2990.68 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 144/240 [00:35<02:10,  1.36s/it, est. speed input: 519.21 toks/s, output: 2747.29 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 145/240 [00:36<02:04,  1.32s/it, est. speed input: 505.12 toks/s, output: 2701.50 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 146/240 [00:37<01:42,  1.09s/it, est. speed input: 500.76 toks/s, output: 2709.30 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 147/240 [00:38<01:35,  1.03s/it, est. speed input: 492.23 toks/s, output: 2689.77 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 148/240 [00:39<01:42,  1.12s/it, est. speed input: 477.89 toks/s, output: 2641.82 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 149/240 [00:40<01:29,  1.02it/s, est. speed input: 474.14 toks/s, output: 2642.10 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 150/240 [00:43<02:40,  1.79s/it, est. speed input: 438.01 toks/s, output: 2460.61 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 151/240 [00:43<01:56,  1.31s/it, est. speed input: 438.89 toks/s, output: 2493.21 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 152/240 [00:45<01:55,  1.31s/it, est. speed input: 428.23 toks/s, output: 2464.22 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 153/240 [00:45<01:37,  1.12s/it, est. speed input: 425.89 toks/s, output: 2470.20 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 154/240 [00:54<04:40,  3.26s/it, est. speed input: 364.16 toks/s, output: 2134.48 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 155/240 [01:01<06:10,  4.35s/it, est. speed input: 329.67 toks/s, output: 1933.70 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 156/240 [01:02<04:47,  3.42s/it, est. speed input: 326.87 toks/s, output: 1935.96 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 157/240 [01:09<06:03,  4.38s/it, est. speed input: 297.85 toks/s, output: 1789.66 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 158/240 [01:11<05:04,  3.71s/it, est. speed input: 294.67 toks/s, output: 1775.45 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 159/240 [01:18<06:36,  4.90s/it, est. speed input: 268.10 toks/s, output: 1641.35 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 160/240 [01:19<04:43,  3.54s/it, est. speed input: 268.93 toks/s, output: 1672.26 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 170/240 [01:19<00:48,  1.44it/s, est. speed input: 284.24 toks/s, output: 2052.55 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 186/240 [01:19<00:13,  3.98it/s, est. speed input: 308.02 toks/s, output: 2664.33 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 236/240 [01:20<00:00, 13.56it/s, est. speed input: 402.98 toks/s, output: 4555.88 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [01:22<00:00,  2.92it/s, est. speed input: 406.79 toks/s, output: 4598.84 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/240 [00:00<?, ?it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<00:00, 18503.60it/s]
{'num_samples': 30, 'num_scores': 240, 'timeout_samples': 0, 'empty_samples': 2, 'acc': 0.0, 'total_acc': 5.416666666666667, 'pass_at_k_percent': {'1': 5.4, '8': 23.3}, 'pass_at_k_valid_counts': {'1': 30, '8': 30}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_results/noise_rlvr_1_5b_128batchsize_deepscaler_v2_think-boxed/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g1/aime24x8/test_think-boxed_-1_seed0_t0.6_s0_e-1_part0.jsonl
[2025-12-04 00:07:29] ‚úì B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g1/aime24x8  acc=0.0 pass_at_k={'1': 5.4, '8': 23.3}
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [04:30<00:00, 88.31s/ds]B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [04:30<00:00, 90.12s/ds]
[2025-12-04 00:07:29] ‚ñ∂ B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g2  ÂæÖËØÑÊµã=['minerva_math', 'olympiadbench', 'math500']  T=0.0  n=8
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g2:   0%|          | 0/3 [00:00<?, ?ds/s][Info] Sharding enabled: Process 0/8 handling range [0:34]
==================================================
data: minerva_math  ,remain samples: 34
{'problem': 'Each of the two Magellan telescopes has a diameter of $6.5 \\mathrm{~m}$. In one configuration the effective focal length is $72 \\mathrm{~m}$. Find the diameter of the image of a planet (in $\\mathrm{cm}$ ) at this focus if the angular diameter of the planet at the time of the observation is $45^{\\prime \\prime}$.', 'solution': 'Start with:\n\\[\ns=\\alpha f \\text {, }\n\\]\nwhere $s$ is the diameter of the image, $f$ the focal length, and $\\alpha$ the angular diameter of the planet. For the values given in the problem:\n\\[\ns=\\frac{45}{3600} \\frac{\\pi}{180} 7200=\\boxed{1.6} \\mathrm{~cm}\n\\]', 'type': 'Introduction to Astronomy (8.282J Spring 2006)', 'idx': 0}

  0%|          | 0/34 [00:00<?, ?it/s][ALet's think step by step and enclose the reasoning process within <think> and </think> tags.
The final result in the answer MUST BE within \boxed{}.

Each of the two Magellan telescopes has a diameter of $6.5 \mathrm{~m}$. In one configuration the effective focal length is $72 \mathrm{~m}$. Find the diameter of the image of a planet (in $\mathrm{cm}$ ) at this focus if the angular diameter of the planet at the time of the observation is $45^{\prime \prime}$.

100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 34/34 [00:00<00:00, 13266.94it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/272 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 1/272 [00:06<27:42,  6.14s/it, est. speed input: 14.02 toks/s, output: 45.48 toks/s][A
Processed prompts:   3%|‚ñé         | 9/272 [00:06<02:29,  1.76it/s, est. speed input: 112.47 toks/s, output: 373.76 toks/s][A
Processed prompts:   6%|‚ñã         | 17/272 [00:07<01:07,  3.79it/s, est. speed input: 193.98 toks/s, output: 710.07 toks/s][A
Processed prompts:   9%|‚ñâ         | 25/272 [00:07<00:44,  5.50it/s, est. speed input: 253.10 toks/s, output: 982.49 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 33/272 [00:07<00:28,  8.40it/s, est. speed input: 338.69 toks/s, output: 1310.86 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 49/272 [00:08<00:16, 13.56it/s, est. speed input: 523.04 toks/s, output: 1902.03 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 57/272 [00:08<00:14, 14.45it/s, est. speed input: 588.82 toks/s, output: 2143.43 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 65/272 [00:09<00:16, 12.86it/s, est. speed input: 639.01 toks/s, output: 2296.89 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 81/272 [00:10<00:10, 17.40it/s, est. speed input: 770.87 toks/s, output: 2858.34 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 87/272 [00:12<00:19,  9.41it/s, est. speed input: 710.74 toks/s, output: 2647.59 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 95/272 [00:12<00:14, 12.14it/s, est. speed input: 785.45 toks/s, output: 2968.72 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 103/272 [00:12<00:11, 14.35it/s, est. speed input: 877.68 toks/s, output: 3247.44 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 111/272 [00:12<00:09, 17.56it/s, est. speed input: 988.97 toks/s, output: 3546.02 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 115/272 [00:13<00:13, 11.77it/s, est. speed input: 952.46 toks/s, output: 3486.87 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 118/272 [00:14<00:19,  8.01it/s, est. speed input: 916.54 toks/s, output: 3371.51 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 124/272 [00:15<00:17,  8.59it/s, est. speed input: 944.54 toks/s, output: 3499.18 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 132/272 [00:15<00:14,  9.90it/s, est. speed input: 998.84 toks/s, output: 3709.91 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 140/272 [00:16<00:10, 12.17it/s, est. speed input: 1037.22 toks/s, output: 3973.31 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 146/272 [00:16<00:11, 11.08it/s, est. speed input: 1025.27 toks/s, output: 4072.70 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 154/272 [00:20<00:23,  5.08it/s, est. speed input: 905.98 toks/s, output: 3724.03 toks/s] [A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 162/272 [00:20<00:16,  6.77it/s, est. speed input: 950.95 toks/s, output: 4001.77 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 170/272 [00:33<01:04,  1.58it/s, est. speed input: 591.88 toks/s, output: 2593.12 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 172/272 [00:38<01:21,  1.22it/s, est. speed input: 524.72 toks/s, output: 2351.31 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 180/272 [01:18<03:36,  2.36s/it, est. speed input: 280.33 toks/s, output: 1350.79 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 193/272 [01:18<01:41,  1.28s/it, est. speed input: 310.56 toks/s, output: 1852.70 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 257/272 [01:19<00:04,  3.25it/s, est. speed input: 492.02 toks/s, output: 4314.38 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 263/272 [01:19<00:02,  3.55it/s, est. speed input: 505.32 toks/s, output: 4538.27 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 268/272 [01:26<00:01,  2.57it/s, est. speed input: 477.85 toks/s, output: 4357.04 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 272/272 [01:26<00:00,  2.80it/s, est. speed input: 486.47 toks/s, output: 4483.55 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 272/272 [01:26<00:00,  3.14it/s, est. speed input: 486.47 toks/s, output: 4483.55 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/272 [00:00<?, ?it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 272/272 [00:00<00:00, 6838.24it/s]
{'num_samples': 34, 'num_scores': 272, 'timeout_samples': 0, 'empty_samples': 0, 'acc': 2.9, 'total_acc': 2.941176470588235, 'pass_at_k_percent': {'1': 2.9, '8': 2.9}, 'pass_at_k_valid_counts': {'1': 34, '8': 34}, 'type_acc': {'Introduction to Astronomy (8.282J Spring 2006)': 2.9}, 'type_pass_at_k_percent': {'Introduction to Astronomy (8.282J Spring 2006)': {'1': 2.9, '8': 2.9}}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_results/noise_rlvr_1_5b_128batchsize_deepscaler_v2_think-boxed/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g2/minerva_math/test_think-boxed_-1_seed0_t0.0_s0_e-1_part0.jsonl
[2025-12-04 00:08:57] ‚úì B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g2/minerva_math  acc=2.9 pass_at_k={'1': 2.9, '8': 2.9}
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g2:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [01:27<02:54, 87.08s/ds][Info] Sharding enabled: Process 0/8 handling range [0:84]
==================================================
data: olympiadbench  ,remain samples: 84
{'idx': 0, 'id': 1606, 'subfield': 'Combinatorics', 'context': None, 'question': 'Xenia and Sergey play the following game. Xenia thinks of a positive integer $N$ not exceeding 5000. Then she fixes 20 distinct positive integers $a_{1}, a_{2}, \\ldots, a_{20}$ such that, for each $k=1,2, \\ldots, 20$, the numbers $N$ and $a_{k}$ are congruent modulo $k$. By a move, Sergey tells Xenia a set $S$ of positive integers not exceeding 20 , and she tells him back the set $\\left\\{a_{k}: k \\in S\\right\\}$ without spelling out which number corresponds to which index. How many moves does Sergey need to determine for sure the number Xenia thought of?', 'solution': ["Sergey can determine Xenia's number in 2 but not fewer moves.\n\n\n\nWe first show that 2 moves are sufficient. Let Sergey provide the set $\\{17,18\\}$ on his first move, and the set $\\{18,19\\}$ on the second move. In Xenia's two responses, exactly one number occurs twice, namely, $a_{18}$. Thus, Sergey is able to identify $a_{17}, a_{18}$, and $a_{19}$, and thence the residue of $N$ modulo $17 \\cdot 18 \\cdot 19=5814>5000$, by the Chinese Remainder Theorem. This means that the given range contains a single number satisfying all congruences, and Sergey achieves his goal.\n\n\n\nTo show that 1 move is not sufficient, let $M=\\operatorname{lcm}(1,2, \\ldots, 10)=2^{3} \\cdot 3^{2} \\cdot 5 \\cdot 7=2520$. Notice that $M$ is divisible by the greatest common divisor of every pair of distinct positive integers not exceeding 20. Let Sergey provide the set $S=\\left\\{s_{1}, s_{2}, \\ldots, s_{k}\\right\\}$. We show that there exist pairwise distinct positive integers $b_{1}, b_{2}, \\ldots, b_{k}$ such that $1 \\equiv b_{i}\\left(\\bmod s_{i}\\right)$ and $M+1 \\equiv b_{i-1}\\left(\\bmod s_{i}\\right)$ (indices are reduced modulo $k$ ). Thus, if in response Xenia provides the set $\\left\\{b_{1}, b_{2}, \\ldots, b_{k}\\right\\}$, then Sergey will be unable to distinguish 1 from $M+1$, as desired.\n\n\n\nTo this end, notice that, for each $i$, the numbers of the form $1+m s_{i}, m \\in \\mathbb{Z}$, cover all residues modulo $s_{i+1}$ which are congruent to $1(\\equiv M+1)$ modulo $\\operatorname{gcd}\\left(s_{i}, s_{i+1}\\right) \\mid M$. Xenia can therefore choose a positive integer $b_{i}$ such that $b_{i} \\equiv 1\\left(\\bmod s_{i}\\right)$ and $b_{i} \\equiv M+1\\left(\\bmod s_{i+1}\\right)$. Clearly, such choices can be performed so as to make the $b_{i}$ pairwise distinct, as required."], 'final_answer': ['2'], 'is_multiple_answer': False, 'unit': None, 'answer_type': 'Numerical', 'error': None}

  0%|          | 0/84 [00:00<?, ?it/s][ALet's think step by step and enclose the reasoning process within <think> and </think> tags.
The final result in the answer MUST BE within \boxed{}.

Xenia and Sergey play the following game. Xenia thinks of a positive integer $N$ not exceeding 5000. Then she fixes 20 distinct positive integers $a_{1}, a_{2}, \ldots, a_{20}$ such that, for each $k=1,2, \ldots, 20$, the numbers $N$ and $a_{k}$ are congruent modulo $k$. By a move, Sergey tells Xenia a set $S$ of positive integers not exceeding 20 , and she tells him back the set $\left\{a_{k}: k \in S\right\}$ without spelling out which number corresponds to which index. How many moves does Sergey need to determine for sure the number Xenia thought of?


 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 39/84 [00:00<00:00, 385.71it/s][A
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 78/84 [00:00<00:00, 366.40it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [00:00<00:00, 372.43it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/672 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 1/672 [00:05<1:04:31,  5.77s/it, est. speed input: 20.28 toks/s, output: 48.88 toks/s][A
Processed prompts:   1%|‚ñè         | 9/672 [00:06<05:35,  1.98it/s, est. speed input: 180.34 toks/s, output: 416.12 toks/s][A
Processed prompts:   3%|‚ñé         | 17/672 [00:07<03:46,  2.89it/s, est. speed input: 308.31 toks/s, output: 630.26 toks/s][A
Processed prompts:   4%|‚ñé         | 25/672 [00:12<05:04,  2.12it/s, est. speed input: 277.06 toks/s, output: 628.52 toks/s][A
Processed prompts:   5%|‚ñç         | 33/672 [00:13<03:27,  3.08it/s, est. speed input: 330.30 toks/s, output: 921.72 toks/s][A
Processed prompts:   6%|‚ñå         | 41/672 [00:14<02:38,  3.97it/s, est. speed input: 371.42 toks/s, output: 1181.80 toks/s][A
Processed prompts:   7%|‚ñã         | 49/672 [00:15<02:04,  5.02it/s, est. speed input: 417.81 toks/s, output: 1444.80 toks/s][A
Processed prompts:   8%|‚ñä         | 57/672 [00:17<02:18,  4.45it/s, est. speed input: 404.98 toks/s, output: 1560.36 toks/s][A
Processed prompts:  10%|‚ñâ         | 65/672 [00:18<01:46,  5.69it/s, est. speed input: 458.42 toks/s, output: 1827.89 toks/s][A
Processed prompts:  11%|‚ñà         | 73/672 [00:20<02:13,  4.48it/s, est. speed input: 467.41 toks/s, output: 1884.23 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 81/672 [00:22<02:03,  4.78it/s, est. speed input: 484.26 toks/s, output: 2060.60 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 89/672 [00:23<02:00,  4.82it/s, est. speed input: 497.47 toks/s, output: 2199.89 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 94/672 [00:26<02:31,  3.83it/s, est. speed input: 481.59 toks/s, output: 2128.34 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 97/672 [00:28<03:07,  3.06it/s, est. speed input: 459.62 toks/s, output: 2050.52 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 105/672 [00:31<03:17,  2.88it/s, est. speed input: 436.88 toks/s, output: 2033.55 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 113/672 [00:31<02:18,  4.05it/s, est. speed input: 476.92 toks/s, output: 2110.51 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 121/672 [00:33<02:05,  4.40it/s, est. speed input: 493.80 toks/s, output: 2175.15 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 129/672 [00:48<06:57,  1.30it/s, est. speed input: 364.92 toks/s, output: 1692.93 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 137/672 [00:55<07:07,  1.25it/s, est. speed input: 340.46 toks/s, output: 1710.89 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 145/672 [01:08<09:07,  1.04s/it, est. speed input: 300.52 toks/s, output: 1606.08 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 153/672 [01:39<16:39,  1.92s/it, est. speed input: 212.79 toks/s, output: 1279.00 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 154/672 [01:39<15:48,  1.83s/it, est. speed input: 214.48 toks/s, output: 1308.32 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñç       | 166/672 [01:39<08:15,  1.02it/s, est. speed input: 235.96 toks/s, output: 1673.58 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñã       | 177/672 [01:40<05:05,  1.62it/s, est. speed input: 256.13 toks/s, output: 2005.66 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 230/672 [01:40<01:16,  5.75it/s, est. speed input: 323.75 toks/s, output: 3620.94 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 238/672 [01:42<01:16,  5.65it/s, est. speed input: 337.10 toks/s, output: 3653.21 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñã      | 244/672 [01:45<01:33,  4.60it/s, est. speed input: 336.05 toks/s, output: 3703.53 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 248/672 [01:45<01:28,  4.81it/s, est. speed input: 339.41 toks/s, output: 3801.86 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 251/672 [01:51<02:51,  2.46it/s, est. speed input: 324.00 toks/s, output: 3606.51 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 254/672 [01:52<02:30,  2.77it/s, est. speed input: 327.51 toks/s, output: 3623.68 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 256/672 [01:52<02:33,  2.71it/s, est. speed input: 327.69 toks/s, output: 3650.46 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 258/672 [01:53<02:17,  3.00it/s, est. speed input: 329.74 toks/s, output: 3697.84 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñä      | 260/672 [01:53<02:05,  3.29it/s, est. speed input: 331.52 toks/s, output: 3742.11 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 262/672 [01:53<01:45,  3.88it/s, est. speed input: 333.84 toks/s, output: 3792.44 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 264/672 [01:55<02:57,  2.30it/s, est. speed input: 330.05 toks/s, output: 3729.23 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 272/672 [01:55<01:22,  4.87it/s, est. speed input: 340.94 toks/s, output: 3759.68 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 278/672 [01:57<01:41,  3.86it/s, est. speed input: 342.05 toks/s, output: 3720.79 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 280/672 [01:58<01:36,  4.06it/s, est. speed input: 343.01 toks/s, output: 3719.29 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 287/672 [02:00<01:34,  4.07it/s, est. speed input: 344.91 toks/s, output: 3699.81 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 296/672 [02:00<00:57,  6.53it/s, est. speed input: 352.95 toks/s, output: 3757.62 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 298/672 [02:00<00:53,  7.04it/s, est. speed input: 354.83 toks/s, output: 3804.74 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 300/672 [02:00<00:51,  7.28it/s, est. speed input: 356.42 toks/s, output: 3848.68 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 302/672 [02:00<00:46,  7.90it/s, est. speed input: 358.20 toks/s, output: 3894.63 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 304/672 [02:01<00:44,  8.35it/s, est. speed input: 360.55 toks/s, output: 3919.33 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 306/672 [02:03<02:25,  2.51it/s, est. speed input: 356.84 toks/s, output: 3855.19 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 308/672 [02:03<01:58,  3.07it/s, est. speed input: 360.55 toks/s, output: 3871.70 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 310/672 [02:04<01:35,  3.80it/s, est. speed input: 364.35 toks/s, output: 3889.28 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 312/672 [02:05<02:29,  2.40it/s, est. speed input: 363.49 toks/s, output: 3855.14 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 320/672 [02:06<01:27,  4.03it/s, est. speed input: 375.18 toks/s, output: 3869.51 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 321/672 [02:07<01:31,  3.84it/s, est. speed input: 375.45 toks/s, output: 3882.27 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 322/672 [02:07<01:24,  4.14it/s, est. speed input: 376.53 toks/s, output: 3903.27 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 323/672 [02:07<01:16,  4.54it/s, est. speed input: 377.60 toks/s, output: 3924.27 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 324/672 [02:07<01:13,  4.73it/s, est. speed input: 378.47 toks/s, output: 3943.16 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 325/672 [02:07<01:07,  5.10it/s, est. speed input: 379.45 toks/s, output: 3963.05 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 326/672 [02:08<01:16,  4.54it/s, est. speed input: 379.91 toks/s, output: 3977.59 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 328/672 [02:08<00:59,  5.76it/s, est. speed input: 382.04 toks/s, output: 4019.25 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 329/672 [02:10<03:11,  1.79it/s, est. speed input: 377.15 toks/s, output: 3967.96 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 331/672 [02:10<02:04,  2.74it/s, est. speed input: 378.47 toks/s, output: 3982.08 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 332/672 [02:11<03:29,  1.62it/s, est. speed input: 375.77 toks/s, output: 3939.84 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 333/672 [02:13<04:56,  1.14it/s, est. speed input: 371.82 toks/s, output: 3912.10 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 334/672 [02:13<03:53,  1.45it/s, est. speed input: 372.30 toks/s, output: 3930.85 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 335/672 [02:13<03:10,  1.77it/s, est. speed input: 372.58 toks/s, output: 3947.41 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 336/672 [02:14<02:31,  2.22it/s, est. speed input: 373.05 toks/s, output: 3966.06 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 337/672 [02:14<01:58,  2.82it/s, est. speed input: 373.63 toks/s, output: 3985.77 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 338/672 [02:14<01:38,  3.38it/s, est. speed input: 374.09 toks/s, output: 4004.13 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 339/672 [02:14<01:30,  3.67it/s, est. speed input: 374.37 toks/s, output: 4020.54 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 340/672 [02:14<01:25,  3.90it/s, est. speed input: 374.64 toks/s, output: 4036.88 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 341/672 [02:16<03:20,  1.65it/s, est. speed input: 371.50 toks/s, output: 3998.90 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 342/672 [02:16<02:49,  1.95it/s, est. speed input: 371.51 toks/s, output: 3995.09 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 343/672 [02:19<06:02,  1.10s/it, est. speed input: 365.93 toks/s, output: 3934.99 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 344/672 [02:19<05:10,  1.06it/s, est. speed input: 365.03 toks/s, output: 3940.64 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 345/672 [02:19<03:53,  1.40it/s, est. speed input: 365.21 toks/s, output: 3957.90 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 346/672 [02:19<03:00,  1.81it/s, est. speed input: 365.37 toks/s, output: 3974.77 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 347/672 [02:20<02:16,  2.38it/s, est. speed input: 365.71 toks/s, output: 3993.68 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 348/672 [02:20<01:51,  2.91it/s, est. speed input: 365.89 toks/s, output: 4010.80 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 349/672 [02:20<01:37,  3.30it/s, est. speed input: 365.98 toks/s, output: 4026.81 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 350/672 [02:20<01:24,  3.83it/s, est. speed input: 366.17 toks/s, output: 4043.97 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 351/672 [02:20<01:27,  3.66it/s, est. speed input: 366.01 toks/s, output: 4057.13 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 352/672 [02:21<01:38,  3.25it/s, est. speed input: 365.70 toks/s, output: 4049.82 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 353/672 [02:22<02:22,  2.24it/s, est. speed input: 364.49 toks/s, output: 4033.22 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 354/672 [02:22<02:19,  2.28it/s, est. speed input: 364.20 toks/s, output: 4026.39 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 355/672 [02:23<03:35,  1.47it/s, est. speed input: 361.82 toks/s, output: 3997.20 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 356/672 [02:26<06:11,  1.17s/it, est. speed input: 357.00 toks/s, output: 3954.57 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 357/672 [02:26<04:37,  1.14it/s, est. speed input: 357.46 toks/s, output: 3970.29 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 358/672 [02:26<03:30,  1.49it/s, est. speed input: 357.97 toks/s, output: 3986.44 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 359/672 [02:26<02:44,  1.91it/s, est. speed input: 358.46 toks/s, output: 4002.33 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 360/672 [02:26<02:18,  2.26it/s, est. speed input: 358.79 toks/s, output: 4016.42 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 362/672 [02:27<01:33,  3.33it/s, est. speed input: 360.01 toks/s, output: 4050.83 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 363/672 [02:27<01:30,  3.40it/s, est. speed input: 360.27 toks/s, output: 4064.15 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 364/672 [02:27<01:32,  3.31it/s, est. speed input: 361.00 toks/s, output: 4061.58 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 365/672 [02:30<04:27,  1.15it/s, est. speed input: 355.91 toks/s, output: 4002.12 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 366/672 [02:44<24:09,  4.74s/it, est. speed input: 325.33 toks/s, output: 3664.18 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 368/672 [02:45<13:42,  2.71s/it, est. speed input: 326.93 toks/s, output: 3694.02 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 370/672 [02:45<08:39,  1.72s/it, est. speed input: 328.50 toks/s, output: 3723.57 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 371/672 [02:45<07:01,  1.40s/it, est. speed input: 329.15 toks/s, output: 3736.67 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 372/672 [02:45<05:30,  1.10s/it, est. speed input: 330.00 toks/s, output: 3752.11 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 373/672 [02:46<04:24,  1.13it/s, est. speed input: 330.64 toks/s, output: 3765.19 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 374/672 [02:55<15:26,  3.11s/it, est. speed input: 313.79 toks/s, output: 3583.64 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 375/672 [02:55<11:23,  2.30s/it, est. speed input: 314.10 toks/s, output: 3597.60 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 376/672 [02:55<08:25,  1.71s/it, est. speed input: 314.39 toks/s, output: 3611.21 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 377/672 [02:55<06:14,  1.27s/it, est. speed input: 314.68 toks/s, output: 3624.76 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 378/672 [02:56<04:40,  1.05it/s, est. speed input: 314.97 toks/s, output: 3638.42 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 379/672 [02:56<03:33,  1.37it/s, est. speed input: 315.27 toks/s, output: 3652.02 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 380/672 [02:56<02:42,  1.80it/s, est. speed input: 315.64 toks/s, output: 3666.50 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 381/672 [02:56<02:14,  2.16it/s, est. speed input: 315.82 toks/s, output: 3678.82 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 382/672 [02:59<05:38,  1.17s/it, est. speed input: 311.50 toks/s, output: 3637.92 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 383/672 [02:59<04:06,  1.17it/s, est. speed input: 311.97 toks/s, output: 3652.83 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 384/672 [02:59<03:10,  1.51it/s, est. speed input: 312.25 toks/s, output: 3665.56 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 385/672 [03:00<02:27,  1.94it/s, est. speed input: 312.61 toks/s, output: 3679.16 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 386/672 [03:00<01:55,  2.47it/s, est. speed input: 313.01 toks/s, output: 3693.20 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 387/672 [03:00<01:32,  3.09it/s, est. speed input: 313.43 toks/s, output: 3707.49 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 388/672 [03:00<01:19,  3.58it/s, est. speed input: 313.78 toks/s, output: 3720.87 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 389/672 [03:00<01:11,  3.95it/s, est. speed input: 314.10 toks/s, output: 3733.92 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 390/672 [03:07<10:15,  2.18s/it, est. speed input: 304.30 toks/s, output: 3616.98 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 391/672 [03:12<14:00,  2.99s/it, est. speed input: 297.65 toks/s, output: 3541.22 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 392/672 [03:12<10:01,  2.15s/it, est. speed input: 298.44 toks/s, output: 3553.96 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 393/672 [03:12<07:13,  1.55s/it, est. speed input: 299.24 toks/s, output: 3566.80 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 394/672 [03:12<05:13,  1.13s/it, est. speed input: 300.10 toks/s, output: 3580.25 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 395/672 [03:12<03:58,  1.16it/s, est. speed input: 300.80 toks/s, output: 3591.82 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 396/672 [03:13<02:55,  1.57it/s, est. speed input: 301.68 toks/s, output: 3605.59 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 397/672 [03:13<02:17,  2.00it/s, est. speed input: 302.46 toks/s, output: 3618.15 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 398/672 [03:13<01:47,  2.55it/s, est. speed input: 303.30 toks/s, output: 3631.40 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 399/672 [03:15<04:10,  1.09it/s, est. speed input: 300.72 toks/s, output: 3607.19 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 400/672 [03:18<06:33,  1.45s/it, est. speed input: 297.67 toks/s, output: 3573.87 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 401/672 [03:18<04:44,  1.05s/it, est. speed input: 298.49 toks/s, output: 3587.13 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 402/672 [03:18<03:36,  1.25it/s, est. speed input: 299.18 toks/s, output: 3598.68 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 404/672 [03:18<02:07,  2.09it/s, est. speed input: 300.90 toks/s, output: 3625.95 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 405/672 [03:21<04:14,  1.05it/s, est. speed input: 298.32 toks/s, output: 3598.13 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 406/672 [03:21<03:17,  1.35it/s, est. speed input: 299.11 toks/s, output: 3610.79 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 408/672 [03:23<04:06,  1.07it/s, est. speed input: 297.13 toks/s, output: 3598.85 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 409/672 [03:23<03:16,  1.34it/s, est. speed input: 297.43 toks/s, output: 3611.37 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 410/672 [03:24<02:41,  1.63it/s, est. speed input: 297.64 toks/s, output: 3622.58 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 411/672 [03:24<02:08,  2.03it/s, est. speed input: 297.94 toks/s, output: 3634.98 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 412/672 [03:24<01:43,  2.51it/s, est. speed input: 298.24 toks/s, output: 3647.35 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 413/672 [03:27<04:59,  1.16s/it, est. speed input: 294.56 toks/s, output: 3607.72 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 416/672 [03:27<02:27,  1.73it/s, est. speed input: 296.47 toks/s, output: 3647.14 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 417/672 [03:27<02:04,  2.05it/s, est. speed input: 297.03 toks/s, output: 3659.35 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 419/672 [03:28<01:28,  2.86it/s, est. speed input: 298.24 toks/s, output: 3684.85 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 420/672 [03:28<01:19,  3.18it/s, est. speed input: 298.75 toks/s, output: 3696.38 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 421/672 [03:28<01:35,  2.62it/s, est. speed input: 298.57 toks/s, output: 3700.38 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 422/672 [03:29<01:25,  2.93it/s, est. speed input: 298.95 toks/s, output: 3711.15 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 423/672 [03:29<01:12,  3.44it/s, est. speed input: 299.44 toks/s, output: 3723.24 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 425/672 [03:29<00:49,  4.97it/s, est. speed input: 300.59 toks/s, output: 3749.67 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 428/672 [03:30<01:01,  4.00it/s, est. speed input: 301.15 toks/s, output: 3767.35 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 429/672 [03:30<01:12,  3.35it/s, est. speed input: 301.02 toks/s, output: 3772.77 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 431/672 [03:31<01:02,  3.87it/s, est. speed input: 301.60 toks/s, output: 3774.24 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 434/672 [03:31<00:56,  4.22it/s, est. speed input: 302.16 toks/s, output: 3777.44 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 435/672 [03:32<01:08,  3.45it/s, est. speed input: 302.33 toks/s, output: 3782.07 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 443/672 [03:32<00:30,  7.46it/s, est. speed input: 308.86 toks/s, output: 3890.03 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 451/672 [03:33<00:19, 11.08it/s, est. speed input: 312.09 toks/s, output: 3998.95 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 491/672 [03:34<00:09, 18.90it/s, est. speed input: 334.36 toks/s, output: 4529.14 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 493/672 [03:35<00:09, 18.05it/s, est. speed input: 336.55 toks/s, output: 4553.50 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 495/672 [03:35<00:10, 17.32it/s, est. speed input: 338.76 toks/s, output: 4578.28 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 497/672 [03:35<00:11, 14.99it/s, est. speed input: 340.75 toks/s, output: 4600.13 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 499/672 [03:35<00:12, 14.22it/s, est. speed input: 342.93 toks/s, output: 4624.42 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 501/672 [03:39<00:58,  2.92it/s, est. speed input: 337.79 toks/s, output: 4544.86 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 509/672 [03:40<00:33,  4.83it/s, est. speed input: 341.61 toks/s, output: 4564.21 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 511/672 [03:40<00:30,  5.24it/s, est. speed input: 343.29 toks/s, output: 4588.40 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 513/672 [03:40<00:28,  5.61it/s, est. speed input: 344.36 toks/s, output: 4602.73 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 517/672 [03:40<00:20,  7.59it/s, est. speed input: 346.49 toks/s, output: 4629.41 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 520/672 [03:41<00:21,  6.91it/s, est. speed input: 347.93 toks/s, output: 4638.87 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 528/672 [03:41<00:14, 10.08it/s, est. speed input: 354.08 toks/s, output: 4647.07 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 530/672 [03:42<00:18,  7.55it/s, est. speed input: 354.15 toks/s, output: 4641.31 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 532/672 [03:45<00:55,  2.51it/s, est. speed input: 351.62 toks/s, output: 4600.85 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 533/672 [03:45<00:53,  2.61it/s, est. speed input: 352.53 toks/s, output: 4609.14 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 534/672 [03:45<00:48,  2.87it/s, est. speed input: 353.64 toks/s, output: 4620.09 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 535/672 [03:46<00:45,  3.03it/s, est. speed input: 354.59 toks/s, output: 4628.91 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 537/672 [03:46<00:35,  3.77it/s, est. speed input: 356.43 toks/s, output: 4640.59 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 538/672 [03:46<00:39,  3.42it/s, est. speed input: 356.39 toks/s, output: 4635.03 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 546/672 [03:48<00:25,  4.91it/s, est. speed input: 359.01 toks/s, output: 4635.30 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 547/672 [03:48<00:27,  4.50it/s, est. speed input: 359.73 toks/s, output: 4641.14 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 549/672 [03:48<00:22,  5.37it/s, est. speed input: 360.40 toks/s, output: 4648.42 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 550/672 [03:49<00:39,  3.05it/s, est. speed input: 359.86 toks/s, output: 4638.18 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 551/672 [03:50<00:46,  2.58it/s, est. speed input: 359.24 toks/s, output: 4629.88 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 552/672 [03:52<01:19,  1.52it/s, est. speed input: 357.99 toks/s, output: 4598.54 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 554/672 [03:52<00:58,  2.02it/s, est. speed input: 359.39 toks/s, output: 4601.39 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 557/672 [03:53<00:46,  2.47it/s, est. speed input: 360.12 toks/s, output: 4612.09 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 558/672 [03:54<01:02,  1.83it/s, est. speed input: 359.69 toks/s, output: 4592.36 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 559/672 [03:55<00:59,  1.89it/s, est. speed input: 360.05 toks/s, output: 4596.38 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 560/672 [03:55<00:49,  2.24it/s, est. speed input: 360.89 toks/s, output: 4606.60 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 561/672 [03:56<01:14,  1.50it/s, est. speed input: 359.68 toks/s, output: 4585.38 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 562/672 [03:57<01:05,  1.67it/s, est. speed input: 360.14 toks/s, output: 4590.79 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 563/672 [03:59<01:48,  1.01it/s, est. speed input: 357.67 toks/s, output: 4555.57 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 571/672 [03:59<00:28,  3.60it/s, est. speed input: 362.92 toks/s, output: 4595.97 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 572/672 [04:02<00:54,  1.83it/s, est. speed input: 360.12 toks/s, output: 4560.15 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 573/672 [04:04<01:19,  1.24it/s, est. speed input: 357.69 toks/s, output: 4529.01 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 574/672 [04:04<01:11,  1.36it/s, est. speed input: 357.71 toks/s, output: 4527.81 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 582/672 [04:10<01:04,  1.39it/s, est. speed input: 354.32 toks/s, output: 4475.82 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 583/672 [04:13<01:25,  1.04it/s, est. speed input: 351.01 toks/s, output: 4434.93 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 584/672 [04:15<01:31,  1.04s/it, est. speed input: 349.69 toks/s, output: 4419.15 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 585/672 [04:16<01:29,  1.03s/it, est. speed input: 349.25 toks/s, output: 4414.50 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 586/672 [04:16<01:14,  1.16it/s, est. speed input: 349.98 toks/s, output: 4424.65 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 587/672 [04:17<01:23,  1.02it/s, est. speed input: 348.91 toks/s, output: 4411.94 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 588/672 [04:18<01:22,  1.01it/s, est. speed input: 347.97 toks/s, output: 4406.58 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 589/672 [04:19<01:14,  1.11it/s, est. speed input: 347.54 toks/s, output: 4407.58 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 590/672 [04:20<01:22,  1.01s/it, est. speed input: 346.23 toks/s, output: 4397.26 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 591/672 [04:21<01:31,  1.13s/it, est. speed input: 344.58 toks/s, output: 4384.47 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 593/672 [04:22<00:52,  1.52it/s, est. speed input: 345.02 toks/s, output: 4406.15 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 596/672 [04:22<00:27,  2.77it/s, est. speed input: 345.71 toks/s, output: 4439.14 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 598/672 [04:23<00:29,  2.52it/s, est. speed input: 345.03 toks/s, output: 4446.49 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 599/672 [04:24<00:40,  1.82it/s, est. speed input: 343.82 toks/s, output: 4435.69 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 600/672 [04:26<01:02,  1.15it/s, est. speed input: 341.61 toks/s, output: 4412.47 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 604/672 [04:26<00:28,  2.42it/s, est. speed input: 343.37 toks/s, output: 4456.48 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 606/672 [04:29<00:44,  1.47it/s, est. speed input: 340.73 toks/s, output: 4434.17 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 607/672 [04:29<00:41,  1.56it/s, est. speed input: 340.54 toks/s, output: 4438.24 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 608/672 [04:30<00:37,  1.69it/s, est. speed input: 340.53 toks/s, output: 4443.14 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 609/672 [04:30<00:32,  1.94it/s, est. speed input: 340.72 toks/s, output: 4450.62 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 610/672 [04:30<00:28,  2.17it/s, est. speed input: 340.85 toks/s, output: 4457.33 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 611/672 [04:31<00:28,  2.13it/s, est. speed input: 340.72 toks/s, output: 4460.57 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 612/672 [04:31<00:27,  2.16it/s, est. speed input: 340.65 toks/s, output: 4464.55 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 614/672 [04:33<00:43,  1.33it/s, est. speed input: 338.88 toks/s, output: 4450.17 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 615/672 [04:34<00:36,  1.58it/s, est. speed input: 339.11 toks/s, output: 4457.17 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 616/672 [04:34<00:28,  1.98it/s, est. speed input: 339.52 toks/s, output: 4466.46 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 618/672 [04:34<00:17,  3.05it/s, est. speed input: 340.43 toks/s, output: 4486.20 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 619/672 [04:34<00:16,  3.16it/s, est. speed input: 340.63 toks/s, output: 4492.85 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 621/672 [04:35<00:20,  2.46it/s, est. speed input: 340.39 toks/s, output: 4497.38 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 622/672 [04:36<00:18,  2.66it/s, est. speed input: 340.43 toks/s, output: 4504.10 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 624/672 [04:36<00:19,  2.52it/s, est. speed input: 340.11 toks/s, output: 4512.28 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 625/672 [04:37<00:22,  2.11it/s, est. speed input: 339.69 toks/s, output: 4511.11 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 626/672 [04:38<00:20,  2.23it/s, est. speed input: 339.76 toks/s, output: 4516.26 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 627/672 [04:38<00:17,  2.56it/s, est. speed input: 340.00 toks/s, output: 4523.71 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 629/672 [04:38<00:11,  3.61it/s, est. speed input: 340.73 toks/s, output: 4541.91 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 630/672 [04:39<00:21,  1.98it/s, est. speed input: 339.94 toks/s, output: 4532.32 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 632/672 [04:40<00:19,  2.06it/s, est. speed input: 340.33 toks/s, output: 4539.52 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 633/672 [04:41<00:23,  1.63it/s, est. speed input: 339.79 toks/s, output: 4533.30 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 635/672 [04:41<00:15,  2.36it/s, est. speed input: 340.98 toks/s, output: 4551.07 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 636/672 [04:42<00:13,  2.59it/s, est. speed input: 341.90 toks/s, output: 4557.96 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 638/672 [04:42<00:09,  3.64it/s, est. speed input: 344.11 toks/s, output: 4576.66 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 640/672 [04:43<00:10,  3.09it/s, est. speed input: 345.53 toks/s, output: 4584.95 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 641/672 [04:44<00:14,  2.16it/s, est. speed input: 344.65 toks/s, output: 4579.43 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 647/672 [04:44<00:04,  5.44it/s, est. speed input: 346.57 toks/s, output: 4642.07 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 649/672 [04:44<00:03,  6.12it/s, est. speed input: 347.18 toks/s, output: 4660.56 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 672/672 [04:44<00:00,  2.36it/s, est. speed input: 364.93 toks/s, output: 4908.82 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/672 [00:00<?, ?it/s][A
Evaluate:  13%|‚ñà‚ñé        | 89/672 [00:00<00:02, 233.82it/s][A
Evaluate:  17%|‚ñà‚ñã        | 113/672 [00:00<00:03, 151.55it/s][A
Evaluate:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 417/672 [00:00<00:00, 590.02it/s][A
Evaluate:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 489/672 [00:01<00:00, 349.62it/s][A
Evaluate:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 601/672 [00:01<00:00, 389.68it/s][A
Evaluate:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 651/672 [00:02<00:00, 259.89it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 672/672 [00:02<00:00, 316.02it/s]
{'num_samples': 84, 'num_scores': 672, 'timeout_samples': 0, 'empty_samples': 3, 'acc': 6.0, 'total_acc': 7.291666666666667, 'pass_at_k_percent': {'1': 7.3, '8': 9.5}, 'pass_at_k_valid_counts': {'1': 84, '8': 84}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_results/noise_rlvr_1_5b_128batchsize_deepscaler_v2_think-boxed/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g2/olympiadbench/test_think-boxed_-1_seed0_t0.0_s0_e-1_part0.jsonl
[2025-12-04 00:13:46] ‚úì B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g2/olympiadbench  acc=6.0 pass_at_k={'1': 7.3, '8': 9.5}
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g2:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [06:16<03:25, 205.96s/ds][Info] Sharding enabled: Process 0/8 handling range [0:62]
==================================================
data: math500  ,remain samples: 62
{'idx': 0, 'problem': 'Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\\theta),$ where $r > 0$ and $0 \\le \\theta < 2 \\pi.$', 'solution': 'We have that $r = \\sqrt{0^2 + 3^2} = 3.$  Also, if we draw the line connecting the origin and $(0,3),$ this line makes an angle of $\\frac{\\pi}{2}$ with the positive $x$-axis.\n\n[asy]\nunitsize(0.8 cm);\n\ndraw((-0.5,0)--(3.5,0));\ndraw((0,-0.5)--(0,3.5));\ndraw(arc((0,0),3,0,90),red,Arrow(6));\n\ndot((0,3), red);\nlabel("$(0,3)$", (0,3), W);\ndot((3,0), red);\n[/asy]\n\nTherefore, the polar coordinates are $\\boxed{\\left( 3, \\frac{\\pi}{2} \\right)}.$', 'answer': '\\left( 3, \\frac{\\pi}{2} \\right)', 'subject': 'Precalculus', 'level': 2, 'unique_id': 'test/precalculus/807.json'}

  0%|          | 0/62 [00:00<?, ?it/s][ALet's think step by step and enclose the reasoning process within <think> and </think> tags.
The final result in the answer MUST BE within \boxed{}.

Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$


 35%|‚ñà‚ñà‚ñà‚ñå      | 22/62 [00:00<00:00, 218.57it/s][A
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 45/62 [00:00<00:00, 223.91it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 62/62 [00:00<00:00, 222.56it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/496 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 1/496 [00:02<18:31,  2.24s/it, est. speed input: 33.86 toks/s, output: 51.68 toks/s][A
Processed prompts:   2%|‚ñè         | 9/496 [00:03<02:18,  3.51it/s, est. speed input: 215.03 toks/s, output: 344.74 toks/s][A
Processed prompts:   5%|‚ñå         | 25/496 [00:03<00:45, 10.38it/s, est. speed input: 453.49 toks/s, output: 1034.17 toks/s][A
Processed prompts:   7%|‚ñã         | 33/496 [00:03<00:37, 12.48it/s, est. speed input: 508.45 toks/s, output: 1299.72 toks/s][A
Processed prompts:   8%|‚ñä         | 41/496 [00:04<00:29, 15.45it/s, est. speed input: 585.69 toks/s, output: 1592.30 toks/s][A
Processed prompts:  10%|‚ñâ         | 49/496 [00:05<00:41, 10.84it/s, est. speed input: 559.63 toks/s, output: 1554.27 toks/s][A
Processed prompts:  11%|‚ñà‚ñè        | 57/496 [00:05<00:32, 13.38it/s, est. speed input: 721.24 toks/s, output: 1846.17 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 73/496 [00:06<00:21, 19.82it/s, est. speed input: 838.05 toks/s, output: 2459.98 toks/s][A
Processed prompts:  16%|‚ñà‚ñã        | 81/496 [00:06<00:25, 16.33it/s, est. speed input: 898.14 toks/s, output: 2536.29 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 97/496 [00:06<00:15, 25.32it/s, est. speed input: 1231.54 toks/s, output: 3224.83 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 104/496 [00:07<00:15, 25.31it/s, est. speed input: 1263.74 toks/s, output: 3423.03 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 112/496 [00:07<00:17, 22.38it/s, est. speed input: 1260.11 toks/s, output: 3567.33 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 120/496 [00:08<00:17, 21.44it/s, est. speed input: 1281.60 toks/s, output: 3743.06 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñç       | 123/496 [00:08<00:17, 21.30it/s, est. speed input: 1306.97 toks/s, output: 3816.27 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 129/496 [00:08<00:15, 24.37it/s, est. speed input: 1376.54 toks/s, output: 4025.38 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 137/496 [00:08<00:16, 21.49it/s, est. speed input: 1412.32 toks/s, output: 4171.86 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 145/496 [00:09<00:23, 15.15it/s, est. speed input: 1411.96 toks/s, output: 4120.99 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 153/496 [00:10<00:21, 15.96it/s, est. speed input: 1409.67 toks/s, output: 4115.87 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 161/496 [00:10<00:17, 19.63it/s, est. speed input: 1433.71 toks/s, output: 4397.37 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 177/496 [00:11<00:20, 15.45it/s, est. speed input: 1380.50 toks/s, output: 4452.29 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 185/496 [00:11<00:17, 18.23it/s, est. speed input: 1412.74 toks/s, output: 4632.16 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 195/496 [00:12<00:12, 23.98it/s, est. speed input: 1520.96 toks/s, output: 4804.39 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 201/496 [00:12<00:13, 22.23it/s, est. speed input: 1639.92 toks/s, output: 4935.06 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 209/496 [00:12<00:11, 25.98it/s, est. speed input: 1721.57 toks/s, output: 5194.63 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 217/496 [00:12<00:11, 25.19it/s, est. speed input: 1728.66 toks/s, output: 5231.76 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 225/496 [00:13<00:14, 19.29it/s, est. speed input: 1727.78 toks/s, output: 5312.73 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 233/496 [00:14<00:14, 17.64it/s, est. speed input: 1705.32 toks/s, output: 5342.52 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 241/496 [00:14<00:11, 21.87it/s, est. speed input: 1719.80 toks/s, output: 5395.27 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 249/496 [00:14<00:13, 17.78it/s, est. speed input: 1674.07 toks/s, output: 5229.95 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 256/496 [00:15<00:14, 17.01it/s, est. speed input: 1667.71 toks/s, output: 5223.83 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 263/496 [00:15<00:15, 15.24it/s, est. speed input: 1639.31 toks/s, output: 5179.18 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 271/496 [00:16<00:12, 18.66it/s, est. speed input: 1659.30 toks/s, output: 5277.25 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 279/496 [00:16<00:11, 18.97it/s, est. speed input: 1656.13 toks/s, output: 5377.29 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 287/496 [00:17<00:12, 17.40it/s, est. speed input: 1661.16 toks/s, output: 5335.43 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 303/496 [00:17<00:07, 27.18it/s, est. speed input: 1723.28 toks/s, output: 5591.31 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 311/496 [00:18<00:12, 14.96it/s, est. speed input: 1640.20 toks/s, output: 5295.19 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 319/496 [00:18<00:09, 17.80it/s, est. speed input: 1643.69 toks/s, output: 5344.59 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 323/496 [00:19<00:09, 17.39it/s, est. speed input: 1639.74 toks/s, output: 5400.05 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 338/496 [00:19<00:09, 17.32it/s, est. speed input: 1635.86 toks/s, output: 5544.57 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 345/496 [00:20<00:09, 16.43it/s, est. speed input: 1619.36 toks/s, output: 5528.49 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 369/496 [00:21<00:05, 21.96it/s, est. speed input: 1659.58 toks/s, output: 5757.86 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 384/496 [00:21<00:04, 27.77it/s, est. speed input: 1740.84 toks/s, output: 6210.89 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 388/496 [00:23<00:09, 11.93it/s, est. speed input: 1610.64 toks/s, output: 5886.04 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 392/496 [00:42<00:08, 11.93it/s, est. speed input: 1621.79 toks/s, output: 6065.49 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 393/496 [00:56<01:59,  1.16s/it, est. speed input: 667.29 toks/s, output: 2530.60 toks/s] [A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 401/496 [01:17<02:27,  1.55s/it, est. speed input: 495.52 toks/s, output: 2092.61 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 425/496 [01:17<00:51,  1.39it/s, est. speed input: 537.78 toks/s, output: 3036.26 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 449/496 [01:20<00:21,  2.15it/s, est. speed input: 548.87 toks/s, output: 3827.26 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 457/496 [01:22<00:16,  2.37it/s, est. speed input: 545.19 toks/s, output: 4048.98 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 473/496 [01:22<00:06,  3.48it/s, est. speed input: 562.63 toks/s, output: 4632.84 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 481/496 [01:25<00:04,  3.34it/s, est. speed input: 551.99 toks/s, output: 4768.55 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 485/496 [01:25<00:02,  3.75it/s, est. speed input: 554.18 toks/s, output: 4905.51 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 489/496 [01:26<00:01,  4.09it/s, est. speed input: 554.39 toks/s, output: 5018.26 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 493/496 [01:26<00:00,  4.79it/s, est. speed input: 557.43 toks/s, output: 5137.94 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 496/496 [01:26<00:00,  5.51it/s, est. speed input: 559.76 toks/s, output: 5228.19 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 496/496 [01:26<00:00,  5.74it/s, est. speed input: 559.76 toks/s, output: 5228.19 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/496 [00:00<?, ?it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 496/496 [00:00<00:00, 12936.93it/s]
{'num_samples': 62, 'num_scores': 496, 'timeout_samples': 0, 'empty_samples': 1, 'acc': 53.2, 'total_acc': 53.0241935483871, 'pass_at_k_percent': {'1': 53.0, '8': 53.2}, 'pass_at_k_valid_counts': {'1': 62, '8': 62}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_results/noise_rlvr_1_5b_128batchsize_deepscaler_v2_think-boxed/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g2/math500/test_think-boxed_-1_seed0_t0.0_s0_e-1_part0.jsonl
[2025-12-04 00:15:14] ‚úì B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g2/math500  acc=53.2 pass_at_k={'1': 53.0, '8': 53.2}
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [07:44<00:00, 152.20s/ds]B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [07:44<00:00, 154.83s/ds]
[2025-12-04 00:15:14] ‚úÖ ÂÆåÊàêÔºöB_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300Ôºàg1+g2 Áº∫Â§±Êï∞ÊçÆÈõÜÂ∑≤Ë°•ÂÖ®Ôºâ
[2025-12-04 00:15:14] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_313
INFO 12-04 00:15:14 [config.py:717] This model supports multiple tasks: {'classify', 'score', 'generate', 'reward', 'embed'}. Defaulting to 'generate'.
INFO 12-04 00:15:14 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-04 00:15:14 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-04 00:15:20 [__init__.py:239] Automatically detected platform cuda.
INFO 12-04 00:15:27 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-04 00:15:27 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fb8abf77070>
INFO 12-04 00:15:48 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-04 00:15:48 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-04 00:15:48 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-04 00:15:48 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-04 00:15:48 [core.py:396] EngineCore failed to start.
ERROR 12-04 00:15:48 [core.py:396] Traceback (most recent call last):
ERROR 12-04 00:15:48 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-04 00:15:48 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-04 00:15:48 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-04 00:15:48 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-04 00:15:48 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-04 00:15:48 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-04 00:15:48 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-04 00:15:48 [core.py:396]     self._init_executor()
ERROR 12-04 00:15:48 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-04 00:15:48 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-04 00:15:48 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-04 00:15:48 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-04 00:15:48 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-04 00:15:48 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:15:48 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-04 00:15:48 [core.py:396]     self.model_runner.load_model()
ERROR 12-04 00:15:48 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-04 00:15:48 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-04 00:15:48 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-04 00:15:48 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-04 00:15:48 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-04 00:15:48 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-04 00:15:48 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-04 00:15:48 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-04 00:15:48 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-04 00:15:48 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-04 00:15:48 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-04 00:15:48 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-04 00:15:48 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-04 00:15:48 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-04 00:15:48 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-04 00:15:48 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-04 00:15:48 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-04 00:15:48 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-04 00:15:48 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-04 00:15:48 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-04 00:15:48 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-04 00:15:48 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-04 00:15:48 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
ERROR 12-04 00:15:48 [core.py:396]     self.self_attn = LlamaAttention(
ERROR 12-04 00:15:48 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
ERROR 12-04 00:15:48 [core.py:396]     self.qkv_proj = QKVParallelLinear(
ERROR 12-04 00:15:48 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
ERROR 12-04 00:15:48 [core.py:396]     super().__init__(input_size=input_size,
ERROR 12-04 00:15:48 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
ERROR 12-04 00:15:48 [core.py:396]     self.quant_method.create_weights(
ERROR 12-04 00:15:48 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-04 00:15:48 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-04 00:15:48 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-04 00:15:48 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:15:48 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3513093 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
    self.self_attn = LlamaAttention(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
    self.qkv_proj = QKVParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
    super().__init__(input_size=input_size,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3513093 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fbb5f96c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7fbb5f915b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7fbb1088e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7fbb5fd45b78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7fbb5fd4620e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7fbb5fd5cb0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7fbb5fd48329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7fbb57e864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7fbb575a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7fbb575a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x55c169cddc04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x55c169c6a2a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x55c169c6abbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x55c169c6ac83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x55c169cddb85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x55c169d49c3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x55c169d4cf1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x55c169c6bc98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x55c169daac30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x55c169dd0407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x55c169dd0634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x55c169dd0718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x55c169dd075b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x55c169dd0972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x55c169dd6f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x55c169dd71ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x55c169dd7469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7fbb60afad90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7fbb60afae40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x55c169d422d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-04 00:15:50] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-04 00:15:50] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_100
INFO 12-04 00:15:50 [config.py:717] This model supports multiple tasks: {'classify', 'score', 'generate', 'reward', 'embed'}. Defaulting to 'generate'.
INFO 12-04 00:15:50 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-04 00:15:50 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-04 00:15:56 [__init__.py:239] Automatically detected platform cuda.
INFO 12-04 00:16:02 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_100', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_100', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_100, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-04 00:16:02 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f6a4e652500>
INFO 12-04 00:16:23 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-04 00:16:23 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-04 00:16:23 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-04 00:16:23 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_100...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-04 00:16:23 [core.py:396] EngineCore failed to start.
ERROR 12-04 00:16:23 [core.py:396] Traceback (most recent call last):
ERROR 12-04 00:16:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-04 00:16:23 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-04 00:16:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-04 00:16:23 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-04 00:16:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-04 00:16:23 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-04 00:16:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-04 00:16:23 [core.py:396]     self._init_executor()
ERROR 12-04 00:16:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-04 00:16:23 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-04 00:16:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-04 00:16:23 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-04 00:16:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-04 00:16:23 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:16:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-04 00:16:23 [core.py:396]     self.model_runner.load_model()
ERROR 12-04 00:16:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-04 00:16:23 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-04 00:16:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-04 00:16:23 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-04 00:16:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-04 00:16:23 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-04 00:16:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-04 00:16:23 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-04 00:16:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-04 00:16:23 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-04 00:16:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-04 00:16:23 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-04 00:16:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-04 00:16:23 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-04 00:16:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-04 00:16:23 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-04 00:16:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-04 00:16:23 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-04 00:16:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-04 00:16:23 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-04 00:16:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-04 00:16:23 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-04 00:16:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
ERROR 12-04 00:16:23 [core.py:396]     self.self_attn = LlamaAttention(
ERROR 12-04 00:16:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
ERROR 12-04 00:16:23 [core.py:396]     self.qkv_proj = QKVParallelLinear(
ERROR 12-04 00:16:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
ERROR 12-04 00:16:23 [core.py:396]     super().__init__(input_size=input_size,
ERROR 12-04 00:16:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
ERROR 12-04 00:16:23 [core.py:396]     self.quant_method.create_weights(
ERROR 12-04 00:16:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-04 00:16:23 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-04 00:16:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-04 00:16:23 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:16:23 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3514037 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
    self.self_attn = LlamaAttention(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
    self.qkv_proj = QKVParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
    super().__init__(input_size=input_size,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3514037 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f6d0216c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f6d02115b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f6cb2c8e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f6d02520b78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f6d0252120e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7f6d02537b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f6d02523329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f6cfa2864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f6cf99a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f6cf99a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x55afd6f5ec04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x55afd6eeb2a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x55afd6eebbbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x55afd6eebc83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x55afd6f5eb85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x55afd6fcac3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x55afd6fcdf1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x55afd6eecc98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x55afd702bc30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x55afd7051407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x55afd7051634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x55afd7051718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x55afd705175b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x55afd7051972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x55afd7057f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x55afd70581ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x55afd7058469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f6d0301cd90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f6d0301ce40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x55afd6fc32d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-04 00:16:25] ‚ö† Ê®°Âûã B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct__global_step_100 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-04 00:16:25] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_200
INFO 12-04 00:16:25 [config.py:717] This model supports multiple tasks: {'classify', 'score', 'generate', 'reward', 'embed'}. Defaulting to 'generate'.
INFO 12-04 00:16:25 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-04 00:16:25 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-04 00:16:31 [__init__.py:239] Automatically detected platform cuda.
INFO 12-04 00:16:37 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-04 00:16:38 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fda3d2bebc0>
INFO 12-04 00:16:48 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-04 00:16:48 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-04 00:16:48 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-04 00:16:48 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-04 00:16:49 [core.py:396] EngineCore failed to start.
ERROR 12-04 00:16:49 [core.py:396] Traceback (most recent call last):
ERROR 12-04 00:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-04 00:16:49 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-04 00:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-04 00:16:49 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-04 00:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-04 00:16:49 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-04 00:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-04 00:16:49 [core.py:396]     self._init_executor()
ERROR 12-04 00:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-04 00:16:49 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-04 00:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-04 00:16:49 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-04 00:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-04 00:16:49 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-04 00:16:49 [core.py:396]     self.model_runner.load_model()
ERROR 12-04 00:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-04 00:16:49 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-04 00:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-04 00:16:49 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-04 00:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-04 00:16:49 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-04 00:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-04 00:16:49 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-04 00:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-04 00:16:49 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-04 00:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-04 00:16:49 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-04 00:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-04 00:16:49 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-04 00:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-04 00:16:49 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-04 00:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-04 00:16:49 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-04 00:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-04 00:16:49 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-04 00:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-04 00:16:49 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-04 00:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
ERROR 12-04 00:16:49 [core.py:396]     self.self_attn = LlamaAttention(
ERROR 12-04 00:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
ERROR 12-04 00:16:49 [core.py:396]     self.qkv_proj = QKVParallelLinear(
ERROR 12-04 00:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
ERROR 12-04 00:16:49 [core.py:396]     super().__init__(input_size=input_size,
ERROR 12-04 00:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
ERROR 12-04 00:16:49 [core.py:396]     self.quant_method.create_weights(
ERROR 12-04 00:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-04 00:16:49 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-04 00:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-04 00:16:49 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:16:49 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3515231 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
    self.self_attn = LlamaAttention(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
    self.qkv_proj = QKVParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
    super().__init__(input_size=input_size,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3515231 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fdcf0f6c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7fdcf0f15b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7fdca1a8e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7fdcf1341b78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7fdcf134220e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7fdcf1358b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7fdcf1344329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7fdce90864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7fdce87a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7fdce87a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x55f9eece2c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x55f9eec6f2a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x55f9eec6fbbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x55f9eec6fc83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x55f9eece2b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x55f9eed4ec3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x55f9eed51f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x55f9eec70c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x55f9eedafc30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x55f9eedd5407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x55f9eedd5634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x55f9eedd5718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x55f9eedd575b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x55f9eedd5972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x55f9eeddbf60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x55f9eeddc1ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x55f9eeddc469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7fdcf1e3dd90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7fdcf1e3de40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x55f9eed472d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-04 00:16:50] ‚ö† Ê®°Âûã B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-04 00:16:50] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_300
INFO 12-04 00:16:50 [config.py:717] This model supports multiple tasks: {'classify', 'score', 'generate', 'reward', 'embed'}. Defaulting to 'generate'.
INFO 12-04 00:16:50 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-04 00:16:50 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-04 00:16:56 [__init__.py:239] Automatically detected platform cuda.
INFO 12-04 00:17:03 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_300', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_300', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_300, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-04 00:17:03 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fe6f660e4d0>
INFO 12-04 00:17:14 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-04 00:17:14 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-04 00:17:14 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-04 00:17:14 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_300...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-04 00:17:14 [core.py:396] EngineCore failed to start.
ERROR 12-04 00:17:14 [core.py:396] Traceback (most recent call last):
ERROR 12-04 00:17:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-04 00:17:14 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-04 00:17:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-04 00:17:14 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-04 00:17:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-04 00:17:14 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-04 00:17:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-04 00:17:14 [core.py:396]     self._init_executor()
ERROR 12-04 00:17:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-04 00:17:14 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-04 00:17:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-04 00:17:14 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-04 00:17:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-04 00:17:14 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:17:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-04 00:17:14 [core.py:396]     self.model_runner.load_model()
ERROR 12-04 00:17:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-04 00:17:14 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-04 00:17:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-04 00:17:14 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-04 00:17:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-04 00:17:14 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-04 00:17:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-04 00:17:14 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-04 00:17:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-04 00:17:14 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-04 00:17:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-04 00:17:14 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-04 00:17:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-04 00:17:14 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-04 00:17:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-04 00:17:14 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-04 00:17:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-04 00:17:14 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-04 00:17:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-04 00:17:14 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-04 00:17:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-04 00:17:14 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-04 00:17:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
ERROR 12-04 00:17:14 [core.py:396]     self.self_attn = LlamaAttention(
ERROR 12-04 00:17:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
ERROR 12-04 00:17:14 [core.py:396]     self.qkv_proj = QKVParallelLinear(
ERROR 12-04 00:17:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
ERROR 12-04 00:17:14 [core.py:396]     super().__init__(input_size=input_size,
ERROR 12-04 00:17:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
ERROR 12-04 00:17:14 [core.py:396]     self.quant_method.create_weights(
ERROR 12-04 00:17:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-04 00:17:14 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-04 00:17:14 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-04 00:17:14 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:17:14 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3515988 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
    self.self_attn = LlamaAttention(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
    self.qkv_proj = QKVParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
    super().__init__(input_size=input_size,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3515988 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fe9a9d6c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7fe9a9d15b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7fe95ac8e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7fe9aa16bb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7fe9aa16c20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7fe9aa182b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7fe9aa16e329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7fe9a22864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7fe9a19a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7fe9a19a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x561364ab9c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x561364a462a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x561364a46bbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x561364a46c83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x561364ab9b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x561364b25c3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x561364b28f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x561364a47c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x561364b86c30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x561364bac407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x561364bac634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x561364bac718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x561364bac75b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x561364bac972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x561364bb2f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x561364bb31ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x561364bb3469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7fe9aafb3d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7fe9aafb3e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x561364b1e2d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-04 00:17:15] ‚ö† Ê®°Âûã B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct__global_step_300 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-04 00:17:15] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_313
INFO 12-04 00:17:15 [config.py:717] This model supports multiple tasks: {'classify', 'score', 'generate', 'reward', 'embed'}. Defaulting to 'generate'.
INFO 12-04 00:17:15 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-04 00:17:15 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-04 00:17:21 [__init__.py:239] Automatically detected platform cuda.
INFO 12-04 00:17:27 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-04 00:17:28 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f4cc661f2e0>
INFO 12-04 00:17:38 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-04 00:17:38 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-04 00:17:38 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-04 00:17:38 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-04 00:17:39 [core.py:396] EngineCore failed to start.
ERROR 12-04 00:17:39 [core.py:396] Traceback (most recent call last):
ERROR 12-04 00:17:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-04 00:17:39 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-04 00:17:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-04 00:17:39 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-04 00:17:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-04 00:17:39 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-04 00:17:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-04 00:17:39 [core.py:396]     self._init_executor()
ERROR 12-04 00:17:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-04 00:17:39 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-04 00:17:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-04 00:17:39 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-04 00:17:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-04 00:17:39 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:17:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-04 00:17:39 [core.py:396]     self.model_runner.load_model()
ERROR 12-04 00:17:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-04 00:17:39 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-04 00:17:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-04 00:17:39 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-04 00:17:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-04 00:17:39 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-04 00:17:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-04 00:17:39 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-04 00:17:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-04 00:17:39 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-04 00:17:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-04 00:17:39 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-04 00:17:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-04 00:17:39 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-04 00:17:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-04 00:17:39 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-04 00:17:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-04 00:17:39 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-04 00:17:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-04 00:17:39 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-04 00:17:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-04 00:17:39 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-04 00:17:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
ERROR 12-04 00:17:39 [core.py:396]     self.self_attn = LlamaAttention(
ERROR 12-04 00:17:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
ERROR 12-04 00:17:39 [core.py:396]     self.qkv_proj = QKVParallelLinear(
ERROR 12-04 00:17:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
ERROR 12-04 00:17:39 [core.py:396]     super().__init__(input_size=input_size,
ERROR 12-04 00:17:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
ERROR 12-04 00:17:39 [core.py:396]     self.quant_method.create_weights(
ERROR 12-04 00:17:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-04 00:17:39 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-04 00:17:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-04 00:17:39 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:17:39 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3516917 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
    self.self_attn = LlamaAttention(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
    self.qkv_proj = QKVParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
    super().__init__(input_size=input_size,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3516917 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f4f79f6c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f4f79f15b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f4f2ae8e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f4f7a36bb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f4f7a36c20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7f4f7a382b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f4f7a36e329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f4f724864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f4f71ba5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f4f71ba64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x5646fa09fc04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x5646fa02c2a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x5646fa02cbbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x5646fa02cc83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x5646fa09fb85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x5646fa10bc3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x5646fa10ef1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x5646fa02dc98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x5646fa16cc30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x5646fa192407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x5646fa192634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x5646fa192718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x5646fa19275b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x5646fa192972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x5646fa198f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x5646fa1991ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x5646fa199469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f4f7b195d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f4f7b195e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x5646fa1042d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-04 00:17:40] ‚ö† Ê®°Âûã B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-04 00:17:40] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_100
INFO 12-04 00:17:40 [config.py:717] This model supports multiple tasks: {'classify', 'score', 'generate', 'reward', 'embed'}. Defaulting to 'generate'.
INFO 12-04 00:17:40 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-04 00:17:40 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-04 00:17:46 [__init__.py:239] Automatically detected platform cuda.
INFO 12-04 00:17:52 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_100', speculative_config=None, tokenizer='/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_100', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_100, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-04 00:17:52 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fe064c66d10>
INFO 12-04 00:18:13 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-04 00:18:13 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-04 00:18:13 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-04 00:18:13 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_100...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-04 00:18:13 [core.py:396] EngineCore failed to start.
ERROR 12-04 00:18:13 [core.py:396] Traceback (most recent call last):
ERROR 12-04 00:18:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-04 00:18:13 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-04 00:18:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-04 00:18:13 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-04 00:18:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-04 00:18:13 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-04 00:18:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-04 00:18:13 [core.py:396]     self._init_executor()
ERROR 12-04 00:18:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-04 00:18:13 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-04 00:18:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-04 00:18:13 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-04 00:18:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-04 00:18:13 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:18:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-04 00:18:13 [core.py:396]     self.model_runner.load_model()
ERROR 12-04 00:18:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-04 00:18:13 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-04 00:18:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-04 00:18:13 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-04 00:18:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-04 00:18:13 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-04 00:18:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-04 00:18:13 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-04 00:18:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-04 00:18:13 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-04 00:18:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-04 00:18:13 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-04 00:18:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-04 00:18:13 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-04 00:18:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-04 00:18:13 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-04 00:18:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-04 00:18:13 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-04 00:18:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-04 00:18:13 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-04 00:18:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-04 00:18:13 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-04 00:18:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
ERROR 12-04 00:18:13 [core.py:396]     self.self_attn = LlamaAttention(
ERROR 12-04 00:18:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
ERROR 12-04 00:18:13 [core.py:396]     self.qkv_proj = QKVParallelLinear(
ERROR 12-04 00:18:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
ERROR 12-04 00:18:13 [core.py:396]     super().__init__(input_size=input_size,
ERROR 12-04 00:18:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
ERROR 12-04 00:18:13 [core.py:396]     self.quant_method.create_weights(
ERROR 12-04 00:18:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-04 00:18:13 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-04 00:18:13 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-04 00:18:13 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:18:13 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3517700 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
    self.self_attn = LlamaAttention(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
    self.qkv_proj = QKVParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
    super().__init__(input_size=input_size,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3517700 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fe31876c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7fe318715b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7fe2c928e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7fe318b2fb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7fe318b3020e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7fe318b46b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7fe318b32329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7fe3108864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7fe30ffa5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7fe30ffa64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x5573c36ffc04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x5573c368c2a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x5573c368cbbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x5573c368cc83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x5573c36ffb85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x5573c376bc3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x5573c376ef1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x5573c368dc98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x5573c37ccc30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x5573c37f2407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x5573c37f2634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x5573c37f2718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x5573c37f275b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x5573c37f2972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x5573c37f8f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x5573c37f91ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x5573c37f9469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7fe31962bd90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7fe31962be40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x5573c37642d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-04 00:18:15] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_200
[2025-12-04 00:18:15] ‚ö† Ê®°Âûã C_llm_verifier_grpo_Llama-3.2-3B-Instruct__global_step_100 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
INFO 12-04 00:18:15 [config.py:717] This model supports multiple tasks: {'classify', 'score', 'generate', 'reward', 'embed'}. Defaulting to 'generate'.
INFO 12-04 00:18:15 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-04 00:18:15 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-04 00:18:21 [__init__.py:239] Automatically detected platform cuda.
INFO 12-04 00:18:27 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-04 00:18:27 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f19b2c09ea0>
INFO 12-04 00:18:43 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-04 00:18:43 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-04 00:18:43 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-04 00:18:43 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-04 00:18:43 [core.py:396] EngineCore failed to start.
ERROR 12-04 00:18:43 [core.py:396] Traceback (most recent call last):
ERROR 12-04 00:18:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-04 00:18:43 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-04 00:18:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-04 00:18:43 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-04 00:18:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-04 00:18:43 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-04 00:18:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-04 00:18:43 [core.py:396]     self._init_executor()
ERROR 12-04 00:18:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-04 00:18:43 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-04 00:18:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-04 00:18:43 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-04 00:18:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-04 00:18:43 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:18:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-04 00:18:43 [core.py:396]     self.model_runner.load_model()
ERROR 12-04 00:18:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-04 00:18:43 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-04 00:18:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-04 00:18:43 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-04 00:18:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-04 00:18:43 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-04 00:18:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-04 00:18:43 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-04 00:18:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-04 00:18:43 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-04 00:18:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-04 00:18:43 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-04 00:18:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-04 00:18:43 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-04 00:18:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-04 00:18:43 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-04 00:18:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-04 00:18:43 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-04 00:18:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-04 00:18:43 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-04 00:18:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-04 00:18:43 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-04 00:18:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
ERROR 12-04 00:18:43 [core.py:396]     self.self_attn = LlamaAttention(
ERROR 12-04 00:18:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
ERROR 12-04 00:18:43 [core.py:396]     self.qkv_proj = QKVParallelLinear(
ERROR 12-04 00:18:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
ERROR 12-04 00:18:43 [core.py:396]     super().__init__(input_size=input_size,
ERROR 12-04 00:18:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
ERROR 12-04 00:18:43 [core.py:396]     self.quant_method.create_weights(
ERROR 12-04 00:18:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-04 00:18:43 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-04 00:18:43 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-04 00:18:43 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:18:43 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3518758 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
    self.self_attn = LlamaAttention(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
    self.qkv_proj = QKVParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
    super().__init__(input_size=input_size,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3518758 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f1c6656c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f1c66515b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f1c1748e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f1c6696bb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f1c6696c20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7f1c66982b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f1c6696e329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f1c5ea864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f1c5e1a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f1c5e1a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x55d212f98c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x55d212f252a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x55d212f25bbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x55d212f25c83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x55d212f98b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x55d213004c3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x55d213007f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x55d212f26c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x55d213065c30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x55d21308b407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x55d21308b634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x55d21308b718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x55d21308b75b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x55d21308b972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x55d213091f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x55d2130921ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x55d213092469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f1c6776fd90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f1c6776fe40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x55d212ffd2d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-04 00:18:45] ‚ö† Ê®°Âûã C_llm_verifier_grpo_Llama-3.2-3B-Instruct__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-04 00:18:45] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_300
INFO 12-04 00:18:45 [config.py:717] This model supports multiple tasks: {'classify', 'score', 'generate', 'reward', 'embed'}. Defaulting to 'generate'.
INFO 12-04 00:18:45 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-04 00:18:45 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-04 00:18:50 [__init__.py:239] Automatically detected platform cuda.
INFO 12-04 00:18:57 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_300', speculative_config=None, tokenizer='/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_300', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_300, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-04 00:18:57 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f246437e500>
INFO 12-04 00:19:07 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-04 00:19:07 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-04 00:19:07 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-04 00:19:08 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_300...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-04 00:19:08 [core.py:396] EngineCore failed to start.
ERROR 12-04 00:19:08 [core.py:396] Traceback (most recent call last):
ERROR 12-04 00:19:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-04 00:19:08 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-04 00:19:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-04 00:19:08 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-04 00:19:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-04 00:19:08 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-04 00:19:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-04 00:19:08 [core.py:396]     self._init_executor()
ERROR 12-04 00:19:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-04 00:19:08 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-04 00:19:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-04 00:19:08 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-04 00:19:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-04 00:19:08 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:19:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-04 00:19:08 [core.py:396]     self.model_runner.load_model()
ERROR 12-04 00:19:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-04 00:19:08 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-04 00:19:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-04 00:19:08 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-04 00:19:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-04 00:19:08 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-04 00:19:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-04 00:19:08 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-04 00:19:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-04 00:19:08 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-04 00:19:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-04 00:19:08 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-04 00:19:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-04 00:19:08 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-04 00:19:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-04 00:19:08 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-04 00:19:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-04 00:19:08 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-04 00:19:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-04 00:19:08 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-04 00:19:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-04 00:19:08 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-04 00:19:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
ERROR 12-04 00:19:08 [core.py:396]     self.self_attn = LlamaAttention(
ERROR 12-04 00:19:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
ERROR 12-04 00:19:08 [core.py:396]     self.qkv_proj = QKVParallelLinear(
ERROR 12-04 00:19:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
ERROR 12-04 00:19:08 [core.py:396]     super().__init__(input_size=input_size,
ERROR 12-04 00:19:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
ERROR 12-04 00:19:08 [core.py:396]     self.quant_method.create_weights(
ERROR 12-04 00:19:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-04 00:19:08 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-04 00:19:08 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-04 00:19:08 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:19:08 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3519728 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
    self.self_attn = LlamaAttention(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
    self.qkv_proj = QKVParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
    super().__init__(input_size=input_size,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3519728 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f2717b6c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f2717b15b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f26c8a8e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f2717f6bb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f2717f6c20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7f2717f82b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f2717f6e329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f27100864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f270f7a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f270f7a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x55dbe2450c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x55dbe23dd2a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x55dbe23ddbbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x55dbe23ddc83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x55dbe2450b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x55dbe24bcc3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x55dbe24bff1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x55dbe23dec98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x55dbe251dc30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x55dbe2543407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x55dbe2543634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x55dbe2543718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x55dbe254375b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x55dbe2543972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x55dbe2549f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x55dbe254a1ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x55dbe254a469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f2718d44d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f2718d44e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x55dbe24b52d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-04 00:19:09] ‚ö† Ê®°Âûã C_llm_verifier_grpo_Llama-3.2-3B-Instruct__global_step_300 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-04 00:19:09] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_313
INFO 12-04 00:19:09 [config.py:717] This model supports multiple tasks: {'classify', 'score', 'generate', 'reward', 'embed'}. Defaulting to 'generate'.
INFO 12-04 00:19:09 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-04 00:19:09 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-04 00:19:15 [__init__.py:239] Automatically detected platform cuda.
INFO 12-04 00:19:22 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-04 00:19:22 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f80890524a0>
INFO 12-04 00:19:32 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-04 00:19:32 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-04 00:19:32 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-04 00:19:32 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-04 00:19:33 [core.py:396] EngineCore failed to start.
ERROR 12-04 00:19:33 [core.py:396] Traceback (most recent call last):
ERROR 12-04 00:19:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-04 00:19:33 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-04 00:19:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-04 00:19:33 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-04 00:19:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-04 00:19:33 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-04 00:19:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-04 00:19:33 [core.py:396]     self._init_executor()
ERROR 12-04 00:19:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-04 00:19:33 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-04 00:19:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-04 00:19:33 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-04 00:19:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-04 00:19:33 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:19:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-04 00:19:33 [core.py:396]     self.model_runner.load_model()
ERROR 12-04 00:19:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-04 00:19:33 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-04 00:19:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-04 00:19:33 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-04 00:19:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-04 00:19:33 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-04 00:19:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-04 00:19:33 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-04 00:19:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-04 00:19:33 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-04 00:19:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-04 00:19:33 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-04 00:19:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-04 00:19:33 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-04 00:19:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-04 00:19:33 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-04 00:19:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-04 00:19:33 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-04 00:19:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-04 00:19:33 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-04 00:19:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-04 00:19:33 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-04 00:19:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
ERROR 12-04 00:19:33 [core.py:396]     self.self_attn = LlamaAttention(
ERROR 12-04 00:19:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
ERROR 12-04 00:19:33 [core.py:396]     self.qkv_proj = QKVParallelLinear(
ERROR 12-04 00:19:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
ERROR 12-04 00:19:33 [core.py:396]     super().__init__(input_size=input_size,
ERROR 12-04 00:19:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
ERROR 12-04 00:19:33 [core.py:396]     self.quant_method.create_weights(
ERROR 12-04 00:19:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-04 00:19:33 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-04 00:19:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-04 00:19:33 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:19:33 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3520360 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
    self.self_attn = LlamaAttention(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
    self.qkv_proj = QKVParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
    super().__init__(input_size=input_size,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3520360 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f833cd6c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f833cd15b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f82ed88e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f833d107b78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f833d10820e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7f833d11eb0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f833d10a329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f8334e864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f83345a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f83345a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x563e4ef22c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x563e4eeaf2a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x563e4eeafbbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x563e4eeafc83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x563e4ef22b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x563e4ef8ec3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x563e4ef91f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x563e4eeb0c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x563e4efefc30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x563e4f015407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x563e4f015634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x563e4f015718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x563e4f01575b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x563e4f015972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x563e4f01bf60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x563e4f01c1ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x563e4f01c469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f833dc03d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f833dc03e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x563e4ef872d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-04 00:19:34] ‚ö† Ê®°Âûã C_llm_verifier_grpo_Llama-3.2-3B-Instruct__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-04 00:19:34] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_100
INFO 12-04 00:19:34 [config.py:717] This model supports multiple tasks: {'classify', 'score', 'generate', 'reward', 'embed'}. Defaulting to 'generate'.
INFO 12-04 00:19:34 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-04 00:19:34 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-04 00:19:40 [__init__.py:239] Automatically detected platform cuda.
INFO 12-04 00:19:46 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_100', speculative_config=None, tokenizer='/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_100', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_100, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-04 00:19:47 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f7add81a4a0>
INFO 12-04 00:20:02 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-04 00:20:02 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-04 00:20:02 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-04 00:20:02 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_100...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-04 00:20:03 [core.py:396] EngineCore failed to start.
ERROR 12-04 00:20:03 [core.py:396] Traceback (most recent call last):
ERROR 12-04 00:20:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-04 00:20:03 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-04 00:20:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-04 00:20:03 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-04 00:20:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-04 00:20:03 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-04 00:20:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-04 00:20:03 [core.py:396]     self._init_executor()
ERROR 12-04 00:20:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-04 00:20:03 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-04 00:20:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-04 00:20:03 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-04 00:20:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-04 00:20:03 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:20:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-04 00:20:03 [core.py:396]     self.model_runner.load_model()
ERROR 12-04 00:20:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-04 00:20:03 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-04 00:20:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-04 00:20:03 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-04 00:20:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-04 00:20:03 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-04 00:20:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-04 00:20:03 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-04 00:20:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-04 00:20:03 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-04 00:20:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-04 00:20:03 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-04 00:20:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-04 00:20:03 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-04 00:20:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-04 00:20:03 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-04 00:20:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-04 00:20:03 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-04 00:20:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-04 00:20:03 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-04 00:20:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-04 00:20:03 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-04 00:20:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
ERROR 12-04 00:20:03 [core.py:396]     self.self_attn = LlamaAttention(
ERROR 12-04 00:20:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
ERROR 12-04 00:20:03 [core.py:396]     self.qkv_proj = QKVParallelLinear(
ERROR 12-04 00:20:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
ERROR 12-04 00:20:03 [core.py:396]     super().__init__(input_size=input_size,
ERROR 12-04 00:20:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
ERROR 12-04 00:20:03 [core.py:396]     self.quant_method.create_weights(
ERROR 12-04 00:20:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-04 00:20:03 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-04 00:20:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-04 00:20:03 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:20:03 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3521139 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
    self.self_attn = LlamaAttention(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
    self.qkv_proj = QKVParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
    super().__init__(input_size=input_size,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3521139 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f7d9116c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f7d91115b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f7d4208e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f7d9156bb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f7d9156c20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7f7d91582b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f7d9156e329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f7d896864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f7d88da5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f7d88da64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x5583cbf8ec04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x5583cbf1b2a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x5583cbf1bbbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x5583cbf1bc83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x5583cbf8eb85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x5583cbffac3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x5583cbffdf1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x5583cbf1cc98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x5583cc05bc30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x5583cc081407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x5583cc081634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x5583cc081718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x5583cc08175b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x5583cc081972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x5583cc087f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x5583cc0881ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x5583cc088469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f7d92399d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f7d92399e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x5583cbff32d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-04 00:20:04] ‚ö† Ê®°Âûã D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct__global_step_100 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-04 00:20:04] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_200
INFO 12-04 00:20:04 [config.py:717] This model supports multiple tasks: {'classify', 'score', 'generate', 'reward', 'embed'}. Defaulting to 'generate'.
INFO 12-04 00:20:04 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-04 00:20:04 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-04 00:20:10 [__init__.py:239] Automatically detected platform cuda.
INFO 12-04 00:20:16 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-04 00:20:17 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f85956124a0>
INFO 12-04 00:20:32 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-04 00:20:32 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-04 00:20:32 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-04 00:20:32 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-04 00:20:33 [core.py:396] EngineCore failed to start.
ERROR 12-04 00:20:33 [core.py:396] Traceback (most recent call last):
ERROR 12-04 00:20:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-04 00:20:33 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-04 00:20:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-04 00:20:33 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-04 00:20:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-04 00:20:33 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-04 00:20:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-04 00:20:33 [core.py:396]     self._init_executor()
ERROR 12-04 00:20:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-04 00:20:33 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-04 00:20:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-04 00:20:33 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-04 00:20:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-04 00:20:33 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:20:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-04 00:20:33 [core.py:396]     self.model_runner.load_model()
ERROR 12-04 00:20:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-04 00:20:33 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-04 00:20:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-04 00:20:33 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-04 00:20:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-04 00:20:33 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-04 00:20:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-04 00:20:33 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-04 00:20:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-04 00:20:33 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-04 00:20:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-04 00:20:33 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-04 00:20:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-04 00:20:33 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-04 00:20:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-04 00:20:33 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-04 00:20:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-04 00:20:33 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-04 00:20:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-04 00:20:33 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-04 00:20:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-04 00:20:33 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-04 00:20:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
ERROR 12-04 00:20:33 [core.py:396]     self.self_attn = LlamaAttention(
ERROR 12-04 00:20:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
ERROR 12-04 00:20:33 [core.py:396]     self.qkv_proj = QKVParallelLinear(
ERROR 12-04 00:20:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
ERROR 12-04 00:20:33 [core.py:396]     super().__init__(input_size=input_size,
ERROR 12-04 00:20:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
ERROR 12-04 00:20:33 [core.py:396]     self.quant_method.create_weights(
ERROR 12-04 00:20:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-04 00:20:33 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-04 00:20:33 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-04 00:20:33 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:20:33 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3522195 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
    self.self_attn = LlamaAttention(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
    self.qkv_proj = QKVParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
    super().__init__(input_size=input_size,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3522195 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f884916c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f8849115b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f87f9c8e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f88494d1b78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f88494d220e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7f88494e8b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f88494d4329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f88412864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f88409a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f88409a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x55e924bcdc04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x55e924b5a2a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x55e924b5abbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x55e924b5ac83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x55e924bcdb85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x55e924c39c3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x55e924c3cf1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x55e924b5bc98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x55e924c9ac30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x55e924cc0407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x55e924cc0634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x55e924cc0718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x55e924cc075b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x55e924cc0972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x55e924cc6f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x55e924cc71ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x55e924cc7469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f8849fcdd90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f8849fcde40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x55e924c322d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-04 00:20:34] ‚ö† Ê®°Âûã D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-04 00:20:34] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_300
INFO 12-04 00:20:34 [config.py:717] This model supports multiple tasks: {'classify', 'score', 'generate', 'reward', 'embed'}. Defaulting to 'generate'.
INFO 12-04 00:20:34 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-04 00:20:34 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-04 00:20:40 [__init__.py:239] Automatically detected platform cuda.
INFO 12-04 00:20:47 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_300', speculative_config=None, tokenizer='/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_300', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_300, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-04 00:20:47 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f6a78be9ba0>
INFO 12-04 00:20:57 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-04 00:20:57 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-04 00:20:57 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-04 00:20:58 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_300...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-04 00:20:58 [core.py:396] EngineCore failed to start.
ERROR 12-04 00:20:58 [core.py:396] Traceback (most recent call last):
ERROR 12-04 00:20:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-04 00:20:58 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-04 00:20:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-04 00:20:58 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-04 00:20:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-04 00:20:58 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-04 00:20:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-04 00:20:58 [core.py:396]     self._init_executor()
ERROR 12-04 00:20:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-04 00:20:58 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-04 00:20:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-04 00:20:58 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-04 00:20:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-04 00:20:58 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:20:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-04 00:20:58 [core.py:396]     self.model_runner.load_model()
ERROR 12-04 00:20:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-04 00:20:58 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-04 00:20:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-04 00:20:58 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-04 00:20:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-04 00:20:58 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-04 00:20:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-04 00:20:58 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-04 00:20:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-04 00:20:58 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-04 00:20:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-04 00:20:58 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-04 00:20:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-04 00:20:58 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-04 00:20:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-04 00:20:58 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-04 00:20:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-04 00:20:58 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-04 00:20:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-04 00:20:58 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-04 00:20:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-04 00:20:58 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-04 00:20:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
ERROR 12-04 00:20:58 [core.py:396]     self.self_attn = LlamaAttention(
ERROR 12-04 00:20:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
ERROR 12-04 00:20:58 [core.py:396]     self.qkv_proj = QKVParallelLinear(
ERROR 12-04 00:20:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
ERROR 12-04 00:20:58 [core.py:396]     super().__init__(input_size=input_size,
ERROR 12-04 00:20:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
ERROR 12-04 00:20:58 [core.py:396]     self.quant_method.create_weights(
ERROR 12-04 00:20:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-04 00:20:58 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-04 00:20:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-04 00:20:58 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:20:58 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3523184 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
    self.self_attn = LlamaAttention(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
    self.qkv_proj = QKVParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
    super().__init__(input_size=input_size,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3523184 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f6d2c56c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f6d2c515b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f6cdd48e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f6d2c96bb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f6d2c96c20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7f6d2c982b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f6d2c96e329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f6d24a864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f6d241a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f6d241a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x556708986c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x5567089132a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x556708913bbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x556708913c83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x556708986b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x5567089f2c3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x5567089f5f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x556708914c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x556708a53c30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x556708a79407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x556708a79634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x556708a79718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x556708a7975b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x556708a79972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x556708a7ff60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x556708a801ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x556708a80469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f6d2d766d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f6d2d766e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x5567089eb2d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-04 00:20:59] ‚ö† Ê®°Âûã D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct__global_step_300 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-04 00:20:59] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_313
INFO 12-04 00:20:59 [config.py:717] This model supports multiple tasks: {'classify', 'score', 'generate', 'reward', 'embed'}. Defaulting to 'generate'.
INFO 12-04 00:20:59 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-04 00:20:59 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-04 00:21:06 [__init__.py:239] Automatically detected platform cuda.
INFO 12-04 00:21:12 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-04 00:21:12 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f76d9016bc0>
INFO 12-04 00:21:22 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-04 00:21:22 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-04 00:21:22 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-04 00:21:23 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-04 00:21:23 [core.py:396] EngineCore failed to start.
ERROR 12-04 00:21:23 [core.py:396] Traceback (most recent call last):
ERROR 12-04 00:21:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-04 00:21:23 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-04 00:21:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-04 00:21:23 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-04 00:21:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-04 00:21:23 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-04 00:21:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-04 00:21:23 [core.py:396]     self._init_executor()
ERROR 12-04 00:21:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-04 00:21:23 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-04 00:21:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-04 00:21:23 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-04 00:21:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-04 00:21:23 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:21:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-04 00:21:23 [core.py:396]     self.model_runner.load_model()
ERROR 12-04 00:21:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-04 00:21:23 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-04 00:21:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-04 00:21:23 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-04 00:21:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-04 00:21:23 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-04 00:21:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-04 00:21:23 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-04 00:21:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-04 00:21:23 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-04 00:21:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-04 00:21:23 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-04 00:21:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-04 00:21:23 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-04 00:21:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-04 00:21:23 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-04 00:21:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-04 00:21:23 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-04 00:21:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-04 00:21:23 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-04 00:21:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-04 00:21:23 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-04 00:21:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
ERROR 12-04 00:21:23 [core.py:396]     self.self_attn = LlamaAttention(
ERROR 12-04 00:21:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
ERROR 12-04 00:21:23 [core.py:396]     self.qkv_proj = QKVParallelLinear(
ERROR 12-04 00:21:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
ERROR 12-04 00:21:23 [core.py:396]     super().__init__(input_size=input_size,
ERROR 12-04 00:21:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
ERROR 12-04 00:21:23 [core.py:396]     self.quant_method.create_weights(
ERROR 12-04 00:21:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-04 00:21:23 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-04 00:21:23 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-04 00:21:23 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:21:23 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3524094 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
    self.self_attn = LlamaAttention(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
    self.qkv_proj = QKVParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
    super().__init__(input_size=input_size,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3524094 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f798cb6c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f798cb15b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f793d68e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f798ced1b78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f798ced220e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7f798cee8b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f798ced4329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f7984c864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f79843a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f79843a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x56008b939c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x56008b8c62a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x56008b8c6bbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x56008b8c6c83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x56008b939b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x56008b9a5c3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x56008b9a8f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x56008b8c7c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x56008ba06c30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x56008ba2c407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x56008ba2c634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x56008ba2c718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x56008ba2c75b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x56008ba2c972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x56008ba32f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x56008ba331ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x56008ba33469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f798d9cdd90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f798d9cde40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x56008b99e2d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-04 00:21:25] ‚ö† Ê®°Âûã D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-04 00:21:25] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_100
INFO 12-04 00:21:25 [config.py:717] This model supports multiple tasks: {'classify', 'score', 'generate', 'reward', 'embed'}. Defaulting to 'generate'.
INFO 12-04 00:21:25 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-04 00:21:25 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-04 00:21:30 [__init__.py:239] Automatically detected platform cuda.
INFO 12-04 00:21:37 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_100', speculative_config=None, tokenizer='/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_100', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_100, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-04 00:21:37 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f1538e2d8a0>
INFO 12-04 00:21:57 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-04 00:21:57 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-04 00:21:57 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-04 00:21:57 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_100...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-04 00:21:58 [core.py:396] EngineCore failed to start.
ERROR 12-04 00:21:58 [core.py:396] Traceback (most recent call last):
ERROR 12-04 00:21:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-04 00:21:58 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-04 00:21:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-04 00:21:58 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-04 00:21:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-04 00:21:58 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-04 00:21:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-04 00:21:58 [core.py:396]     self._init_executor()
ERROR 12-04 00:21:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-04 00:21:58 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-04 00:21:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-04 00:21:58 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-04 00:21:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-04 00:21:58 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:21:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-04 00:21:58 [core.py:396]     self.model_runner.load_model()
ERROR 12-04 00:21:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-04 00:21:58 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-04 00:21:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-04 00:21:58 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-04 00:21:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-04 00:21:58 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-04 00:21:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-04 00:21:58 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-04 00:21:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-04 00:21:58 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-04 00:21:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-04 00:21:58 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-04 00:21:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-04 00:21:58 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-04 00:21:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-04 00:21:58 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-04 00:21:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-04 00:21:58 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-04 00:21:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-04 00:21:58 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-04 00:21:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-04 00:21:58 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-04 00:21:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
ERROR 12-04 00:21:58 [core.py:396]     self.self_attn = LlamaAttention(
ERROR 12-04 00:21:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
ERROR 12-04 00:21:58 [core.py:396]     self.qkv_proj = QKVParallelLinear(
ERROR 12-04 00:21:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
ERROR 12-04 00:21:58 [core.py:396]     super().__init__(input_size=input_size,
ERROR 12-04 00:21:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
ERROR 12-04 00:21:58 [core.py:396]     self.quant_method.create_weights(
ERROR 12-04 00:21:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-04 00:21:58 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-04 00:21:58 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-04 00:21:58 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:21:58 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3524860 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
    self.self_attn = LlamaAttention(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
    self.qkv_proj = QKVParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
    super().__init__(input_size=input_size,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3524860 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f17ec76c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f17ec715b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f179d68e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f17ecb6bb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f17ecb6c20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7f17ecb82b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f17ecb6e329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f17e4c864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f17e43a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f17e43a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x5590cfd7cc04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x5590cfd092a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x5590cfd09bbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x5590cfd09c83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x5590cfd7cb85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x5590cfde8c3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x5590cfdebf1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x5590cfd0ac98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x5590cfe49c30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x5590cfe6f407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x5590cfe6f634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x5590cfe6f718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x5590cfe6f75b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x5590cfe6f972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x5590cfe75f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x5590cfe761ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x5590cfe76469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f17ed9aed90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f17ed9aee40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x5590cfde12d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-04 00:21:59] ‚ö† Ê®°Âûã E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct__global_step_100 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-04 00:21:59] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_200
INFO 12-04 00:21:59 [config.py:717] This model supports multiple tasks: {'classify', 'score', 'generate', 'reward', 'embed'}. Defaulting to 'generate'.
INFO 12-04 00:21:59 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-04 00:21:59 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-04 00:22:06 [__init__.py:239] Automatically detected platform cuda.
INFO 12-04 00:22:12 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-04 00:22:12 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f2e5b98d8d0>
INFO 12-04 00:22:28 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-04 00:22:28 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-04 00:22:28 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-04 00:22:28 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-04 00:22:28 [core.py:396] EngineCore failed to start.
ERROR 12-04 00:22:28 [core.py:396] Traceback (most recent call last):
ERROR 12-04 00:22:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-04 00:22:28 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-04 00:22:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-04 00:22:28 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-04 00:22:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-04 00:22:28 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-04 00:22:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-04 00:22:28 [core.py:396]     self._init_executor()
ERROR 12-04 00:22:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-04 00:22:28 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-04 00:22:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-04 00:22:28 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-04 00:22:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-04 00:22:28 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:22:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-04 00:22:28 [core.py:396]     self.model_runner.load_model()
ERROR 12-04 00:22:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-04 00:22:28 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-04 00:22:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-04 00:22:28 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-04 00:22:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-04 00:22:28 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-04 00:22:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-04 00:22:28 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-04 00:22:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-04 00:22:28 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-04 00:22:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-04 00:22:28 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-04 00:22:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-04 00:22:28 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-04 00:22:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-04 00:22:28 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-04 00:22:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-04 00:22:28 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-04 00:22:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-04 00:22:28 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-04 00:22:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-04 00:22:28 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-04 00:22:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
ERROR 12-04 00:22:28 [core.py:396]     self.self_attn = LlamaAttention(
ERROR 12-04 00:22:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
ERROR 12-04 00:22:28 [core.py:396]     self.qkv_proj = QKVParallelLinear(
ERROR 12-04 00:22:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
ERROR 12-04 00:22:28 [core.py:396]     super().__init__(input_size=input_size,
ERROR 12-04 00:22:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
ERROR 12-04 00:22:28 [core.py:396]     self.quant_method.create_weights(
ERROR 12-04 00:22:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-04 00:22:28 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-04 00:22:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-04 00:22:28 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:22:28 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3525935 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
    self.self_attn = LlamaAttention(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
    self.qkv_proj = QKVParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
    super().__init__(input_size=input_size,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3525935 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f310f36c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f310f315b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f30c028e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f310f76bb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f310f76c20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7f310f782b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f310f76e329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f31078864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f3106fa5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f3106fa64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x55f85a2c7c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x55f85a2542a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x55f85a254bbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x55f85a254c83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x55f85a2c7b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x55f85a333c3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x55f85a336f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x55f85a255c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x55f85a394c30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x55f85a3ba407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x55f85a3ba634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x55f85a3ba718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x55f85a3ba75b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x55f85a3ba972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x55f85a3c0f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x55f85a3c11ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x55f85a3c1469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f3110520d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f3110520e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x55f85a32c2d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-04 00:22:29] ‚ö† Ê®°Âûã E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-04 00:22:29] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_300
INFO 12-04 00:22:29 [config.py:717] This model supports multiple tasks: {'classify', 'score', 'generate', 'reward', 'embed'}. Defaulting to 'generate'.
INFO 12-04 00:22:29 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-04 00:22:29 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-04 00:22:36 [__init__.py:239] Automatically detected platform cuda.
INFO 12-04 00:22:42 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_300', speculative_config=None, tokenizer='/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_300', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_300, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-04 00:22:42 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f3d70ae1ba0>
INFO 12-04 00:23:02 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-04 00:23:02 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-04 00:23:02 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-04 00:23:02 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_300...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-04 00:23:03 [core.py:396] EngineCore failed to start.
ERROR 12-04 00:23:03 [core.py:396] Traceback (most recent call last):
ERROR 12-04 00:23:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-04 00:23:03 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-04 00:23:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-04 00:23:03 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-04 00:23:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-04 00:23:03 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-04 00:23:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-04 00:23:03 [core.py:396]     self._init_executor()
ERROR 12-04 00:23:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-04 00:23:03 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-04 00:23:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-04 00:23:03 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-04 00:23:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-04 00:23:03 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:23:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-04 00:23:03 [core.py:396]     self.model_runner.load_model()
ERROR 12-04 00:23:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-04 00:23:03 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-04 00:23:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-04 00:23:03 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-04 00:23:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-04 00:23:03 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-04 00:23:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-04 00:23:03 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-04 00:23:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-04 00:23:03 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-04 00:23:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-04 00:23:03 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-04 00:23:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-04 00:23:03 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-04 00:23:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-04 00:23:03 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-04 00:23:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-04 00:23:03 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-04 00:23:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-04 00:23:03 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-04 00:23:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-04 00:23:03 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-04 00:23:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
ERROR 12-04 00:23:03 [core.py:396]     self.self_attn = LlamaAttention(
ERROR 12-04 00:23:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
ERROR 12-04 00:23:03 [core.py:396]     self.qkv_proj = QKVParallelLinear(
ERROR 12-04 00:23:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
ERROR 12-04 00:23:03 [core.py:396]     super().__init__(input_size=input_size,
ERROR 12-04 00:23:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
ERROR 12-04 00:23:03 [core.py:396]     self.quant_method.create_weights(
ERROR 12-04 00:23:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-04 00:23:03 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-04 00:23:03 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-04 00:23:03 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:23:03 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3526849 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
    self.self_attn = LlamaAttention(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
    self.qkv_proj = QKVParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
    super().__init__(input_size=input_size,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3526849 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f402476c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f4024715b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f3fd528e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f4024b4ab78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f4024b4b20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7f4024b61b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f4024b4d329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f401c8864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f401bfa5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f401bfa64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x56192701dc04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x561926faa2a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x561926faabbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x561926faac83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x56192701db85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x561927089c3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x56192708cf1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x561926fabc98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x5619270eac30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x561927110407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x561927110634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x561927110718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x56192711075b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x561927110972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x561927116f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x5619271171ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x561927117469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f4025646d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f4025646e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x5619270822d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-04 00:23:04] ‚ö† Ê®°Âûã E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct__global_step_300 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-04 00:23:04] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_313
INFO 12-04 00:23:04 [config.py:717] This model supports multiple tasks: {'classify', 'score', 'generate', 'reward', 'embed'}. Defaulting to 'generate'.
INFO 12-04 00:23:04 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-04 00:23:04 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-04 00:23:10 [__init__.py:239] Automatically detected platform cuda.
INFO 12-04 00:23:17 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-04 00:23:17 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f80669424a0>
INFO 12-04 00:23:37 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-04 00:23:37 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-04 00:23:37 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-04 00:23:37 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-04 00:23:38 [core.py:396] EngineCore failed to start.
ERROR 12-04 00:23:38 [core.py:396] Traceback (most recent call last):
ERROR 12-04 00:23:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-04 00:23:38 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-04 00:23:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-04 00:23:38 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-04 00:23:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-04 00:23:38 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-04 00:23:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-04 00:23:38 [core.py:396]     self._init_executor()
ERROR 12-04 00:23:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-04 00:23:38 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-04 00:23:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-04 00:23:38 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-04 00:23:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-04 00:23:38 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:23:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-04 00:23:38 [core.py:396]     self.model_runner.load_model()
ERROR 12-04 00:23:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-04 00:23:38 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-04 00:23:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-04 00:23:38 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-04 00:23:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-04 00:23:38 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-04 00:23:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-04 00:23:38 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-04 00:23:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-04 00:23:38 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-04 00:23:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-04 00:23:38 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-04 00:23:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-04 00:23:38 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-04 00:23:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-04 00:23:38 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-04 00:23:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-04 00:23:38 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-04 00:23:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-04 00:23:38 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-04 00:23:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-04 00:23:38 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-04 00:23:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
ERROR 12-04 00:23:38 [core.py:396]     self.self_attn = LlamaAttention(
ERROR 12-04 00:23:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
ERROR 12-04 00:23:38 [core.py:396]     self.qkv_proj = QKVParallelLinear(
ERROR 12-04 00:23:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
ERROR 12-04 00:23:38 [core.py:396]     super().__init__(input_size=input_size,
ERROR 12-04 00:23:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
ERROR 12-04 00:23:38 [core.py:396]     self.quant_method.create_weights(
ERROR 12-04 00:23:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-04 00:23:38 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-04 00:23:38 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-04 00:23:38 [core.py:396]     return func(*args, **kwargs)
ERROR 12-04 00:23:38 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3527913 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 239, in __init__
    self.self_attn = LlamaAttention(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 141, in __init__
    self.qkv_proj = QKVParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 849, in __init__
    super().__init__(input_size=input_size,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 409, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3496778 has 33.94 GiB memory in use. Process 3527913 has 5.42 GiB memory in use. Of the allocated memory 4.98 GiB is allocated by PyTorch, with 33.67 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f831a56c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f831a515b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f82cb08e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f831a9ccb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f831a9cd20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7f831a9e3b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f831a9cf329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f83126864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f8311da5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f8311da64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x56378dfe9c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x56378df762a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x56378df76bbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x56378df76c83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x56378dfe9b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x56378e055c3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x56378e058f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x56378df77c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x56378e0b6c30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x56378e0dc407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x56378e0dc634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x56378e0dc718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x56378e0dc75b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x56378e0dc972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x56378e0e2f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x56378e0e31ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x56378e0e3469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f831b4c8d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f831b4c8e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x56378e04e2d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-04 00:23:39] ‚ö† Ê®°Âûã E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
