INFO 12-03 19:37:24 [__init__.py:239] Automatically detected platform cuda.
[2025-12-03 19:38:37] ÂèëÁé∞ 7 ‰∏™ run„ÄÇ
[2025-12-03 19:38:38] ‚è≠ Ë∑≥Ëøá base-onlyÔºöLlama-3.2-3B-Instruct
[2025-12-03 19:38:38] ‚è≠ Ë∑≥ËøáÔºöA_rb_oracle_grpo_Llama-3.2-3B-Instruct__global_step_100
[2025-12-03 19:38:38] ‚è≠ Ë∑≥ËøáÔºöA_rb_oracle_grpo_Llama-3.2-3B-Instruct__global_step_200
[2025-12-03 19:38:38] ‚è≠ Ë∑≥ËøáÔºöA_rb_oracle_grpo_Llama-3.2-3B-Instruct__global_step_300
[2025-12-03 19:38:38] ‚è≠ Ë∑≥ËøáÔºöA_rb_oracle_grpo_Llama-3.2-3B-Instruct__global_step_313
[2025-12-03 19:38:38] ‚è≠ Ë∑≥ËøáÔºöB_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100
[2025-12-03 19:38:38] ‚è≠ Ë∑≥ËøáÔºöB_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200
[2025-12-03 19:38:38] ‚è≠ Ë∑≥ËøáÔºöB_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300
[2025-12-03 19:38:38] ‚è≠ Ë∑≥ËøáÔºöB_rb_manual_algo1_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_313
INFO 12-03 19:38:45 [__init__.py:239] Automatically detected platform cuda.
[2025-12-03 19:43:16] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_100
INFO 12-03 19:43:27 [config.py:717] This model supports multiple tasks: {'embed', 'classify', 'reward', 'generate', 'score'}. Defaulting to 'generate'.
INFO 12-03 19:43:27 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-03 19:43:27 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-03 19:43:37 [__init__.py:239] Automatically detected platform cuda.
INFO 12-03 19:43:45 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_100', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_100', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_100, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-03 19:43:51 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f1c66613070>
INFO 12-03 19:44:23 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-03 19:44:23 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-03 19:44:23 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-03 19:44:23 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_100...
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.69s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.00s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.11s/it]

INFO 12-03 19:44:25 [loader.py:458] Loading weights took 2.26 seconds
INFO 12-03 19:44:25 [gpu_model_runner.py:1347] Model loading took 6.0160 GiB and 2.410730 seconds
INFO 12-03 19:44:26 [kv_cache_utils.py:634] GPU KV cache size: 258,240 tokens
INFO 12-03 19:44:26 [kv_cache_utils.py:637] Maximum concurrency for 131,072 tokens per request: 1.97x
INFO 12-03 19:44:26 [core.py:159] init engine (profile, create kv cache, warmup model) took 0.78 seconds
INFO 12-03 19:44:26 [core_client.py:439] Core engine process 0 ready.
[2025-12-03 19:44:26] ‚ÑπÔ∏è  ÂΩìÂâçÂ∑•‰ΩúËäÇÁÇπÂàÜÁâá: 7/8
[2025-12-03 19:44:26] ‚úì Ê®°ÂûãÂ∞±Áª™ÔºåÂºÄÂßãËØÑÊµã B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100ÔºàÂÖ±‰∫´Âêå‰∏Ä LLMÔºå‰ªÖË°•Áº∫Êï∞ÊçÆÈõÜÔºâ
[2025-12-03 19:44:26] ‚ñ∂ B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100/g1  ÂæÖËØÑÊµã=['aime25x8', 'amc23x8', 'aime24x8']  T=0.6  n=8
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100/g1:   0%|          | 0/3 [00:00<?, ?ds/s][Info] Sharding enabled: Process 7/8 handling range [210:240]
==================================================
data: aime25x8  ,remain samples: 30
{'idx': 210, 'problem': 'Find the sum of all integer bases $b>9$ for which $17_{b}$ is a divisor of $97_{b}$.', 'answer': '70'}

  0%|          | 0/30 [00:00<?, ?it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 321.62it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/240 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 1/240 [00:00<03:28,  1.14it/s, est. speed input: 112.14 toks/s, output: 44.62 toks/s][A
Processed prompts:   1%|          | 2/240 [00:02<04:59,  1.26s/it, est. speed input: 156.67 toks/s, output: 63.33 toks/s][A
Processed prompts:   1%|‚ñè         | 3/240 [00:03<04:39,  1.18s/it, est. speed input: 187.37 toks/s, output: 90.53 toks/s][A
Processed prompts:   2%|‚ñè         | 4/240 [00:04<03:42,  1.06it/s, est. speed input: 190.22 toks/s, output: 125.01 toks/s][A
Processed prompts:   2%|‚ñè         | 5/240 [00:04<02:40,  1.47it/s, est. speed input: 216.85 toks/s, output: 165.73 toks/s][A
Processed prompts:   2%|‚ñé         | 6/240 [00:05<03:50,  1.02it/s, est. speed input: 173.28 toks/s, output: 167.14 toks/s][A
Processed prompts:   3%|‚ñé         | 7/240 [00:05<02:45,  1.41it/s, est. speed input: 180.05 toks/s, output: 209.40 toks/s][A
Processed prompts:   3%|‚ñé         | 8/240 [00:06<02:21,  1.64it/s, est. speed input: 188.09 toks/s, output: 241.83 toks/s][A
Processed prompts:   4%|‚ñç         | 9/240 [00:06<01:57,  1.97it/s, est. speed input: 189.84 toks/s, output: 277.35 toks/s][A
Processed prompts:   4%|‚ñç         | 10/240 [00:07<01:58,  1.95it/s, est. speed input: 214.28 toks/s, output: 302.48 toks/s][A
Processed prompts:   5%|‚ñç         | 11/240 [00:07<01:53,  2.01it/s, est. speed input: 212.65 toks/s, output: 329.34 toks/s][A
Processed prompts:   5%|‚ñå         | 12/240 [00:07<01:32,  2.47it/s, est. speed input: 223.14 toks/s, output: 366.05 toks/s][A
Processed prompts:   6%|‚ñå         | 14/240 [00:07<00:55,  4.08it/s, est. speed input: 251.54 toks/s, output: 449.86 toks/s][A
Processed prompts:   6%|‚ñã         | 15/240 [00:08<00:59,  3.80it/s, est. speed input: 271.66 toks/s, output: 477.33 toks/s][A
Processed prompts:   7%|‚ñã         | 16/240 [00:08<00:55,  4.07it/s, est. speed input: 278.44 toks/s, output: 511.01 toks/s][A
Processed prompts:   8%|‚ñä         | 18/240 [00:08<00:48,  4.57it/s, est. speed input: 281.61 toks/s, output: 577.89 toks/s][A
Processed prompts:   8%|‚ñä         | 19/240 [00:09<01:02,  3.53it/s, est. speed input: 293.15 toks/s, output: 591.63 toks/s][A
Processed prompts:   8%|‚ñä         | 20/240 [00:09<00:54,  4.01it/s, est. speed input: 304.95 toks/s, output: 626.73 toks/s][A
Processed prompts:   9%|‚ñâ         | 22/240 [00:09<00:37,  5.84it/s, est. speed input: 339.73 toks/s, output: 706.55 toks/s][A
Processed prompts:  10%|‚ñà         | 25/240 [00:09<00:23,  9.09it/s, est. speed input: 366.75 toks/s, output: 829.01 toks/s][A
Processed prompts:  11%|‚ñà‚ñè        | 27/240 [00:09<00:21, 10.12it/s, est. speed input: 389.55 toks/s, output: 904.79 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 29/240 [00:10<00:19, 10.98it/s, est. speed input: 410.60 toks/s, output: 979.14 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 31/240 [00:10<00:21,  9.92it/s, est. speed input: 436.62 toks/s, output: 1042.96 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 33/240 [00:10<00:18, 11.24it/s, est. speed input: 450.15 toks/s, output: 1118.28 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 35/240 [00:10<00:27,  7.33it/s, est. speed input: 452.76 toks/s, output: 1154.98 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 37/240 [00:11<00:26,  7.76it/s, est. speed input: 476.64 toks/s, output: 1218.77 toks/s][A
Processed prompts:  16%|‚ñà‚ñã        | 39/240 [00:11<00:21,  9.19it/s, est. speed input: 486.76 toks/s, output: 1292.45 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 42/240 [00:11<00:17, 11.29it/s, est. speed input: 518.44 toks/s, output: 1403.15 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 44/240 [00:11<00:19,  9.87it/s, est. speed input: 523.53 toks/s, output: 1457.39 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 46/240 [00:11<00:18, 10.28it/s, est. speed input: 557.14 toks/s, output: 1522.66 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 48/240 [00:12<00:22,  8.41it/s, est. speed input: 560.75 toks/s, output: 1565.51 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 49/240 [00:12<00:25,  7.54it/s, est. speed input: 557.67 toks/s, output: 1583.68 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 53/240 [00:12<00:18,  9.91it/s, est. speed input: 603.92 toks/s, output: 1720.80 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 55/240 [00:13<00:21,  8.60it/s, est. speed input: 601.58 toks/s, output: 1764.27 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 56/240 [00:13<00:23,  7.98it/s, est. speed input: 600.99 toks/s, output: 1784.09 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 62/240 [00:13<00:16, 10.71it/s, est. speed input: 627.84 toks/s, output: 1983.23 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 65/240 [00:13<00:15, 11.42it/s, est. speed input: 656.51 toks/s, output: 2079.64 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 67/240 [00:13<00:14, 12.22it/s, est. speed input: 680.80 toks/s, output: 2147.40 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 69/240 [00:14<00:14, 12.11it/s, est. speed input: 700.08 toks/s, output: 2207.25 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 73/240 [00:14<00:12, 13.55it/s, est. speed input: 733.42 toks/s, output: 2340.19 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà‚ñè      | 75/240 [00:14<00:11, 14.11it/s, est. speed input: 747.09 toks/s, output: 2406.26 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 77/240 [00:14<00:11, 14.06it/s, est. speed input: 759.28 toks/s, output: 2468.08 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 79/240 [00:14<00:12, 12.43it/s, est. speed input: 761.03 toks/s, output: 2517.99 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 81/240 [00:15<00:12, 12.29it/s, est. speed input: 767.86 toks/s, output: 2575.49 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 83/240 [00:15<00:13, 11.72it/s, est. speed input: 775.76 toks/s, output: 2628.78 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 86/240 [00:15<00:12, 12.04it/s, est. speed input: 794.77 toks/s, output: 2716.02 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 90/240 [00:15<00:10, 13.65it/s, est. speed input: 807.85 toks/s, output: 2845.14 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 94/240 [00:15<00:10, 14.26it/s, est. speed input: 835.24 toks/s, output: 2968.68 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 96/240 [00:16<00:09, 14.77it/s, est. speed input: 848.81 toks/s, output: 3032.49 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 98/240 [00:16<00:14,  9.65it/s, est. speed input: 837.84 toks/s, output: 3036.13 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 100/240 [00:16<00:17,  8.23it/s, est. speed input: 837.88 toks/s, output: 3057.82 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 102/240 [00:17<00:17,  7.72it/s, est. speed input: 840.49 toks/s, output: 3088.62 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 104/240 [00:17<00:15,  8.58it/s, est. speed input: 847.96 toks/s, output: 3144.92 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 107/240 [00:17<00:13,  9.54it/s, est. speed input: 864.38 toks/s, output: 3227.30 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 109/240 [00:17<00:16,  7.79it/s, est. speed input: 866.88 toks/s, output: 3242.75 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 110/240 [00:18<00:19,  6.60it/s, est. speed input: 867.85 toks/s, output: 3236.58 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 113/240 [00:18<00:14,  8.55it/s, est. speed input: 875.52 toks/s, output: 3330.25 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 114/240 [00:18<00:20,  6.30it/s, est. speed input: 865.60 toks/s, output: 3306.54 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 115/240 [00:18<00:18,  6.73it/s, est. speed input: 865.38 toks/s, output: 3331.36 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 116/240 [00:19<00:18,  6.56it/s, est. speed input: 868.98 toks/s, output: 3345.30 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 119/240 [00:19<00:14,  8.38it/s, est. speed input: 884.10 toks/s, output: 3430.70 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 121/240 [00:19<00:12,  9.55it/s, est. speed input: 896.50 toks/s, output: 3491.32 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 123/240 [00:19<00:11, 10.57it/s, est. speed input: 908.93 toks/s, output: 3552.01 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 125/240 [00:19<00:11,  9.98it/s, est. speed input: 923.23 toks/s, output: 3598.16 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 127/240 [00:20<00:11,  9.62it/s, est. speed input: 925.67 toks/s, output: 3644.31 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 129/240 [00:20<00:11,  9.67it/s, est. speed input: 936.82 toks/s, output: 3694.22 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 131/240 [00:20<00:10, 10.69it/s, est. speed input: 942.13 toks/s, output: 3755.28 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 134/240 [00:20<00:10, 10.23it/s, est. speed input: 945.80 toks/s, output: 3827.91 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 137/240 [00:20<00:08, 12.30it/s, est. speed input: 965.32 toks/s, output: 3929.77 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 139/240 [00:21<00:08, 11.40it/s, est. speed input: 968.93 toks/s, output: 3977.22 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 141/240 [00:21<00:08, 12.13it/s, est. speed input: 982.47 toks/s, output: 4039.11 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 144/240 [00:21<00:06, 14.07it/s, est. speed input: 1006.21 toks/s, output: 4141.24 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 146/240 [00:21<00:07, 13.27it/s, est. speed input: 1011.06 toks/s, output: 4195.28 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 148/240 [00:21<00:07, 12.74it/s, est. speed input: 1012.03 toks/s, output: 4249.25 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 150/240 [00:22<00:09,  9.08it/s, est. speed input: 1005.17 toks/s, output: 4262.72 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 152/240 [00:22<00:12,  7.04it/s, est. speed input: 1000.61 toks/s, output: 4266.52 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 153/240 [00:22<00:15,  5.56it/s, est. speed input: 988.41 toks/s, output: 4242.79 toks/s] [A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 155/240 [00:23<00:14,  5.94it/s, est. speed input: 987.37 toks/s, output: 4278.33 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 156/240 [00:23<00:17,  4.78it/s, est. speed input: 977.84 toks/s, output: 4253.02 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 159/240 [00:24<00:16,  4.97it/s, est. speed input: 981.16 toks/s, output: 4284.10 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 161/240 [00:24<00:14,  5.39it/s, est. speed input: 978.81 toks/s, output: 4321.66 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 162/240 [00:25<00:22,  3.53it/s, est. speed input: 959.30 toks/s, output: 4239.68 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 163/240 [00:25<00:22,  3.40it/s, est. speed input: 952.06 toks/s, output: 4229.27 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 164/240 [00:25<00:24,  3.09it/s, est. speed input: 946.93 toks/s, output: 4204.70 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 166/240 [00:26<00:16,  4.48it/s, est. speed input: 950.95 toks/s, output: 4274.39 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 167/240 [00:26<00:17,  4.18it/s, est. speed input: 950.02 toks/s, output: 4271.96 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 168/240 [00:28<00:41,  1.73it/s, est. speed input: 902.12 toks/s, output: 4065.13 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 169/240 [00:28<00:37,  1.92it/s, est. speed input: 898.97 toks/s, output: 4059.95 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 170/240 [00:29<00:47,  1.47it/s, est. speed input: 869.18 toks/s, output: 3952.47 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 171/240 [00:30<00:53,  1.28it/s, est. speed input: 847.51 toks/s, output: 3863.54 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 172/240 [00:30<00:43,  1.56it/s, est. speed input: 847.92 toks/s, output: 3873.81 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 173/240 [00:31<00:35,  1.87it/s, est. speed input: 844.16 toks/s, output: 3886.79 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 175/240 [00:31<00:27,  2.39it/s, est. speed input: 838.65 toks/s, output: 3910.99 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 176/240 [00:32<00:25,  2.55it/s, est. speed input: 834.69 toks/s, output: 3920.19 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 177/240 [00:34<01:06,  1.05s/it, est. speed input: 768.37 toks/s, output: 3637.62 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 178/240 [00:35<01:02,  1.01s/it, est. speed input: 752.72 toks/s, output: 3591.91 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 179/240 [00:37<01:17,  1.28s/it, est. speed input: 715.97 toks/s, output: 3453.12 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 180/240 [00:38<01:05,  1.09s/it, est. speed input: 706.12 toks/s, output: 3443.92 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 181/240 [00:47<03:28,  3.53s/it, est. speed input: 568.92 toks/s, output: 2808.53 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 182/240 [00:54<04:14,  4.39s/it, est. speed input: 503.73 toks/s, output: 2521.51 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 183/240 [00:58<04:07,  4.34s/it, est. speed input: 469.71 toks/s, output: 2386.32 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 184/240 [01:07<05:10,  5.54s/it, est. speed input: 413.56 toks/s, output: 2133.84 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [01:07<00:00,  3.57it/s, est. speed input: 539.27 toks/s, output: 4693.74 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/240 [00:00<?, ?it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<00:00, 18227.19it/s]
{'num_samples': 30, 'num_scores': 240, 'timeout_samples': 0, 'empty_samples': 0, 'acc': 0.0, 'total_acc': 1.25, 'pass_at_k_percent': {'1': 1.2, '8': 6.7}, 'pass_at_k_valid_counts': {'1': 30, '8': 30}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_results/noise_rlvr_1_5b_128batchsize_deepscaler_v2_think-boxed/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100/g1/aime25x8/test_think-boxed_-1_seed0_t0.6_s0_e-1_part7.jsonl
[2025-12-03 19:45:34] ‚úì B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100/g1/aime25x8  acc=0.0 pass_at_k={'1': 1.2, '8': 6.7}
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100/g1:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [01:08<02:16, 68.10s/ds][Info] Sharding enabled: Process 7/8 handling range [280:320]
==================================================
data: amc23x8  ,remain samples: 40
{'idx': 280, 'id': 0, 'problem': 'Cities $A$ and $B$ are $45$ miles apart. Alicia lives in $A$ and Beth lives in $B$. Alicia bikes towards $B$ at 18 miles per hour. Leaving at the same time, Beth bikes toward $A$ at 12 miles per hour. How many miles from City $A$ will they be when they meet?', 'answer': 27.0, 'url': 'https://artofproblemsolving.com/wiki/index.php/2023_AMC_12A_Problems/Problem_1', 'question': 'Cities $A$ and $B$ are $45$ miles apart. Alicia lives in $A$ and Beth lives in $B$. Alicia bikes towards $B$ at 18 miles per hour. Leaving at the same time, Beth bikes toward $A$ at 12 miles per hour. How many miles from City $A$ will they be when they meet?'}

  0%|          | 0/40 [00:00<?, ?it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 441.20it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/320 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   1%|          | 3/320 [00:00<00:11, 26.79it/s, est. speed input: 3385.13 toks/s, output: 80.38 toks/s][A
Processed prompts:   2%|‚ñè         | 6/320 [00:02<02:22,  2.20it/s, est. speed input: 269.32 toks/s, output: 127.64 toks/s][A
Processed prompts:   2%|‚ñé         | 8/320 [00:04<03:41,  1.41it/s, est. speed input: 173.08 toks/s, output: 154.70 toks/s][A
Processed prompts:   3%|‚ñé         | 9/320 [00:04<03:09,  1.64it/s, est. speed input: 198.91 toks/s, output: 194.21 toks/s][A
Processed prompts:   3%|‚ñé         | 10/320 [00:05<02:33,  2.02it/s, est. speed input: 205.57 toks/s, output: 236.17 toks/s][A
Processed prompts:   3%|‚ñé         | 11/320 [00:05<02:12,  2.34it/s, est. speed input: 215.50 toks/s, output: 271.82 toks/s][A
Processed prompts:   4%|‚ñç         | 12/320 [00:05<01:57,  2.63it/s, est. speed input: 217.97 toks/s, output: 305.27 toks/s][A
Processed prompts:   4%|‚ñç         | 14/320 [00:05<01:15,  4.03it/s, est. speed input: 234.73 toks/s, output: 388.77 toks/s][A
Processed prompts:   5%|‚ñå         | 17/320 [00:05<00:50,  6.05it/s, est. speed input: 275.74 toks/s, output: 506.15 toks/s][A
Processed prompts:   6%|‚ñã         | 20/320 [00:06<00:38,  7.88it/s, est. speed input: 313.59 toks/s, output: 621.71 toks/s][A
Processed prompts:   7%|‚ñã         | 23/320 [00:06<00:29, 10.23it/s, est. speed input: 345.05 toks/s, output: 741.40 toks/s][A
Processed prompts:   8%|‚ñä         | 25/320 [00:06<00:32,  9.14it/s, est. speed input: 357.95 toks/s, output: 796.04 toks/s][A
Processed prompts:   8%|‚ñä         | 27/320 [00:06<00:29, 10.05it/s, est. speed input: 369.45 toks/s, output: 866.59 toks/s][A
Processed prompts:   9%|‚ñâ         | 29/320 [00:06<00:36,  7.97it/s, est. speed input: 378.79 toks/s, output: 904.81 toks/s][A
Processed prompts:  10%|‚ñâ         | 31/320 [00:07<00:33,  8.63it/s, est. speed input: 394.18 toks/s, output: 969.30 toks/s][A
Processed prompts:  10%|‚ñà         | 33/320 [00:07<00:30,  9.32it/s, est. speed input: 413.53 toks/s, output: 1033.42 toks/s][A
Processed prompts:  11%|‚ñà‚ñè        | 36/320 [00:07<00:22, 12.38it/s, est. speed input: 436.29 toks/s, output: 1146.91 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 38/320 [00:07<00:23, 12.14it/s, est. speed input: 462.90 toks/s, output: 1206.35 toks/s][A
Processed prompts:  12%|‚ñà‚ñé        | 40/320 [00:07<00:20, 13.61it/s, est. speed input: 481.72 toks/s, output: 1276.40 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 45/320 [00:07<00:14, 18.84it/s, est. speed input: 541.07 toks/s, output: 1419.81 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 48/320 [00:08<00:14, 18.73it/s, est. speed input: 563.67 toks/s, output: 1392.36 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 51/320 [00:08<00:12, 21.04it/s, est. speed input: 591.20 toks/s, output: 1459.70 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 54/320 [00:08<00:13, 20.14it/s, est. speed input: 624.47 toks/s, output: 1556.68 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 57/320 [00:08<00:15, 17.42it/s, est. speed input: 639.84 toks/s, output: 1639.92 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 59/320 [00:08<00:15, 17.05it/s, est. speed input: 652.33 toks/s, output: 1699.31 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 61/320 [00:09<00:30,  8.56it/s, est. speed input: 635.45 toks/s, output: 1671.58 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 63/320 [00:09<00:29,  8.84it/s, est. speed input: 652.26 toks/s, output: 1717.51 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 65/320 [00:09<00:37,  6.76it/s, est. speed input: 637.10 toks/s, output: 1715.87 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 67/320 [00:10<00:31,  8.02it/s, est. speed input: 645.38 toks/s, output: 1776.05 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 69/320 [00:10<00:36,  6.96it/s, est. speed input: 643.34 toks/s, output: 1792.00 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 71/320 [00:10<00:31,  7.80it/s, est. speed input: 650.68 toks/s, output: 1817.74 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 73/320 [00:10<00:26,  9.45it/s, est. speed input: 661.90 toks/s, output: 1851.51 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 76/320 [00:10<00:21, 11.33it/s, est. speed input: 672.10 toks/s, output: 1851.79 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 78/320 [00:11<00:21, 11.25it/s, est. speed input: 681.82 toks/s, output: 1903.12 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 80/320 [00:11<00:19, 12.15it/s, est. speed input: 700.86 toks/s, output: 1941.64 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 82/320 [00:11<00:17, 13.61it/s, est. speed input: 715.49 toks/s, output: 2005.91 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñã       | 84/320 [00:11<00:15, 14.89it/s, est. speed input: 729.55 toks/s, output: 2069.59 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 86/320 [00:11<00:18, 12.91it/s, est. speed input: 732.50 toks/s, output: 2114.71 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 89/320 [00:11<00:14, 16.41it/s, est. speed input: 756.14 toks/s, output: 2218.39 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 91/320 [00:11<00:14, 15.37it/s, est. speed input: 767.16 toks/s, output: 2248.24 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 93/320 [00:12<00:19, 11.61it/s, est. speed input: 759.92 toks/s, output: 2277.20 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 95/320 [00:12<00:22,  9.83it/s, est. speed input: 755.29 toks/s, output: 2285.97 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 97/320 [00:12<00:21, 10.59it/s, est. speed input: 762.07 toks/s, output: 2318.30 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 99/320 [00:12<00:24,  8.97it/s, est. speed input: 765.29 toks/s, output: 2344.07 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñé      | 104/320 [00:13<00:15, 14.26it/s, est. speed input: 800.60 toks/s, output: 2518.74 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 108/320 [00:13<00:16, 12.69it/s, est. speed input: 807.43 toks/s, output: 2588.07 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 110/320 [00:13<00:20, 10.09it/s, est. speed input: 809.70 toks/s, output: 2602.87 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 112/320 [00:14<00:23,  8.78it/s, est. speed input: 804.84 toks/s, output: 2605.12 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 114/320 [00:14<00:26,  7.73it/s, est. speed input: 797.89 toks/s, output: 2605.12 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñã      | 116/320 [00:14<00:24,  8.41it/s, est. speed input: 804.51 toks/s, output: 2629.76 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 118/320 [00:14<00:20,  9.63it/s, est. speed input: 807.41 toks/s, output: 2660.52 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 120/320 [00:14<00:19, 10.05it/s, est. speed input: 809.35 toks/s, output: 2710.22 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 122/320 [00:15<00:17, 11.21it/s, est. speed input: 821.82 toks/s, output: 2768.28 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 124/320 [00:15<00:15, 12.26it/s, est. speed input: 825.20 toks/s, output: 2826.32 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 127/320 [00:15<00:12, 15.07it/s, est. speed input: 838.84 toks/s, output: 2924.28 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 132/320 [00:15<00:08, 21.47it/s, est. speed input: 865.28 toks/s, output: 3083.35 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 135/320 [00:15<00:12, 14.52it/s, est. speed input: 864.56 toks/s, output: 3107.44 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 137/320 [00:16<00:13, 13.26it/s, est. speed input: 875.42 toks/s, output: 3149.92 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 140/320 [00:16<00:11, 15.50it/s, est. speed input: 887.88 toks/s, output: 3247.14 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 142/320 [00:16<00:11, 15.02it/s, est. speed input: 897.88 toks/s, output: 3298.60 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 145/320 [00:16<00:10, 17.25it/s, est. speed input: 912.92 toks/s, output: 3371.75 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 147/320 [00:16<00:11, 14.84it/s, est. speed input: 917.24 toks/s, output: 3397.73 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 149/320 [00:16<00:12, 13.34it/s, est. speed input: 923.75 toks/s, output: 3425.51 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 151/320 [00:16<00:12, 14.05it/s, est. speed input: 944.97 toks/s, output: 3476.15 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 153/320 [00:17<00:13, 12.80it/s, est. speed input: 956.73 toks/s, output: 3517.58 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 155/320 [00:17<00:12, 13.08it/s, est. speed input: 963.77 toks/s, output: 3541.40 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 158/320 [00:17<00:15, 10.76it/s, est. speed input: 968.69 toks/s, output: 3577.19 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 160/320 [00:17<00:13, 11.44it/s, est. speed input: 973.31 toks/s, output: 3611.25 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 162/320 [00:18<00:16,  9.72it/s, est. speed input: 976.48 toks/s, output: 3634.57 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 165/320 [00:18<00:14, 10.60it/s, est. speed input: 985.60 toks/s, output: 3692.34 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 167/320 [00:18<00:15,  9.92it/s, est. speed input: 984.46 toks/s, output: 3725.94 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 171/320 [00:18<00:11, 12.80it/s, est. speed input: 1005.27 toks/s, output: 3832.28 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 176/320 [00:19<00:11, 13.01it/s, est. speed input: 1021.04 toks/s, output: 3893.06 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 179/320 [00:19<00:09, 14.99it/s, est. speed input: 1041.39 toks/s, output: 3975.68 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 182/320 [00:19<00:08, 15.81it/s, est. speed input: 1049.13 toks/s, output: 4051.09 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 184/320 [00:19<00:12, 11.26it/s, est. speed input: 1041.59 toks/s, output: 4056.50 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 186/320 [00:19<00:11, 11.50it/s, est. speed input: 1049.17 toks/s, output: 4099.40 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 188/320 [00:20<00:13, 10.03it/s, est. speed input: 1045.21 toks/s, output: 4124.52 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 190/320 [00:20<00:11, 11.27it/s, est. speed input: 1049.29 toks/s, output: 4182.62 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 193/320 [00:20<00:09, 13.80it/s, est. speed input: 1061.87 toks/s, output: 4261.39 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 197/320 [00:20<00:06, 18.05it/s, est. speed input: 1080.05 toks/s, output: 4367.26 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 200/320 [00:21<00:09, 12.26it/s, est. speed input: 1080.05 toks/s, output: 4385.94 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 202/320 [00:21<00:09, 11.94it/s, est. speed input: 1080.15 toks/s, output: 4397.74 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 204/320 [00:21<00:17,  6.81it/s, est. speed input: 1063.48 toks/s, output: 4337.50 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 206/320 [00:22<00:17,  6.51it/s, est. speed input: 1055.78 toks/s, output: 4337.98 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 208/320 [00:22<00:15,  7.16it/s, est. speed input: 1058.43 toks/s, output: 4381.61 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 210/320 [00:22<00:12,  8.51it/s, est. speed input: 1063.18 toks/s, output: 4427.10 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 212/320 [00:22<00:11,  9.62it/s, est. speed input: 1066.62 toks/s, output: 4483.08 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 214/320 [00:22<00:11,  9.50it/s, est. speed input: 1066.08 toks/s, output: 4508.66 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 216/320 [00:23<00:09, 10.58it/s, est. speed input: 1077.52 toks/s, output: 4565.37 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 218/320 [00:23<00:10, 10.18it/s, est. speed input: 1077.42 toks/s, output: 4606.86 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 220/320 [00:23<00:16,  6.21it/s, est. speed input: 1058.79 toks/s, output: 4542.87 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 221/320 [00:24<00:15,  6.38it/s, est. speed input: 1059.62 toks/s, output: 4559.19 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 226/320 [00:24<00:10,  9.19it/s, est. speed input: 1070.66 toks/s, output: 4689.75 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 229/320 [00:24<00:10,  8.49it/s, est. speed input: 1066.41 toks/s, output: 4738.09 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 231/320 [00:24<00:09,  9.62it/s, est. speed input: 1069.11 toks/s, output: 4787.91 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 233/320 [00:25<00:11,  7.90it/s, est. speed input: 1067.54 toks/s, output: 4799.15 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 234/320 [00:25<00:11,  7.47it/s, est. speed input: 1065.25 toks/s, output: 4809.00 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 236/320 [00:25<00:11,  7.45it/s, est. speed input: 1063.83 toks/s, output: 4843.73 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 237/320 [00:25<00:11,  7.26it/s, est. speed input: 1061.63 toks/s, output: 4857.82 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 239/320 [00:26<00:10,  7.54it/s, est. speed input: 1064.68 toks/s, output: 4897.70 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 240/320 [00:26<00:14,  5.58it/s, est. speed input: 1052.48 toks/s, output: 4857.64 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 243/320 [00:26<00:12,  6.16it/s, est. speed input: 1051.86 toks/s, output: 4909.19 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 244/320 [00:27<00:14,  5.10it/s, est. speed input: 1046.41 toks/s, output: 4889.37 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 245/320 [00:27<00:16,  4.47it/s, est. speed input: 1042.80 toks/s, output: 4874.00 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 246/320 [00:27<00:18,  4.04it/s, est. speed input: 1036.27 toks/s, output: 4860.03 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 250/320 [00:28<00:11,  6.29it/s, est. speed input: 1039.24 toks/s, output: 4958.73 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 252/320 [00:28<00:10,  6.46it/s, est. speed input: 1038.52 toks/s, output: 4995.54 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 253/320 [00:28<00:10,  6.67it/s, est. speed input: 1036.36 toks/s, output: 5017.31 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 254/320 [00:29<00:14,  4.49it/s, est. speed input: 1025.38 toks/s, output: 4971.53 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 255/320 [00:29<00:16,  3.84it/s, est. speed input: 1014.26 toks/s, output: 4949.18 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 256/320 [00:30<00:31,  2.03it/s, est. speed input: 977.06 toks/s, output: 4795.63 toks/s] [A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 257/320 [00:32<00:47,  1.31it/s, est. speed input: 934.28 toks/s, output: 4611.41 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 258/320 [00:32<00:41,  1.48it/s, est. speed input: 924.79 toks/s, output: 4594.13 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 260/320 [00:33<00:27,  2.16it/s, est. speed input: 919.79 toks/s, output: 4625.03 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 261/320 [00:34<00:36,  1.61it/s, est. speed input: 894.19 toks/s, output: 4518.51 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 263/320 [00:37<00:53,  1.07it/s, est. speed input: 833.82 toks/s, output: 4264.25 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 265/320 [00:40<01:01,  1.12s/it, est. speed input: 779.30 toks/s, output: 4046.08 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 266/320 [00:40<00:51,  1.05it/s, est. speed input: 775.59 toks/s, output: 4062.75 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 267/320 [00:41<00:50,  1.05it/s, est. speed input: 762.14 toks/s, output: 4017.49 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 268/320 [00:41<00:45,  1.15it/s, est. speed input: 754.49 toks/s, output: 4004.23 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 269/320 [00:44<01:10,  1.38s/it, est. speed input: 708.45 toks/s, output: 3798.83 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 270/320 [00:47<01:23,  1.66s/it, est. speed input: 676.71 toks/s, output: 3651.59 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 271/320 [00:48<01:16,  1.56s/it, est. speed input: 660.82 toks/s, output: 3601.75 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 272/320 [00:50<01:21,  1.71s/it, est. speed input: 636.04 toks/s, output: 3502.67 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 273/320 [00:52<01:28,  1.88s/it, est. speed input: 609.85 toks/s, output: 3398.90 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 274/320 [01:03<03:20,  4.37s/it, est. speed input: 511.48 toks/s, output: 2889.43 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 315/320 [01:06<00:01,  3.12it/s, est. speed input: 560.09 toks/s, output: 4627.23 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 316/320 [01:06<00:01,  3.16it/s, est. speed input: 559.80 toks/s, output: 4660.52 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 317/320 [01:07<00:00,  3.07it/s, est. speed input: 557.70 toks/s, output: 4669.66 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 318/320 [01:07<00:00,  3.20it/s, est. speed input: 558.52 toks/s, output: 4707.75 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 320/320 [01:07<00:00,  3.39it/s, est. speed input: 558.65 toks/s, output: 4771.49 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 320/320 [01:07<00:00,  4.71it/s, est. speed input: 558.65 toks/s, output: 4771.49 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/320 [00:00<?, ?it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 320/320 [00:00<00:00, 19483.75it/s]
{'num_samples': 40, 'num_scores': 320, 'timeout_samples': 0, 'empty_samples': 4, 'acc': 17.5, 'total_acc': 19.6875, 'pass_at_k_percent': {'1': 19.7, '8': 52.5}, 'pass_at_k_valid_counts': {'1': 40, '8': 40}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_results/noise_rlvr_1_5b_128batchsize_deepscaler_v2_think-boxed/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100/g1/amc23x8/test_think-boxed_-1_seed0_t0.6_s0_e-1_part7.jsonl
[2025-12-03 19:46:43] ‚úì B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100/g1/amc23x8  acc=17.5 pass_at_k={'1': 19.7, '8': 52.5}
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100/g1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [02:17<01:08, 68.66s/ds][Info] Sharding enabled: Process 7/8 handling range [210:240]
==================================================
data: aime24x8  ,remain samples: 30
{'idx': 210, 'id': 60, 'problem': 'Every morning Aya goes for a $9$-kilometer-long walk and stops at a coffee shop afterwards. When she walks at a constant speed of $s$ kilometers per hour, the walk takes her 4 hours, including $t$ minutes spent in the coffee shop. When she walks $s+2$ kilometers per hour, the walk takes her 2 hours and 24 minutes, including $t$ minutes spent in the coffee shop. Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find the number of minutes the walk takes her, including the $t$ minutes spent in the coffee shop.', 'solution': '$\\frac{9}{s} + t = 4$ in hours and $\\frac{9}{s+2} + t = 2.4$ in hours.\nSubtracting the second equation from the first, we get, \n$\\frac{9}{s} - \\frac{9}{s+2} = 1.6$\nMultiplying by $(s)(s+2)$, we get \n$9s+18-9s=18=1.6s^{2} + 3.2s$\nMultiplying by 5/2 on both sides, we get\n$0 = 4s^{2} + 8s - 45$\nFactoring gives us \n$(2s-5)(2s+9) = 0$, of which the solution we want is $s=2.5$.\nSubstituting this back to the first equation, we can find that $t = 0.4$ hours.\nLastly, $s + \\frac{1}{2} = 3$ kilometers per hour, so\n$\\frac{9}{3} + 0.4 = 3.4$ hours, or $\\framebox{204}$ minutes\n-Failure.net\nThe amount of hours spent while walking on the first travel is $\\frac{240-t}{6}$. Thus, we have the equation $(240-t)(s) = 540$, and by the same logic, the second equation yields $(144-t)(s+2) = 540$. We have $240s-st = 540$, and $288+144s-2t-st = 540$. We subtract the two equations to get $96s+2t-288 = 0$, so we have $48s+t = 144$, so $t = 144-48s$, and now we have $(96+48s)(s) = 540$. The numerator of $s$ must evenly divide 540, however, $s$ must be less than 3. We can guess that $s = 2.5$. Now, $2.5+0.5 = 3$. Taking $\\frac{9}{3} = 3$, we find that it will take three hours for the 9 kilometers to be traveled. The t minutes spent at the coffeeshop can be written as $144-48(2.5)$, so t = 24. $180 + 24 = 204$. -sepehr2010', 'answer': '204', 'url': 'https://artofproblemsolving.com/wiki/index.php/2024_AIME_I_Problems/Problem_1', 'question': 'Every morning Aya goes for a $9$-kilometer-long walk and stops at a coffee shop afterwards. When she walks at a constant speed of $s$ kilometers per hour, the walk takes her 4 hours, including $t$ minutes spent in the coffee shop. When she walks $s+2$ kilometers per hour, the walk takes her 2 hours and 24 minutes, including $t$ minutes spent in the coffee shop. Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find the number of minutes the walk takes her, including the $t$ minutes spent in the coffee shop.'}

  0%|          | 0/30 [00:00<?, ?it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 441.45it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/240 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 1/240 [00:00<01:00,  3.98it/s, est. speed input: 353.86 toks/s, output: 23.85 toks/s][A
Processed prompts:   1%|          | 2/240 [00:04<09:45,  2.46s/it, est. speed input: 50.73 toks/s, output: 46.74 toks/s] [A
Processed prompts:   2%|‚ñè         | 4/240 [00:04<04:17,  1.09s/it, est. speed input: 120.17 toks/s, output: 126.61 toks/s][A
Processed prompts:   2%|‚ñè         | 5/240 [00:04<03:07,  1.26it/s, est. speed input: 135.38 toks/s, output: 167.91 toks/s][A
Processed prompts:   2%|‚ñé         | 6/240 [00:05<02:56,  1.33it/s, est. speed input: 140.31 toks/s, output: 193.15 toks/s][A
Processed prompts:   3%|‚ñé         | 7/240 [00:05<02:25,  1.60it/s, est. speed input: 165.55 toks/s, output: 227.08 toks/s][A
Processed prompts:   3%|‚ñé         | 8/240 [00:06<01:49,  2.12it/s, est. speed input: 180.63 toks/s, output: 267.22 toks/s][A
Processed prompts:   4%|‚ñç         | 10/240 [00:06<01:40,  2.28it/s, est. speed input: 184.67 toks/s, output: 319.89 toks/s][A
Processed prompts:   5%|‚ñç         | 11/240 [00:07<01:28,  2.60it/s, est. speed input: 197.87 toks/s, output: 354.04 toks/s][A
Processed prompts:   6%|‚ñå         | 14/240 [00:07<00:51,  4.39it/s, est. speed input: 249.60 toks/s, output: 471.59 toks/s][A
Processed prompts:   7%|‚ñã         | 17/240 [00:07<00:39,  5.59it/s, est. speed input: 281.04 toks/s, output: 579.83 toks/s][A
Processed prompts:   8%|‚ñä         | 19/240 [00:07<00:34,  6.44it/s, est. speed input: 297.96 toks/s, output: 652.23 toks/s][A
Processed prompts:   8%|‚ñä         | 20/240 [00:08<00:40,  5.48it/s, est. speed input: 297.76 toks/s, output: 670.73 toks/s][A
Processed prompts:   9%|‚ñâ         | 22/240 [00:08<00:41,  5.25it/s, est. speed input: 313.12 toks/s, output: 723.94 toks/s][A
Processed prompts:  10%|‚ñâ         | 23/240 [00:09<01:17,  2.80it/s, est. speed input: 287.13 toks/s, output: 686.68 toks/s][A
Processed prompts:  10%|‚ñà         | 24/240 [00:09<01:15,  2.84it/s, est. speed input: 293.70 toks/s, output: 707.14 toks/s][A
Processed prompts:  11%|‚ñà         | 26/240 [00:10<00:51,  4.13it/s, est. speed input: 319.75 toks/s, output: 784.00 toks/s][A
Processed prompts:  11%|‚ñà‚ñè        | 27/240 [00:10<00:47,  4.48it/s, est. speed input: 323.58 toks/s, output: 815.33 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 28/240 [00:10<00:51,  4.14it/s, est. speed input: 324.90 toks/s, output: 834.93 toks/s][A
Processed prompts:  12%|‚ñà‚ñé        | 30/240 [00:10<00:36,  5.70it/s, est. speed input: 345.22 toks/s, output: 908.23 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 31/240 [00:10<00:40,  5.19it/s, est. speed input: 345.67 toks/s, output: 930.11 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 32/240 [00:11<00:36,  5.66it/s, est. speed input: 350.00 toks/s, output: 962.19 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 33/240 [00:11<00:37,  5.45it/s, est. speed input: 355.58 toks/s, output: 987.57 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 35/240 [00:11<00:33,  6.06it/s, est. speed input: 363.42 toks/s, output: 1048.08 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 36/240 [00:12<00:47,  4.29it/s, est. speed input: 360.11 toks/s, output: 1050.59 toks/s][A
Processed prompts:  16%|‚ñà‚ñã        | 39/240 [00:12<00:31,  6.45it/s, est. speed input: 381.25 toks/s, output: 1156.79 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 40/240 [00:12<00:29,  6.89it/s, est. speed input: 385.52 toks/s, output: 1189.46 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 41/240 [00:12<00:27,  7.36it/s, est. speed input: 393.10 toks/s, output: 1222.06 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 42/240 [00:12<00:33,  5.88it/s, est. speed input: 398.93 toks/s, output: 1237.33 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 45/240 [00:13<00:29,  6.70it/s, est. speed input: 415.71 toks/s, output: 1325.47 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 47/240 [00:13<00:24,  7.93it/s, est. speed input: 432.44 toks/s, output: 1394.02 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 48/240 [00:13<00:23,  8.22it/s, est. speed input: 441.07 toks/s, output: 1425.43 toks/s][A
Processed prompts:  21%|‚ñà‚ñà‚ñè       | 51/240 [00:13<00:17, 10.62it/s, est. speed input: 459.40 toks/s, output: 1531.91 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 53/240 [00:13<00:18, 10.31it/s, est. speed input: 478.77 toks/s, output: 1592.62 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 55/240 [00:14<00:21,  8.51it/s, est. speed input: 481.61 toks/s, output: 1638.21 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñç       | 59/240 [00:14<00:13, 13.30it/s, est. speed input: 528.88 toks/s, output: 1793.71 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 61/240 [00:14<00:14, 12.74it/s, est. speed input: 536.97 toks/s, output: 1855.04 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñã       | 63/240 [00:14<00:13, 13.43it/s, est. speed input: 548.77 toks/s, output: 1922.48 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 65/240 [00:14<00:15, 11.33it/s, est. speed input: 561.54 toks/s, output: 1973.11 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 67/240 [00:14<00:15, 11.34it/s, est. speed input: 573.99 toks/s, output: 2033.23 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 69/240 [00:15<00:15, 10.93it/s, est. speed input: 593.56 toks/s, output: 2089.56 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 71/240 [00:15<00:14, 11.52it/s, est. speed input: 603.74 toks/s, output: 2152.30 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 73/240 [00:15<00:18,  9.18it/s, est. speed input: 606.36 toks/s, output: 2190.20 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà‚ñè      | 75/240 [00:15<00:16,  9.75it/s, est. speed input: 613.53 toks/s, output: 2249.07 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 77/240 [00:16<00:17,  9.16it/s, est. speed input: 635.84 toks/s, output: 2297.12 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 79/240 [00:16<00:17,  9.10it/s, est. speed input: 643.89 toks/s, output: 2348.58 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 80/240 [00:16<00:24,  6.59it/s, est. speed input: 636.80 toks/s, output: 2340.86 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 81/240 [00:16<00:28,  5.51it/s, est. speed input: 631.12 toks/s, output: 2340.90 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 83/240 [00:17<00:21,  7.24it/s, est. speed input: 640.06 toks/s, output: 2406.82 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 85/240 [00:17<00:18,  8.58it/s, est. speed input: 652.57 toks/s, output: 2468.73 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 89/240 [00:17<00:11, 12.95it/s, est. speed input: 674.68 toks/s, output: 2613.11 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 91/240 [00:18<00:21,  6.92it/s, est. speed input: 682.61 toks/s, output: 2597.64 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 93/240 [00:18<00:19,  7.56it/s, est. speed input: 691.38 toks/s, output: 2652.46 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 95/240 [00:18<00:16,  8.88it/s, est. speed input: 702.52 toks/s, output: 2717.40 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 97/240 [00:18<00:15,  9.22it/s, est. speed input: 708.99 toks/s, output: 2771.20 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 99/240 [00:18<00:15,  8.88it/s, est. speed input: 713.84 toks/s, output: 2817.63 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 101/240 [00:19<00:19,  7.12it/s, est. speed input: 716.39 toks/s, output: 2838.94 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 102/240 [00:19<00:20,  6.84it/s, est. speed input: 718.25 toks/s, output: 2855.04 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 103/240 [00:19<00:20,  6.61it/s, est. speed input: 715.94 toks/s, output: 2871.42 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 106/240 [00:19<00:13,  9.60it/s, est. speed input: 733.22 toks/s, output: 2973.97 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 108/240 [00:20<00:18,  7.22it/s, est. speed input: 730.60 toks/s, output: 2991.90 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 110/240 [00:20<00:15,  8.45it/s, est. speed input: 733.09 toks/s, output: 3053.37 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 112/240 [00:20<00:17,  7.51it/s, est. speed input: 738.91 toks/s, output: 3086.02 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 113/240 [00:20<00:18,  6.70it/s, est. speed input: 736.53 toks/s, output: 3094.34 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 114/240 [00:21<00:22,  5.67it/s, est. speed input: 732.87 toks/s, output: 3094.44 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 116/240 [00:21<00:23,  5.23it/s, est. speed input: 730.53 toks/s, output: 3114.42 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 119/240 [00:21<00:16,  7.36it/s, est. speed input: 737.63 toks/s, output: 3210.91 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 120/240 [00:21<00:15,  7.63it/s, est. speed input: 741.66 toks/s, output: 3236.72 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 122/240 [00:22<00:18,  6.27it/s, est. speed input: 738.94 toks/s, output: 3256.37 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 126/240 [00:22<00:13,  8.63it/s, est. speed input: 749.13 toks/s, output: 3382.07 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 128/240 [00:22<00:16,  6.96it/s, est. speed input: 744.88 toks/s, output: 3399.27 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 129/240 [00:23<00:19,  5.62it/s, est. speed input: 738.28 toks/s, output: 3388.39 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 130/240 [00:23<00:20,  5.42it/s, est. speed input: 737.60 toks/s, output: 3399.72 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 131/240 [00:23<00:19,  5.60it/s, est. speed input: 740.25 toks/s, output: 3419.44 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 132/240 [00:23<00:20,  5.40it/s, est. speed input: 737.68 toks/s, output: 3431.84 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 133/240 [00:24<00:28,  3.78it/s, est. speed input: 727.08 toks/s, output: 3402.39 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 138/240 [00:24<00:12,  8.33it/s, est. speed input: 758.03 toks/s, output: 3586.07 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 140/240 [00:25<00:14,  7.12it/s, est. speed input: 759.19 toks/s, output: 3613.69 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 142/240 [00:25<00:11,  8.65it/s, est. speed input: 764.80 toks/s, output: 3683.43 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 144/240 [00:25<00:09,  9.70it/s, est. speed input: 769.50 toks/s, output: 3747.16 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 146/240 [00:25<00:13,  6.77it/s, est. speed input: 763.73 toks/s, output: 3756.47 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 148/240 [00:25<00:10,  8.36it/s, est. speed input: 771.68 toks/s, output: 3826.29 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 150/240 [00:26<00:10,  8.96it/s, est. speed input: 775.99 toks/s, output: 3883.91 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 152/240 [00:26<00:09,  8.95it/s, est. speed input: 779.38 toks/s, output: 3935.62 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 154/240 [00:26<00:09,  8.96it/s, est. speed input: 784.03 toks/s, output: 3987.60 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 156/240 [00:26<00:07, 10.70it/s, est. speed input: 789.98 toks/s, output: 4057.53 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 158/240 [00:26<00:07, 10.82it/s, est. speed input: 794.50 toks/s, output: 4115.48 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 160/240 [00:27<00:09,  8.29it/s, est. speed input: 793.13 toks/s, output: 4144.28 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 162/240 [00:28<00:16,  4.60it/s, est. speed input: 776.27 toks/s, output: 4098.88 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 163/240 [00:28<00:16,  4.62it/s, est. speed input: 775.17 toks/s, output: 4111.14 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 164/240 [00:28<00:14,  5.09it/s, est. speed input: 780.20 toks/s, output: 4137.45 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 166/240 [00:28<00:14,  4.97it/s, est. speed input: 779.08 toks/s, output: 4163.03 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 168/240 [00:28<00:11,  6.18it/s, est. speed input: 784.36 toks/s, output: 4224.84 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 170/240 [00:30<00:22,  3.13it/s, est. speed input: 759.36 toks/s, output: 4131.17 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 171/240 [00:30<00:24,  2.80it/s, est. speed input: 754.21 toks/s, output: 4105.89 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 172/240 [00:31<00:29,  2.34it/s, est. speed input: 741.94 toks/s, output: 4060.48 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 173/240 [00:32<00:34,  1.94it/s, est. speed input: 728.95 toks/s, output: 4003.53 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 176/240 [00:33<00:26,  2.38it/s, est. speed input: 723.50 toks/s, output: 4016.28 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 177/240 [00:33<00:26,  2.35it/s, est. speed input: 716.56 toks/s, output: 4008.39 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 178/240 [00:34<00:28,  2.16it/s, est. speed input: 708.80 toks/s, output: 3982.39 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 179/240 [00:34<00:26,  2.31it/s, est. speed input: 707.19 toks/s, output: 3989.03 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 180/240 [00:35<00:28,  2.07it/s, est. speed input: 699.29 toks/s, output: 3962.67 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 182/240 [00:35<00:21,  2.76it/s, est. speed input: 697.58 toks/s, output: 4009.04 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 183/240 [00:35<00:20,  2.81it/s, est. speed input: 693.43 toks/s, output: 4016.88 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 184/240 [00:36<00:19,  2.89it/s, est. speed input: 691.00 toks/s, output: 4027.20 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 185/240 [00:36<00:16,  3.29it/s, est. speed input: 690.03 toks/s, output: 4052.18 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 186/240 [00:37<00:21,  2.56it/s, est. speed input: 680.82 toks/s, output: 4029.69 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 188/240 [00:38<00:24,  2.09it/s, est. speed input: 670.66 toks/s, output: 3995.70 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 189/240 [00:39<00:29,  1.73it/s, est. speed input: 658.99 toks/s, output: 3950.74 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 190/240 [00:39<00:31,  1.60it/s, est. speed input: 648.85 toks/s, output: 3921.17 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 191/240 [00:45<01:38,  2.00s/it, est. speed input: 569.53 toks/s, output: 3471.63 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 192/240 [00:48<01:51,  2.32s/it, est. speed input: 537.49 toks/s, output: 3295.18 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 193/240 [00:59<03:33,  4.54s/it, est. speed input: 446.37 toks/s, output: 2775.93 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 194/240 [01:03<03:30,  4.58s/it, est. speed input: 415.70 toks/s, output: 2619.51 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [01:03<00:00,  3.76it/s, est. speed input: 524.07 toks/s, output: 4831.05 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/240 [00:00<?, ?it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<00:00, 19915.58it/s]
{'num_samples': 30, 'num_scores': 240, 'timeout_samples': 0, 'empty_samples': 1, 'acc': 10.0, 'total_acc': 10.0, 'pass_at_k_percent': {'1': 10.0, '8': 26.7}, 'pass_at_k_valid_counts': {'1': 30, '8': 30}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_results/noise_rlvr_1_5b_128batchsize_deepscaler_v2_think-boxed/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100/g1/aime24x8/test_think-boxed_-1_seed0_t0.6_s0_e-1_part7.jsonl
[2025-12-03 19:47:48] ‚úì B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100/g1/aime24x8  acc=10.0 pass_at_k={'1': 10.0, '8': 26.7}
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100/g1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [03:21<00:00, 66.87s/ds]B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100/g1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [03:21<00:00, 67.30s/ds]
[2025-12-03 19:47:48] ‚ñ∂ B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100/g2  ÂæÖËØÑÊµã=['minerva_math', 'olympiadbench', 'math500']  T=0.0  n=8
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100/g2:   0%|          | 0/3 [00:00<?, ?ds/s][Info] Sharding enabled: Process 7/8 handling range [238:272]
==================================================
data: minerva_math  ,remain samples: 34
{'problem': 'Determine the highest linear density of atoms (atoms/m) encountered in vanadium (V). Please format your answer as $n \\times 10^x$ where $n$ is to 2 decimal places.', 'solution': '\\[\n\\begin{aligned}\n&\\mathrm{V}: \\quad \\text { atomic weight }=50.94 \\mathrm{~g} / \\text { mole } \\\\\n&\\rho=5.8 \\mathrm{~g} / \\mathrm{cm}^{3}\n\\end{aligned}\n\\]\n$B C C$, so $n=2$\nThe highest density would be found in the [111] direction. To find "a":\n\\[\n\\begin{aligned}\n&\\frac{\\text { atomic weight }}{\\rho}=a^{3} \\frac{N_{A}}{n} \\rightarrow a^{3}=\\frac{50.94 \\times 2}{5.8 \\times 6.023 \\times 10^{23}} \\\\\n&a=3.08 \\times 10^{-8} \\mathrm{~cm}=3.08 \\times 10^{-10} \\mathrm{~m}\n\\end{aligned}\n\\]\nThe length in the [111] direction is $\\mathrm{a} \\sqrt{3}$, so there are:\n\\[\n\\begin{aligned}\n&2 \\text { atoms } / \\mathrm{a} \\sqrt{3}=2 \\text { atoms/ }\\left(3.08 \\times 10^{-10} \\mathrm{~m} \\times \\sqrt{3}\\right) \\\\\n&= \\boxed{3.75e9} \\text { atoms } / \\mathrm{m}\n\\end{aligned}\n\\]', 'type': 'Introduction to Solid State Chemistry (3.091 Fall 2010)', 'idx': 238}

  0%|          | 0/34 [00:00<?, ?it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 34/34 [00:00<00:00, 12822.00it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/272 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 1/272 [00:01<07:51,  1.74s/it, est. speed input: 70.10 toks/s, output: 47.11 toks/s][A
Processed prompts:   3%|‚ñé         | 9/272 [00:02<00:48,  5.39it/s, est. speed input: 573.98 toks/s, output: 354.40 toks/s][A
Processed prompts:   6%|‚ñã         | 17/272 [00:04<01:06,  3.82it/s, est. speed input: 687.31 toks/s, output: 336.85 toks/s][A
Processed prompts:   9%|‚ñâ         | 25/272 [00:05<00:42,  5.83it/s, est. speed input: 1020.67 toks/s, output: 513.04 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 33/272 [00:05<00:27,  8.56it/s, est. speed input: 1362.21 toks/s, output: 846.73 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 41/272 [00:05<00:19, 11.75it/s, est. speed input: 1526.93 toks/s, output: 1171.28 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 57/272 [00:05<00:10, 19.86it/s, est. speed input: 1696.96 toks/s, output: 1836.91 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñé       | 64/272 [00:06<00:10, 19.12it/s, est. speed input: 1678.33 toks/s, output: 2026.26 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñã       | 72/272 [00:06<00:11, 17.67it/s, est. speed input: 1677.83 toks/s, output: 2213.06 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 80/272 [00:07<00:09, 19.58it/s, est. speed input: 1858.38 toks/s, output: 2478.76 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 96/272 [00:07<00:06, 28.51it/s, est. speed input: 2383.63 toks/s, output: 3116.17 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 100/272 [00:07<00:05, 29.61it/s, est. speed input: 2539.49 toks/s, output: 3259.37 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñä      | 105/272 [00:08<00:09, 17.90it/s, est. speed input: 2497.15 toks/s, output: 3188.43 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 113/272 [00:10<00:20,  7.94it/s, est. speed input: 2024.02 toks/s, output: 2810.83 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 129/272 [00:11<00:13, 10.54it/s, est. speed input: 2096.45 toks/s, output: 3270.34 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 137/272 [00:12<00:13,  9.78it/s, est. speed input: 2038.93 toks/s, output: 3359.81 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 145/272 [00:12<00:10, 12.69it/s, est. speed input: 2185.52 toks/s, output: 3705.17 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 153/272 [00:12<00:07, 16.27it/s, est. speed input: 2281.48 toks/s, output: 4043.83 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 161/272 [00:13<00:08, 13.22it/s, est. speed input: 2207.85 toks/s, output: 4135.78 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 169/272 [00:13<00:06, 16.99it/s, est. speed input: 2261.77 toks/s, output: 4476.12 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 177/272 [00:17<00:16,  5.70it/s, est. speed input: 1835.36 toks/s, output: 3844.75 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 185/272 [00:18<00:14,  5.85it/s, est. speed input: 1765.90 toks/s, output: 3955.99 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 193/272 [00:19<00:11,  6.97it/s, est. speed input: 1762.29 toks/s, output: 4218.33 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 201/272 [00:23<00:18,  3.77it/s, est. speed input: 1478.19 toks/s, output: 3769.28 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 209/272 [00:30<00:27,  2.31it/s, est. speed input: 1204.79 toks/s, output: 3276.81 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 217/272 [00:41<00:39,  1.38it/s, est. speed input: 903.49 toks/s, output: 2692.94 toks/s] [A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 225/272 [00:59<00:55,  1.18s/it, est. speed input: 668.73 toks/s, output: 2185.31 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 272/272 [00:59<00:00,  4.55it/s, est. speed input: 837.87 toks/s, output: 4601.28 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/272 [00:00<?, ?it/s][A
Evaluate:  36%|‚ñà‚ñà‚ñà‚ñå      | 97/272 [00:01<00:02, 75.22it/s][A
Evaluate:  39%|‚ñà‚ñà‚ñà‚ñä      | 105/272 [00:02<00:04, 40.05it/s][A
Evaluate:  40%|‚ñà‚ñà‚ñà‚ñà      | 109/272 [00:02<00:05, 31.66it/s][A
Evaluate:  41%|‚ñà‚ñà‚ñà‚ñà      | 112/272 [00:03<00:06, 26.40it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 272/272 [00:03<00:00, 86.35it/s]
{'num_samples': 34, 'num_scores': 272, 'timeout_samples': 0, 'empty_samples': 1, 'acc': 11.8, 'total_acc': 11.76470588235294, 'pass_at_k_percent': {'1': 11.8, '8': 11.8}, 'pass_at_k_valid_counts': {'1': 34, '8': 34}, 'type_acc': {'Introduction to Solid State Chemistry (3.091 Fall 2010)': 0.0, 'Physical Chemistry (5.61 Fall 2017)': 9.1, 'Principles of Microeconomics (14.01 Fall 2011)': 16.7}, 'type_pass_at_k_percent': {'Introduction to Solid State Chemistry (3.091 Fall 2010)': {'1': 0.0, '8': 0.0}, 'Physical Chemistry (5.61 Fall 2017)': {'1': 9.1, '8': 9.1}, 'Principles of Microeconomics (14.01 Fall 2011)': {'1': 16.7, '8': 16.7}}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_results/noise_rlvr_1_5b_128batchsize_deepscaler_v2_think-boxed/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100/g2/minerva_math/test_think-boxed_-1_seed0_t0.0_s0_e-1_part7.jsonl
[2025-12-03 19:48:51] ‚úì B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100/g2/minerva_math  acc=11.8 pass_at_k={'1': 11.8, '8': 11.8}
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100/g2:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [01:03<02:06, 63.20s/ds][Info] Sharding enabled: Process 7/8 handling range [588:675]
==================================================
data: olympiadbench  ,remain samples: 87
{'idx': 588, 'id': 2984, 'subfield': 'Algebra', 'context': None, 'question': 'Compute the value of\n\n$$\n\\sin \\left(6^{\\circ}\\right) \\cdot \\sin \\left(12^{\\circ}\\right) \\cdot \\sin \\left(24^{\\circ}\\right) \\cdot \\sin \\left(42^{\\circ}\\right)+\\sin \\left(12^{\\circ}\\right) \\cdot \\sin \\left(24^{\\circ}\\right) \\cdot \\sin \\left(42^{\\circ}\\right) \\text {. }\n$$', 'solution': ['Let $S=\\left(1+\\sin 6^{\\circ}\\right)\\left(\\sin 12^{\\circ} \\sin 24^{\\circ} \\sin 42^{\\circ}\\right)$. It follows from a sum-to-product identity that $1+\\sin 6^{\\circ}=$ $\\sin 90^{\\circ}+\\sin 6^{\\circ}=2 \\sin 48^{\\circ} \\cos 42^{\\circ}$. Because the sine of an angle is the cosine of its complement, it follows that\n\n$$\nS=\\left(2 \\sin 48^{\\circ} \\cos 42^{\\circ}\\right)\\left(\\sin 12^{\\circ} \\sin 24^{\\circ} \\sin 42^{\\circ}\\right)=2\\left(\\sin 48^{\\circ}\\right)^{2}\\left(\\sin 12^{\\circ} \\sin 24^{\\circ} \\cos 48^{\\circ}\\right)\n$$\n\nBy the double-angle formula, this means $S=\\sin 12^{\\circ} \\sin 24^{\\circ} \\sin 48^{\\circ} \\sin 96^{\\circ}$. By a product-to-sum identity,\n\n$$\n\\sin 12^{\\circ} \\sin 48^{\\circ}=\\frac{\\cos 36^{\\circ}-\\cos 60^{\\circ}}{2}=\\frac{\\sqrt{5}-1}{8}\n$$\n\n\n\nand\n\n$$\n\\sin 24^{\\circ} \\sin 96^{\\circ}=\\frac{\\cos 72^{\\circ}-\\cos 120^{\\circ}}{2}=\\frac{\\sqrt{5}+1}{8}\n$$\n\nMultiply the expressions on the right-hand sides of (1) and (2) to obtain $\\frac{\\mathbf{1}}{\\mathbf{1 6}}$'], 'final_answer': ['$\\frac{1}{16}$'], 'is_multiple_answer': False, 'unit': None, 'answer_type': 'Numerical', 'error': None}

  0%|          | 0/87 [00:00<?, ?it/s][A
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 44/87 [00:00<00:00, 432.44it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 87/87 [00:00<00:00, 429.11it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/696 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 1/696 [00:04<47:43,  4.12s/it, est. speed input: 22.33 toks/s, output: 44.42 toks/s][A
Processed prompts:   1%|‚ñè         | 9/696 [00:04<04:16,  2.68it/s, est. speed input: 232.25 toks/s, output: 370.79 toks/s][A
Processed prompts:   2%|‚ñè         | 17/696 [00:05<02:23,  4.74it/s, est. speed input: 631.15 toks/s, output: 631.92 toks/s][A
Processed prompts:   4%|‚ñé         | 25/696 [00:05<01:22,  8.10it/s, est. speed input: 757.89 toks/s, output: 961.53 toks/s][A
Processed prompts:   5%|‚ñç         | 33/696 [00:05<01:03, 10.43it/s, est. speed input: 813.45 toks/s, output: 1217.81 toks/s][A
Processed prompts:   6%|‚ñå         | 41/696 [00:06<00:51, 12.75it/s, est. speed input: 876.78 toks/s, output: 1473.08 toks/s][A
Processed prompts:   7%|‚ñã         | 49/696 [00:11<03:05,  3.48it/s, est. speed input: 554.05 toks/s, output: 974.47 toks/s] [A
Processed prompts:   8%|‚ñä         | 57/696 [00:11<02:08,  4.97it/s, est. speed input: 799.26 toks/s, output: 1267.28 toks/s][A
Processed prompts:   9%|‚ñâ         | 65/696 [00:12<01:46,  5.90it/s, est. speed input: 808.73 toks/s, output: 1353.27 toks/s][A
Processed prompts:  10%|‚ñà         | 73/696 [00:13<01:38,  6.31it/s, est. speed input: 803.20 toks/s, output: 1555.72 toks/s][A
Processed prompts:  14%|‚ñà‚ñé        | 94/696 [00:13<00:46, 12.98it/s, est. speed input: 978.46 toks/s, output: 2377.02 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 102/696 [00:14<00:43, 13.54it/s, est. speed input: 989.98 toks/s, output: 2521.46 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 110/696 [00:14<00:40, 14.52it/s, est. speed input: 1023.51 toks/s, output: 2764.47 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 118/696 [00:15<00:36, 15.87it/s, est. speed input: 1046.43 toks/s, output: 3013.47 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 134/696 [00:17<00:51, 10.81it/s, est. speed input: 1052.02 toks/s, output: 3215.27 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 137/696 [00:18<01:11,  7.86it/s, est. speed input: 1008.87 toks/s, output: 3104.94 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 145/696 [00:19<01:14,  7.38it/s, est. speed input: 1068.11 toks/s, output: 3207.44 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 156/696 [00:19<00:49, 10.91it/s, est. speed input: 1182.47 toks/s, output: 3445.14 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 160/696 [00:20<00:44, 12.08it/s, est. speed input: 1197.42 toks/s, output: 3498.26 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 167/696 [00:20<00:48, 10.95it/s, est. speed input: 1181.29 toks/s, output: 3554.77 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 175/696 [00:21<00:39, 13.15it/s, est. speed input: 1203.23 toks/s, output: 3712.37 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñã       | 183/696 [00:23<01:07,  7.56it/s, est. speed input: 1124.09 toks/s, output: 3477.15 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 196/696 [00:23<00:47, 10.55it/s, est. speed input: 1152.50 toks/s, output: 3567.07 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 201/696 [00:25<00:59,  8.29it/s, est. speed input: 1118.00 toks/s, output: 3476.38 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 209/696 [00:25<00:51,  9.54it/s, est. speed input: 1126.32 toks/s, output: 3609.12 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 214/696 [00:26<00:51,  9.35it/s, est. speed input: 1113.40 toks/s, output: 3605.98 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 217/696 [00:28<01:36,  4.97it/s, est. speed input: 1034.58 toks/s, output: 3365.82 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 223/696 [00:28<01:13,  6.39it/s, est. speed input: 1036.85 toks/s, output: 3386.20 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 231/696 [00:29<01:09,  6.65it/s, est. speed input: 1024.77 toks/s, output: 3401.09 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñé      | 234/696 [00:31<01:36,  4.78it/s, est. speed input: 984.38 toks/s, output: 3274.35 toks/s] [A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 236/696 [00:31<01:28,  5.20it/s, est. speed input: 986.66 toks/s, output: 3293.86 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 244/696 [00:32<01:22,  5.51it/s, est. speed input: 985.58 toks/s, output: 3360.27 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 252/696 [00:36<02:17,  3.24it/s, est. speed input: 891.08 toks/s, output: 3041.75 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñã      | 254/696 [00:37<02:26,  3.01it/s, est. speed input: 871.27 toks/s, output: 2983.72 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 260/696 [00:39<02:22,  3.07it/s, est. speed input: 840.15 toks/s, output: 2902.57 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 263/696 [00:40<02:17,  3.14it/s, est. speed input: 828.14 toks/s, output: 2867.56 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 265/696 [00:41<02:19,  3.08it/s, est. speed input: 817.81 toks/s, output: 2837.36 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 270/696 [00:45<03:29,  2.03it/s, est. speed input: 753.55 toks/s, output: 2627.13 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 272/696 [00:46<03:39,  1.93it/s, est. speed input: 736.48 toks/s, output: 2588.38 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 275/696 [00:50<05:19,  1.32it/s, est. speed input: 680.38 toks/s, output: 2421.39 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 277/696 [00:55<07:51,  1.12s/it, est. speed input: 621.40 toks/s, output: 2246.86 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 285/696 [00:56<03:47,  1.80it/s, est. speed input: 626.54 toks/s, output: 2460.24 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 287/696 [00:56<03:15,  2.09it/s, est. speed input: 627.59 toks/s, output: 2485.14 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 288/696 [00:56<03:02,  2.23it/s, est. speed input: 626.86 toks/s, output: 2492.59 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 290/696 [00:57<02:28,  2.74it/s, est. speed input: 627.85 toks/s, output: 2517.01 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 291/696 [00:58<03:32,  1.90it/s, est. speed input: 617.06 toks/s, output: 2482.88 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 299/696 [01:01<02:47,  2.37it/s, est. speed input: 626.18 toks/s, output: 2590.46 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 301/696 [01:01<02:21,  2.80it/s, est. speed input: 628.68 toks/s, output: 2625.20 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 310/696 [01:01<01:08,  5.60it/s, est. speed input: 644.01 toks/s, output: 2807.23 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 312/696 [01:01<01:03,  6.09it/s, est. speed input: 645.67 toks/s, output: 2834.24 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 314/696 [01:04<02:31,  2.53it/s, est. speed input: 619.18 toks/s, output: 2726.52 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 315/696 [01:24<02:30,  2.53it/s, est. speed input: 620.59 toks/s, output: 2737.00 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 316/696 [01:44<26:30,  4.18s/it, est. speed input: 388.55 toks/s, output: 1737.08 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 318/696 [01:44<20:43,  3.29s/it, est. speed input: 390.39 toks/s, output: 1791.94 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 324/696 [01:44<10:39,  1.72s/it, est. speed input: 397.27 toks/s, output: 1962.55 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 366/696 [01:44<01:38,  3.34it/s, est. speed input: 492.60 toks/s, output: 3186.21 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 399/696 [01:45<00:46,  6.32it/s, est. speed input: 534.04 toks/s, output: 4144.46 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 408/696 [01:46<00:44,  6.54it/s, est. speed input: 539.95 toks/s, output: 4291.88 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 415/696 [01:48<00:48,  5.78it/s, est. speed input: 537.81 toks/s, output: 4261.24 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 420/696 [01:49<00:48,  5.66it/s, est. speed input: 538.19 toks/s, output: 4257.19 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 424/696 [01:50<00:48,  5.64it/s, est. speed input: 538.46 toks/s, output: 4261.62 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 427/696 [01:50<00:49,  5.48it/s, est. speed input: 539.33 toks/s, output: 4253.60 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 429/696 [01:50<00:45,  5.89it/s, est. speed input: 540.38 toks/s, output: 4268.25 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 431/696 [01:50<00:41,  6.35it/s, est. speed input: 541.28 toks/s, output: 4281.73 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 433/696 [01:51<00:40,  6.50it/s, est. speed input: 541.14 toks/s, output: 4275.15 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 440/696 [01:51<00:28,  8.94it/s, est. speed input: 544.27 toks/s, output: 4274.44 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 442/696 [01:52<00:41,  6.19it/s, est. speed input: 542.26 toks/s, output: 4272.16 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 446/696 [01:52<00:30,  8.27it/s, est. speed input: 545.22 toks/s, output: 4354.27 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 450/696 [01:52<00:23, 10.56it/s, est. speed input: 549.01 toks/s, output: 4411.08 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 453/696 [01:53<00:28,  8.65it/s, est. speed input: 548.45 toks/s, output: 4454.84 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 455/696 [01:53<00:25,  9.62it/s, est. speed input: 549.11 toks/s, output: 4455.64 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 462/696 [01:53<00:21, 11.03it/s, est. speed input: 550.85 toks/s, output: 4460.50 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 465/696 [01:54<00:22, 10.14it/s, est. speed input: 552.75 toks/s, output: 4454.84 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 467/696 [01:54<00:28,  8.04it/s, est. speed input: 552.49 toks/s, output: 4442.37 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 472/696 [01:55<00:21, 10.55it/s, est. speed input: 556.27 toks/s, output: 4452.77 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 474/696 [01:55<00:28,  7.79it/s, est. speed input: 555.39 toks/s, output: 4436.90 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 483/696 [01:55<00:15, 13.97it/s, est. speed input: 561.76 toks/s, output: 4455.76 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 486/696 [01:56<00:20, 10.38it/s, est. speed input: 562.04 toks/s, output: 4441.66 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 488/696 [01:56<00:20,  9.99it/s, est. speed input: 562.82 toks/s, output: 4439.31 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 490/696 [01:56<00:19, 10.68it/s, est. speed input: 563.70 toks/s, output: 4439.67 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 493/696 [01:57<00:21,  9.54it/s, est. speed input: 564.57 toks/s, output: 4434.52 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 499/696 [01:57<00:13, 14.83it/s, est. speed input: 568.76 toks/s, output: 4446.75 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 503/696 [01:57<00:11, 16.42it/s, est. speed input: 571.18 toks/s, output: 4451.68 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 506/696 [01:57<00:10, 18.32it/s, est. speed input: 572.53 toks/s, output: 4453.70 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 512/696 [01:57<00:09, 20.01it/s, est. speed input: 575.12 toks/s, output: 4457.70 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 520/696 [01:57<00:05, 29.72it/s, est. speed input: 579.37 toks/s, output: 4482.78 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 525/696 [01:58<00:10, 16.22it/s, est. speed input: 580.45 toks/s, output: 4524.76 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 529/696 [01:58<00:09, 17.41it/s, est. speed input: 583.27 toks/s, output: 4600.65 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 533/696 [01:58<00:08, 18.55it/s, est. speed input: 586.18 toks/s, output: 4655.62 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 536/696 [02:01<00:34,  4.65it/s, est. speed input: 577.03 toks/s, output: 4597.30 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 544/696 [02:02<00:24,  6.13it/s, est. speed input: 580.64 toks/s, output: 4606.91 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 546/696 [02:02<00:25,  5.94it/s, est. speed input: 580.92 toks/s, output: 4603.52 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 548/696 [02:02<00:23,  6.27it/s, est. speed input: 581.67 toks/s, output: 4605.59 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 555/696 [02:03<00:20,  6.88it/s, est. speed input: 583.85 toks/s, output: 4609.57 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 557/696 [02:04<00:21,  6.33it/s, est. speed input: 582.91 toks/s, output: 4601.89 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 558/696 [02:04<00:26,  5.25it/s, est. speed input: 581.26 toks/s, output: 4588.72 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 559/696 [02:04<00:24,  5.48it/s, est. speed input: 581.40 toks/s, output: 4594.20 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 561/696 [02:04<00:22,  5.97it/s, est. speed input: 581.41 toks/s, output: 4594.02 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 562/696 [02:05<00:28,  4.69it/s, est. speed input: 579.88 toks/s, output: 4582.22 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 563/696 [02:06<00:36,  3.61it/s, est. speed input: 578.03 toks/s, output: 4571.89 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 564/696 [02:06<00:31,  4.15it/s, est. speed input: 578.57 toks/s, output: 4574.34 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 572/696 [02:07<00:24,  5.14it/s, est. speed input: 579.95 toks/s, output: 4577.51 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 573/696 [02:08<00:31,  3.94it/s, est. speed input: 577.39 toks/s, output: 4558.48 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 582/696 [02:08<00:16,  6.85it/s, est. speed input: 581.64 toks/s, output: 4601.10 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 585/696 [02:09<00:20,  5.35it/s, est. speed input: 580.23 toks/s, output: 4588.54 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 593/696 [02:10<00:13,  7.56it/s, est. speed input: 583.97 toks/s, output: 4631.37 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 594/696 [02:10<00:13,  7.55it/s, est. speed input: 584.07 toks/s, output: 4637.64 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 595/696 [02:11<00:17,  5.83it/s, est. speed input: 582.44 toks/s, output: 4627.40 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 597/696 [02:11<00:17,  5.71it/s, est. speed input: 582.23 toks/s, output: 4634.12 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 599/696 [02:12<00:20,  4.83it/s, est. speed input: 581.55 toks/s, output: 4631.73 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 600/696 [02:14<00:48,  1.97it/s, est. speed input: 572.21 toks/s, output: 4575.77 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 602/696 [02:14<00:36,  2.59it/s, est. speed input: 572.52 toks/s, output: 4615.13 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 603/696 [02:14<00:31,  2.91it/s, est. speed input: 572.48 toks/s, output: 4633.18 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 605/696 [02:14<00:23,  3.90it/s, est. speed input: 572.89 toks/s, output: 4673.22 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 607/696 [02:14<00:17,  5.19it/s, est. speed input: 573.50 toks/s, output: 4714.79 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 609/696 [02:18<01:03,  1.36it/s, est. speed input: 559.49 toks/s, output: 4605.24 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 611/696 [02:19<00:58,  1.44it/s, est. speed input: 556.22 toks/s, output: 4597.63 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 612/696 [02:20<00:49,  1.70it/s, est. speed input: 556.62 toks/s, output: 4615.72 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 614/696 [02:20<00:34,  2.38it/s, est. speed input: 557.60 toks/s, output: 4653.34 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 616/696 [02:22<00:49,  1.61it/s, est. speed input: 550.82 toks/s, output: 4629.05 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 619/696 [02:23<00:37,  2.03it/s, est. speed input: 549.02 toks/s, output: 4663.30 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 624/696 [02:23<00:18,  3.85it/s, est. speed input: 553.02 toks/s, output: 4766.75 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 627/696 [02:25<00:23,  2.89it/s, est. speed input: 550.15 toks/s, output: 4766.50 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 629/696 [02:25<00:20,  3.25it/s, est. speed input: 551.76 toks/s, output: 4778.30 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 633/696 [02:26<00:19,  3.29it/s, est. speed input: 552.21 toks/s, output: 4785.18 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 634/696 [02:27<00:25,  2.40it/s, est. speed input: 548.35 toks/s, output: 4766.32 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 636/696 [02:27<00:19,  3.08it/s, est. speed input: 549.33 toks/s, output: 4803.89 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 638/696 [02:28<00:15,  3.86it/s, est. speed input: 550.16 toks/s, output: 4840.13 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 640/696 [02:28<00:11,  4.97it/s, est. speed input: 551.22 toks/s, output: 4878.31 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 642/696 [02:28<00:12,  4.19it/s, est. speed input: 550.68 toks/s, output: 4889.46 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 644/696 [02:31<00:28,  1.82it/s, est. speed input: 542.26 toks/s, output: 4844.96 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 645/696 [02:31<00:24,  2.10it/s, est. speed input: 542.43 toks/s, output: 4861.55 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 648/696 [02:31<00:13,  3.44it/s, est. speed input: 543.76 toks/s, output: 4918.65 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 650/696 [02:32<00:13,  3.29it/s, est. speed input: 542.50 toks/s, output: 4937.12 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 652/696 [02:33<00:14,  3.09it/s, est. speed input: 541.32 toks/s, output: 4953.43 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 655/696 [02:33<00:08,  4.65it/s, est. speed input: 543.04 toks/s, output: 5009.56 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 657/696 [02:37<00:27,  1.41it/s, est. speed input: 530.18 toks/s, output: 4916.81 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 658/696 [02:39<00:32,  1.16it/s, est. speed input: 525.65 toks/s, output: 4881.73 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 659/696 [02:40<00:37,  1.02s/it, est. speed input: 520.99 toks/s, output: 4848.98 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 660/696 [02:40<00:29,  1.20it/s, est. speed input: 521.50 toks/s, output: 4864.33 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 661/696 [02:44<00:49,  1.41s/it, est. speed input: 511.27 toks/s, output: 4783.52 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 664/696 [02:46<00:34,  1.07s/it, est. speed input: 505.89 toks/s, output: 4776.35 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 666/696 [02:46<00:24,  1.23it/s, est. speed input: 505.12 toks/s, output: 4797.75 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 669/696 [02:50<00:24,  1.11it/s, est. speed input: 498.31 toks/s, output: 4765.63 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 671/696 [02:50<00:16,  1.50it/s, est. speed input: 500.71 toks/s, output: 4797.44 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 675/696 [02:50<00:09,  2.30it/s, est. speed input: 504.02 toks/s, output: 4853.48 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 680/696 [02:51<00:04,  3.50it/s, est. speed input: 505.87 toks/s, output: 4929.33 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 696/696 [02:53<00:00,  5.58it/s, est. speed input: 509.42 toks/s, output: 5155.42 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 696/696 [02:53<00:00,  4.02it/s, est. speed input: 509.42 toks/s, output: 5155.42 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/696 [00:00<?, ?it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 696/696 [00:00<00:00, 7568.18it/s]
{'num_samples': 87, 'num_scores': 696, 'timeout_samples': 0, 'empty_samples': 0, 'acc': 18.4, 'total_acc': 17.24137931034483, 'pass_at_k_percent': {'1': 17.2, '8': 19.5}, 'pass_at_k_valid_counts': {'1': 87, '8': 87}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_results/noise_rlvr_1_5b_128batchsize_deepscaler_v2_think-boxed/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100/g2/olympiadbench/test_think-boxed_-1_seed0_t0.0_s0_e-1_part7.jsonl
[2025-12-03 19:51:47] ‚úì B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100/g2/olympiadbench  acc=18.4 pass_at_k={'1': 17.2, '8': 19.5}
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100/g2:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [03:59<02:09, 129.67s/ds][Info] Sharding enabled: Process 7/8 handling range [434:500]
==================================================
data: math500  ,remain samples: 66
{'idx': 434, 'problem': 'In a certain isosceles right triangle, the altitude to the hypotenuse has length $4\\sqrt{2}$.  What is the area of the triangle?', 'solution': 'In isosceles right triangle $\\triangle ABC$ below, $\\overline{AD}$ is the altitude to the hypotenuse.\n\n[asy]\nimport olympiad;\nunitsize(0.8inch);\npair A,B,C,D;\nA = (0,1);\nB= (1,0);\nC = -B;\nD = (0,0);\ndraw(A--B--C--A,linewidth(1));\ndraw(A--D,linewidth(0.8));\ndraw(rightanglemark(C,A,B,s=5));\ndraw(rightanglemark(C,D,A,s=5));\nlabel("$A$",A,N);\nlabel("$B$",B,S);\nlabel("$C$",C,S);\nlabel("$D$",D,S);\n[/asy]\n\nBecause $\\triangle ABC$ is an isosceles right triangle, $\\angle ABC = 45^\\circ$.  Since $\\angle ADB = 90^\\circ$, we know that $\\angle DAB = 45^\\circ$, so $\\triangle ABD$ is also a 45-45-90 triangle.  Similarly, $\\triangle ACD$ is a 45-45-90 triangle.  Therefore, $DB=DC = DA = 4\\sqrt{2}$, so $BC = BD+DC = 8\\sqrt{2}$, and  \\[[ABC] = \\frac{(AD)(BC)}{2} = \\frac{(4\\sqrt{2})(8\\sqrt{2})}{2} = \\boxed{32}.\\]', 'answer': '32', 'subject': 'Prealgebra', 'level': 5, 'unique_id': 'test/prealgebra/1640.json'}

  0%|          | 0/66 [00:00<?, ?it/s][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 21/66 [00:00<00:00, 208.29it/s][A
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 44/66 [00:00<00:00, 216.81it/s][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [00:00<00:00, 213.17it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [00:00<00:00, 213.23it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/528 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 1/528 [00:02<18:33,  2.11s/it, est. speed input: 29.33 toks/s, output: 52.04 toks/s][A
Processed prompts:   1%|          | 6/528 [00:02<02:32,  3.42it/s, est. speed input: 161.61 toks/s, output: 291.07 toks/s][A
Processed prompts:   3%|‚ñé         | 17/528 [00:02<00:46, 10.95it/s, est. speed input: 425.12 toks/s, output: 804.29 toks/s][A
Processed prompts:   5%|‚ñç         | 25/528 [00:02<00:29, 17.01it/s, est. speed input: 555.51 toks/s, output: 1153.58 toks/s][A
Processed prompts:   6%|‚ñã         | 33/528 [00:02<00:26, 18.80it/s, est. speed input: 653.62 toks/s, output: 1381.61 toks/s][A
Processed prompts:   8%|‚ñä         | 41/528 [00:03<00:24, 19.97it/s, est. speed input: 716.75 toks/s, output: 1599.36 toks/s][A
Processed prompts:  11%|‚ñà         | 57/528 [00:03<00:18, 25.48it/s, est. speed input: 884.56 toks/s, output: 2124.73 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 65/528 [00:04<00:16, 27.49it/s, est. speed input: 1019.34 toks/s, output: 2381.43 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 73/528 [00:04<00:15, 28.75it/s, est. speed input: 1117.22 toks/s, output: 2620.82 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 79/528 [00:04<00:14, 31.03it/s, est. speed input: 1179.48 toks/s, output: 2825.74 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 83/528 [00:04<00:17, 25.13it/s, est. speed input: 1256.15 toks/s, output: 2761.22 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 105/528 [00:05<00:12, 34.25it/s, est. speed input: 1741.48 toks/s, output: 3163.48 toks/s][A
Processed prompts:  21%|‚ñà‚ñà‚ñè       | 113/528 [00:05<00:15, 26.52it/s, est. speed input: 1667.57 toks/s, output: 3226.39 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñé       | 125/528 [00:05<00:11, 34.71it/s, est. speed input: 1772.52 toks/s, output: 3719.47 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 137/528 [00:06<00:09, 39.63it/s, est. speed input: 2008.31 toks/s, output: 4147.60 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 145/528 [00:06<00:15, 25.03it/s, est. speed input: 1913.87 toks/s, output: 4062.58 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 161/528 [00:07<00:14, 26.01it/s, est. speed input: 1906.79 toks/s, output: 4307.78 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñé      | 177/528 [00:08<00:15, 22.33it/s, est. speed input: 1857.18 toks/s, output: 4334.62 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 185/528 [00:08<00:16, 20.52it/s, est. speed input: 1812.33 toks/s, output: 4299.58 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 193/528 [00:09<00:15, 21.85it/s, est. speed input: 1822.34 toks/s, output: 4497.24 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 201/528 [00:09<00:14, 22.29it/s, est. speed input: 1827.12 toks/s, output: 4507.20 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 209/528 [00:09<00:16, 19.32it/s, est. speed input: 1791.48 toks/s, output: 4599.27 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 217/528 [00:11<00:30, 10.13it/s, est. speed input: 1579.17 toks/s, output: 4210.81 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 233/528 [00:11<00:18, 16.15it/s, est. speed input: 1664.99 toks/s, output: 4654.03 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 241/528 [00:12<00:17, 15.96it/s, est. speed input: 1677.09 toks/s, output: 4795.17 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 249/528 [00:13<00:18, 14.69it/s, est. speed input: 1647.34 toks/s, output: 4813.29 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 265/528 [00:13<00:11, 22.31it/s, est. speed input: 1742.10 toks/s, output: 5198.46 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 273/528 [00:14<00:14, 18.08it/s, est. speed input: 1716.90 toks/s, output: 5134.94 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 286/528 [00:14<00:09, 24.65it/s, est. speed input: 1862.86 toks/s, output: 5447.13 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 302/528 [00:14<00:07, 32.01it/s, est. speed input: 1931.00 toks/s, output: 5897.25 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 310/528 [00:16<00:14, 15.15it/s, est. speed input: 1788.07 toks/s, output: 5473.48 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 318/528 [00:16<00:12, 16.83it/s, est. speed input: 1833.05 toks/s, output: 5513.27 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 326/528 [00:16<00:12, 16.13it/s, est. speed input: 1814.12 toks/s, output: 5519.01 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 334/528 [00:17<00:13, 14.59it/s, est. speed input: 1785.11 toks/s, output: 5547.36 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 342/528 [00:17<00:11, 16.89it/s, est. speed input: 1810.62 toks/s, output: 5701.85 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 350/528 [00:19<00:16, 11.00it/s, est. speed input: 1784.61 toks/s, output: 5596.69 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 366/528 [00:19<00:09, 16.71it/s, est. speed input: 1830.61 toks/s, output: 5750.43 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 374/528 [00:19<00:08, 17.80it/s, est. speed input: 1833.22 toks/s, output: 5766.02 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 390/528 [00:21<00:08, 15.77it/s, est. speed input: 1803.37 toks/s, output: 5727.20 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 398/528 [00:21<00:08, 14.93it/s, est. speed input: 1794.77 toks/s, output: 5731.65 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 406/528 [00:28<00:30,  4.00it/s, est. speed input: 1409.95 toks/s, output: 4546.36 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 414/528 [00:29<00:27,  4.22it/s, est. speed input: 1359.69 toks/s, output: 4565.79 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 422/528 [00:30<00:20,  5.21it/s, est. speed input: 1370.50 toks/s, output: 4732.63 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 428/528 [00:31<00:19,  5.08it/s, est. speed input: 1350.22 toks/s, output: 4768.10 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 436/528 [00:34<00:22,  4.08it/s, est. speed input: 1274.43 toks/s, output: 4699.67 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 440/528 [00:40<00:41,  2.14it/s, est. speed input: 1099.79 toks/s, output: 4138.32 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 444/528 [01:14<02:55,  2.09s/it, est. speed input: 603.57 toks/s, output: 2350.03 toks/s] [A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 484/528 [01:17<00:25,  1.71it/s, est. speed input: 636.47 toks/s, output: 3867.98 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 487/528 [01:18<00:23,  1.74it/s, est. speed input: 631.89 toks/s, output: 3918.23 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 495/528 [01:19<00:15,  2.16it/s, est. speed input: 653.92 toks/s, output: 4204.48 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 497/528 [01:19<00:13,  2.28it/s, est. speed input: 655.48 toks/s, output: 4267.43 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 505/528 [01:20<00:08,  2.80it/s, est. speed input: 655.32 toks/s, output: 4503.63 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 513/528 [01:23<00:05,  2.69it/s, est. speed input: 636.75 toks/s, output: 4621.96 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 521/528 [01:24<00:01,  3.61it/s, est. speed input: 640.47 toks/s, output: 4890.63 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 528/528 [01:24<00:00,  6.26it/s, est. speed input: 648.35 toks/s, output: 5145.59 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/528 [00:00<?, ?it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 528/528 [00:00<00:00, 12469.34it/s]
{'num_samples': 66, 'num_scores': 528, 'timeout_samples': 0, 'empty_samples': 0, 'acc': 40.9, 'total_acc': 41.66666666666667, 'pass_at_k_percent': {'1': 41.7, '8': 42.4}, 'pass_at_k_valid_counts': {'1': 66, '8': 66}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_results/noise_rlvr_1_5b_128batchsize_deepscaler_v2_think-boxed/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100/g2/math500/test_think-boxed_-1_seed0_t0.0_s0_e-1_part7.jsonl
[2025-12-03 19:53:15] ‚úì B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100/g2/math500  acc=40.9 pass_at_k={'1': 41.7, '8': 42.4}
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100/g2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [05:27<00:00, 110.51s/ds]B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100/g2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [05:27<00:00, 109.04s/ds]
[2025-12-03 19:53:15] ‚úÖ ÂÆåÊàêÔºöB_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_100Ôºàg1+g2 Áº∫Â§±Êï∞ÊçÆÈõÜÂ∑≤Ë°•ÂÖ®Ôºâ
[2025-12-03 19:53:17] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_200
INFO 12-03 19:53:17 [config.py:717] This model supports multiple tasks: {'embed', 'classify', 'reward', 'generate', 'score'}. Defaulting to 'generate'.
INFO 12-03 19:53:17 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-03 19:53:17 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-03 19:53:23 [__init__.py:239] Automatically detected platform cuda.
INFO 12-03 19:53:30 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-03 19:53:30 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f7a37b87070>
INFO 12-03 19:54:01 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-03 19:54:01 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-03 19:54:01 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-03 19:54:01 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_200...
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.81s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.19s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.29s/it]

INFO 12-03 19:54:03 [loader.py:458] Loading weights took 2.62 seconds
INFO 12-03 19:54:04 [gpu_model_runner.py:1347] Model loading took 6.0160 GiB and 2.776504 seconds
INFO 12-03 19:54:04 [kv_cache_utils.py:634] GPU KV cache size: 258,240 tokens
INFO 12-03 19:54:04 [kv_cache_utils.py:637] Maximum concurrency for 131,072 tokens per request: 1.97x
INFO 12-03 19:54:04 [core.py:159] init engine (profile, create kv cache, warmup model) took 0.82 seconds
INFO 12-03 19:54:04 [core_client.py:439] Core engine process 0 ready.
[2025-12-03 19:54:04] ‚ÑπÔ∏è  ÂΩìÂâçÂ∑•‰ΩúËäÇÁÇπÂàÜÁâá: 7/8
[2025-12-03 19:54:04] ‚úì Ê®°ÂûãÂ∞±Áª™ÔºåÂºÄÂßãËØÑÊµã B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200ÔºàÂÖ±‰∫´Âêå‰∏Ä LLMÔºå‰ªÖË°•Áº∫Êï∞ÊçÆÈõÜÔºâ
[2025-12-03 19:54:04] ‚ñ∂ B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200/g1  ÂæÖËØÑÊµã=['aime25x8', 'amc23x8', 'aime24x8']  T=0.6  n=8
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200/g1:   0%|          | 0/3 [00:00<?, ?ds/s][Info] Sharding enabled: Process 7/8 handling range [210:240]
==================================================
data: aime25x8  ,remain samples: 30
{'idx': 210, 'problem': 'Find the sum of all integer bases $b>9$ for which $17_{b}$ is a divisor of $97_{b}$.', 'answer': '70'}

  0%|          | 0/30 [00:00<?, ?it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 461.00it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/240 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 1/240 [00:03<12:05,  3.04s/it, est. speed input: 31.95 toks/s, output: 46.44 toks/s][A
Processed prompts:   1%|          | 2/240 [00:06<11:54,  3.00s/it, est. speed input: 42.07 toks/s, output: 69.01 toks/s][A
Processed prompts:   1%|‚ñè         | 3/240 [00:06<07:51,  1.99s/it, est. speed input: 48.09 toks/s, output: 106.03 toks/s][A
Processed prompts:   2%|‚ñè         | 4/240 [00:06<04:55,  1.25s/it, est. speed input: 69.79 toks/s, output: 149.26 toks/s][A
Processed prompts:   2%|‚ñè         | 5/240 [00:07<03:18,  1.18it/s, est. speed input: 82.36 toks/s, output: 191.56 toks/s][A
Processed prompts:   2%|‚ñé         | 6/240 [00:07<02:49,  1.38it/s, est. speed input: 95.23 toks/s, output: 223.79 toks/s][A
Processed prompts:   3%|‚ñé         | 7/240 [00:07<02:06,  1.84it/s, est. speed input: 110.90 toks/s, output: 263.35 toks/s][A
Processed prompts:   3%|‚ñé         | 8/240 [00:08<01:54,  2.02it/s, est. speed input: 123.28 toks/s, output: 294.99 toks/s][A
Processed prompts:   4%|‚ñç         | 9/240 [00:08<01:27,  2.64it/s, est. speed input: 140.39 toks/s, output: 334.93 toks/s][A
Processed prompts:   4%|‚ñç         | 10/240 [00:08<01:30,  2.54it/s, est. speed input: 143.53 toks/s, output: 362.59 toks/s][A
Processed prompts:   5%|‚ñç         | 11/240 [00:08<01:13,  3.13it/s, est. speed input: 150.83 toks/s, output: 400.32 toks/s][A
Processed prompts:   5%|‚ñå         | 12/240 [00:09<01:11,  3.17it/s, est. speed input: 152.93 toks/s, output: 431.01 toks/s][A
Processed prompts:   5%|‚ñå         | 13/240 [00:09<01:11,  3.19it/s, est. speed input: 157.05 toks/s, output: 460.51 toks/s][A
Processed prompts:   6%|‚ñå         | 14/240 [00:09<00:59,  3.77it/s, est. speed input: 163.51 toks/s, output: 496.71 toks/s][A
Processed prompts:   7%|‚ñã         | 16/240 [00:09<00:51,  4.32it/s, est. speed input: 174.87 toks/s, output: 563.11 toks/s][A
Processed prompts:   7%|‚ñã         | 17/240 [00:10<01:04,  3.46it/s, est. speed input: 176.51 toks/s, output: 581.28 toks/s][A
Processed prompts:   8%|‚ñä         | 19/240 [00:10<00:43,  5.10it/s, est. speed input: 194.61 toks/s, output: 660.17 toks/s][A
Processed prompts:   9%|‚ñâ         | 22/240 [00:10<00:27,  7.81it/s, est. speed input: 232.56 toks/s, output: 779.01 toks/s][A
Processed prompts:  10%|‚ñà         | 24/240 [00:11<00:30,  7.12it/s, est. speed input: 240.15 toks/s, output: 840.54 toks/s][A
Processed prompts:  10%|‚ñà         | 25/240 [00:11<00:33,  6.33it/s, est. speed input: 259.60 toks/s, output: 865.84 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 29/240 [00:11<00:21,  9.98it/s, est. speed input: 309.27 toks/s, output: 1022.06 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 31/240 [00:11<00:23,  9.02it/s, est. speed input: 320.74 toks/s, output: 1082.34 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 33/240 [00:12<00:24,  8.41it/s, est. speed input: 328.48 toks/s, output: 1142.07 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 36/240 [00:12<00:18, 11.00it/s, est. speed input: 346.20 toks/s, output: 1257.13 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 38/240 [00:12<00:20,  9.62it/s, est. speed input: 360.18 toks/s, output: 1313.60 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 40/240 [00:12<00:21,  9.35it/s, est. speed input: 373.23 toks/s, output: 1374.10 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 42/240 [00:12<00:20,  9.79it/s, est. speed input: 385.39 toks/s, output: 1439.54 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 44/240 [00:12<00:18, 10.54it/s, est. speed input: 399.86 toks/s, output: 1507.27 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 46/240 [00:13<00:22,  8.66it/s, est. speed input: 416.70 toks/s, output: 1554.01 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 48/240 [00:13<00:18, 10.36it/s, est. speed input: 429.56 toks/s, output: 1626.59 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 50/240 [00:13<00:15, 12.03it/s, est. speed input: 455.16 toks/s, output: 1698.68 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 52/240 [00:13<00:16, 11.29it/s, est. speed input: 473.57 toks/s, output: 1757.94 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñé       | 54/240 [00:13<00:16, 11.31it/s, est. speed input: 483.54 toks/s, output: 1819.55 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 56/240 [00:14<00:18, 10.01it/s, est. speed input: 498.04 toks/s, output: 1870.97 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 58/240 [00:14<00:22,  8.13it/s, est. speed input: 506.50 toks/s, output: 1909.29 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 60/240 [00:14<00:19,  9.19it/s, est. speed input: 526.72 toks/s, output: 1973.32 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 62/240 [00:14<00:19,  9.09it/s, est. speed input: 534.79 toks/s, output: 2026.83 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 64/240 [00:15<00:21,  8.17it/s, est. speed input: 539.41 toks/s, output: 2070.24 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 66/240 [00:15<00:18,  9.56it/s, est. speed input: 562.40 toks/s, output: 2137.08 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 68/240 [00:15<00:15, 10.86it/s, est. speed input: 569.81 toks/s, output: 2203.50 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 70/240 [00:15<00:14, 11.41it/s, est. speed input: 588.14 toks/s, output: 2265.22 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 72/240 [00:16<00:22,  7.54it/s, est. speed input: 587.36 toks/s, output: 2280.78 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà‚ñè      | 75/240 [00:16<00:16, 10.09it/s, est. speed input: 615.07 toks/s, output: 2385.70 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 77/240 [00:16<00:16,  9.73it/s, est. speed input: 628.06 toks/s, output: 2435.69 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 79/240 [00:16<00:15, 10.15it/s, est. speed input: 653.64 toks/s, output: 2492.58 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 82/240 [00:16<00:13, 12.01it/s, est. speed input: 675.91 toks/s, output: 2590.95 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 85/240 [00:16<00:11, 12.98it/s, est. speed input: 698.08 toks/s, output: 2684.64 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñã      | 87/240 [00:17<00:13, 10.95it/s, est. speed input: 710.38 toks/s, output: 2725.57 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 91/240 [00:17<00:10, 13.58it/s, est. speed input: 737.35 toks/s, output: 2860.08 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 93/240 [00:17<00:11, 13.11it/s, est. speed input: 741.01 toks/s, output: 2915.38 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 95/240 [00:17<00:14,  9.79it/s, est. speed input: 737.93 toks/s, output: 2938.85 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 97/240 [00:18<00:14,  9.64it/s, est. speed input: 744.70 toks/s, output: 2986.54 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 99/240 [00:18<00:19,  7.09it/s, est. speed input: 744.57 toks/s, output: 2991.67 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 100/240 [00:18<00:20,  6.69it/s, est. speed input: 750.55 toks/s, output: 3002.41 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 103/240 [00:19<00:15,  8.98it/s, est. speed input: 776.48 toks/s, output: 3099.73 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 105/240 [00:19<00:17,  7.65it/s, est. speed input: 780.37 toks/s, output: 3124.56 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 106/240 [00:19<00:18,  7.32it/s, est. speed input: 777.51 toks/s, output: 3139.41 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 108/240 [00:20<00:24,  5.29it/s, est. speed input: 766.51 toks/s, output: 3128.16 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 109/240 [00:20<00:24,  5.41it/s, est. speed input: 767.98 toks/s, output: 3143.93 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 112/240 [00:20<00:21,  5.91it/s, est. speed input: 773.77 toks/s, output: 3198.90 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 114/240 [00:21<00:19,  6.50it/s, est. speed input: 775.73 toks/s, output: 3245.77 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 115/240 [00:21<00:19,  6.53it/s, est. speed input: 781.30 toks/s, output: 3264.46 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 117/240 [00:21<00:22,  5.54it/s, est. speed input: 778.91 toks/s, output: 3275.96 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 118/240 [00:21<00:23,  5.11it/s, est. speed input: 781.45 toks/s, output: 3279.00 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 120/240 [00:22<00:17,  6.72it/s, est. speed input: 788.80 toks/s, output: 3343.25 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 122/240 [00:22<00:13,  8.56it/s, est. speed input: 803.59 toks/s, output: 3410.55 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 124/240 [00:22<00:15,  7.44it/s, est. speed input: 804.73 toks/s, output: 3441.90 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 125/240 [00:22<00:15,  7.51it/s, est. speed input: 805.66 toks/s, output: 3464.29 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 126/240 [00:23<00:27,  4.14it/s, est. speed input: 788.13 toks/s, output: 3410.47 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 127/240 [00:23<00:31,  3.63it/s, est. speed input: 781.17 toks/s, output: 3396.67 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 128/240 [00:24<00:35,  3.18it/s, est. speed input: 770.17 toks/s, output: 3377.65 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 129/240 [00:24<00:39,  2.84it/s, est. speed input: 760.72 toks/s, output: 3357.23 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 130/240 [00:24<00:31,  3.51it/s, est. speed input: 762.90 toks/s, output: 3384.80 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 132/240 [00:24<00:20,  5.18it/s, est. speed input: 768.99 toks/s, output: 3448.75 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 133/240 [00:25<00:27,  3.89it/s, est. speed input: 759.95 toks/s, output: 3428.21 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 134/240 [00:25<00:36,  2.93it/s, est. speed input: 747.64 toks/s, output: 3392.53 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 135/240 [00:26<00:47,  2.21it/s, est. speed input: 728.64 toks/s, output: 3337.91 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 136/240 [00:27<00:57,  1.81it/s, est. speed input: 710.55 toks/s, output: 3281.59 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 137/240 [00:27<00:45,  2.28it/s, est. speed input: 710.98 toks/s, output: 3306.46 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 140/240 [00:27<00:26,  3.83it/s, est. speed input: 721.36 toks/s, output: 3393.54 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 141/240 [00:28<00:25,  3.91it/s, est. speed input: 721.48 toks/s, output: 3408.22 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 142/240 [00:28<00:27,  3.51it/s, est. speed input: 714.83 toks/s, output: 3405.37 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 143/240 [00:28<00:27,  3.54it/s, est. speed input: 712.84 toks/s, output: 3415.59 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 145/240 [00:29<00:22,  4.29it/s, est. speed input: 713.50 toks/s, output: 3463.15 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 146/240 [00:29<00:32,  2.91it/s, est. speed input: 699.27 toks/s, output: 3423.04 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 147/240 [00:30<00:32,  2.83it/s, est. speed input: 698.83 toks/s, output: 3422.32 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 148/240 [00:30<00:28,  3.18it/s, est. speed input: 697.59 toks/s, output: 3442.82 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 149/240 [00:30<00:25,  3.54it/s, est. speed input: 698.23 toks/s, output: 3463.62 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 150/240 [00:31<00:28,  3.17it/s, est. speed input: 692.56 toks/s, output: 3462.17 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 151/240 [00:31<00:27,  3.25it/s, est. speed input: 690.71 toks/s, output: 3473.56 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 152/240 [00:32<00:44,  1.97it/s, est. speed input: 671.65 toks/s, output: 3409.42 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 153/240 [00:32<00:48,  1.80it/s, est. speed input: 662.07 toks/s, output: 3383.13 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 154/240 [00:34<01:10,  1.23it/s, est. speed input: 641.25 toks/s, output: 3285.29 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 155/240 [00:37<02:07,  1.50s/it, est. speed input: 592.08 toks/s, output: 3055.10 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 156/240 [00:38<01:57,  1.39s/it, est. speed input: 576.19 toks/s, output: 3007.64 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 157/240 [00:39<01:40,  1.21s/it, est. speed input: 571.39 toks/s, output: 2991.89 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 158/240 [00:40<01:42,  1.26s/it, est. speed input: 554.84 toks/s, output: 2935.11 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 159/240 [00:47<03:59,  2.96s/it, est. speed input: 478.96 toks/s, output: 2550.41 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 160/240 [00:51<04:14,  3.18s/it, est. speed input: 447.28 toks/s, output: 2409.16 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 161/240 [00:53<03:42,  2.82s/it, est. speed input: 433.04 toks/s, output: 2362.61 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 162/240 [00:54<02:52,  2.22s/it, est. speed input: 429.00 toks/s, output: 2369.61 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 163/240 [00:54<02:13,  1.74s/it, est. speed input: 426.60 toks/s, output: 2384.76 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 164/240 [00:56<02:06,  1.67s/it, est. speed input: 417.97 toks/s, output: 2362.82 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 165/240 [01:03<03:59,  3.19s/it, est. speed input: 375.55 toks/s, output: 2151.84 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 166/240 [01:16<07:33,  6.13s/it, est. speed input: 312.38 toks/s, output: 1825.40 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [01:16<00:00,  3.15it/s, est. speed input: 475.61 toks/s, output: 4809.85 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/240 [00:00<?, ?it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<00:00, 22934.84it/s]
{'num_samples': 30, 'num_scores': 240, 'timeout_samples': 0, 'empty_samples': 2, 'acc': 0.0, 'total_acc': 0.0, 'pass_at_k_percent': {'1': 0.0, '8': 0.0}, 'pass_at_k_valid_counts': {'1': 30, '8': 30}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_results/noise_rlvr_1_5b_128batchsize_deepscaler_v2_think-boxed/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200/g1/aime25x8/test_think-boxed_-1_seed0_t0.6_s0_e-1_part7.jsonl
[2025-12-03 19:55:21] ‚úì B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200/g1/aime25x8  acc=0.0 pass_at_k={'1': 0.0, '8': 0.0}
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200/g1:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [01:17<02:34, 77.04s/ds][Info] Sharding enabled: Process 7/8 handling range [280:320]
==================================================
data: amc23x8  ,remain samples: 40
{'idx': 280, 'id': 0, 'problem': 'Cities $A$ and $B$ are $45$ miles apart. Alicia lives in $A$ and Beth lives in $B$. Alicia bikes towards $B$ at 18 miles per hour. Leaving at the same time, Beth bikes toward $A$ at 12 miles per hour. How many miles from City $A$ will they be when they meet?', 'answer': 27.0, 'url': 'https://artofproblemsolving.com/wiki/index.php/2023_AMC_12A_Problems/Problem_1', 'question': 'Cities $A$ and $B$ are $45$ miles apart. Alicia lives in $A$ and Beth lives in $B$. Alicia bikes towards $B$ at 18 miles per hour. Leaving at the same time, Beth bikes toward $A$ at 12 miles per hour. How many miles from City $A$ will they be when they meet?'}

  0%|          | 0/40 [00:00<?, ?it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 434.92it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/320 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   1%|          | 3/320 [00:00<00:15, 20.59it/s, est. speed input: 2375.25 toks/s, output: 61.78 toks/s][A
Processed prompts:   2%|‚ñè         | 6/320 [00:05<05:12,  1.01it/s, est. speed input: 143.86 toks/s, output: 128.61 toks/s][A
Processed prompts:   2%|‚ñè         | 7/320 [00:05<04:13,  1.24it/s, est. speed input: 160.87 toks/s, output: 171.31 toks/s][A
Processed prompts:   2%|‚ñé         | 8/320 [00:05<03:27,  1.50it/s, est. speed input: 168.25 toks/s, output: 210.86 toks/s][A
Processed prompts:   3%|‚ñé         | 9/320 [00:05<03:05,  1.68it/s, est. speed input: 173.64 toks/s, output: 242.28 toks/s][A
Processed prompts:   3%|‚ñé         | 11/320 [00:06<01:55,  2.67it/s, est. speed input: 196.98 toks/s, output: 326.63 toks/s][A
Processed prompts:   4%|‚ñç         | 14/320 [00:06<01:09,  4.43it/s, est. speed input: 229.32 toks/s, output: 451.19 toks/s][A
Processed prompts:   5%|‚ñå         | 16/320 [00:06<00:54,  5.63it/s, est. speed input: 252.90 toks/s, output: 530.00 toks/s][A
Processed prompts:   6%|‚ñå         | 18/320 [00:06<00:48,  6.20it/s, est. speed input: 270.72 toks/s, output: 597.58 toks/s][A
Processed prompts:   6%|‚ñã         | 20/320 [00:06<00:41,  7.23it/s, est. speed input: 291.12 toks/s, output: 669.14 toks/s][A
Processed prompts:   7%|‚ñã         | 22/320 [00:06<00:36,  8.25it/s, est. speed input: 300.98 toks/s, output: 739.49 toks/s][A
Processed prompts:   8%|‚ñä         | 24/320 [00:07<00:37,  7.99it/s, est. speed input: 319.39 toks/s, output: 797.78 toks/s][A
Processed prompts:   8%|‚ñä         | 26/320 [00:07<00:38,  7.68it/s, est. speed input: 332.33 toks/s, output: 853.29 toks/s][A
Processed prompts:   9%|‚ñâ         | 28/320 [00:07<00:32,  8.91it/s, est. speed input: 357.20 toks/s, output: 922.00 toks/s][A
Processed prompts:   9%|‚ñâ         | 30/320 [00:07<00:27, 10.68it/s, est. speed input: 373.43 toks/s, output: 995.13 toks/s][A
Processed prompts:  10%|‚ñà         | 32/320 [00:07<00:24, 11.61it/s, est. speed input: 389.84 toks/s, output: 1062.75 toks/s][A
Processed prompts:  11%|‚ñà         | 35/320 [00:08<00:21, 13.53it/s, est. speed input: 429.16 toks/s, output: 1166.29 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 37/320 [00:08<00:24, 11.38it/s, est. speed input: 436.25 toks/s, output: 1213.88 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 39/320 [00:08<00:32,  8.62it/s, est. speed input: 437.68 toks/s, output: 1243.88 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 41/320 [00:08<00:32,  8.65it/s, est. speed input: 444.76 toks/s, output: 1294.43 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 44/320 [00:09<00:26, 10.37it/s, est. speed input: 465.54 toks/s, output: 1349.68 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 47/320 [00:09<00:20, 13.36it/s, est. speed input: 491.96 toks/s, output: 1376.56 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 51/320 [00:09<00:15, 17.58it/s, est. speed input: 526.00 toks/s, output: 1400.65 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 54/320 [00:09<00:15, 16.84it/s, est. speed input: 555.03 toks/s, output: 1493.08 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 56/320 [00:09<00:15, 16.94it/s, est. speed input: 566.05 toks/s, output: 1556.28 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 58/320 [00:10<00:27,  9.64it/s, est. speed input: 555.69 toks/s, output: 1561.04 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 60/320 [00:10<00:30,  8.52it/s, est. speed input: 562.30 toks/s, output: 1593.97 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 62/320 [00:10<00:31,  8.16it/s, est. speed input: 568.49 toks/s, output: 1633.00 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 65/320 [00:10<00:24, 10.59it/s, est. speed input: 579.29 toks/s, output: 1732.41 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 67/320 [00:11<00:34,  7.27it/s, est. speed input: 586.51 toks/s, output: 1732.61 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 69/320 [00:11<00:39,  6.37it/s, est. speed input: 597.20 toks/s, output: 1749.45 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 70/320 [00:12<00:48,  5.11it/s, est. speed input: 583.71 toks/s, output: 1732.34 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñé       | 72/320 [00:12<00:38,  6.46it/s, est. speed input: 603.62 toks/s, output: 1793.01 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 73/320 [00:12<00:36,  6.85it/s, est. speed input: 611.22 toks/s, output: 1817.65 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 74/320 [00:12<00:36,  6.73it/s, est. speed input: 612.22 toks/s, output: 1834.43 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 76/320 [00:12<00:27,  8.85it/s, est. speed input: 631.51 toks/s, output: 1898.64 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñç       | 79/320 [00:12<00:22, 10.52it/s, est. speed input: 641.28 toks/s, output: 1962.38 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 81/320 [00:13<00:28,  8.46it/s, est. speed input: 643.20 toks/s, output: 1967.82 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 83/320 [00:13<00:23, 10.12it/s, est. speed input: 659.51 toks/s, output: 2031.47 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 85/320 [00:13<00:29,  8.00it/s, est. speed input: 659.58 toks/s, output: 2055.14 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 87/320 [00:14<00:31,  7.37it/s, est. speed input: 664.88 toks/s, output: 2086.76 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 88/320 [00:14<00:31,  7.39it/s, est. speed input: 663.82 toks/s, output: 2076.20 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 91/320 [00:14<00:22, 10.37it/s, est. speed input: 681.45 toks/s, output: 2174.85 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 93/320 [00:14<00:19, 11.91it/s, est. speed input: 687.91 toks/s, output: 2194.80 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 95/320 [00:14<00:30,  7.46it/s, est. speed input: 683.71 toks/s, output: 2197.71 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 97/320 [00:15<00:26,  8.45it/s, est. speed input: 696.37 toks/s, output: 2252.92 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 99/320 [00:15<00:23,  9.36it/s, est. speed input: 697.41 toks/s, output: 2307.89 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 102/320 [00:15<00:19, 11.19it/s, est. speed input: 711.86 toks/s, output: 2379.78 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñé      | 104/320 [00:15<00:20, 10.66it/s, est. speed input: 721.10 toks/s, output: 2408.31 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 106/320 [00:15<00:24,  8.67it/s, est. speed input: 722.32 toks/s, output: 2435.15 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 108/320 [00:16<00:25,  8.33it/s, est. speed input: 727.76 toks/s, output: 2451.54 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 111/320 [00:16<00:26,  8.03it/s, est. speed input: 732.77 toks/s, output: 2509.56 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 114/320 [00:16<00:19, 10.40it/s, est. speed input: 749.59 toks/s, output: 2587.52 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñã      | 116/320 [00:16<00:18, 10.89it/s, est. speed input: 763.35 toks/s, output: 2624.98 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 118/320 [00:17<00:19, 10.12it/s, est. speed input: 764.64 toks/s, output: 2667.00 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 120/320 [00:17<00:18, 10.70it/s, est. speed input: 779.55 toks/s, output: 2705.64 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 123/320 [00:17<00:19, 10.25it/s, est. speed input: 786.09 toks/s, output: 2774.08 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 127/320 [00:17<00:14, 13.62it/s, est. speed input: 816.15 toks/s, output: 2905.89 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 129/320 [00:17<00:14, 13.43it/s, est. speed input: 819.98 toks/s, output: 2958.98 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 131/320 [00:18<00:13, 14.53it/s, est. speed input: 832.93 toks/s, output: 3020.37 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 133/320 [00:18<00:12, 14.73it/s, est. speed input: 837.96 toks/s, output: 3077.22 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 135/320 [00:18<00:16, 11.39it/s, est. speed input: 839.14 toks/s, output: 3108.16 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 137/320 [00:18<00:17, 10.46it/s, est. speed input: 841.33 toks/s, output: 3132.85 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 139/320 [00:18<00:19,  9.22it/s, est. speed input: 840.60 toks/s, output: 3149.93 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 141/320 [00:19<00:16, 10.88it/s, est. speed input: 852.97 toks/s, output: 3200.76 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 143/320 [00:19<00:14, 11.94it/s, est. speed input: 861.15 toks/s, output: 3240.72 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 146/320 [00:19<00:11, 14.73it/s, est. speed input: 873.88 toks/s, output: 3316.81 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 148/320 [00:19<00:10, 15.80it/s, est. speed input: 879.26 toks/s, output: 3377.93 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 153/320 [00:19<00:07, 23.73it/s, est. speed input: 903.89 toks/s, output: 3492.53 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 158/320 [00:19<00:06, 23.17it/s, est. speed input: 928.83 toks/s, output: 3626.98 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 161/320 [00:19<00:08, 18.75it/s, est. speed input: 937.33 toks/s, output: 3682.89 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 164/320 [00:20<00:12, 12.69it/s, est. speed input: 936.44 toks/s, output: 3708.28 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 166/320 [00:20<00:11, 13.29it/s, est. speed input: 940.19 toks/s, output: 3764.52 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 170/320 [00:20<00:08, 17.02it/s, est. speed input: 957.70 toks/s, output: 3864.06 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 173/320 [00:21<00:11, 12.33it/s, est. speed input: 953.90 toks/s, output: 3906.05 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 177/320 [00:21<00:10, 13.19it/s, est. speed input: 962.24 toks/s, output: 3980.72 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 179/320 [00:21<00:14,  9.86it/s, est. speed input: 956.17 toks/s, output: 3969.87 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 181/320 [00:21<00:12, 10.84it/s, est. speed input: 967.56 toks/s, output: 4010.59 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 184/320 [00:21<00:10, 13.27it/s, est. speed input: 980.19 toks/s, output: 4092.30 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 187/320 [00:22<00:08, 15.05it/s, est. speed input: 989.69 toks/s, output: 4184.23 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 189/320 [00:22<00:08, 15.47it/s, est. speed input: 994.69 toks/s, output: 4240.99 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 191/320 [00:22<00:08, 15.15it/s, est. speed input: 995.77 toks/s, output: 4276.29 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 193/320 [00:22<00:10, 12.54it/s, est. speed input: 995.91 toks/s, output: 4294.98 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 195/320 [00:22<00:11, 10.53it/s, est. speed input: 999.78 toks/s, output: 4322.90 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 197/320 [00:23<00:12, 10.24it/s, est. speed input: 997.97 toks/s, output: 4344.39 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 199/320 [00:23<00:12,  9.76it/s, est. speed input: 1002.32 toks/s, output: 4364.40 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 201/320 [00:23<00:10, 11.39it/s, est. speed input: 1007.86 toks/s, output: 4410.09 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 203/320 [00:23<00:11,  9.80it/s, est. speed input: 1003.99 toks/s, output: 4423.08 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 205/320 [00:24<00:18,  6.36it/s, est. speed input: 988.45 toks/s, output: 4396.86 toks/s] [A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 207/320 [00:24<00:14,  7.93it/s, est. speed input: 994.41 toks/s, output: 4444.46 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 209/320 [00:25<00:20,  5.54it/s, est. speed input: 975.50 toks/s, output: 4414.96 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 211/320 [00:25<00:20,  5.24it/s, est. speed input: 969.99 toks/s, output: 4406.36 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 212/320 [00:26<00:29,  3.62it/s, est. speed input: 953.27 toks/s, output: 4332.68 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 213/320 [00:26<00:29,  3.64it/s, est. speed input: 947.75 toks/s, output: 4315.24 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 215/320 [00:26<00:20,  5.07it/s, est. speed input: 953.56 toks/s, output: 4376.71 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 217/320 [00:26<00:15,  6.80it/s, est. speed input: 957.37 toks/s, output: 4441.59 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 219/320 [00:26<00:14,  6.88it/s, est. speed input: 952.77 toks/s, output: 4446.01 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 221/320 [00:28<00:37,  2.61it/s, est. speed input: 900.29 toks/s, output: 4239.98 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 223/320 [00:29<00:31,  3.05it/s, est. speed input: 893.97 toks/s, output: 4261.56 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 224/320 [00:29<00:37,  2.59it/s, est. speed input: 878.81 toks/s, output: 4210.39 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 227/320 [00:29<00:22,  4.08it/s, est. speed input: 888.20 toks/s, output: 4297.02 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 228/320 [00:30<00:25,  3.58it/s, est. speed input: 878.96 toks/s, output: 4275.75 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 229/320 [00:30<00:22,  4.08it/s, est. speed input: 879.66 toks/s, output: 4302.63 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 230/320 [00:30<00:26,  3.40it/s, est. speed input: 871.24 toks/s, output: 4279.41 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 231/320 [00:32<00:45,  1.95it/s, est. speed input: 842.38 toks/s, output: 4161.68 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 232/320 [00:32<00:41,  2.13it/s, est. speed input: 835.70 toks/s, output: 4159.60 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 233/320 [00:33<00:57,  1.51it/s, est. speed input: 808.31 toks/s, output: 4054.11 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 234/320 [00:34<01:02,  1.38it/s, est. speed input: 790.84 toks/s, output: 3993.33 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 235/320 [00:35<01:08,  1.25it/s, est. speed input: 772.11 toks/s, output: 3923.57 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 236/320 [00:35<00:51,  1.64it/s, est. speed input: 772.94 toks/s, output: 3951.25 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 238/320 [00:37<01:05,  1.25it/s, est. speed input: 736.05 toks/s, output: 3817.41 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 239/320 [00:38<00:58,  1.38it/s, est. speed input: 729.00 toks/s, output: 3810.82 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 240/320 [00:38<00:52,  1.53it/s, est. speed input: 724.82 toks/s, output: 3810.23 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 241/320 [00:39<00:48,  1.62it/s, est. speed input: 719.57 toks/s, output: 3802.13 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 242/320 [00:39<00:37,  2.10it/s, est. speed input: 720.44 toks/s, output: 3834.23 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 243/320 [00:39<00:34,  2.24it/s, est. speed input: 715.59 toks/s, output: 3841.17 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 244/320 [00:42<01:19,  1.05s/it, est. speed input: 676.72 toks/s, output: 3654.29 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 245/320 [00:43<01:27,  1.17s/it, est. speed input: 656.57 toks/s, output: 3573.71 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 246/320 [00:44<01:20,  1.09s/it, est. speed input: 645.76 toks/s, output: 3535.81 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 247/320 [00:45<01:05,  1.11it/s, est. speed input: 642.86 toks/s, output: 3543.23 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 248/320 [00:49<02:11,  1.82s/it, est. speed input: 592.00 toks/s, output: 3297.50 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 249/320 [00:55<03:41,  3.12s/it, est. speed input: 527.85 toks/s, output: 2971.33 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 251/320 [01:00<03:21,  2.92s/it, est. speed input: 485.53 toks/s, output: 2789.94 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 252/320 [01:06<04:14,  3.75s/it, est. speed input: 442.26 toks/s, output: 2570.44 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 253/320 [01:11<04:22,  3.92s/it, est. speed input: 416.01 toks/s, output: 2453.97 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 254/320 [01:13<03:55,  3.56s/it, est. speed input: 402.24 toks/s, output: 2408.42 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 310/320 [01:16<00:02,  4.91it/s, est. speed input: 479.81 toks/s, output: 4566.16 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 311/320 [01:17<00:01,  4.80it/s, est. speed input: 480.61 toks/s, output: 4582.69 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 312/320 [01:17<00:01,  4.88it/s, est. speed input: 483.23 toks/s, output: 4616.45 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 313/320 [01:17<00:01,  4.64it/s, est. speed input: 481.55 toks/s, output: 4629.71 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 315/320 [01:17<00:00,  5.06it/s, est. speed input: 482.96 toks/s, output: 4701.79 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 317/320 [01:18<00:00,  4.84it/s, est. speed input: 482.25 toks/s, output: 4748.80 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 318/320 [01:19<00:00,  3.65it/s, est. speed input: 477.38 toks/s, output: 4730.48 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 319/320 [01:19<00:00,  3.86it/s, est. speed input: 477.48 toks/s, output: 4760.90 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 320/320 [01:19<00:00,  4.18it/s, est. speed input: 477.68 toks/s, output: 4792.31 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 320/320 [01:19<00:00,  4.03it/s, est. speed input: 477.68 toks/s, output: 4792.31 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/320 [00:00<?, ?it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 320/320 [00:00<00:00, 21996.05it/s]
{'num_samples': 40, 'num_scores': 320, 'timeout_samples': 0, 'empty_samples': 0, 'acc': 20.0, 'total_acc': 20.9375, 'pass_at_k_percent': {'1': 20.9, '8': 52.5}, 'pass_at_k_valid_counts': {'1': 40, '8': 40}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_results/noise_rlvr_1_5b_128batchsize_deepscaler_v2_think-boxed/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200/g1/amc23x8/test_think-boxed_-1_seed0_t0.6_s0_e-1_part7.jsonl
[2025-12-03 19:56:42] ‚úì B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200/g1/amc23x8  acc=20.0 pass_at_k={'1': 20.9, '8': 52.5}
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200/g1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [02:37<01:19, 79.32s/ds][Info] Sharding enabled: Process 7/8 handling range [210:240]
==================================================
data: aime24x8  ,remain samples: 30
{'idx': 210, 'id': 60, 'problem': 'Every morning Aya goes for a $9$-kilometer-long walk and stops at a coffee shop afterwards. When she walks at a constant speed of $s$ kilometers per hour, the walk takes her 4 hours, including $t$ minutes spent in the coffee shop. When she walks $s+2$ kilometers per hour, the walk takes her 2 hours and 24 minutes, including $t$ minutes spent in the coffee shop. Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find the number of minutes the walk takes her, including the $t$ minutes spent in the coffee shop.', 'solution': '$\\frac{9}{s} + t = 4$ in hours and $\\frac{9}{s+2} + t = 2.4$ in hours.\nSubtracting the second equation from the first, we get, \n$\\frac{9}{s} - \\frac{9}{s+2} = 1.6$\nMultiplying by $(s)(s+2)$, we get \n$9s+18-9s=18=1.6s^{2} + 3.2s$\nMultiplying by 5/2 on both sides, we get\n$0 = 4s^{2} + 8s - 45$\nFactoring gives us \n$(2s-5)(2s+9) = 0$, of which the solution we want is $s=2.5$.\nSubstituting this back to the first equation, we can find that $t = 0.4$ hours.\nLastly, $s + \\frac{1}{2} = 3$ kilometers per hour, so\n$\\frac{9}{3} + 0.4 = 3.4$ hours, or $\\framebox{204}$ minutes\n-Failure.net\nThe amount of hours spent while walking on the first travel is $\\frac{240-t}{6}$. Thus, we have the equation $(240-t)(s) = 540$, and by the same logic, the second equation yields $(144-t)(s+2) = 540$. We have $240s-st = 540$, and $288+144s-2t-st = 540$. We subtract the two equations to get $96s+2t-288 = 0$, so we have $48s+t = 144$, so $t = 144-48s$, and now we have $(96+48s)(s) = 540$. The numerator of $s$ must evenly divide 540, however, $s$ must be less than 3. We can guess that $s = 2.5$. Now, $2.5+0.5 = 3$. Taking $\\frac{9}{3} = 3$, we find that it will take three hours for the 9 kilometers to be traveled. The t minutes spent at the coffeeshop can be written as $144-48(2.5)$, so t = 24. $180 + 24 = 204$. -sepehr2010', 'answer': '204', 'url': 'https://artofproblemsolving.com/wiki/index.php/2024_AIME_I_Problems/Problem_1', 'question': 'Every morning Aya goes for a $9$-kilometer-long walk and stops at a coffee shop afterwards. When she walks at a constant speed of $s$ kilometers per hour, the walk takes her 4 hours, including $t$ minutes spent in the coffee shop. When she walks $s+2$ kilometers per hour, the walk takes her 2 hours and 24 minutes, including $t$ minutes spent in the coffee shop. Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find the number of minutes the walk takes her, including the $t$ minutes spent in the coffee shop.'}

  0%|          | 0/30 [00:00<?, ?it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 460.15it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/240 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 1/240 [00:05<23:34,  5.92s/it, est. speed input: 15.03 toks/s, output: 45.78 toks/s][A
Processed prompts:   1%|          | 2/240 [00:06<10:50,  2.73s/it, est. speed input: 44.37 toks/s, output: 87.50 toks/s][A
Processed prompts:   1%|‚ñè         | 3/240 [00:06<06:36,  1.67s/it, est. speed input: 70.37 toks/s, output: 127.27 toks/s][A
Processed prompts:   2%|‚ñè         | 4/240 [00:06<04:10,  1.06s/it, est. speed input: 82.79 toks/s, output: 170.03 toks/s][A
Processed prompts:   2%|‚ñé         | 6/240 [00:07<02:17,  1.70it/s, est. speed input: 109.44 toks/s, output: 250.25 toks/s][A
Processed prompts:   3%|‚ñé         | 8/240 [00:07<01:35,  2.44it/s, est. speed input: 137.08 toks/s, output: 327.13 toks/s][A
Processed prompts:   4%|‚ñç         | 10/240 [00:07<01:10,  3.27it/s, est. speed input: 155.21 toks/s, output: 403.74 toks/s][A
Processed prompts:   5%|‚ñç         | 11/240 [00:08<01:46,  2.14it/s, est. speed input: 158.77 toks/s, output: 400.10 toks/s][A
Processed prompts:   5%|‚ñå         | 12/240 [00:09<01:33,  2.43it/s, est. speed input: 164.02 toks/s, output: 433.96 toks/s][A
Processed prompts:   5%|‚ñå         | 13/240 [00:09<01:17,  2.94it/s, est. speed input: 181.59 toks/s, output: 471.82 toks/s][A
Processed prompts:   6%|‚ñå         | 14/240 [00:09<01:30,  2.49it/s, est. speed input: 182.90 toks/s, output: 488.14 toks/s][A
Processed prompts:   8%|‚ñä         | 18/240 [00:10<00:40,  5.45it/s, est. speed input: 235.44 toks/s, output: 653.46 toks/s][A
Processed prompts:   8%|‚ñä         | 20/240 [00:10<00:39,  5.61it/s, est. speed input: 254.47 toks/s, output: 718.88 toks/s][A
Processed prompts:   9%|‚ñâ         | 21/240 [00:10<00:37,  5.91it/s, est. speed input: 268.98 toks/s, output: 753.43 toks/s][A
Processed prompts:  10%|‚ñâ         | 23/240 [00:10<00:32,  6.61it/s, est. speed input: 283.75 toks/s, output: 822.97 toks/s][A
Processed prompts:  10%|‚ñà         | 24/240 [00:10<00:31,  6.82it/s, est. speed input: 298.43 toks/s, output: 856.33 toks/s][A
Processed prompts:  11%|‚ñà         | 26/240 [00:11<00:47,  4.52it/s, est. speed input: 296.90 toks/s, output: 887.15 toks/s][A
Processed prompts:  11%|‚ñà‚ñè        | 27/240 [00:11<00:48,  4.38it/s, est. speed input: 303.99 toks/s, output: 910.78 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 31/240 [00:12<00:26,  7.91it/s, est. speed input: 349.08 toks/s, output: 1068.90 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 33/240 [00:12<00:32,  6.45it/s, est. speed input: 352.89 toks/s, output: 1113.46 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 35/240 [00:12<00:25,  7.96it/s, est. speed input: 365.30 toks/s, output: 1189.48 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 37/240 [00:12<00:24,  8.15it/s, est. speed input: 377.62 toks/s, output: 1252.58 toks/s][A
Processed prompts:  16%|‚ñà‚ñã        | 39/240 [00:12<00:21,  9.15it/s, est. speed input: 394.62 toks/s, output: 1322.32 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 43/240 [00:13<00:20,  9.69it/s, est. speed input: 422.80 toks/s, output: 1450.80 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 45/240 [00:13<00:18, 10.69it/s, est. speed input: 435.87 toks/s, output: 1521.56 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 47/240 [00:13<00:20,  9.46it/s, est. speed input: 440.78 toks/s, output: 1574.86 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 50/240 [00:13<00:18, 10.50it/s, est. speed input: 461.67 toks/s, output: 1674.54 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 52/240 [00:14<00:20,  9.11it/s, est. speed input: 469.19 toks/s, output: 1722.93 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 57/240 [00:14<00:13, 13.89it/s, est. speed input: 502.11 toks/s, output: 1914.18 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 62/240 [00:14<00:14, 12.33it/s, est. speed input: 524.31 toks/s, output: 2059.10 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 64/240 [00:15<00:15, 11.20it/s, est. speed input: 537.12 toks/s, output: 2108.75 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 66/240 [00:15<00:15, 11.59it/s, est. speed input: 553.94 toks/s, output: 2171.85 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 68/240 [00:15<00:24,  6.92it/s, est. speed input: 543.56 toks/s, output: 2162.60 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 70/240 [00:16<00:21,  8.05it/s, est. speed input: 553.59 toks/s, output: 2229.47 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 72/240 [00:16<00:31,  5.32it/s, est. speed input: 560.83 toks/s, output: 2215.70 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà‚ñè      | 75/240 [00:16<00:21,  7.55it/s, est. speed input: 581.28 toks/s, output: 2327.60 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 77/240 [00:17<00:18,  8.97it/s, est. speed input: 593.87 toks/s, output: 2397.30 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 79/240 [00:17<00:17,  8.96it/s, est. speed input: 599.37 toks/s, output: 2449.27 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 81/240 [00:17<00:16,  9.87it/s, est. speed input: 609.07 toks/s, output: 2511.46 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 84/240 [00:17<00:12, 12.65it/s, est. speed input: 624.36 toks/s, output: 2618.60 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñã      | 87/240 [00:17<00:10, 13.98it/s, est. speed input: 646.60 toks/s, output: 2717.65 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 89/240 [00:17<00:13, 11.07it/s, est. speed input: 648.30 toks/s, output: 2756.43 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 92/240 [00:18<00:11, 12.70it/s, est. speed input: 663.56 toks/s, output: 2854.93 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 94/240 [00:18<00:12, 11.57it/s, est. speed input: 670.43 toks/s, output: 2904.00 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 100/240 [00:18<00:07, 19.15it/s, est. speed input: 715.33 toks/s, output: 3134.25 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 103/240 [00:18<00:10, 12.70it/s, est. speed input: 720.05 toks/s, output: 3183.20 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 105/240 [00:19<00:11, 12.17it/s, est. speed input: 727.81 toks/s, output: 3234.95 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 108/240 [00:19<00:09, 13.55it/s, est. speed input: 755.37 toks/s, output: 3331.86 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 110/240 [00:19<00:12, 10.30it/s, est. speed input: 763.56 toks/s, output: 3354.76 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 112/240 [00:20<00:18,  7.05it/s, est. speed input: 752.93 toks/s, output: 3344.46 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 114/240 [00:21<00:26,  4.77it/s, est. speed input: 736.39 toks/s, output: 3298.15 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 115/240 [00:21<00:25,  4.91it/s, est. speed input: 734.93 toks/s, output: 3313.52 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 116/240 [00:21<00:26,  4.60it/s, est. speed input: 731.48 toks/s, output: 3312.56 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 117/240 [00:21<00:24,  5.03it/s, est. speed input: 731.39 toks/s, output: 3334.93 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 119/240 [00:22<00:25,  4.70it/s, est. speed input: 726.38 toks/s, output: 3347.23 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 121/240 [00:22<00:32,  3.71it/s, est. speed input: 711.22 toks/s, output: 3319.96 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 122/240 [00:23<00:31,  3.73it/s, est. speed input: 706.57 toks/s, output: 3324.87 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 123/240 [00:23<00:38,  3.04it/s, est. speed input: 693.63 toks/s, output: 3290.90 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 124/240 [00:23<00:33,  3.43it/s, est. speed input: 692.78 toks/s, output: 3309.25 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 125/240 [00:24<00:37,  3.09it/s, est. speed input: 685.24 toks/s, output: 3295.01 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 127/240 [00:24<00:29,  3.83it/s, est. speed input: 684.65 toks/s, output: 3332.47 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 128/240 [00:24<00:28,  3.98it/s, est. speed input: 682.18 toks/s, output: 3345.56 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 129/240 [00:25<00:30,  3.69it/s, est. speed input: 676.32 toks/s, output: 3344.27 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 131/240 [00:25<00:21,  5.13it/s, est. speed input: 680.91 toks/s, output: 3406.25 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 132/240 [00:25<00:18,  5.71it/s, est. speed input: 685.01 toks/s, output: 3434.35 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 133/240 [00:25<00:16,  6.32it/s, est. speed input: 698.22 toks/s, output: 3462.72 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 134/240 [00:26<00:27,  3.84it/s, est. speed input: 687.33 toks/s, output: 3432.14 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 135/240 [00:26<00:23,  4.48it/s, est. speed input: 690.91 toks/s, output: 3458.64 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 136/240 [00:26<00:33,  3.06it/s, est. speed input: 679.13 toks/s, output: 3424.55 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 138/240 [00:27<00:23,  4.37it/s, est. speed input: 682.23 toks/s, output: 3482.76 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 139/240 [00:28<00:46,  2.16it/s, est. speed input: 657.91 toks/s, output: 3377.79 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 142/240 [00:28<00:33,  2.94it/s, est. speed input: 653.60 toks/s, output: 3426.83 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 143/240 [00:29<00:41,  2.35it/s, est. speed input: 640.36 toks/s, output: 3379.96 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 144/240 [00:30<00:42,  2.27it/s, est. speed input: 633.11 toks/s, output: 3367.13 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 145/240 [00:30<00:42,  2.26it/s, est. speed input: 629.40 toks/s, output: 3361.37 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 148/240 [00:31<00:28,  3.28it/s, est. speed input: 642.00 toks/s, output: 3434.55 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 150/240 [00:31<00:24,  3.70it/s, est. speed input: 642.85 toks/s, output: 3477.14 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 151/240 [00:32<00:31,  2.87it/s, est. speed input: 632.29 toks/s, output: 3446.29 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 153/240 [00:33<00:38,  2.27it/s, est. speed input: 619.67 toks/s, output: 3404.99 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 154/240 [00:34<00:45,  1.89it/s, est. speed input: 608.66 toks/s, output: 3360.96 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 155/240 [00:35<00:56,  1.52it/s, est. speed input: 596.05 toks/s, output: 3298.29 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 156/240 [00:35<00:53,  1.57it/s, est. speed input: 591.49 toks/s, output: 3289.03 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 157/240 [00:36<00:46,  1.79it/s, est. speed input: 589.14 toks/s, output: 3303.18 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 158/240 [00:36<00:44,  1.86it/s, est. speed input: 586.28 toks/s, output: 3303.04 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 159/240 [00:37<00:43,  1.85it/s, est. speed input: 581.16 toks/s, output: 3297.79 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 160/240 [00:40<01:39,  1.24s/it, est. speed input: 540.20 toks/s, output: 3094.61 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 161/240 [00:42<01:53,  1.44s/it, est. speed input: 517.86 toks/s, output: 2997.18 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 162/240 [00:45<02:23,  1.84s/it, est. speed input: 487.93 toks/s, output: 2853.07 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 163/240 [00:47<02:29,  1.94s/it, est. speed input: 469.18 toks/s, output: 2764.44 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 165/240 [00:54<03:19,  2.66s/it, est. speed input: 419.54 toks/s, output: 2488.03 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 166/240 [00:56<03:17,  2.66s/it, est. speed input: 402.31 toks/s, output: 2413.81 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 167/240 [01:14<08:00,  6.59s/it, est. speed input: 308.95 toks/s, output: 1881.28 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [01:14<00:00,  3.21it/s, est. speed input: 447.13 toks/s, output: 4876.59 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/240 [00:00<?, ?it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<00:00, 27268.94it/s]
{'num_samples': 30, 'num_scores': 240, 'timeout_samples': 0, 'empty_samples': 0, 'acc': 10.0, 'total_acc': 8.333333333333332, 'pass_at_k_percent': {'1': 8.3, '8': 30.0}, 'pass_at_k_valid_counts': {'1': 30, '8': 30}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_results/noise_rlvr_1_5b_128batchsize_deepscaler_v2_think-boxed/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200/g1/aime24x8/test_think-boxed_-1_seed0_t0.6_s0_e-1_part7.jsonl
[2025-12-03 19:57:59] ‚úì B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200/g1/aime24x8  acc=10.0 pass_at_k={'1': 8.3, '8': 30.0}
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200/g1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [03:54<00:00, 77.85s/ds]B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200/g1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [03:54<00:00, 78.02s/ds]
[2025-12-03 19:57:59] ‚ñ∂ B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200/g2  ÂæÖËØÑÊµã=['minerva_math', 'olympiadbench', 'math500']  T=0.0  n=8
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200/g2:   0%|          | 0/3 [00:00<?, ?ds/s][Info] Sharding enabled: Process 7/8 handling range [238:272]
==================================================
data: minerva_math  ,remain samples: 34
{'problem': 'Determine the highest linear density of atoms (atoms/m) encountered in vanadium (V). Please format your answer as $n \\times 10^x$ where $n$ is to 2 decimal places.', 'solution': '\\[\n\\begin{aligned}\n&\\mathrm{V}: \\quad \\text { atomic weight }=50.94 \\mathrm{~g} / \\text { mole } \\\\\n&\\rho=5.8 \\mathrm{~g} / \\mathrm{cm}^{3}\n\\end{aligned}\n\\]\n$B C C$, so $n=2$\nThe highest density would be found in the [111] direction. To find "a":\n\\[\n\\begin{aligned}\n&\\frac{\\text { atomic weight }}{\\rho}=a^{3} \\frac{N_{A}}{n} \\rightarrow a^{3}=\\frac{50.94 \\times 2}{5.8 \\times 6.023 \\times 10^{23}} \\\\\n&a=3.08 \\times 10^{-8} \\mathrm{~cm}=3.08 \\times 10^{-10} \\mathrm{~m}\n\\end{aligned}\n\\]\nThe length in the [111] direction is $\\mathrm{a} \\sqrt{3}$, so there are:\n\\[\n\\begin{aligned}\n&2 \\text { atoms } / \\mathrm{a} \\sqrt{3}=2 \\text { atoms/ }\\left(3.08 \\times 10^{-10} \\mathrm{~m} \\times \\sqrt{3}\\right) \\\\\n&= \\boxed{3.75e9} \\text { atoms } / \\mathrm{m}\n\\end{aligned}\n\\]', 'type': 'Introduction to Solid State Chemistry (3.091 Fall 2010)', 'idx': 238}

  0%|          | 0/34 [00:00<?, ?it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 34/34 [00:00<00:00, 13121.67it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/272 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 1/272 [00:05<23:27,  5.19s/it, est. speed input: 48.13 toks/s, output: 46.78 toks/s][A
Processed prompts:   3%|‚ñé         | 9/272 [00:05<01:57,  2.24it/s, est. speed input: 397.79 toks/s, output: 404.23 toks/s][A
Processed prompts:   4%|‚ñç         | 11/272 [00:05<01:33,  2.80it/s, est. speed input: 427.01 toks/s, output: 482.95 toks/s][A
Processed prompts:  10%|‚ñâ         | 26/272 [00:05<00:26,  9.12it/s, est. speed input: 616.75 toks/s, output: 1135.81 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 42/272 [00:06<00:15, 15.15it/s, est. speed input: 914.32 toks/s, output: 1750.93 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 50/272 [00:06<00:14, 15.50it/s, est. speed input: 1023.94 toks/s, output: 1970.85 toks/s][A
Processed prompts:  21%|‚ñà‚ñà‚ñè       | 58/272 [00:07<00:13, 15.63it/s, est. speed input: 1089.81 toks/s, output: 2181.67 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 66/272 [00:09<00:23,  8.78it/s, est. speed input: 1065.29 toks/s, output: 2028.84 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 74/272 [00:09<00:16, 11.78it/s, est. speed input: 1159.75 toks/s, output: 2366.68 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 82/272 [00:09<00:13, 14.01it/s, est. speed input: 1296.26 toks/s, output: 2646.40 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 86/272 [00:09<00:12, 14.98it/s, est. speed input: 1326.99 toks/s, output: 2781.79 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 97/272 [00:10<00:08, 19.64it/s, est. speed input: 1445.13 toks/s, output: 3189.38 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñä      | 105/272 [00:10<00:08, 20.31it/s, est. speed input: 1467.16 toks/s, output: 3433.76 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 110/272 [00:10<00:07, 23.04it/s, est. speed input: 1522.87 toks/s, output: 3626.23 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 118/272 [00:11<00:12, 12.18it/s, est. speed input: 1497.90 toks/s, output: 3558.86 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 126/272 [00:12<00:12, 11.83it/s, est. speed input: 1508.85 toks/s, output: 3704.82 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 134/272 [00:13<00:13, 10.54it/s, est. speed input: 1598.68 toks/s, output: 3792.67 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 142/272 [00:15<00:18,  6.90it/s, est. speed input: 1464.14 toks/s, output: 3617.86 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 150/272 [00:16<00:14,  8.23it/s, est. speed input: 1468.89 toks/s, output: 3852.43 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 158/272 [00:18<00:18,  6.19it/s, est. speed input: 1389.52 toks/s, output: 3756.94 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 166/272 [00:19<00:18,  5.79it/s, est. speed input: 1338.38 toks/s, output: 3805.19 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 174/272 [00:21<00:16,  5.83it/s, est. speed input: 1354.96 toks/s, output: 3919.37 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 182/272 [00:26<00:29,  3.00it/s, est. speed input: 1155.59 toks/s, output: 3402.91 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 190/272 [00:29<00:26,  3.14it/s, est. speed input: 1140.80 toks/s, output: 3487.45 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 192/272 [00:33<00:42,  1.90it/s, est. speed input: 990.01 toks/s, output: 3055.24 toks/s] [A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 198/272 [00:39<00:47,  1.55it/s, est. speed input: 885.69 toks/s, output: 2841.65 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 206/272 [01:08<01:53,  1.71s/it, est. speed input: 524.14 toks/s, output: 1852.24 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 272/272 [01:08<00:00,  3.97it/s, est. speed input: 729.85 toks/s, output: 4807.26 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/272 [00:00<?, ?it/s][A
Evaluate:  39%|‚ñà‚ñà‚ñà‚ñä      | 105/272 [00:00<00:00, 376.97it/s][A
Evaluate:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 143/272 [00:00<00:01, 123.10it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 272/272 [00:01<00:00, 266.73it/s]
{'num_samples': 34, 'num_scores': 272, 'timeout_samples': 0, 'empty_samples': 1, 'acc': 5.9, 'total_acc': 5.88235294117647, 'pass_at_k_percent': {'1': 5.9, '8': 5.9}, 'pass_at_k_valid_counts': {'1': 34, '8': 34}, 'type_acc': {'Introduction to Solid State Chemistry (3.091 Fall 2010)': 0.0, 'Physical Chemistry (5.61 Fall 2017)': 0.0, 'Principles of Microeconomics (14.01 Fall 2011)': 11.1}, 'type_pass_at_k_percent': {'Introduction to Solid State Chemistry (3.091 Fall 2010)': {'1': 0.0, '8': 0.0}, 'Physical Chemistry (5.61 Fall 2017)': {'1': 0.0, '8': 0.0}, 'Principles of Microeconomics (14.01 Fall 2011)': {'1': 11.1, '8': 11.1}}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_results/noise_rlvr_1_5b_128batchsize_deepscaler_v2_think-boxed/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200/g2/minerva_math/test_think-boxed_-1_seed0_t0.0_s0_e-1_part7.jsonl
[2025-12-03 19:59:08] ‚úì B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200/g2/minerva_math  acc=5.9 pass_at_k={'1': 5.9, '8': 5.9}
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200/g2:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [01:09<02:19, 69.90s/ds][Info] Sharding enabled: Process 7/8 handling range [588:675]
==================================================
data: olympiadbench  ,remain samples: 87
{'idx': 588, 'id': 2984, 'subfield': 'Algebra', 'context': None, 'question': 'Compute the value of\n\n$$\n\\sin \\left(6^{\\circ}\\right) \\cdot \\sin \\left(12^{\\circ}\\right) \\cdot \\sin \\left(24^{\\circ}\\right) \\cdot \\sin \\left(42^{\\circ}\\right)+\\sin \\left(12^{\\circ}\\right) \\cdot \\sin \\left(24^{\\circ}\\right) \\cdot \\sin \\left(42^{\\circ}\\right) \\text {. }\n$$', 'solution': ['Let $S=\\left(1+\\sin 6^{\\circ}\\right)\\left(\\sin 12^{\\circ} \\sin 24^{\\circ} \\sin 42^{\\circ}\\right)$. It follows from a sum-to-product identity that $1+\\sin 6^{\\circ}=$ $\\sin 90^{\\circ}+\\sin 6^{\\circ}=2 \\sin 48^{\\circ} \\cos 42^{\\circ}$. Because the sine of an angle is the cosine of its complement, it follows that\n\n$$\nS=\\left(2 \\sin 48^{\\circ} \\cos 42^{\\circ}\\right)\\left(\\sin 12^{\\circ} \\sin 24^{\\circ} \\sin 42^{\\circ}\\right)=2\\left(\\sin 48^{\\circ}\\right)^{2}\\left(\\sin 12^{\\circ} \\sin 24^{\\circ} \\cos 48^{\\circ}\\right)\n$$\n\nBy the double-angle formula, this means $S=\\sin 12^{\\circ} \\sin 24^{\\circ} \\sin 48^{\\circ} \\sin 96^{\\circ}$. By a product-to-sum identity,\n\n$$\n\\sin 12^{\\circ} \\sin 48^{\\circ}=\\frac{\\cos 36^{\\circ}-\\cos 60^{\\circ}}{2}=\\frac{\\sqrt{5}-1}{8}\n$$\n\n\n\nand\n\n$$\n\\sin 24^{\\circ} \\sin 96^{\\circ}=\\frac{\\cos 72^{\\circ}-\\cos 120^{\\circ}}{2}=\\frac{\\sqrt{5}+1}{8}\n$$\n\nMultiply the expressions on the right-hand sides of (1) and (2) to obtain $\\frac{\\mathbf{1}}{\\mathbf{1 6}}$'], 'final_answer': ['$\\frac{1}{16}$'], 'is_multiple_answer': False, 'unit': None, 'answer_type': 'Numerical', 'error': None}

  0%|          | 0/87 [00:00<?, ?it/s][A
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 44/87 [00:00<00:00, 436.26it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 87/87 [00:00<00:00, 434.21it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/696 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 1/696 [00:00<03:12,  3.60it/s, est. speed input: 270.26 toks/s, output: 10.81 toks/s][A
Processed prompts:   1%|‚ñè         | 9/696 [00:04<06:22,  1.80it/s, est. speed input: 183.84 toks/s, output: 50.99 toks/s][A
Processed prompts:   2%|‚ñè         | 17/696 [00:05<02:54,  3.88it/s, est. speed input: 604.15 toks/s, output: 401.93 toks/s][A
Processed prompts:   4%|‚ñé         | 25/696 [00:05<02:06,  5.30it/s, est. speed input: 628.83 toks/s, output: 666.02 toks/s][A
Processed prompts:   5%|‚ñç         | 33/696 [00:06<01:45,  6.27it/s, est. speed input: 690.77 toks/s, output: 901.38 toks/s][A
Processed prompts:   6%|‚ñå         | 41/696 [00:07<01:15,  8.63it/s, est. speed input: 971.56 toks/s, output: 1210.53 toks/s][A
Processed prompts:   7%|‚ñã         | 48/696 [00:09<01:45,  6.14it/s, est. speed input: 868.67 toks/s, output: 1217.98 toks/s][A
Processed prompts:   8%|‚ñä         | 56/696 [00:09<01:32,  6.90it/s, est. speed input: 1038.87 toks/s, output: 1435.19 toks/s][A
Processed prompts:   8%|‚ñä         | 59/696 [00:11<01:59,  5.34it/s, est. speed input: 993.07 toks/s, output: 1392.83 toks/s] [A
Processed prompts:  11%|‚ñà         | 75/696 [00:11<01:07,  9.15it/s, est. speed input: 1258.93 toks/s, output: 1957.31 toks/s][A
Processed prompts:  11%|‚ñà         | 77/696 [00:12<01:30,  6.86it/s, est. speed input: 1205.69 toks/s, output: 1881.58 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 81/696 [00:13<01:28,  6.92it/s, est. speed input: 1257.46 toks/s, output: 1965.48 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 89/696 [00:13<01:00, 10.09it/s, est. speed input: 1478.33 toks/s, output: 2271.03 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 97/696 [00:13<00:44, 13.48it/s, est. speed input: 1615.26 toks/s, output: 2534.89 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 104/696 [00:14<00:43, 13.61it/s, est. speed input: 1595.25 toks/s, output: 2559.88 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 112/696 [00:14<00:39, 14.73it/s, est. speed input: 1589.40 toks/s, output: 2771.67 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 115/696 [00:15<01:03,  9.18it/s, est. speed input: 1506.30 toks/s, output: 2713.97 toks/s][A
Processed prompts:  19%|‚ñà‚ñä        | 129/696 [00:18<01:29,  6.36it/s, est. speed input: 1353.49 toks/s, output: 2765.89 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 136/696 [00:20<01:40,  5.58it/s, est. speed input: 1274.09 toks/s, output: 2701.83 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 144/696 [00:21<01:21,  6.79it/s, est. speed input: 1266.91 toks/s, output: 2913.73 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 146/696 [00:21<01:24,  6.54it/s, est. speed input: 1253.95 toks/s, output: 2880.72 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 152/696 [00:22<01:16,  7.15it/s, est. speed input: 1251.06 toks/s, output: 2864.01 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 160/696 [00:23<01:29,  5.97it/s, est. speed input: 1208.92 toks/s, output: 2755.04 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 168/696 [00:24<01:19,  6.60it/s, est. speed input: 1200.87 toks/s, output: 2766.26 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 170/696 [00:25<01:19,  6.65it/s, est. speed input: 1195.03 toks/s, output: 2791.58 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 178/696 [00:25<01:01,  8.37it/s, est. speed input: 1204.72 toks/s, output: 3008.38 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 179/696 [00:26<01:39,  5.21it/s, est. speed input: 1151.00 toks/s, output: 2884.85 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñã       | 184/696 [00:33<04:52,  1.75it/s, est. speed input: 924.39 toks/s, output: 2357.81 toks/s] [A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 192/696 [00:34<03:10,  2.64it/s, est. speed input: 928.80 toks/s, output: 2421.84 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 193/696 [00:35<03:19,  2.52it/s, est. speed input: 913.34 toks/s, output: 2385.20 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 194/696 [00:35<03:28,  2.41it/s, est. speed input: 900.23 toks/s, output: 2363.64 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 202/696 [00:36<01:58,  4.18it/s, est. speed input: 901.49 toks/s, output: 2462.28 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 209/696 [00:36<01:22,  5.93it/s, est. speed input: 908.39 toks/s, output: 2530.23 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 214/696 [00:39<01:54,  4.20it/s, est. speed input: 868.81 toks/s, output: 2447.55 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 222/696 [00:43<03:04,  2.57it/s, est. speed input: 788.37 toks/s, output: 2324.96 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 223/696 [00:54<08:23,  1.06s/it, est. speed input: 636.39 toks/s, output: 1902.28 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 231/696 [00:57<05:42,  1.36it/s, est. speed input: 625.15 toks/s, output: 2054.74 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 233/696 [01:42<28:08,  3.65s/it, est. speed input: 351.10 toks/s, output: 1187.65 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñé      | 234/696 [01:42<25:45,  3.35s/it, est. speed input: 351.92 toks/s, output: 1215.65 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 249/696 [01:42<08:49,  1.18s/it, est. speed input: 367.65 toks/s, output: 1660.11 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 257/696 [01:43<05:53,  1.24it/s, est. speed input: 378.41 toks/s, output: 1893.37 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 285/696 [01:43<02:07,  3.23it/s, est. speed input: 431.99 toks/s, output: 2719.63 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 316/696 [01:43<01:00,  6.31it/s, est. speed input: 466.04 toks/s, output: 3634.61 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 325/696 [01:44<00:53,  6.93it/s, est. speed input: 471.01 toks/s, output: 3752.24 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 332/696 [01:49<01:25,  4.24it/s, est. speed input: 454.88 toks/s, output: 3611.69 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 340/696 [01:49<01:07,  5.26it/s, est. speed input: 460.23 toks/s, output: 3648.65 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 346/696 [01:50<01:01,  5.66it/s, est. speed input: 464.29 toks/s, output: 3792.87 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 351/696 [01:51<01:01,  5.65it/s, est. speed input: 464.02 toks/s, output: 3800.29 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 358/696 [01:51<00:48,  6.92it/s, est. speed input: 466.37 toks/s, output: 3808.02 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 361/696 [01:51<00:49,  6.74it/s, est. speed input: 466.08 toks/s, output: 3802.69 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 364/696 [01:52<00:43,  7.62it/s, est. speed input: 467.40 toks/s, output: 3810.52 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 367/696 [01:55<01:45,  3.12it/s, est. speed input: 456.56 toks/s, output: 3731.91 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 369/696 [01:55<01:34,  3.46it/s, est. speed input: 457.34 toks/s, output: 3743.00 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 371/696 [01:55<01:25,  3.79it/s, est. speed input: 458.14 toks/s, output: 3741.87 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 374/696 [01:56<01:04,  4.97it/s, est. speed input: 460.62 toks/s, output: 3750.84 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 376/696 [01:57<01:25,  3.74it/s, est. speed input: 458.73 toks/s, output: 3770.24 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 378/696 [01:57<01:10,  4.50it/s, est. speed input: 460.32 toks/s, output: 3817.94 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 380/696 [01:57<01:02,  5.09it/s, est. speed input: 461.56 toks/s, output: 3862.56 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 382/696 [01:57<00:59,  5.32it/s, est. speed input: 462.43 toks/s, output: 3903.98 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 383/696 [01:57<00:56,  5.50it/s, est. speed input: 462.42 toks/s, output: 3901.34 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 387/696 [01:58<00:34,  8.89it/s, est. speed input: 464.13 toks/s, output: 3905.63 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 389/696 [01:58<00:36,  8.51it/s, est. speed input: 464.73 toks/s, output: 3913.35 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 391/696 [01:59<01:04,  4.75it/s, est. speed input: 463.19 toks/s, output: 3911.18 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 392/696 [01:59<01:01,  4.98it/s, est. speed input: 463.17 toks/s, output: 3908.77 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 393/696 [01:59<01:08,  4.44it/s, est. speed input: 462.65 toks/s, output: 3901.94 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 399/696 [02:02<01:36,  3.09it/s, est. speed input: 457.48 toks/s, output: 3844.17 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 402/696 [02:02<01:26,  3.41it/s, est. speed input: 457.60 toks/s, output: 3838.02 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 403/696 [02:02<01:19,  3.67it/s, est. speed input: 457.86 toks/s, output: 3838.70 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 404/696 [02:03<01:13,  4.00it/s, est. speed input: 457.91 toks/s, output: 3837.58 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 405/696 [02:03<01:23,  3.49it/s, est. speed input: 456.76 toks/s, output: 3826.41 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 407/696 [02:03<01:09,  4.19it/s, est. speed input: 456.95 toks/s, output: 3825.20 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 408/696 [02:03<01:04,  4.46it/s, est. speed input: 457.03 toks/s, output: 3844.93 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 410/696 [02:04<00:47,  5.99it/s, est. speed input: 457.93 toks/s, output: 3890.50 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 412/696 [02:04<00:38,  7.30it/s, est. speed input: 458.72 toks/s, output: 3935.07 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 413/696 [02:04<00:38,  7.42it/s, est. speed input: 458.94 toks/s, output: 3955.78 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 414/696 [02:04<00:37,  7.53it/s, est. speed input: 459.38 toks/s, output: 3956.59 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 416/696 [02:04<00:34,  8.06it/s, est. speed input: 459.93 toks/s, output: 3998.88 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 417/696 [02:05<01:01,  4.53it/s, est. speed input: 458.55 toks/s, output: 3985.77 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 418/696 [02:05<01:01,  4.51it/s, est. speed input: 458.47 toks/s, output: 3983.89 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 422/696 [02:05<00:31,  8.57it/s, est. speed input: 460.10 toks/s, output: 3991.91 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 424/696 [02:07<01:26,  3.13it/s, est. speed input: 455.97 toks/s, output: 3949.68 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 425/696 [02:07<01:23,  3.23it/s, est. speed input: 455.91 toks/s, output: 3945.67 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 426/696 [02:07<01:14,  3.64it/s, est. speed input: 456.32 toks/s, output: 3945.74 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 428/696 [02:07<00:56,  4.74it/s, est. speed input: 457.37 toks/s, output: 3947.89 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 429/696 [02:08<01:24,  3.15it/s, est. speed input: 455.64 toks/s, output: 3929.50 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 432/696 [02:08<00:54,  4.87it/s, est. speed input: 457.10 toks/s, output: 3933.68 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 433/696 [02:09<01:16,  3.45it/s, est. speed input: 455.26 toks/s, output: 3916.44 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 435/696 [02:09<00:58,  4.45it/s, est. speed input: 455.63 toks/s, output: 3916.69 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 449/696 [02:10<00:19, 12.48it/s, est. speed input: 469.84 toks/s, output: 3978.86 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 451/696 [02:10<00:21, 11.15it/s, est. speed input: 469.94 toks/s, output: 4016.78 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 454/696 [02:10<00:18, 12.99it/s, est. speed input: 471.35 toks/s, output: 4084.25 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 456/696 [02:10<00:20, 11.55it/s, est. speed input: 471.58 toks/s, output: 4123.01 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 458/696 [02:11<00:19, 12.14it/s, est. speed input: 472.55 toks/s, output: 4144.20 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 460/696 [02:11<00:26,  9.00it/s, est. speed input: 472.83 toks/s, output: 4139.94 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 476/696 [02:11<00:09, 23.52it/s, est. speed input: 485.98 toks/s, output: 4231.50 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 480/696 [02:11<00:10, 21.53it/s, est. speed input: 488.30 toks/s, output: 4232.24 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 483/696 [02:12<00:15, 13.32it/s, est. speed input: 488.22 toks/s, output: 4225.00 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 487/696 [02:12<00:13, 15.21it/s, est. speed input: 490.73 toks/s, output: 4239.15 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 490/696 [02:13<00:15, 13.58it/s, est. speed input: 491.58 toks/s, output: 4235.39 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 492/696 [02:13<00:25,  8.07it/s, est. speed input: 489.81 toks/s, output: 4214.24 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 495/696 [02:13<00:21,  9.30it/s, est. speed input: 490.56 toks/s, output: 4211.84 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 497/696 [02:16<01:02,  3.20it/s, est. speed input: 484.00 toks/s, output: 4152.22 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 501/696 [02:16<00:45,  4.24it/s, est. speed input: 485.00 toks/s, output: 4165.58 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 502/696 [02:17<01:04,  2.99it/s, est. speed input: 481.79 toks/s, output: 4136.87 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 503/696 [02:18<01:16,  2.52it/s, est. speed input: 479.55 toks/s, output: 4116.03 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 505/696 [02:19<01:14,  2.56it/s, est. speed input: 477.98 toks/s, output: 4098.38 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 512/696 [02:19<00:31,  5.85it/s, est. speed input: 481.40 toks/s, output: 4109.51 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 514/696 [02:21<01:01,  2.97it/s, est. speed input: 475.89 toks/s, output: 4062.99 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 522/696 [02:22<00:37,  4.59it/s, est. speed input: 479.46 toks/s, output: 4116.03 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 525/696 [02:22<00:31,  5.49it/s, est. speed input: 481.31 toks/s, output: 4176.00 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 527/696 [02:22<00:27,  6.07it/s, est. speed input: 482.36 toks/s, output: 4214.34 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 529/696 [02:22<00:24,  6.76it/s, est. speed input: 483.41 toks/s, output: 4252.62 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 531/696 [02:24<00:58,  2.83it/s, est. speed input: 477.59 toks/s, output: 4198.79 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 533/696 [02:25<00:59,  2.75it/s, est. speed input: 476.04 toks/s, output: 4184.22 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 534/696 [02:25<00:53,  3.04it/s, est. speed input: 476.30 toks/s, output: 4185.80 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 539/696 [02:26<00:31,  4.98it/s, est. speed input: 478.42 toks/s, output: 4205.85 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 540/696 [02:26<00:33,  4.70it/s, est. speed input: 478.03 toks/s, output: 4218.40 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 544/696 [02:26<00:22,  6.66it/s, est. speed input: 479.45 toks/s, output: 4294.73 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 547/696 [02:26<00:17,  8.56it/s, est. speed input: 480.85 toks/s, output: 4338.34 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 549/696 [02:27<00:19,  7.51it/s, est. speed input: 481.01 toks/s, output: 4352.75 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 551/696 [02:28<00:42,  3.43it/s, est. speed input: 478.49 toks/s, output: 4323.01 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 559/696 [02:30<00:36,  3.71it/s, est. speed input: 484.14 toks/s, output: 4334.54 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 561/696 [02:30<00:31,  4.28it/s, est. speed input: 486.04 toks/s, output: 4371.59 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 564/696 [02:31<00:24,  5.50it/s, est. speed input: 489.09 toks/s, output: 4428.94 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 567/696 [02:31<00:18,  6.87it/s, est. speed input: 492.04 toks/s, output: 4485.35 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 569/696 [02:34<01:02,  2.04it/s, est. speed input: 482.33 toks/s, output: 4396.29 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 571/696 [02:35<00:52,  2.38it/s, est. speed input: 482.55 toks/s, output: 4425.18 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 573/696 [02:35<00:41,  2.99it/s, est. speed input: 483.50 toks/s, output: 4460.63 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 575/696 [02:35<00:31,  3.82it/s, est. speed input: 484.53 toks/s, output: 4496.88 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 578/696 [02:37<00:47,  2.49it/s, est. speed input: 480.51 toks/s, output: 4486.88 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 580/696 [02:39<01:08,  1.69it/s, est. speed input: 475.03 toks/s, output: 4437.33 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 581/696 [02:42<01:40,  1.15it/s, est. speed input: 468.41 toks/s, output: 4378.36 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 582/696 [02:46<03:00,  1.58s/it, est. speed input: 455.26 toks/s, output: 4270.35 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 584/696 [02:47<01:59,  1.07s/it, est. speed input: 455.67 toks/s, output: 4304.04 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 586/696 [02:47<01:21,  1.35it/s, est. speed input: 456.01 toks/s, output: 4336.94 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 588/696 [02:47<00:56,  1.91it/s, est. speed input: 456.43 toks/s, output: 4370.58 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 590/696 [02:55<02:50,  1.61s/it, est. speed input: 437.10 toks/s, output: 4199.97 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 591/696 [02:56<02:37,  1.50s/it, est. speed input: 435.18 toks/s, output: 4193.17 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 594/696 [02:56<01:27,  1.16it/s, est. speed input: 436.68 toks/s, output: 4242.46 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 596/696 [02:56<01:02,  1.60it/s, est. speed input: 437.58 toks/s, output: 4274.34 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 598/696 [02:57<01:01,  1.60it/s, est. speed input: 435.69 toks/s, output: 4278.80 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 599/696 [02:58<01:02,  1.56it/s, est. speed input: 434.52 toks/s, output: 4278.85 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 601/696 [02:58<00:42,  2.24it/s, est. speed input: 435.36 toks/s, output: 4310.34 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 604/696 [02:58<00:25,  3.60it/s, est. speed input: 436.78 toks/s, output: 4359.00 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 606/696 [02:59<00:32,  2.74it/s, est. speed input: 435.08 toks/s, output: 4364.85 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 608/696 [03:00<00:25,  3.46it/s, est. speed input: 435.47 toks/s, output: 4394.00 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 611/696 [03:00<00:16,  5.18it/s, est. speed input: 436.50 toks/s, output: 4442.31 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 613/696 [03:00<00:13,  6.38it/s, est. speed input: 437.10 toks/s, output: 4473.58 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 615/696 [03:02<00:35,  2.30it/s, est. speed input: 432.50 toks/s, output: 4450.26 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 617/696 [03:02<00:25,  3.06it/s, est. speed input: 433.21 toks/s, output: 4481.21 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 621/696 [03:03<00:17,  4.29it/s, est. speed input: 434.24 toks/s, output: 4531.50 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 623/696 [03:07<00:52,  1.38it/s, est. speed input: 424.94 toks/s, output: 4451.85 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 625/696 [03:08<00:45,  1.57it/s, est. speed input: 424.13 toks/s, output: 4458.67 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 626/696 [03:13<01:32,  1.32s/it, est. speed input: 413.56 toks/s, output: 4358.46 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 628/696 [03:13<01:03,  1.07it/s, est. speed input: 414.27 toks/s, output: 4387.71 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 630/696 [03:14<00:47,  1.39it/s, est. speed input: 414.08 toks/s, output: 4408.57 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 636/696 [03:16<00:28,  2.08it/s, est. speed input: 412.63 toks/s, output: 4462.27 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 638/696 [03:16<00:27,  2.14it/s, est. speed input: 411.98 toks/s, output: 4474.61 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 677/696 [03:16<00:01, 14.20it/s, est. speed input: 437.26 toks/s, output: 5079.96 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 687/696 [03:22<00:01,  5.44it/s, est. speed input: 431.22 toks/s, output: 5094.72 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 694/696 [03:25<00:00,  4.32it/s, est. speed input: 428.85 toks/s, output: 5124.73 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 696/696 [03:25<00:00,  3.39it/s, est. speed input: 429.41 toks/s, output: 5152.70 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/696 [00:00<?, ?it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 696/696 [00:00<00:00, 8467.54it/s]
{'num_samples': 87, 'num_scores': 696, 'timeout_samples': 0, 'empty_samples': 4, 'acc': 20.7, 'total_acc': 19.10919540229885, 'pass_at_k_percent': {'1': 19.1, '8': 24.1}, 'pass_at_k_valid_counts': {'1': 87, '8': 87}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_results/noise_rlvr_1_5b_128batchsize_deepscaler_v2_think-boxed/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200/g2/olympiadbench/test_think-boxed_-1_seed0_t0.0_s0_e-1_part7.jsonl
[2025-12-03 20:02:36] ‚úì B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200/g2/olympiadbench  acc=20.7 pass_at_k={'1': 19.1, '8': 24.1}
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200/g2:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [04:37<02:31, 151.13s/ds][Info] Sharding enabled: Process 7/8 handling range [434:500]
==================================================
data: math500  ,remain samples: 66
{'idx': 434, 'problem': 'In a certain isosceles right triangle, the altitude to the hypotenuse has length $4\\sqrt{2}$.  What is the area of the triangle?', 'solution': 'In isosceles right triangle $\\triangle ABC$ below, $\\overline{AD}$ is the altitude to the hypotenuse.\n\n[asy]\nimport olympiad;\nunitsize(0.8inch);\npair A,B,C,D;\nA = (0,1);\nB= (1,0);\nC = -B;\nD = (0,0);\ndraw(A--B--C--A,linewidth(1));\ndraw(A--D,linewidth(0.8));\ndraw(rightanglemark(C,A,B,s=5));\ndraw(rightanglemark(C,D,A,s=5));\nlabel("$A$",A,N);\nlabel("$B$",B,S);\nlabel("$C$",C,S);\nlabel("$D$",D,S);\n[/asy]\n\nBecause $\\triangle ABC$ is an isosceles right triangle, $\\angle ABC = 45^\\circ$.  Since $\\angle ADB = 90^\\circ$, we know that $\\angle DAB = 45^\\circ$, so $\\triangle ABD$ is also a 45-45-90 triangle.  Similarly, $\\triangle ACD$ is a 45-45-90 triangle.  Therefore, $DB=DC = DA = 4\\sqrt{2}$, so $BC = BD+DC = 8\\sqrt{2}$, and  \\[[ABC] = \\frac{(AD)(BC)}{2} = \\frac{(4\\sqrt{2})(8\\sqrt{2})}{2} = \\boxed{32}.\\]', 'answer': '32', 'subject': 'Prealgebra', 'level': 5, 'unique_id': 'test/prealgebra/1640.json'}

  0%|          | 0/66 [00:00<?, ?it/s][A
 33%|‚ñà‚ñà‚ñà‚ñé      | 22/66 [00:00<00:00, 213.53it/s][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 45/66 [00:00<00:00, 221.01it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [00:00<00:00, 218.26it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/528 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 1/528 [00:02<22:39,  2.58s/it, est. speed input: 24.04 toks/s, output: 48.47 toks/s][A
Processed prompts:   2%|‚ñè         | 9/528 [00:02<01:54,  4.54it/s, est. speed input: 202.11 toks/s, output: 419.45 toks/s][A
Processed prompts:   3%|‚ñé         | 17/528 [00:02<00:55,  9.16it/s, est. speed input: 327.27 toks/s, output: 751.86 toks/s][A
Processed prompts:   5%|‚ñç         | 25/528 [00:03<00:48, 10.35it/s, est. speed input: 415.46 toks/s, output: 937.25 toks/s][A
Processed prompts:   6%|‚ñã         | 33/528 [00:03<00:39, 12.69it/s, est. speed input: 516.47 toks/s, output: 1189.89 toks/s][A
Processed prompts:   9%|‚ñâ         | 49/528 [00:04<00:22, 20.97it/s, est. speed input: 808.58 toks/s, output: 1816.42 toks/s][A
Processed prompts:  11%|‚ñà         | 57/528 [00:04<00:18, 25.44it/s, est. speed input: 894.03 toks/s, output: 2130.57 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 78/528 [00:04<00:10, 44.55it/s, est. speed input: 1145.26 toks/s, output: 3048.64 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 89/528 [00:04<00:10, 42.74it/s, est. speed input: 1444.04 toks/s, output: 3356.87 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 97/528 [00:05<00:11, 36.70it/s, est. speed input: 1464.39 toks/s, output: 3500.27 toks/s][A
Processed prompts:  21%|‚ñà‚ñà‚ñè       | 113/528 [00:06<00:17, 23.65it/s, est. speed input: 1413.70 toks/s, output: 3534.09 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 122/528 [00:06<00:16, 24.84it/s, est. speed input: 1570.54 toks/s, output: 3772.03 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñç       | 130/528 [00:07<00:23, 17.10it/s, est. speed input: 1483.81 toks/s, output: 3620.20 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 138/528 [00:07<00:18, 20.64it/s, est. speed input: 1590.30 toks/s, output: 3913.61 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 146/528 [00:07<00:15, 24.26it/s, est. speed input: 1660.28 toks/s, output: 4174.29 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 154/528 [00:07<00:13, 27.90it/s, est. speed input: 1820.13 toks/s, output: 4329.90 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 162/528 [00:08<00:11, 33.26it/s, est. speed input: 1846.90 toks/s, output: 4604.82 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 170/528 [00:08<00:13, 26.90it/s, est. speed input: 1805.37 toks/s, output: 4551.16 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñé      | 178/528 [00:08<00:13, 25.06it/s, est. speed input: 1814.08 toks/s, output: 4522.05 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 186/528 [00:10<00:31, 10.96it/s, est. speed input: 1584.00 toks/s, output: 3972.17 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 194/528 [00:11<00:32, 10.22it/s, est. speed input: 1522.36 toks/s, output: 3959.81 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 197/528 [00:11<00:32, 10.23it/s, est. speed input: 1502.31 toks/s, output: 3960.25 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 203/528 [00:11<00:25, 12.99it/s, est. speed input: 1519.30 toks/s, output: 4085.25 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 210/528 [00:12<00:26, 12.08it/s, est. speed input: 1479.71 toks/s, output: 3973.14 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 218/528 [00:12<00:19, 15.96it/s, est. speed input: 1509.73 toks/s, output: 4245.10 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 226/528 [00:13<00:27, 11.12it/s, est. speed input: 1435.60 toks/s, output: 4094.33 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 234/528 [00:14<00:20, 14.24it/s, est. speed input: 1455.87 toks/s, output: 4247.97 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 242/528 [00:14<00:17, 16.73it/s, est. speed input: 1473.04 toks/s, output: 4385.72 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 249/528 [00:14<00:17, 16.11it/s, est. speed input: 1465.53 toks/s, output: 4392.69 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 257/528 [00:15<00:13, 19.54it/s, est. speed input: 1510.74 toks/s, output: 4645.50 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 260/528 [00:15<00:19, 13.69it/s, est. speed input: 1477.73 toks/s, output: 4594.96 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 266/528 [00:16<00:17, 15.07it/s, est. speed input: 1496.88 toks/s, output: 4739.38 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 269/528 [00:16<00:20, 12.79it/s, est. speed input: 1508.56 toks/s, output: 4712.81 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 275/528 [00:16<00:16, 15.15it/s, est. speed input: 1570.92 toks/s, output: 4809.67 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 282/528 [00:17<00:18, 13.59it/s, est. speed input: 1550.73 toks/s, output: 4774.45 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 289/528 [00:18<00:25,  9.46it/s, est. speed input: 1489.23 toks/s, output: 4609.54 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 291/528 [00:20<00:52,  4.48it/s, est. speed input: 1345.85 toks/s, output: 4166.63 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 292/528 [00:21<00:58,  4.04it/s, est. speed input: 1316.47 toks/s, output: 4090.02 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 293/528 [00:21<00:58,  4.04it/s, est. speed input: 1306.55 toks/s, output: 4077.43 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 301/528 [00:21<00:30,  7.52it/s, est. speed input: 1331.95 toks/s, output: 4296.77 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 308/528 [00:21<00:20, 10.87it/s, est. speed input: 1343.61 toks/s, output: 4443.72 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 316/528 [00:22<00:17, 11.88it/s, est. speed input: 1350.59 toks/s, output: 4652.37 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 324/528 [00:22<00:12, 16.78it/s, est. speed input: 1390.90 toks/s, output: 4926.90 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 328/528 [00:22<00:11, 17.28it/s, est. speed input: 1393.65 toks/s, output: 4939.76 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 332/528 [00:23<00:10, 18.70it/s, est. speed input: 1399.90 toks/s, output: 4972.91 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 335/528 [00:23<00:10, 18.85it/s, est. speed input: 1403.15 toks/s, output: 5025.94 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 341/528 [00:23<00:13, 14.28it/s, est. speed input: 1390.91 toks/s, output: 5053.25 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 348/528 [00:24<00:17, 10.35it/s, est. speed input: 1355.82 toks/s, output: 4950.36 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 350/528 [00:24<00:16, 11.04it/s, est. speed input: 1358.05 toks/s, output: 4973.79 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 356/528 [00:25<00:15, 10.92it/s, est. speed input: 1351.99 toks/s, output: 4991.44 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 358/528 [00:26<00:24,  7.03it/s, est. speed input: 1321.39 toks/s, output: 4882.26 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 372/528 [00:28<00:20,  7.68it/s, est. speed input: 1332.96 toks/s, output: 4946.76 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 380/528 [00:32<00:39,  3.74it/s, est. speed input: 1174.49 toks/s, output: 4406.58 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 394/528 [00:42<01:03,  2.10it/s, est. speed input: 923.86 toks/s, output: 3709.12 toks/s] [A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 395/528 [00:43<01:03,  2.08it/s, est. speed input: 913.71 toks/s, output: 3694.51 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 403/528 [00:50<01:15,  1.65it/s, est. speed input: 802.54 toks/s, output: 3420.54 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 410/528 [00:53<01:05,  1.81it/s, est. speed input: 770.00 toks/s, output: 3412.74 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 418/528 [01:14<02:16,  1.24s/it, est. speed input: 558.93 toks/s, output: 2661.49 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 421/528 [01:25<02:53,  1.62s/it, est. speed input: 489.88 toks/s, output: 2401.92 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 436/528 [01:26<01:13,  1.26it/s, est. speed input: 500.86 toks/s, output: 2929.18 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 452/528 [01:26<00:34,  2.23it/s, est. speed input: 531.84 toks/s, output: 3496.02 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 460/528 [01:30<00:33,  2.05it/s, est. speed input: 516.41 toks/s, output: 3579.80 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 468/528 [01:31<00:22,  2.71it/s, est. speed input: 522.69 toks/s, output: 3841.40 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 473/528 [01:31<00:17,  3.09it/s, est. speed input: 528.85 toks/s, output: 3983.43 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 481/528 [01:32<00:12,  3.82it/s, est. speed input: 533.30 toks/s, output: 4208.73 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 484/528 [01:33<00:12,  3.65it/s, est. speed input: 530.10 toks/s, output: 4259.81 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 490/528 [01:35<00:11,  3.37it/s, est. speed input: 524.20 toks/s, output: 4357.38 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 492/528 [01:36<00:11,  3.18it/s, est. speed input: 522.42 toks/s, output: 4380.48 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 498/528 [01:37<00:06,  4.31it/s, est. speed input: 530.17 toks/s, output: 4551.28 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 510/528 [01:37<00:02,  8.16it/s, est. speed input: 543.42 toks/s, output: 4925.31 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 515/528 [01:39<00:02,  5.22it/s, est. speed input: 537.08 toks/s, output: 4973.64 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 520/528 [01:39<00:01,  6.62it/s, est. speed input: 541.85 toks/s, output: 5121.42 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 524/528 [01:43<00:01,  2.99it/s, est. speed input: 524.40 toks/s, output: 5043.62 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 527/528 [01:43<00:00,  3.51it/s, est. speed input: 525.97 toks/s, output: 5121.89 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 528/528 [01:43<00:00,  5.09it/s, est. speed input: 526.79 toks/s, output: 5150.85 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/528 [00:00<?, ?it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 528/528 [00:00<00:00, 12137.41it/s]
{'num_samples': 66, 'num_scores': 528, 'timeout_samples': 0, 'empty_samples': 5, 'acc': 42.4, 'total_acc': 42.42424242424242, 'pass_at_k_percent': {'1': 42.4, '8': 43.9}, 'pass_at_k_valid_counts': {'1': 66, '8': 66}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_results/noise_rlvr_1_5b_128batchsize_deepscaler_v2_think-boxed/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200/g2/math500/test_think-boxed_-1_seed0_t0.0_s0_e-1_part7.jsonl
[2025-12-03 20:04:22] ‚úì B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200/g2/math500  acc=42.4 pass_at_k={'1': 42.4, '8': 43.9}
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200/g2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [06:23<00:00, 130.43s/ds]B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200/g2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [06:23<00:00, 127.89s/ds]
[2025-12-03 20:04:22] ‚úÖ ÂÆåÊàêÔºöB_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_200Ôºàg1+g2 Áº∫Â§±Êï∞ÊçÆÈõÜÂ∑≤Ë°•ÂÖ®Ôºâ
[2025-12-03 20:04:24] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_300
INFO 12-03 20:04:24 [config.py:717] This model supports multiple tasks: {'embed', 'classify', 'reward', 'generate', 'score'}. Defaulting to 'generate'.
INFO 12-03 20:04:24 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-03 20:04:24 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-03 20:04:29 [__init__.py:239] Automatically detected platform cuda.
INFO 12-03 20:04:35 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_300', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_300', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_300, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-03 20:04:36 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f87b98464a0>
INFO 12-03 20:05:01 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-03 20:05:01 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-03 20:05:01 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-03 20:05:01 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_300...
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.67s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.11s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.20s/it]

INFO 12-03 20:05:04 [loader.py:458] Loading weights took 2.46 seconds
INFO 12-03 20:05:04 [gpu_model_runner.py:1347] Model loading took 6.0160 GiB and 2.605752 seconds
INFO 12-03 20:05:05 [kv_cache_utils.py:634] GPU KV cache size: 258,240 tokens
INFO 12-03 20:05:05 [kv_cache_utils.py:637] Maximum concurrency for 131,072 tokens per request: 1.97x
INFO 12-03 20:05:05 [core.py:159] init engine (profile, create kv cache, warmup model) took 0.71 seconds
INFO 12-03 20:05:05 [core_client.py:439] Core engine process 0 ready.
[2025-12-03 20:05:05] ‚ÑπÔ∏è  ÂΩìÂâçÂ∑•‰ΩúËäÇÁÇπÂàÜÁâá: 7/8
[2025-12-03 20:05:05] ‚úì Ê®°ÂûãÂ∞±Áª™ÔºåÂºÄÂßãËØÑÊµã B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300ÔºàÂÖ±‰∫´Âêå‰∏Ä LLMÔºå‰ªÖË°•Áº∫Êï∞ÊçÆÈõÜÔºâ
[2025-12-03 20:05:05] ‚ñ∂ B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g1  ÂæÖËØÑÊµã=['aime25x8', 'amc23x8', 'aime24x8']  T=0.6  n=8
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g1:   0%|          | 0/3 [00:00<?, ?ds/s][Info] Sharding enabled: Process 7/8 handling range [210:240]
==================================================
data: aime25x8  ,remain samples: 30
{'idx': 210, 'problem': 'Find the sum of all integer bases $b>9$ for which $17_{b}$ is a divisor of $97_{b}$.', 'answer': '70'}

  0%|          | 0/30 [00:00<?, ?it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 463.00it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/240 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 1/240 [00:04<16:38,  4.18s/it, est. speed input: 23.22 toks/s, output: 46.44 toks/s][A
Processed prompts:   1%|          | 2/240 [00:04<07:05,  1.79s/it, est. speed input: 48.49 toks/s, output: 91.84 toks/s][A
Processed prompts:   1%|‚ñè         | 3/240 [00:05<05:15,  1.33s/it, est. speed input: 60.03 toks/s, output: 123.80 toks/s][A
Processed prompts:   2%|‚ñè         | 4/240 [00:06<04:45,  1.21s/it, est. speed input: 66.03 toks/s, output: 148.62 toks/s][A
Processed prompts:   2%|‚ñè         | 5/240 [00:06<03:50,  1.02it/s, est. speed input: 74.91 toks/s, output: 181.28 toks/s][A
Processed prompts:   2%|‚ñé         | 6/240 [00:06<02:42,  1.44it/s, est. speed input: 87.69 toks/s, output: 222.60 toks/s][A
Processed prompts:   3%|‚ñé         | 8/240 [00:07<01:34,  2.46it/s, est. speed input: 123.23 toks/s, output: 305.01 toks/s][A
Processed prompts:   4%|‚ñç         | 10/240 [00:07<01:01,  3.72it/s, est. speed input: 164.44 toks/s, output: 388.90 toks/s][A
Processed prompts:   5%|‚ñç         | 11/240 [00:07<01:09,  3.32it/s, est. speed input: 169.06 toks/s, output: 412.77 toks/s][A
Processed prompts:   5%|‚ñå         | 12/240 [00:07<01:01,  3.71it/s, est. speed input: 176.53 toks/s, output: 448.60 toks/s][A
Processed prompts:   6%|‚ñå         | 14/240 [00:07<00:43,  5.16it/s, est. speed input: 203.19 toks/s, output: 527.68 toks/s][A
Processed prompts:   7%|‚ñã         | 17/240 [00:08<00:27,  8.19it/s, est. speed input: 247.60 toks/s, output: 653.36 toks/s][A
Processed prompts:   8%|‚ñä         | 19/240 [00:08<00:32,  6.73it/s, est. speed input: 261.67 toks/s, output: 709.74 toks/s][A
Processed prompts:   9%|‚ñâ         | 21/240 [00:08<00:29,  7.32it/s, est. speed input: 279.20 toks/s, output: 779.88 toks/s][A
Processed prompts:  10%|‚ñâ         | 23/240 [00:09<00:34,  6.31it/s, est. speed input: 322.75 toks/s, output: 831.29 toks/s][A
Processed prompts:  10%|‚ñà         | 24/240 [00:09<00:38,  5.60it/s, est. speed input: 323.77 toks/s, output: 851.42 toks/s][A
Processed prompts:  11%|‚ñà         | 26/240 [00:09<00:32,  6.60it/s, est. speed input: 350.94 toks/s, output: 921.30 toks/s][A
Processed prompts:  11%|‚ñà‚ñè        | 27/240 [00:09<00:41,  5.16it/s, est. speed input: 350.78 toks/s, output: 930.92 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 28/240 [00:10<00:42,  4.99it/s, est. speed input: 358.60 toks/s, output: 954.31 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 31/240 [00:10<00:29,  7.17it/s, est. speed input: 381.59 toks/s, output: 1063.78 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 32/240 [00:10<00:31,  6.64it/s, est. speed input: 400.67 toks/s, output: 1087.42 toks/s][A
Processed prompts:  15%|‚ñà‚ñç        | 35/240 [00:10<00:26,  7.82it/s, est. speed input: 431.11 toks/s, output: 1186.75 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 38/240 [00:11<00:19, 10.27it/s, est. speed input: 455.65 toks/s, output: 1300.47 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 40/240 [00:11<00:24,  8.25it/s, est. speed input: 470.52 toks/s, output: 1344.09 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 41/240 [00:11<00:26,  7.47it/s, est. speed input: 468.05 toks/s, output: 1364.61 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 42/240 [00:11<00:30,  6.43it/s, est. speed input: 465.45 toks/s, output: 1379.16 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 44/240 [00:11<00:24,  8.12it/s, est. speed input: 481.45 toks/s, output: 1451.01 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 45/240 [00:12<00:25,  7.76it/s, est. speed input: 485.64 toks/s, output: 1476.04 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 47/240 [00:12<00:23,  8.13it/s, est. speed input: 505.42 toks/s, output: 1534.87 toks/s][A
Processed prompts:  21%|‚ñà‚ñà‚ñè       | 51/240 [00:12<00:19,  9.84it/s, est. speed input: 541.23 toks/s, output: 1665.46 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñé       | 54/240 [00:12<00:16, 11.60it/s, est. speed input: 559.87 toks/s, output: 1771.65 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 56/240 [00:13<00:20,  8.97it/s, est. speed input: 563.50 toks/s, output: 1806.63 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 58/240 [00:13<00:22,  8.21it/s, est. speed input: 579.79 toks/s, output: 1851.81 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñç       | 59/240 [00:13<00:24,  7.46it/s, est. speed input: 589.35 toks/s, output: 1867.71 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 60/240 [00:13<00:25,  7.05it/s, est. speed input: 586.59 toks/s, output: 1887.07 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 61/240 [00:14<00:24,  7.24it/s, est. speed input: 588.73 toks/s, output: 1913.24 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñã       | 63/240 [00:14<00:19,  9.12it/s, est. speed input: 608.49 toks/s, output: 1981.84 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 65/240 [00:14<00:25,  6.90it/s, est. speed input: 608.44 toks/s, output: 2008.97 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 66/240 [00:14<00:28,  6.04it/s, est. speed input: 607.75 toks/s, output: 2017.97 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 68/240 [00:15<00:31,  5.49it/s, est. speed input: 611.34 toks/s, output: 2046.50 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 70/240 [00:15<00:28,  5.99it/s, est. speed input: 626.33 toks/s, output: 2094.72 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 71/240 [00:15<00:31,  5.30it/s, est. speed input: 620.79 toks/s, output: 2100.45 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 72/240 [00:15<00:28,  5.90it/s, est. speed input: 632.94 toks/s, output: 2129.52 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 73/240 [00:16<00:26,  6.29it/s, est. speed input: 637.70 toks/s, output: 2155.34 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà‚ñè      | 75/240 [00:16<00:34,  4.84it/s, est. speed input: 637.52 toks/s, output: 2166.98 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 77/240 [00:16<00:25,  6.29it/s, est. speed input: 654.06 toks/s, output: 2231.68 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñé      | 78/240 [00:17<00:40,  3.98it/s, est. speed input: 635.49 toks/s, output: 2196.01 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 80/240 [00:18<01:03,  2.54it/s, est. speed input: 605.43 toks/s, output: 2127.96 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 81/240 [00:18<00:52,  3.00it/s, est. speed input: 608.46 toks/s, output: 2158.36 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 82/240 [00:18<00:44,  3.57it/s, est. speed input: 609.77 toks/s, output: 2188.69 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 84/240 [00:18<00:30,  5.15it/s, est. speed input: 627.49 toks/s, output: 2257.66 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 85/240 [00:19<00:41,  3.78it/s, est. speed input: 624.10 toks/s, output: 2240.01 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñã      | 87/240 [00:19<00:40,  3.77it/s, est. speed input: 624.93 toks/s, output: 2262.89 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 89/240 [00:20<00:38,  3.93it/s, est. speed input: 621.18 toks/s, output: 2293.60 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 90/240 [00:20<00:37,  4.00it/s, est. speed input: 619.95 toks/s, output: 2309.40 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 91/240 [00:21<00:43,  3.42it/s, est. speed input: 611.91 toks/s, output: 2302.82 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 92/240 [00:21<00:40,  3.68it/s, est. speed input: 610.79 toks/s, output: 2321.90 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 94/240 [00:21<00:31,  4.57it/s, est. speed input: 626.51 toks/s, output: 2373.61 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 95/240 [00:21<00:36,  3.97it/s, est. speed input: 621.17 toks/s, output: 2375.62 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 96/240 [00:22<00:38,  3.75it/s, est. speed input: 615.76 toks/s, output: 2383.59 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 97/240 [00:23<00:56,  2.53it/s, est. speed input: 601.29 toks/s, output: 2345.99 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 98/240 [00:23<00:52,  2.72it/s, est. speed input: 596.58 toks/s, output: 2357.96 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 99/240 [00:24<01:03,  2.22it/s, est. speed input: 586.62 toks/s, output: 2333.64 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 100/240 [00:24<00:51,  2.72it/s, est. speed input: 585.42 toks/s, output: 2359.29 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 101/240 [00:24<00:56,  2.45it/s, est. speed input: 584.54 toks/s, output: 2351.67 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 104/240 [00:24<00:28,  4.72it/s, est. speed input: 593.82 toks/s, output: 2459.08 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 105/240 [00:25<00:35,  3.75it/s, est. speed input: 588.09 toks/s, output: 2454.02 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 109/240 [00:26<00:27,  4.69it/s, est. speed input: 594.50 toks/s, output: 2550.77 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 110/240 [00:26<00:29,  4.44it/s, est. speed input: 596.92 toks/s, output: 2563.78 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 111/240 [00:26<00:37,  3.44it/s, est. speed input: 588.02 toks/s, output: 2549.84 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 112/240 [00:26<00:32,  3.89it/s, est. speed input: 595.39 toks/s, output: 2578.25 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 113/240 [00:27<00:32,  3.87it/s, est. speed input: 594.84 toks/s, output: 2594.19 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 115/240 [00:27<00:27,  4.51it/s, est. speed input: 601.61 toks/s, output: 2643.93 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 116/240 [00:29<01:06,  1.87it/s, est. speed input: 570.45 toks/s, output: 2536.69 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 118/240 [00:31<01:22,  1.48it/s, est. speed input: 547.32 toks/s, output: 2469.09 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 119/240 [00:31<01:15,  1.61it/s, est. speed input: 548.71 toks/s, output: 2476.56 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 120/240 [00:31<01:03,  1.89it/s, est. speed input: 549.81 toks/s, output: 2499.80 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 121/240 [00:32<01:22,  1.44it/s, est. speed input: 537.54 toks/s, output: 2450.56 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 122/240 [00:33<01:13,  1.60it/s, est. speed input: 535.31 toks/s, output: 2459.48 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 123/240 [00:33<01:07,  1.73it/s, est. speed input: 531.84 toks/s, output: 2466.76 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 124/240 [00:35<01:40,  1.15it/s, est. speed input: 511.75 toks/s, output: 2395.72 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 125/240 [00:36<01:41,  1.13it/s, est. speed input: 500.53 toks/s, output: 2375.40 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 126/240 [00:37<01:57,  1.03s/it, est. speed input: 485.30 toks/s, output: 2328.60 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 127/240 [00:37<01:28,  1.28it/s, est. speed input: 486.27 toks/s, output: 2357.45 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 128/240 [00:38<01:08,  1.63it/s, est. speed input: 486.95 toks/s, output: 2384.57 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 129/240 [00:38<01:09,  1.59it/s, est. speed input: 480.44 toks/s, output: 2383.71 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 130/240 [00:40<01:38,  1.12it/s, est. speed input: 468.16 toks/s, output: 2334.19 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 131/240 [00:42<02:31,  1.39s/it, est. speed input: 446.18 toks/s, output: 2234.59 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 132/240 [00:43<01:56,  1.08s/it, est. speed input: 447.39 toks/s, output: 2255.91 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 133/240 [00:43<01:30,  1.18it/s, est. speed input: 445.84 toks/s, output: 2280.50 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 134/240 [00:45<01:59,  1.13s/it, est. speed input: 430.16 toks/s, output: 2230.33 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 135/240 [00:45<01:35,  1.10it/s, est. speed input: 432.35 toks/s, output: 2250.13 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 136/240 [00:45<01:15,  1.39it/s, est. speed input: 432.01 toks/s, output: 2276.48 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 137/240 [00:48<02:16,  1.33s/it, est. speed input: 409.72 toks/s, output: 2187.51 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 138/240 [00:49<01:57,  1.16s/it, est. speed input: 406.96 toks/s, output: 2193.75 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 139/240 [00:50<01:40,  1.00it/s, est. speed input: 404.18 toks/s, output: 2206.04 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 140/240 [00:55<03:45,  2.26s/it, est. speed input: 368.55 toks/s, output: 2037.12 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 141/240 [01:01<05:30,  3.34s/it, est. speed input: 334.99 toks/s, output: 1879.85 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 142/240 [01:02<04:30,  2.76s/it, est. speed input: 328.98 toks/s, output: 1875.78 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 143/240 [01:07<05:31,  3.42s/it, est. speed input: 306.58 toks/s, output: 1776.34 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 144/240 [01:24<12:03,  7.54s/it, est. speed input: 245.22 toks/s, output: 1452.66 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 164/240 [01:24<01:00,  1.25it/s, est. speed input: 275.84 toks/s, output: 2170.90 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 201/240 [01:25<00:09,  4.11it/s, est. speed input: 339.66 toks/s, output: 3497.76 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 226/240 [01:26<00:02,  6.29it/s, est. speed input: 394.70 toks/s, output: 4354.30 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 231/240 [01:28<00:01,  5.20it/s, est. speed input: 395.92 toks/s, output: 4409.58 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 235/240 [01:30<00:01,  4.62it/s, est. speed input: 395.25 toks/s, output: 4464.00 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 238/240 [01:31<00:00,  4.28it/s, est. speed input: 394.09 toks/s, output: 4508.02 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [01:32<00:00,  4.11it/s, est. speed input: 393.60 toks/s, output: 4541.12 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [01:32<00:00,  2.61it/s, est. speed input: 393.60 toks/s, output: 4541.12 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/240 [00:00<?, ?it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<00:00, 24689.32it/s]
{'num_samples': 30, 'num_scores': 240, 'timeout_samples': 0, 'empty_samples': 0, 'acc': 0.0, 'total_acc': 0.4166666666666667, 'pass_at_k_percent': {'1': 0.4, '8': 3.3}, 'pass_at_k_valid_counts': {'1': 30, '8': 30}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_results/noise_rlvr_1_5b_128batchsize_deepscaler_v2_think-boxed/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g1/aime25x8/test_think-boxed_-1_seed0_t0.6_s0_e-1_part7.jsonl
[2025-12-03 20:06:38] ‚úì B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g1/aime25x8  acc=0.0 pass_at_k={'1': 0.4, '8': 3.3}
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g1:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [01:32<03:05, 92.91s/ds][Info] Sharding enabled: Process 7/8 handling range [280:320]
==================================================
data: amc23x8  ,remain samples: 40
{'idx': 280, 'id': 0, 'problem': 'Cities $A$ and $B$ are $45$ miles apart. Alicia lives in $A$ and Beth lives in $B$. Alicia bikes towards $B$ at 18 miles per hour. Leaving at the same time, Beth bikes toward $A$ at 12 miles per hour. How many miles from City $A$ will they be when they meet?', 'answer': 27.0, 'url': 'https://artofproblemsolving.com/wiki/index.php/2023_AMC_12A_Problems/Problem_1', 'question': 'Cities $A$ and $B$ are $45$ miles apart. Alicia lives in $A$ and Beth lives in $B$. Alicia bikes towards $B$ at 18 miles per hour. Leaving at the same time, Beth bikes toward $A$ at 12 miles per hour. How many miles from City $A$ will they be when they meet?'}

  0%|          | 0/40 [00:00<?, ?it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 440.57it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/320 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 1/320 [00:03<16:22,  3.08s/it, est. speed input: 36.04 toks/s, output: 48.06 toks/s][A
Processed prompts:   1%|          | 2/320 [00:04<12:41,  2.40s/it, est. speed input: 36.03 toks/s, output: 75.46 toks/s][A
Processed prompts:   1%|          | 3/320 [00:05<07:17,  1.38s/it, est. speed input: 57.64 toks/s, output: 118.56 toks/s][A
Processed prompts:   1%|‚ñè         | 4/320 [00:05<04:51,  1.08it/s, est. speed input: 66.75 toks/s, output: 159.64 toks/s][A
Processed prompts:   2%|‚ñè         | 5/320 [00:05<03:18,  1.59it/s, est. speed input: 75.29 toks/s, output: 202.05 toks/s][A
Processed prompts:   3%|‚ñé         | 10/320 [00:05<01:03,  4.89it/s, est. speed input: 156.56 toks/s, output: 417.02 toks/s][A
Processed prompts:   4%|‚ñç         | 12/320 [00:05<00:54,  5.69it/s, est. speed input: 188.83 toks/s, output: 490.87 toks/s][A
Processed prompts:   4%|‚ñç         | 14/320 [00:06<01:10,  4.34it/s, est. speed input: 210.75 toks/s, output: 521.89 toks/s][A
Processed prompts:   5%|‚ñç         | 15/320 [00:06<01:03,  4.77it/s, est. speed input: 223.74 toks/s, output: 557.79 toks/s][A
Processed prompts:   5%|‚ñå         | 17/320 [00:06<00:52,  5.79it/s, est. speed input: 242.18 toks/s, output: 629.14 toks/s][A
Processed prompts:   6%|‚ñã         | 20/320 [00:07<00:38,  7.77it/s, est. speed input: 274.91 toks/s, output: 742.24 toks/s][A
Processed prompts:   7%|‚ñã         | 22/320 [00:07<00:32,  9.24it/s, est. speed input: 308.67 toks/s, output: 817.24 toks/s][A
Processed prompts:   8%|‚ñä         | 25/320 [00:07<00:30,  9.82it/s, est. speed input: 331.43 toks/s, output: 915.11 toks/s][A
Processed prompts:   8%|‚ñä         | 27/320 [00:07<00:26, 10.89it/s, est. speed input: 362.46 toks/s, output: 985.90 toks/s][A
Processed prompts:   9%|‚ñâ         | 29/320 [00:07<00:29,  9.88it/s, est. speed input: 389.23 toks/s, output: 1039.97 toks/s][A
Processed prompts:  10%|‚ñâ         | 31/320 [00:08<00:29,  9.87it/s, est. speed input: 416.73 toks/s, output: 1099.04 toks/s][A
Processed prompts:  10%|‚ñà         | 33/320 [00:08<00:29,  9.85it/s, est. speed input: 428.61 toks/s, output: 1156.05 toks/s][A
Processed prompts:  11%|‚ñà         | 35/320 [00:08<00:37,  7.61it/s, est. speed input: 437.78 toks/s, output: 1184.84 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 38/320 [00:08<00:30,  9.31it/s, est. speed input: 464.61 toks/s, output: 1281.97 toks/s][A
Processed prompts:  12%|‚ñà‚ñé        | 40/320 [00:09<00:26, 10.40it/s, est. speed input: 484.51 toks/s, output: 1347.02 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 42/320 [00:09<00:35,  7.80it/s, est. speed input: 490.34 toks/s, output: 1370.13 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 43/320 [00:09<00:52,  5.24it/s, est. speed input: 472.49 toks/s, output: 1341.82 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 46/320 [00:10<00:36,  7.44it/s, est. speed input: 496.43 toks/s, output: 1443.71 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 48/320 [00:10<00:32,  8.38it/s, est. speed input: 507.30 toks/s, output: 1502.90 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 50/320 [00:10<00:29,  9.19it/s, est. speed input: 513.34 toks/s, output: 1561.09 toks/s][A
Processed prompts:  16%|‚ñà‚ñã        | 52/320 [00:10<00:30,  8.89it/s, est. speed input: 522.41 toks/s, output: 1607.12 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 54/320 [00:10<00:30,  8.67it/s, est. speed input: 534.65 toks/s, output: 1652.34 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 56/320 [00:11<00:29,  8.80it/s, est. speed input: 552.33 toks/s, output: 1700.49 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 57/320 [00:11<00:31,  8.34it/s, est. speed input: 558.96 toks/s, output: 1718.41 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 59/320 [00:11<00:25, 10.11it/s, est. speed input: 569.66 toks/s, output: 1781.61 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 61/320 [00:11<00:25, 10.18it/s, est. speed input: 578.07 toks/s, output: 1832.07 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 63/320 [00:11<00:23, 11.16it/s, est. speed input: 581.71 toks/s, output: 1889.57 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 65/320 [00:12<00:27,  9.25it/s, est. speed input: 581.08 toks/s, output: 1871.14 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 67/320 [00:12<00:27,  9.28it/s, est. speed input: 594.73 toks/s, output: 1917.90 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 70/320 [00:12<00:20, 12.12it/s, est. speed input: 614.37 toks/s, output: 2016.18 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 73/320 [00:12<00:17, 14.52it/s, est. speed input: 635.79 toks/s, output: 2113.28 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 76/320 [00:12<00:14, 17.41it/s, est. speed input: 662.59 toks/s, output: 2189.83 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñå       | 82/320 [00:12<00:10, 23.70it/s, est. speed input: 714.05 toks/s, output: 2398.44 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 85/320 [00:13<00:14, 16.43it/s, est. speed input: 716.56 toks/s, output: 2406.30 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 88/320 [00:13<00:22, 10.09it/s, est. speed input: 706.35 toks/s, output: 2416.56 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 92/320 [00:13<00:16, 13.44it/s, est. speed input: 729.03 toks/s, output: 2555.48 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 96/320 [00:13<00:13, 17.06it/s, est. speed input: 757.86 toks/s, output: 2656.22 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 99/320 [00:14<00:11, 19.12it/s, est. speed input: 772.20 toks/s, output: 2732.73 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 102/320 [00:14<00:11, 18.43it/s, est. speed input: 794.48 toks/s, output: 2794.63 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 105/320 [00:14<00:10, 19.61it/s, est. speed input: 812.93 toks/s, output: 2888.07 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 108/320 [00:14<00:15, 13.82it/s, est. speed input: 815.88 toks/s, output: 2931.58 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 110/320 [00:14<00:16, 12.76it/s, est. speed input: 816.09 toks/s, output: 2970.77 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 114/320 [00:15<00:14, 13.80it/s, est. speed input: 829.96 toks/s, output: 3023.19 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñã      | 116/320 [00:15<00:14, 14.20it/s, est. speed input: 848.03 toks/s, output: 3077.28 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 118/320 [00:15<00:16, 12.46it/s, est. speed input: 848.48 toks/s, output: 3111.35 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 120/320 [00:15<00:15, 13.17it/s, est. speed input: 850.92 toks/s, output: 3165.44 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 123/320 [00:15<00:14, 13.77it/s, est. speed input: 865.72 toks/s, output: 3223.04 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 125/320 [00:16<00:16, 12.12it/s, est. speed input: 867.55 toks/s, output: 3256.75 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñâ      | 127/320 [00:16<00:15, 12.43it/s, est. speed input: 872.17 toks/s, output: 3305.71 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 129/320 [00:16<00:14, 13.26it/s, est. speed input: 883.56 toks/s, output: 3344.01 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 131/320 [00:16<00:18, 10.43it/s, est. speed input: 882.16 toks/s, output: 3363.46 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 134/320 [00:17<00:19,  9.39it/s, est. speed input: 881.32 toks/s, output: 3380.15 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 137/320 [00:17<00:15, 11.55it/s, est. speed input: 889.74 toks/s, output: 3469.31 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 141/320 [00:17<00:11, 15.55it/s, est. speed input: 912.08 toks/s, output: 3602.59 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 143/320 [00:17<00:12, 13.94it/s, est. speed input: 913.15 toks/s, output: 3617.55 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 145/320 [00:17<00:14, 12.38it/s, est. speed input: 914.12 toks/s, output: 3651.92 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 147/320 [00:17<00:13, 13.21it/s, est. speed input: 921.49 toks/s, output: 3691.33 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 151/320 [00:18<00:18,  9.08it/s, est. speed input: 916.09 toks/s, output: 3700.28 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 153/320 [00:18<00:16,  9.85it/s, est. speed input: 923.28 toks/s, output: 3713.07 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 155/320 [00:18<00:19,  8.65it/s, est. speed input: 925.74 toks/s, output: 3730.04 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 159/320 [00:19<00:13, 12.09it/s, est. speed input: 938.87 toks/s, output: 3841.37 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 162/320 [00:19<00:11, 13.88it/s, est. speed input: 950.01 toks/s, output: 3880.46 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 164/320 [00:19<00:13, 11.32it/s, est. speed input: 943.58 toks/s, output: 3854.40 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 167/320 [00:19<00:13, 11.00it/s, est. speed input: 945.98 toks/s, output: 3878.90 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 170/320 [00:20<00:13, 10.82it/s, est. speed input: 947.06 toks/s, output: 3942.16 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 172/320 [00:20<00:14, 10.13it/s, est. speed input: 947.03 toks/s, output: 3975.57 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 174/320 [00:20<00:18,  7.83it/s, est. speed input: 936.52 toks/s, output: 3972.81 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 176/320 [00:20<00:16,  8.62it/s, est. speed input: 938.94 toks/s, output: 4020.65 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 178/320 [00:21<00:23,  6.16it/s, est. speed input: 923.07 toks/s, output: 3973.33 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 181/320 [00:21<00:18,  7.59it/s, est. speed input: 930.49 toks/s, output: 4031.67 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 184/320 [00:21<00:15,  9.03it/s, est. speed input: 939.45 toks/s, output: 4076.07 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 186/320 [00:22<00:26,  4.98it/s, est. speed input: 908.92 toks/s, output: 3966.48 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 187/320 [00:23<00:26,  4.93it/s, est. speed input: 906.23 toks/s, output: 3969.78 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 190/320 [00:23<00:18,  7.01it/s, est. speed input: 919.96 toks/s, output: 4049.58 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 192/320 [00:23<00:21,  5.94it/s, est. speed input: 915.95 toks/s, output: 4025.25 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 193/320 [00:24<00:23,  5.36it/s, est. speed input: 909.80 toks/s, output: 3999.72 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 195/320 [00:24<00:18,  6.75it/s, est. speed input: 913.00 toks/s, output: 4058.62 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 196/320 [00:24<00:17,  6.92it/s, est. speed input: 913.26 toks/s, output: 4077.41 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 197/320 [00:24<00:18,  6.66it/s, est. speed input: 910.54 toks/s, output: 4071.85 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 198/320 [00:24<00:24,  4.89it/s, est. speed input: 902.86 toks/s, output: 4048.94 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 200/320 [00:25<00:18,  6.52it/s, est. speed input: 904.85 toks/s, output: 4105.37 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 201/320 [00:25<00:22,  5.25it/s, est. speed input: 899.38 toks/s, output: 4080.09 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 204/320 [00:25<00:13,  8.41it/s, est. speed input: 908.09 toks/s, output: 4165.24 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 206/320 [00:25<00:15,  7.22it/s, est. speed input: 904.15 toks/s, output: 4171.00 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 207/320 [00:25<00:15,  7.12it/s, est. speed input: 908.64 toks/s, output: 4178.16 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 209/320 [00:26<00:17,  6.35it/s, est. speed input: 905.47 toks/s, output: 4168.71 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 212/320 [00:26<00:12,  8.90it/s, est. speed input: 915.79 toks/s, output: 4250.71 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 214/320 [00:27<00:23,  4.42it/s, est. speed input: 895.21 toks/s, output: 4165.68 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 215/320 [00:27<00:26,  4.03it/s, est. speed input: 892.72 toks/s, output: 4153.54 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 217/320 [00:28<00:19,  5.24it/s, est. speed input: 896.45 toks/s, output: 4197.30 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 218/320 [00:29<00:38,  2.68it/s, est. speed input: 863.23 toks/s, output: 4072.44 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 219/320 [00:30<00:49,  2.04it/s, est. speed input: 840.58 toks/s, output: 3975.05 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 220/320 [00:30<00:40,  2.47it/s, est. speed input: 840.65 toks/s, output: 3999.60 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 221/320 [00:30<00:36,  2.68it/s, est. speed input: 836.76 toks/s, output: 4004.68 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 224/320 [00:31<00:32,  2.96it/s, est. speed input: 826.29 toks/s, output: 4010.61 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 225/320 [00:32<00:54,  1.75it/s, est. speed input: 790.36 toks/s, output: 3867.18 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 226/320 [00:33<00:46,  2.04it/s, est. speed input: 792.24 toks/s, output: 3885.64 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 227/320 [00:33<00:53,  1.73it/s, est. speed input: 776.24 toks/s, output: 3829.90 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 228/320 [00:34<00:43,  2.10it/s, est. speed input: 774.41 toks/s, output: 3851.69 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 229/320 [00:34<00:41,  2.22it/s, est. speed input: 767.97 toks/s, output: 3851.11 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 230/320 [00:34<00:36,  2.46it/s, est. speed input: 764.12 toks/s, output: 3849.51 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 231/320 [00:35<00:33,  2.62it/s, est. speed input: 764.40 toks/s, output: 3849.79 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 232/320 [00:35<00:40,  2.18it/s, est. speed input: 753.62 toks/s, output: 3821.68 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 233/320 [00:36<00:57,  1.52it/s, est. speed input: 733.45 toks/s, output: 3746.42 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 234/320 [00:39<01:46,  1.23s/it, est. speed input: 686.84 toks/s, output: 3540.59 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 235/320 [00:40<01:35,  1.12s/it, est. speed input: 678.56 toks/s, output: 3508.37 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 236/320 [00:44<02:35,  1.86s/it, est. speed input: 625.69 toks/s, output: 3263.92 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 237/320 [00:49<04:14,  3.07s/it, est. speed input: 554.57 toks/s, output: 2917.91 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 238/320 [00:50<03:03,  2.23s/it, est. speed input: 556.65 toks/s, output: 2944.52 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 239/320 [00:53<03:35,  2.66s/it, est. speed input: 520.14 toks/s, output: 2785.72 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 240/320 [00:58<04:18,  3.23s/it, est. speed input: 482.24 toks/s, output: 2608.85 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 241/320 [01:09<07:28,  5.67s/it, est. speed input: 407.22 toks/s, output: 2224.12 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 242/320 [01:17<08:04,  6.21s/it, est. speed input: 368.84 toks/s, output: 2048.98 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 306/320 [01:20<00:03,  3.77it/s, est. speed input: 447.10 toks/s, output: 4414.88 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 308/320 [01:20<00:03,  3.85it/s, est. speed input: 451.88 toks/s, output: 4476.77 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 310/320 [01:21<00:02,  3.83it/s, est. speed input: 453.41 toks/s, output: 4521.12 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 312/320 [01:21<00:02,  3.96it/s, est. speed input: 454.46 toks/s, output: 4580.85 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 313/320 [01:21<00:01,  3.96it/s, est. speed input: 454.90 toks/s, output: 4604.02 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 315/320 [01:22<00:01,  4.05it/s, est. speed input: 455.85 toks/s, output: 4655.41 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 317/320 [01:22<00:00,  3.72it/s, est. speed input: 454.27 toks/s, output: 4685.68 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 318/320 [01:23<00:00,  3.94it/s, est. speed input: 454.94 toks/s, output: 4716.12 toks/s][A
Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 319/320 [01:23<00:00,  3.73it/s, est. speed input: 453.80 toks/s, output: 4731.89 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 320/320 [01:23<00:00,  3.83it/s, est. speed input: 454.55 toks/s, output: 4767.27 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/320 [00:00<?, ?it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 320/320 [00:00<00:00, 26888.18it/s]
{'num_samples': 40, 'num_scores': 320, 'timeout_samples': 0, 'empty_samples': 2, 'acc': 17.5, 'total_acc': 21.875, 'pass_at_k_percent': {'1': 21.9, '8': 60.0}, 'pass_at_k_valid_counts': {'1': 40, '8': 40}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_results/noise_rlvr_1_5b_128batchsize_deepscaler_v2_think-boxed/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g1/amc23x8/test_think-boxed_-1_seed0_t0.6_s0_e-1_part7.jsonl
[2025-12-03 20:08:02] ‚úì B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g1/amc23x8  acc=17.5 pass_at_k={'1': 21.9, '8': 60.0}
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [02:57<01:28, 88.02s/ds][Info] Sharding enabled: Process 7/8 handling range [210:240]
==================================================
data: aime24x8  ,remain samples: 30
{'idx': 210, 'id': 60, 'problem': 'Every morning Aya goes for a $9$-kilometer-long walk and stops at a coffee shop afterwards. When she walks at a constant speed of $s$ kilometers per hour, the walk takes her 4 hours, including $t$ minutes spent in the coffee shop. When she walks $s+2$ kilometers per hour, the walk takes her 2 hours and 24 minutes, including $t$ minutes spent in the coffee shop. Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find the number of minutes the walk takes her, including the $t$ minutes spent in the coffee shop.', 'solution': '$\\frac{9}{s} + t = 4$ in hours and $\\frac{9}{s+2} + t = 2.4$ in hours.\nSubtracting the second equation from the first, we get, \n$\\frac{9}{s} - \\frac{9}{s+2} = 1.6$\nMultiplying by $(s)(s+2)$, we get \n$9s+18-9s=18=1.6s^{2} + 3.2s$\nMultiplying by 5/2 on both sides, we get\n$0 = 4s^{2} + 8s - 45$\nFactoring gives us \n$(2s-5)(2s+9) = 0$, of which the solution we want is $s=2.5$.\nSubstituting this back to the first equation, we can find that $t = 0.4$ hours.\nLastly, $s + \\frac{1}{2} = 3$ kilometers per hour, so\n$\\frac{9}{3} + 0.4 = 3.4$ hours, or $\\framebox{204}$ minutes\n-Failure.net\nThe amount of hours spent while walking on the first travel is $\\frac{240-t}{6}$. Thus, we have the equation $(240-t)(s) = 540$, and by the same logic, the second equation yields $(144-t)(s+2) = 540$. We have $240s-st = 540$, and $288+144s-2t-st = 540$. We subtract the two equations to get $96s+2t-288 = 0$, so we have $48s+t = 144$, so $t = 144-48s$, and now we have $(96+48s)(s) = 540$. The numerator of $s$ must evenly divide 540, however, $s$ must be less than 3. We can guess that $s = 2.5$. Now, $2.5+0.5 = 3$. Taking $\\frac{9}{3} = 3$, we find that it will take three hours for the 9 kilometers to be traveled. The t minutes spent at the coffeeshop can be written as $144-48(2.5)$, so t = 24. $180 + 24 = 204$. -sepehr2010', 'answer': '204', 'url': 'https://artofproblemsolving.com/wiki/index.php/2024_AIME_I_Problems/Problem_1', 'question': 'Every morning Aya goes for a $9$-kilometer-long walk and stops at a coffee shop afterwards. When she walks at a constant speed of $s$ kilometers per hour, the walk takes her 4 hours, including $t$ minutes spent in the coffee shop. When she walks $s+2$ kilometers per hour, the walk takes her 2 hours and 24 minutes, including $t$ minutes spent in the coffee shop. Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find the number of minutes the walk takes her, including the $t$ minutes spent in the coffee shop.'}

  0%|          | 0/30 [00:00<?, ?it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 457.55it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/240 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 1/240 [00:03<12:21,  3.10s/it, est. speed input: 28.68 toks/s, output: 47.70 toks/s][A
Processed prompts:   1%|          | 2/240 [00:04<08:59,  2.27s/it, est. speed input: 42.85 toks/s, output: 77.56 toks/s][A
Processed prompts:   1%|‚ñè         | 3/240 [00:06<08:01,  2.03s/it, est. speed input: 45.00 toks/s, output: 102.54 toks/s][A
Processed prompts:   2%|‚ñè         | 4/240 [00:06<05:21,  1.36s/it, est. speed input: 76.64 toks/s, output: 142.81 toks/s][A
Processed prompts:   2%|‚ñè         | 5/240 [00:06<03:35,  1.09it/s, est. speed input: 88.44 toks/s, output: 185.60 toks/s][A
Processed prompts:   2%|‚ñé         | 6/240 [00:07<02:36,  1.49it/s, est. speed input: 104.69 toks/s, output: 225.78 toks/s][A
Processed prompts:   3%|‚ñé         | 7/240 [00:07<02:24,  1.61it/s, est. speed input: 109.25 toks/s, output: 255.73 toks/s][A
Processed prompts:   4%|‚ñç         | 9/240 [00:08<01:35,  2.41it/s, est. speed input: 127.45 toks/s, output: 330.97 toks/s][A
Processed prompts:   4%|‚ñç         | 10/240 [00:08<01:21,  2.83it/s, est. speed input: 138.32 toks/s, output: 368.29 toks/s][A
Processed prompts:   5%|‚ñç         | 11/240 [00:08<01:05,  3.49it/s, est. speed input: 147.22 toks/s, output: 407.75 toks/s][A
Processed prompts:   5%|‚ñå         | 12/240 [00:08<00:55,  4.14it/s, est. speed input: 166.82 toks/s, output: 445.77 toks/s][A
Processed prompts:   6%|‚ñå         | 14/240 [00:08<00:36,  6.16it/s, est. speed input: 199.31 toks/s, output: 526.86 toks/s][A
Processed prompts:   6%|‚ñã         | 15/240 [00:08<00:35,  6.28it/s, est. speed input: 210.97 toks/s, output: 561.79 toks/s][A
Processed prompts:   7%|‚ñã         | 16/240 [00:08<00:33,  6.65it/s, est. speed input: 218.01 toks/s, output: 597.74 toks/s][A
Processed prompts:   8%|‚ñä         | 18/240 [00:09<00:35,  6.27it/s, est. speed input: 234.02 toks/s, output: 661.60 toks/s][A
Processed prompts:   8%|‚ñä         | 19/240 [00:09<00:34,  6.37it/s, est. speed input: 242.25 toks/s, output: 694.92 toks/s][A
Processed prompts:   9%|‚ñâ         | 21/240 [00:09<00:29,  7.47it/s, est. speed input: 263.74 toks/s, output: 767.23 toks/s][A
Processed prompts:  10%|‚ñâ         | 23/240 [00:09<00:24,  8.92it/s, est. speed input: 279.46 toks/s, output: 842.07 toks/s][A
Processed prompts:  10%|‚ñà         | 25/240 [00:09<00:21, 10.08it/s, est. speed input: 300.05 toks/s, output: 915.82 toks/s][A
Processed prompts:  11%|‚ñà‚ñè        | 27/240 [00:10<00:18, 11.53it/s, est. speed input: 315.37 toks/s, output: 990.97 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 29/240 [00:10<00:29,  7.08it/s, est. speed input: 327.00 toks/s, output: 1027.84 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 32/240 [00:10<00:20,  9.92it/s, est. speed input: 352.95 toks/s, output: 1144.69 toks/s][A
Processed prompts:  14%|‚ñà‚ñç        | 34/240 [00:10<00:21,  9.66it/s, est. speed input: 376.11 toks/s, output: 1207.19 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 36/240 [00:10<00:18, 10.93it/s, est. speed input: 400.31 toks/s, output: 1279.63 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 38/240 [00:11<00:24,  8.20it/s, est. speed input: 415.46 toks/s, output: 1320.60 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 41/240 [00:11<00:19,  9.97it/s, est. speed input: 451.94 toks/s, output: 1426.18 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 43/240 [00:11<00:17, 11.12it/s, est. speed input: 476.68 toks/s, output: 1497.02 toks/s][A
Processed prompts:  19%|‚ñà‚ñâ        | 45/240 [00:11<00:19, 10.10it/s, est. speed input: 481.34 toks/s, output: 1552.05 toks/s][A
Processed prompts:  20%|‚ñà‚ñà        | 48/240 [00:12<00:19,  9.83it/s, est. speed input: 495.88 toks/s, output: 1638.93 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 50/240 [00:12<00:17, 10.60it/s, est. speed input: 509.11 toks/s, output: 1705.09 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 53/240 [00:12<00:18,  9.85it/s, est. speed input: 531.80 toks/s, output: 1785.93 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 56/240 [00:12<00:15, 11.96it/s, est. speed input: 555.99 toks/s, output: 1893.54 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 58/240 [00:13<00:16, 11.09it/s, est. speed input: 573.37 toks/s, output: 1947.21 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 60/240 [00:13<00:17, 10.49it/s, est. speed input: 587.87 toks/s, output: 2000.46 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñã       | 63/240 [00:13<00:17, 10.41it/s, est. speed input: 606.45 toks/s, output: 2084.41 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 65/240 [00:13<00:15, 11.06it/s, est. speed input: 619.40 toks/s, output: 2147.25 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 69/240 [00:13<00:11, 15.33it/s, est. speed input: 652.51 toks/s, output: 2298.72 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 71/240 [00:14<00:10, 15.63it/s, est. speed input: 660.92 toks/s, output: 2364.30 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 73/240 [00:14<00:13, 12.82it/s, est. speed input: 663.28 toks/s, output: 2409.43 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 76/240 [00:14<00:11, 13.70it/s, est. speed input: 678.82 toks/s, output: 2504.74 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñé      | 78/240 [00:15<00:26,  6.06it/s, est. speed input: 659.26 toks/s, output: 2443.51 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 80/240 [00:15<00:22,  7.27it/s, est. speed input: 672.42 toks/s, output: 2509.60 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 82/240 [00:15<00:19,  7.91it/s, est. speed input: 677.65 toks/s, output: 2563.73 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñå      | 84/240 [00:15<00:16,  9.27it/s, est. speed input: 690.93 toks/s, output: 2629.25 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 86/240 [00:15<00:16,  9.26it/s, est. speed input: 700.53 toks/s, output: 2678.58 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 88/240 [00:16<00:14, 10.62it/s, est. speed input: 710.91 toks/s, output: 2743.57 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 90/240 [00:16<00:14, 10.57it/s, est. speed input: 717.79 toks/s, output: 2796.17 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 92/240 [00:16<00:12, 11.39it/s, est. speed input: 727.71 toks/s, output: 2856.56 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 94/240 [00:16<00:14,  9.94it/s, est. speed input: 728.99 toks/s, output: 2896.69 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 96/240 [00:17<00:17,  8.32it/s, est. speed input: 730.18 toks/s, output: 2925.12 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 97/240 [00:17<00:17,  8.34it/s, est. speed input: 731.38 toks/s, output: 2947.49 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 98/240 [00:17<00:16,  8.36it/s, est. speed input: 732.43 toks/s, output: 2969.71 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 99/240 [00:17<00:18,  7.70it/s, est. speed input: 729.94 toks/s, output: 2984.02 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 100/240 [00:17<00:17,  7.86it/s, est. speed input: 729.44 toks/s, output: 3006.31 toks/s][A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 104/240 [00:17<00:09, 14.15it/s, est. speed input: 754.69 toks/s, output: 3155.82 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 106/240 [00:18<00:13, 10.23it/s, est. speed input: 756.73 toks/s, output: 3182.89 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 108/240 [00:18<00:17,  7.47it/s, est. speed input: 758.55 toks/s, output: 3191.53 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 110/240 [00:18<00:16,  7.78it/s, est. speed input: 764.22 toks/s, output: 3236.36 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 111/240 [00:18<00:17,  7.44it/s, est. speed input: 762.15 toks/s, output: 3251.04 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 112/240 [00:19<00:19,  6.70it/s, est. speed input: 758.63 toks/s, output: 3257.97 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 113/240 [00:19<00:17,  7.17it/s, est. speed input: 761.32 toks/s, output: 3282.72 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 116/240 [00:19<00:16,  7.74it/s, est. speed input: 771.30 toks/s, output: 3349.49 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 118/240 [00:19<00:13,  8.73it/s, est. speed input: 781.10 toks/s, output: 3406.25 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 120/240 [00:19<00:12,  9.55it/s, est. speed input: 783.78 toks/s, output: 3462.97 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 122/240 [00:19<00:10, 11.31it/s, est. speed input: 792.05 toks/s, output: 3530.39 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 124/240 [00:20<00:23,  4.90it/s, est. speed input: 764.09 toks/s, output: 3458.40 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 126/240 [00:21<00:26,  4.36it/s, est. speed input: 756.99 toks/s, output: 3450.82 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 129/240 [00:21<00:19,  5.81it/s, est. speed input: 774.31 toks/s, output: 3539.35 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 132/240 [00:22<00:17,  6.35it/s, est. speed input: 774.08 toks/s, output: 3604.50 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 134/240 [00:22<00:15,  6.63it/s, est. speed input: 780.64 toks/s, output: 3648.20 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 136/240 [00:23<00:24,  4.19it/s, est. speed input: 763.07 toks/s, output: 3583.52 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 138/240 [00:23<00:24,  4.21it/s, est. speed input: 757.27 toks/s, output: 3599.67 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 140/240 [00:24<00:24,  4.07it/s, est. speed input: 753.13 toks/s, output: 3607.65 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 141/240 [00:24<00:23,  4.13it/s, est. speed input: 749.95 toks/s, output: 3618.31 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 142/240 [00:24<00:21,  4.65it/s, est. speed input: 753.56 toks/s, output: 3647.08 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 143/240 [00:25<00:28,  3.42it/s, est. speed input: 741.05 toks/s, output: 3608.20 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 144/240 [00:26<00:45,  2.10it/s, est. speed input: 715.31 toks/s, output: 3505.45 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 145/240 [00:26<00:40,  2.35it/s, est. speed input: 711.91 toks/s, output: 3513.25 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 146/240 [00:26<00:33,  2.79it/s, est. speed input: 714.29 toks/s, output: 3535.11 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 147/240 [00:27<00:44,  2.10it/s, est. speed input: 700.36 toks/s, output: 3478.09 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 149/240 [00:27<00:26,  3.44it/s, est. speed input: 705.46 toks/s, output: 3553.12 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 150/240 [00:28<00:34,  2.64it/s, est. speed input: 703.46 toks/s, output: 3514.42 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 151/240 [00:29<00:42,  2.11it/s, est. speed input: 691.02 toks/s, output: 3467.86 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 152/240 [00:29<00:35,  2.47it/s, est. speed input: 691.60 toks/s, output: 3486.73 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 153/240 [00:29<00:40,  2.17it/s, est. speed input: 681.29 toks/s, output: 3460.45 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 154/240 [00:30<00:48,  1.79it/s, est. speed input: 666.66 toks/s, output: 3413.94 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 155/240 [00:34<01:55,  1.36s/it, est. speed input: 604.33 toks/s, output: 3123.45 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 156/240 [00:34<01:39,  1.19s/it, est. speed input: 594.01 toks/s, output: 3098.02 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 157/240 [00:35<01:38,  1.19s/it, est. speed input: 577.73 toks/s, output: 3040.66 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 158/240 [00:37<01:35,  1.16s/it, est. speed input: 565.43 toks/s, output: 2995.02 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 159/240 [00:37<01:24,  1.04s/it, est. speed input: 556.21 toks/s, output: 2978.68 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 161/240 [00:38<00:58,  1.34it/s, est. speed input: 550.30 toks/s, output: 3006.03 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 162/240 [00:39<01:05,  1.19it/s, est. speed input: 540.45 toks/s, output: 2964.53 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 163/240 [00:39<00:51,  1.49it/s, est. speed input: 540.32 toks/s, output: 2994.29 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 164/240 [00:43<01:43,  1.36s/it, est. speed input: 504.47 toks/s, output: 2816.71 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 165/240 [00:44<01:46,  1.42s/it, est. speed input: 488.77 toks/s, output: 2761.67 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 166/240 [00:54<04:48,  3.89s/it, est. speed input: 400.63 toks/s, output: 2296.71 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 167/240 [00:57<04:28,  3.68s/it, est. speed input: 380.35 toks/s, output: 2214.92 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 168/240 [01:13<08:41,  7.24s/it, est. speed input: 300.95 toks/s, output: 1780.88 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [01:13<00:00,  3.25it/s, est. speed input: 452.57 toks/s, output: 4771.20 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/240 [00:00<?, ?it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<00:00, 25516.03it/s]
{'num_samples': 30, 'num_scores': 240, 'timeout_samples': 0, 'empty_samples': 2, 'acc': 3.3, 'total_acc': 6.666666666666667, 'pass_at_k_percent': {'1': 6.7, '8': 23.3}, 'pass_at_k_valid_counts': {'1': 30, '8': 30}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_results/noise_rlvr_1_5b_128batchsize_deepscaler_v2_think-boxed/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g1/aime24x8/test_think-boxed_-1_seed0_t0.6_s0_e-1_part7.jsonl
[2025-12-03 20:09:17] ‚úì B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g1/aime24x8  acc=3.3 pass_at_k={'1': 6.7, '8': 23.3}
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [04:12<00:00, 81.99s/ds]B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [04:12<00:00, 84.10s/ds]
[2025-12-03 20:09:17] ‚ñ∂ B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g2  ÂæÖËØÑÊµã=['minerva_math', 'olympiadbench', 'math500']  T=0.0  n=8
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g2:   0%|          | 0/3 [00:00<?, ?ds/s][Info] Sharding enabled: Process 7/8 handling range [238:272]
==================================================
data: minerva_math  ,remain samples: 34
{'problem': 'Determine the highest linear density of atoms (atoms/m) encountered in vanadium (V). Please format your answer as $n \\times 10^x$ where $n$ is to 2 decimal places.', 'solution': '\\[\n\\begin{aligned}\n&\\mathrm{V}: \\quad \\text { atomic weight }=50.94 \\mathrm{~g} / \\text { mole } \\\\\n&\\rho=5.8 \\mathrm{~g} / \\mathrm{cm}^{3}\n\\end{aligned}\n\\]\n$B C C$, so $n=2$\nThe highest density would be found in the [111] direction. To find "a":\n\\[\n\\begin{aligned}\n&\\frac{\\text { atomic weight }}{\\rho}=a^{3} \\frac{N_{A}}{n} \\rightarrow a^{3}=\\frac{50.94 \\times 2}{5.8 \\times 6.023 \\times 10^{23}} \\\\\n&a=3.08 \\times 10^{-8} \\mathrm{~cm}=3.08 \\times 10^{-10} \\mathrm{~m}\n\\end{aligned}\n\\]\nThe length in the [111] direction is $\\mathrm{a} \\sqrt{3}$, so there are:\n\\[\n\\begin{aligned}\n&2 \\text { atoms } / \\mathrm{a} \\sqrt{3}=2 \\text { atoms/ }\\left(3.08 \\times 10^{-10} \\mathrm{~m} \\times \\sqrt{3}\\right) \\\\\n&= \\boxed{3.75e9} \\text { atoms } / \\mathrm{m}\n\\end{aligned}\n\\]', 'type': 'Introduction to Solid State Chemistry (3.091 Fall 2010)', 'idx': 238}

  0%|          | 0/34 [00:00<?, ?it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 34/34 [00:00<00:00, 7664.12it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/272 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 1/272 [00:04<20:17,  4.49s/it, est. speed input: 36.05 toks/s, output: 46.29 toks/s][A
Processed prompts:   3%|‚ñé         | 9/272 [00:04<01:39,  2.64it/s, est. speed input: 312.44 toks/s, output: 404.88 toks/s][A
Processed prompts:   6%|‚ñã         | 17/272 [00:05<00:50,  5.08it/s, est. speed input: 518.70 toks/s, output: 708.10 toks/s][A
Processed prompts:   9%|‚ñâ         | 25/272 [00:05<00:38,  6.44it/s, est. speed input: 604.53 toks/s, output: 931.96 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 33/272 [00:07<00:38,  6.27it/s, est. speed input: 586.94 toks/s, output: 1068.76 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 41/272 [00:07<00:30,  7.46it/s, est. speed input: 654.16 toks/s, output: 1306.94 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 49/272 [00:08<00:22,  9.86it/s, est. speed input: 731.28 toks/s, output: 1607.66 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 57/272 [00:09<00:22,  9.68it/s, est. speed input: 821.71 toks/s, output: 1785.73 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 65/272 [00:09<00:17, 11.89it/s, est. speed input: 1061.13 toks/s, output: 2067.18 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 76/272 [00:09<00:13, 14.80it/s, est. speed input: 1114.62 toks/s, output: 2446.17 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 84/272 [00:10<00:10, 18.30it/s, est. speed input: 1179.97 toks/s, output: 2754.48 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñç      | 92/272 [00:10<00:11, 15.54it/s, est. speed input: 1168.03 toks/s, output: 2911.67 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 107/272 [00:11<00:08, 19.47it/s, est. speed input: 1275.29 toks/s, output: 3424.28 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 115/272 [00:11<00:08, 19.28it/s, est. speed input: 1405.49 toks/s, output: 3646.56 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 120/272 [00:12<00:07, 19.04it/s, est. speed input: 1435.15 toks/s, output: 3782.82 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 128/272 [00:13<00:13, 10.72it/s, est. speed input: 1405.30 toks/s, output: 3680.24 toks/s][A
Processed prompts:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 136/272 [00:15<00:19,  6.84it/s, est. speed input: 1305.29 toks/s, output: 3489.45 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 138/272 [00:15<00:18,  7.21it/s, est. speed input: 1310.97 toks/s, output: 3550.76 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 145/272 [00:17<00:23,  5.38it/s, est. speed input: 1219.86 toks/s, output: 3441.82 toks/s][A
Processed prompts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 153/272 [00:23<00:43,  2.76it/s, est. speed input: 1000.25 toks/s, output: 2914.65 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 161/272 [00:25<00:36,  3.08it/s, est. speed input: 1007.57 toks/s, output: 3031.95 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 169/272 [00:30<00:44,  2.33it/s, est. speed input: 872.88 toks/s, output: 2830.05 toks/s] [A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 177/272 [00:40<01:04,  1.47it/s, est. speed input: 710.84 toks/s, output: 2433.86 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 185/272 [01:17<02:46,  1.91s/it, est. speed input: 386.16 toks/s, output: 1470.49 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 257/272 [01:20<00:06,  2.42it/s, est. speed input: 587.16 toks/s, output: 4170.74 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 269/272 [01:20<00:01,  2.86it/s, est. speed input: 611.89 toks/s, output: 4622.34 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 272/272 [01:20<00:00,  3.37it/s, est. speed input: 620.66 toks/s, output: 4731.50 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/272 [00:00<?, ?it/s][A
Evaluate:  39%|‚ñà‚ñà‚ñà‚ñâ      | 107/272 [00:00<00:00, 1033.67it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 272/272 [00:00<00:00, 1377.19it/s]
{'num_samples': 34, 'num_scores': 272, 'timeout_samples': 0, 'empty_samples': 1, 'acc': 8.8, 'total_acc': 8.823529411764707, 'pass_at_k_percent': {'1': 8.8, '8': 8.8}, 'pass_at_k_valid_counts': {'1': 34, '8': 34}, 'type_acc': {'Introduction to Solid State Chemistry (3.091 Fall 2010)': 0.0, 'Physical Chemistry (5.61 Fall 2017)': 9.1, 'Principles of Microeconomics (14.01 Fall 2011)': 11.1}, 'type_pass_at_k_percent': {'Introduction to Solid State Chemistry (3.091 Fall 2010)': {'1': 0.0, '8': 0.0}, 'Physical Chemistry (5.61 Fall 2017)': {'1': 9.1, '8': 9.1}, 'Principles of Microeconomics (14.01 Fall 2011)': {'1': 11.1, '8': 11.1}}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_results/noise_rlvr_1_5b_128batchsize_deepscaler_v2_think-boxed/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g2/minerva_math/test_think-boxed_-1_seed0_t0.0_s0_e-1_part7.jsonl
[2025-12-03 20:10:38] ‚úì B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g2/minerva_math  acc=8.8 pass_at_k={'1': 8.8, '8': 8.8}
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g2:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [01:21<02:42, 81.14s/ds][Info] Sharding enabled: Process 7/8 handling range [588:675]
==================================================
data: olympiadbench  ,remain samples: 87
{'idx': 588, 'id': 2984, 'subfield': 'Algebra', 'context': None, 'question': 'Compute the value of\n\n$$\n\\sin \\left(6^{\\circ}\\right) \\cdot \\sin \\left(12^{\\circ}\\right) \\cdot \\sin \\left(24^{\\circ}\\right) \\cdot \\sin \\left(42^{\\circ}\\right)+\\sin \\left(12^{\\circ}\\right) \\cdot \\sin \\left(24^{\\circ}\\right) \\cdot \\sin \\left(42^{\\circ}\\right) \\text {. }\n$$', 'solution': ['Let $S=\\left(1+\\sin 6^{\\circ}\\right)\\left(\\sin 12^{\\circ} \\sin 24^{\\circ} \\sin 42^{\\circ}\\right)$. It follows from a sum-to-product identity that $1+\\sin 6^{\\circ}=$ $\\sin 90^{\\circ}+\\sin 6^{\\circ}=2 \\sin 48^{\\circ} \\cos 42^{\\circ}$. Because the sine of an angle is the cosine of its complement, it follows that\n\n$$\nS=\\left(2 \\sin 48^{\\circ} \\cos 42^{\\circ}\\right)\\left(\\sin 12^{\\circ} \\sin 24^{\\circ} \\sin 42^{\\circ}\\right)=2\\left(\\sin 48^{\\circ}\\right)^{2}\\left(\\sin 12^{\\circ} \\sin 24^{\\circ} \\cos 48^{\\circ}\\right)\n$$\n\nBy the double-angle formula, this means $S=\\sin 12^{\\circ} \\sin 24^{\\circ} \\sin 48^{\\circ} \\sin 96^{\\circ}$. By a product-to-sum identity,\n\n$$\n\\sin 12^{\\circ} \\sin 48^{\\circ}=\\frac{\\cos 36^{\\circ}-\\cos 60^{\\circ}}{2}=\\frac{\\sqrt{5}-1}{8}\n$$\n\n\n\nand\n\n$$\n\\sin 24^{\\circ} \\sin 96^{\\circ}=\\frac{\\cos 72^{\\circ}-\\cos 120^{\\circ}}{2}=\\frac{\\sqrt{5}+1}{8}\n$$\n\nMultiply the expressions on the right-hand sides of (1) and (2) to obtain $\\frac{\\mathbf{1}}{\\mathbf{1 6}}$'], 'final_answer': ['$\\frac{1}{16}$'], 'is_multiple_answer': False, 'unit': None, 'answer_type': 'Numerical', 'error': None}

  0%|          | 0/87 [00:00<?, ?it/s][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 45/87 [00:00<00:00, 438.36it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 87/87 [00:00<00:00, 437.79it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/696 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 1/696 [00:04<48:56,  4.23s/it, est. speed input: 20.11 toks/s, output: 46.15 toks/s][A
Processed prompts:   1%|‚ñè         | 9/696 [00:04<04:47,  2.39it/s, est. speed input: 200.62 toks/s, output: 363.97 toks/s][A
Processed prompts:   2%|‚ñè         | 17/696 [00:05<02:47,  4.06it/s, est. speed input: 551.73 toks/s, output: 624.75 toks/s][A
Processed prompts:   5%|‚ñç         | 33/696 [00:07<01:43,  6.38it/s, est. speed input: 984.24 toks/s, output: 1075.33 toks/s][A
Processed prompts:   6%|‚ñå         | 41/696 [00:08<01:49,  5.98it/s, est. speed input: 928.14 toks/s, output: 1198.33 toks/s][A
Processed prompts:   7%|‚ñã         | 49/696 [00:09<01:20,  8.03it/s, est. speed input: 1159.21 toks/s, output: 1515.10 toks/s][A
Processed prompts:   8%|‚ñä         | 57/696 [00:09<00:58, 10.86it/s, est. speed input: 1234.39 toks/s, output: 1837.51 toks/s][A
Processed prompts:   9%|‚ñâ         | 65/696 [00:10<00:59, 10.54it/s, est. speed input: 1353.86 toks/s, output: 2016.66 toks/s][A
Processed prompts:  10%|‚ñà         | 73/696 [00:10<00:47, 13.10it/s, est. speed input: 1401.63 toks/s, output: 2303.51 toks/s][A
Processed prompts:  11%|‚ñà‚ñè        | 79/696 [00:10<00:39, 15.77it/s, est. speed input: 1556.27 toks/s, output: 2530.04 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 83/696 [00:10<00:37, 16.22it/s, est. speed input: 1641.84 toks/s, output: 2650.70 toks/s][A
Processed prompts:  13%|‚ñà‚ñé        | 89/696 [00:11<00:41, 14.74it/s, est. speed input: 1721.66 toks/s, output: 2781.99 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 105/696 [00:11<00:25, 23.54it/s, est. speed input: 1970.79 toks/s, output: 3353.55 toks/s][A
Processed prompts:  16%|‚ñà‚ñå        | 113/696 [00:12<00:32, 18.11it/s, est. speed input: 1912.05 toks/s, output: 3330.42 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 121/696 [00:12<00:28, 20.33it/s, est. speed input: 1954.03 toks/s, output: 3592.77 toks/s][A
Processed prompts:  18%|‚ñà‚ñä        | 128/696 [00:12<00:27, 20.36it/s, est. speed input: 2050.64 toks/s, output: 3755.70 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 136/696 [00:14<00:57,  9.73it/s, est. speed input: 1842.29 toks/s, output: 3378.55 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 144/696 [00:15<00:50, 10.93it/s, est. speed input: 1865.10 toks/s, output: 3463.32 toks/s][A
Processed prompts:  22%|‚ñà‚ñà‚ñè       | 152/696 [00:16<01:00,  8.98it/s, est. speed input: 1766.85 toks/s, output: 3484.21 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 160/696 [00:16<00:46, 11.50it/s, est. speed input: 1789.94 toks/s, output: 3567.82 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 168/696 [00:17<00:49, 10.65it/s, est. speed input: 1755.25 toks/s, output: 3520.30 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 176/696 [00:18<00:56,  9.22it/s, est. speed input: 1682.40 toks/s, output: 3598.04 toks/s][A
Processed prompts:  26%|‚ñà‚ñà‚ñã       | 184/696 [00:19<00:43, 11.91it/s, est. speed input: 1719.29 toks/s, output: 3755.52 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 192/696 [00:19<00:34, 14.54it/s, est. speed input: 1814.46 toks/s, output: 3998.43 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñä       | 200/696 [00:23<01:43,  4.78it/s, est. speed input: 1535.28 toks/s, output: 3397.30 toks/s][A
Processed prompts:  29%|‚ñà‚ñà‚ñâ       | 202/696 [00:23<01:38,  4.99it/s, est. speed input: 1526.05 toks/s, output: 3403.90 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 207/696 [00:23<01:17,  6.33it/s, est. speed input: 1529.84 toks/s, output: 3479.19 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 209/696 [00:25<01:40,  4.83it/s, est. speed input: 1470.86 toks/s, output: 3356.05 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñà       | 211/696 [00:27<02:50,  2.84it/s, est. speed input: 1354.61 toks/s, output: 3111.78 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà       | 217/696 [00:28<02:02,  3.90it/s, est. speed input: 1342.59 toks/s, output: 3138.30 toks/s][A
Processed prompts:  32%|‚ñà‚ñà‚ñà‚ñè      | 224/696 [00:29<01:58,  3.98it/s, est. speed input: 1290.02 toks/s, output: 3039.67 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 231/696 [00:29<01:19,  5.87it/s, est. speed input: 1297.62 toks/s, output: 3109.02 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 233/696 [00:30<01:18,  5.90it/s, est. speed input: 1289.43 toks/s, output: 3107.66 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 241/696 [00:30<00:59,  7.64it/s, est. speed input: 1292.76 toks/s, output: 3208.52 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñå      | 249/696 [00:32<01:07,  6.65it/s, est. speed input: 1250.50 toks/s, output: 3235.28 toks/s][A
Processed prompts:  37%|‚ñà‚ñà‚ñà‚ñã      | 257/696 [00:33<01:05,  6.66it/s, est. speed input: 1223.80 toks/s, output: 3398.35 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 265/696 [00:35<01:14,  5.78it/s, est. speed input: 1180.47 toks/s, output: 3443.58 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 271/696 [00:35<00:57,  7.33it/s, est. speed input: 1185.50 toks/s, output: 3481.71 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 273/696 [00:38<02:06,  3.33it/s, est. speed input: 1090.87 toks/s, output: 3206.59 toks/s][A
Processed prompts:  40%|‚ñà‚ñà‚ñà‚ñà      | 281/696 [00:41<02:12,  3.13it/s, est. speed input: 1030.60 toks/s, output: 3027.49 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 289/696 [00:44<02:19,  2.92it/s, est. speed input: 971.65 toks/s, output: 2890.94 toks/s] [A
Processed prompts:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 297/696 [00:44<01:36,  4.11it/s, est. speed input: 985.48 toks/s, output: 3073.03 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 305/696 [00:46<01:27,  4.49it/s, est. speed input: 973.32 toks/s, output: 3216.69 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 307/696 [00:46<01:20,  4.81it/s, est. speed input: 973.90 toks/s, output: 3224.41 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 309/696 [00:46<01:13,  5.23it/s, est. speed input: 974.52 toks/s, output: 3232.21 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 311/696 [00:46<01:06,  5.76it/s, est. speed input: 975.15 toks/s, output: 3240.03 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 313/696 [00:47<01:30,  4.25it/s, est. speed input: 957.68 toks/s, output: 3213.12 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 321/696 [00:49<01:10,  5.30it/s, est. speed input: 947.61 toks/s, output: 3376.67 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 328/696 [00:49<00:58,  6.28it/s, est. speed input: 949.29 toks/s, output: 3403.61 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 329/696 [01:06<08:10,  1.34s/it, est. speed input: 718.47 toks/s, output: 2591.66 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 336/696 [01:14<07:38,  1.27s/it, est. speed input: 647.92 toks/s, output: 2437.26 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 342/696 [01:14<05:02,  1.17it/s, est. speed input: 655.56 toks/s, output: 2566.20 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 342/696 [01:27<05:02,  1.17it/s, est. speed input: 655.56 toks/s, output: 2566.20 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 343/696 [01:43<17:16,  2.94s/it, est. speed input: 475.74 toks/s, output: 1886.66 toks/s][A
Processed prompts:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 344/696 [01:43<15:38,  2.67s/it, est. speed input: 476.49 toks/s, output: 1913.87 toks/s][A
Processed prompts:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 366/696 [01:43<03:40,  1.50it/s, est. speed input: 503.07 toks/s, output: 2560.95 toks/s][A
Processed prompts:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 374/696 [01:44<02:41,  2.00it/s, est. speed input: 512.05 toks/s, output: 2782.84 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 394/696 [01:44<01:16,  3.95it/s, est. speed input: 529.98 toks/s, output: 3367.84 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 428/696 [01:44<00:31,  8.54it/s, est. speed input: 569.82 toks/s, output: 4362.22 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 438/696 [01:51<00:56,  4.59it/s, est. speed input: 548.05 toks/s, output: 4209.40 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 446/696 [01:51<00:48,  5.17it/s, est. speed input: 552.40 toks/s, output: 4203.62 toks/s][A
Processed prompts:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 461/696 [01:51<00:31,  7.45it/s, est. speed input: 560.89 toks/s, output: 4233.73 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 468/696 [01:53<00:33,  6.88it/s, est. speed input: 558.11 toks/s, output: 4199.67 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 475/696 [01:53<00:30,  7.26it/s, est. speed input: 559.66 toks/s, output: 4192.68 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 479/696 [01:54<00:27,  7.93it/s, est. speed input: 560.90 toks/s, output: 4196.76 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 484/696 [01:54<00:22,  9.40it/s, est. speed input: 563.30 toks/s, output: 4207.82 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 490/696 [01:54<00:17, 11.62it/s, est. speed input: 566.92 toks/s, output: 4224.23 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 494/696 [01:54<00:15, 13.42it/s, est. speed input: 569.52 toks/s, output: 4234.64 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 498/696 [01:55<00:25,  7.85it/s, est. speed input: 566.87 toks/s, output: 4235.78 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 502/696 [01:55<00:20,  9.50it/s, est. speed input: 569.82 toks/s, output: 4294.84 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 505/696 [01:56<00:18, 10.53it/s, est. speed input: 571.53 toks/s, output: 4344.01 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 508/696 [01:56<00:15, 12.25it/s, est. speed input: 573.61 toks/s, output: 4351.01 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 515/696 [01:56<00:09, 18.84it/s, est. speed input: 579.08 toks/s, output: 4416.86 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 519/696 [01:56<00:11, 15.55it/s, est. speed input: 581.30 toks/s, output: 4440.09 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 525/696 [01:57<00:10, 16.04it/s, est. speed input: 585.46 toks/s, output: 4448.32 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 528/696 [01:57<00:10, 15.35it/s, est. speed input: 586.89 toks/s, output: 4450.19 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 537/696 [01:57<00:06, 24.25it/s, est. speed input: 594.30 toks/s, output: 4481.20 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 541/696 [01:58<00:10, 14.87it/s, est. speed input: 594.24 toks/s, output: 4474.37 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 547/696 [01:58<00:07, 19.27it/s, est. speed input: 598.08 toks/s, output: 4495.31 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 551/696 [01:58<00:12, 11.53it/s, est. speed input: 597.28 toks/s, output: 4487.22 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 554/696 [01:59<00:15,  8.99it/s, est. speed input: 596.48 toks/s, output: 4473.48 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 563/696 [01:59<00:10, 12.35it/s, est. speed input: 604.01 toks/s, output: 4503.53 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 565/696 [02:00<00:13,  9.37it/s, est. speed input: 604.20 toks/s, output: 4494.13 toks/s][A
Processed prompts:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 567/696 [02:03<00:39,  3.26it/s, est. speed input: 592.99 toks/s, output: 4406.71 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 569/696 [02:03<00:37,  3.35it/s, est. speed input: 591.94 toks/s, output: 4400.35 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 570/696 [02:05<00:52,  2.40it/s, est. speed input: 587.62 toks/s, output: 4361.43 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 571/696 [02:06<01:08,  1.84it/s, est. speed input: 582.22 toks/s, output: 4339.96 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 574/696 [02:06<00:44,  2.73it/s, est. speed input: 583.53 toks/s, output: 4405.33 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 576/696 [02:06<00:35,  3.39it/s, est. speed input: 584.20 toks/s, output: 4447.20 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 577/696 [02:07<00:31,  3.75it/s, est. speed input: 584.42 toks/s, output: 4467.25 toks/s][A
Processed prompts:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 579/696 [02:11<01:49,  1.07it/s, est. speed input: 564.24 toks/s, output: 4350.39 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 582/696 [02:11<01:05,  1.74it/s, est. speed input: 565.22 toks/s, output: 4416.92 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 584/696 [02:12<00:49,  2.27it/s, est. speed input: 565.42 toks/s, output: 4457.65 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 586/696 [02:12<00:37,  2.92it/s, est. speed input: 565.52 toks/s, output: 4497.49 toks/s][A
Processed prompts:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 588/696 [02:13<00:46,  2.33it/s, est. speed input: 561.99 toks/s, output: 4471.20 toks/s][A
Processed prompts:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 595/696 [02:19<01:04,  1.58it/s, est. speed input: 546.22 toks/s, output: 4367.67 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 596/696 [02:19<01:04,  1.56it/s, est. speed input: 544.21 toks/s, output: 4367.52 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 599/696 [02:19<00:43,  2.21it/s, est. speed input: 545.99 toks/s, output: 4429.44 toks/s][A
Processed prompts:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 601/696 [02:20<00:35,  2.71it/s, est. speed input: 546.82 toks/s, output: 4467.75 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 603/696 [02:22<00:57,  1.61it/s, est. speed input: 537.66 toks/s, output: 4423.79 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 604/696 [02:24<01:15,  1.22it/s, est. speed input: 531.15 toks/s, output: 4385.68 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 605/696 [02:25<01:10,  1.29it/s, est. speed input: 529.63 toks/s, output: 4389.72 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 607/696 [02:25<00:47,  1.86it/s, est. speed input: 530.24 toks/s, output: 4428.05 toks/s][A
Processed prompts:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 608/696 [02:25<00:39,  2.21it/s, est. speed input: 530.41 toks/s, output: 4446.04 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 611/696 [02:25<00:23,  3.65it/s, est. speed input: 531.40 toks/s, output: 4503.94 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 613/696 [02:28<00:49,  1.66it/s, est. speed input: 522.79 toks/s, output: 4462.83 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 617/696 [02:28<00:26,  2.94it/s, est. speed input: 524.65 toks/s, output: 4541.09 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 619/696 [02:28<00:21,  3.58it/s, est. speed input: 525.15 toks/s, output: 4576.51 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 621/696 [02:30<00:35,  2.14it/s, est. speed input: 520.00 toks/s, output: 4549.26 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 622/696 [02:32<00:50,  1.47it/s, est. speed input: 514.30 toks/s, output: 4515.54 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 625/696 [02:32<00:29,  2.38it/s, est. speed input: 515.28 toks/s, output: 4572.36 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 628/696 [02:32<00:19,  3.56it/s, est. speed input: 516.26 toks/s, output: 4629.15 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 630/696 [02:34<00:27,  2.38it/s, est. speed input: 511.83 toks/s, output: 4619.90 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 633/696 [02:34<00:18,  3.50it/s, est. speed input: 513.16 toks/s, output: 4675.53 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 636/696 [02:34<00:12,  4.90it/s, est. speed input: 514.49 toks/s, output: 4731.17 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 638/696 [02:42<01:02,  1.08s/it, est. speed input: 491.71 toks/s, output: 4548.30 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 642/696 [02:42<00:34,  1.55it/s, est. speed input: 494.03 toks/s, output: 4620.77 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 645/696 [02:44<00:32,  1.59it/s, est. speed input: 490.87 toks/s, output: 4626.64 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 647/696 [02:47<00:40,  1.21it/s, est. speed input: 483.96 toks/s, output: 4579.68 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 650/696 [02:47<00:26,  1.75it/s, est. speed input: 486.83 toks/s, output: 4631.41 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 654/696 [02:47<00:15,  2.74it/s, est. speed input: 490.78 toks/s, output: 4701.50 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 657/696 [02:48<00:14,  2.63it/s, est. speed input: 488.93 toks/s, output: 4721.32 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 659/696 [02:50<00:18,  1.95it/s, est. speed input: 484.51 toks/s, output: 4702.32 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 662/696 [02:50<00:12,  2.69it/s, est. speed input: 485.98 toks/s, output: 4750.60 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 664/696 [02:52<00:14,  2.19it/s, est. speed input: 483.56 toks/s, output: 4745.78 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 670/696 [02:52<00:06,  4.21it/s, est. speed input: 488.40 toks/s, output: 4849.62 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 673/696 [02:53<00:05,  4.43it/s, est. speed input: 490.98 toks/s, output: 4886.71 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 678/696 [02:53<00:02,  6.46it/s, est. speed input: 496.70 toks/s, output: 4969.48 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 686/696 [02:53<00:01,  8.60it/s, est. speed input: 500.92 toks/s, output: 5094.31 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 688/696 [02:54<00:01,  7.76it/s, est. speed input: 501.26 toks/s, output: 5117.60 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 690/696 [02:55<00:01,  5.25it/s, est. speed input: 499.72 toks/s, output: 5123.96 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 696/696 [02:55<00:00,  3.97it/s, est. speed input: 503.56 toks/s, output: 5229.12 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/696 [00:00<?, ?it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 696/696 [00:00<00:00, 10312.88it/s]
{'num_samples': 87, 'num_scores': 696, 'timeout_samples': 0, 'empty_samples': 2, 'acc': 24.1, 'total_acc': 25.143678160919542, 'pass_at_k_percent': {'1': 25.1, '8': 25.3}, 'pass_at_k_valid_counts': {'1': 87, '8': 87}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_results/noise_rlvr_1_5b_128batchsize_deepscaler_v2_think-boxed/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g2/olympiadbench/test_think-boxed_-1_seed0_t0.0_s0_e-1_part7.jsonl
[2025-12-03 20:13:36] ‚úì B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g2/olympiadbench  acc=24.1 pass_at_k={'1': 25.1, '8': 25.3}
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g2:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [04:18<02:17, 137.94s/ds][Info] Sharding enabled: Process 7/8 handling range [434:500]
==================================================
data: math500  ,remain samples: 66
{'idx': 434, 'problem': 'In a certain isosceles right triangle, the altitude to the hypotenuse has length $4\\sqrt{2}$.  What is the area of the triangle?', 'solution': 'In isosceles right triangle $\\triangle ABC$ below, $\\overline{AD}$ is the altitude to the hypotenuse.\n\n[asy]\nimport olympiad;\nunitsize(0.8inch);\npair A,B,C,D;\nA = (0,1);\nB= (1,0);\nC = -B;\nD = (0,0);\ndraw(A--B--C--A,linewidth(1));\ndraw(A--D,linewidth(0.8));\ndraw(rightanglemark(C,A,B,s=5));\ndraw(rightanglemark(C,D,A,s=5));\nlabel("$A$",A,N);\nlabel("$B$",B,S);\nlabel("$C$",C,S);\nlabel("$D$",D,S);\n[/asy]\n\nBecause $\\triangle ABC$ is an isosceles right triangle, $\\angle ABC = 45^\\circ$.  Since $\\angle ADB = 90^\\circ$, we know that $\\angle DAB = 45^\\circ$, so $\\triangle ABD$ is also a 45-45-90 triangle.  Similarly, $\\triangle ACD$ is a 45-45-90 triangle.  Therefore, $DB=DC = DA = 4\\sqrt{2}$, so $BC = BD+DC = 8\\sqrt{2}$, and  \\[[ABC] = \\frac{(AD)(BC)}{2} = \\frac{(4\\sqrt{2})(8\\sqrt{2})}{2} = \\boxed{32}.\\]', 'answer': '32', 'subject': 'Prealgebra', 'level': 5, 'unique_id': 'test/prealgebra/1640.json'}

  0%|          | 0/66 [00:00<?, ?it/s][A
 33%|‚ñà‚ñà‚ñà‚ñé      | 22/66 [00:00<00:00, 212.30it/s][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 45/66 [00:00<00:00, 220.03it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [00:00<00:00, 217.68it/s]
-------------------- Epoch 0

Processed prompts:   0%|          | 0/528 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   0%|          | 1/528 [00:02<19:37,  2.23s/it, est. speed input: 29.10 toks/s, output: 52.38 toks/s][A
Processed prompts:   2%|‚ñè         | 9/528 [00:02<02:18,  3.75it/s, est. speed input: 239.34 toks/s, output: 364.02 toks/s][A
Processed prompts:   3%|‚ñé         | 17/528 [00:03<01:24,  6.02it/s, est. speed input: 580.27 toks/s, output: 633.14 toks/s][A
Processed prompts:   5%|‚ñç         | 25/528 [00:03<00:50,  9.96it/s, est. speed input: 686.87 toks/s, output: 997.03 toks/s][A
Processed prompts:   6%|‚ñã         | 33/528 [00:04<00:36, 13.69it/s, est. speed input: 765.50 toks/s, output: 1320.99 toks/s][A
Processed prompts:   7%|‚ñã         | 36/528 [00:04<00:35, 13.89it/s, est. speed input: 772.92 toks/s, output: 1405.10 toks/s][A
Processed prompts:  11%|‚ñà         | 57/528 [00:04<00:16, 29.16it/s, est. speed input: 1052.18 toks/s, output: 2321.54 toks/s][A
Processed prompts:  12%|‚ñà‚ñè        | 65/528 [00:04<00:14, 32.46it/s, est. speed input: 1145.93 toks/s, output: 2623.96 toks/s][A
Processed prompts:  14%|‚ñà‚ñé        | 72/528 [00:05<00:16, 27.54it/s, est. speed input: 1160.02 toks/s, output: 2755.46 toks/s][A
Processed prompts:  15%|‚ñà‚ñå        | 80/528 [00:05<00:15, 29.34it/s, est. speed input: 1211.91 toks/s, output: 3014.58 toks/s][A
Processed prompts:  17%|‚ñà‚ñã        | 88/528 [00:06<00:21, 20.47it/s, est. speed input: 1177.58 toks/s, output: 2998.12 toks/s][A
Processed prompts:  20%|‚ñà‚ñâ        | 104/528 [00:06<00:16, 25.91it/s, est. speed input: 1419.02 toks/s, output: 3366.77 toks/s][A
Processed prompts:  21%|‚ñà‚ñà        | 112/528 [00:06<00:18, 22.95it/s, est. speed input: 1422.93 toks/s, output: 3497.53 toks/s][A
Processed prompts:  23%|‚ñà‚ñà‚ñé       | 120/528 [00:07<00:19, 20.64it/s, est. speed input: 1434.50 toks/s, output: 3621.20 toks/s][A
Processed prompts:  24%|‚ñà‚ñà‚ñç       | 126/528 [00:08<00:27, 14.75it/s, est. speed input: 1349.03 toks/s, output: 3518.25 toks/s][A
Processed prompts:  25%|‚ñà‚ñà‚ñå       | 134/528 [00:08<00:20, 19.34it/s, est. speed input: 1400.35 toks/s, output: 3820.38 toks/s][A
Processed prompts:  27%|‚ñà‚ñà‚ñã       | 142/528 [00:08<00:17, 22.07it/s, est. speed input: 1438.78 toks/s, output: 3921.47 toks/s][A
Processed prompts:  28%|‚ñà‚ñà‚ñä       | 150/528 [00:08<00:14, 26.78it/s, est. speed input: 1566.51 toks/s, output: 4196.81 toks/s][A
Processed prompts:  30%|‚ñà‚ñà‚ñâ       | 158/528 [00:09<00:23, 15.71it/s, est. speed input: 1455.62 toks/s, output: 3957.17 toks/s][A
Processed prompts:  31%|‚ñà‚ñà‚ñà‚ñè      | 166/528 [00:10<00:28, 12.75it/s, est. speed input: 1426.27 toks/s, output: 3937.11 toks/s][A
Processed prompts:  33%|‚ñà‚ñà‚ñà‚ñé      | 174/528 [00:10<00:20, 16.91it/s, est. speed input: 1464.22 toks/s, output: 4114.58 toks/s][A
Processed prompts:  34%|‚ñà‚ñà‚ñà‚ñé      | 178/528 [00:10<00:19, 17.64it/s, est. speed input: 1473.25 toks/s, output: 4226.19 toks/s][A
Processed prompts:  35%|‚ñà‚ñà‚ñà‚ñç      | 184/528 [00:11<00:18, 18.23it/s, est. speed input: 1499.51 toks/s, output: 4357.95 toks/s][A
Processed prompts:  36%|‚ñà‚ñà‚ñà‚ñã      | 192/528 [00:11<00:14, 23.94it/s, est. speed input: 1669.58 toks/s, output: 4524.30 toks/s][A
Processed prompts:  38%|‚ñà‚ñà‚ñà‚ñä      | 200/528 [00:11<00:13, 24.72it/s, est. speed input: 1796.53 toks/s, output: 4736.35 toks/s][A
Processed prompts:  39%|‚ñà‚ñà‚ñà‚ñâ      | 207/528 [00:12<00:22, 14.25it/s, est. speed input: 1709.40 toks/s, output: 4522.91 toks/s][A
Processed prompts:  41%|‚ñà‚ñà‚ñà‚ñà      | 216/528 [00:13<00:18, 16.53it/s, est. speed input: 1734.85 toks/s, output: 4696.00 toks/s][A
Processed prompts:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 224/528 [00:13<00:14, 21.20it/s, est. speed input: 1750.96 toks/s, output: 4998.64 toks/s][A
Processed prompts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 232/528 [00:13<00:15, 19.32it/s, est. speed input: 1751.50 toks/s, output: 5131.35 toks/s][A
Processed prompts:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 237/528 [00:13<00:15, 18.94it/s, est. speed input: 1747.80 toks/s, output: 5118.10 toks/s][A
Processed prompts:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 244/528 [00:14<00:15, 18.14it/s, est. speed input: 1741.53 toks/s, output: 5153.11 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 247/528 [00:14<00:14, 19.05it/s, est. speed input: 1743.53 toks/s, output: 5152.03 toks/s][A
Processed prompts:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 250/528 [00:14<00:17, 15.46it/s, est. speed input: 1716.66 toks/s, output: 5077.08 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 252/528 [00:15<00:25, 10.77it/s, est. speed input: 1669.35 toks/s, output: 4932.25 toks/s][A
Processed prompts:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 254/528 [00:15<00:29,  9.38it/s, est. speed input: 1642.19 toks/s, output: 4848.10 toks/s][A
Processed prompts:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 269/528 [00:15<00:12, 20.56it/s, est. speed input: 1719.26 toks/s, output: 5211.85 toks/s][A
Processed prompts:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 275/528 [00:16<00:12, 20.14it/s, est. speed input: 1716.93 toks/s, output: 5270.68 toks/s][A
Processed prompts:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 292/528 [00:16<00:07, 32.05it/s, est. speed input: 1782.81 toks/s, output: 5631.12 toks/s][A
Processed prompts:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 300/528 [00:16<00:08, 27.58it/s, est. speed input: 1802.97 toks/s, output: 5834.97 toks/s][A
Processed prompts:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 308/528 [00:17<00:11, 19.67it/s, est. speed input: 1787.14 toks/s, output: 5907.65 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 311/528 [00:18<00:14, 15.10it/s, est. speed input: 1750.77 toks/s, output: 5802.31 toks/s][A
Processed prompts:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 314/528 [00:18<00:13, 15.81it/s, est. speed input: 1751.59 toks/s, output: 5809.73 toks/s][A
Processed prompts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 318/528 [00:18<00:11, 17.99it/s, est. speed input: 1759.35 toks/s, output: 5818.26 toks/s][A
Processed prompts:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 323/528 [00:18<00:10, 18.89it/s, est. speed input: 1760.80 toks/s, output: 5829.89 toks/s][A
Processed prompts:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 326/528 [00:19<00:15, 13.09it/s, est. speed input: 1730.86 toks/s, output: 5749.41 toks/s][A
Processed prompts:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 334/528 [00:19<00:12, 15.79it/s, est. speed input: 1759.31 toks/s, output: 5949.18 toks/s][A
Processed prompts:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 338/528 [00:19<00:11, 17.27it/s, est. speed input: 1763.73 toks/s, output: 5965.18 toks/s][A
Processed prompts:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 345/528 [00:21<00:23,  7.81it/s, est. speed input: 1656.50 toks/s, output: 5654.56 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 352/528 [00:21<00:15, 11.17it/s, est. speed input: 1681.05 toks/s, output: 5736.54 toks/s][A
Processed prompts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 355/528 [00:23<00:28,  6.18it/s, est. speed input: 1583.55 toks/s, output: 5409.52 toks/s][A
Processed prompts:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 358/528 [00:23<00:25,  6.58it/s, est. speed input: 1573.12 toks/s, output: 5395.76 toks/s][A
Processed prompts:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 364/528 [00:24<00:22,  7.28it/s, est. speed input: 1552.68 toks/s, output: 5359.05 toks/s][A
Processed prompts:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 367/528 [00:24<00:18,  8.52it/s, est. speed input: 1555.79 toks/s, output: 5377.62 toks/s][A
Processed prompts:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 374/528 [00:24<00:12, 12.40it/s, est. speed input: 1569.63 toks/s, output: 5438.13 toks/s][A
Processed prompts:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 378/528 [00:24<00:11, 13.55it/s, est. speed input: 1570.30 toks/s, output: 5477.54 toks/s][A
Processed prompts:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 386/528 [00:26<00:19,  7.27it/s, est. speed input: 1487.43 toks/s, output: 5409.40 toks/s][A
Processed prompts:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 389/528 [00:26<00:17,  7.79it/s, est. speed input: 1492.17 toks/s, output: 5440.88 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 394/528 [00:27<00:17,  7.57it/s, est. speed input: 1491.06 toks/s, output: 5430.75 toks/s][A
Processed prompts:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 397/528 [00:27<00:18,  7.21it/s, est. speed input: 1472.06 toks/s, output: 5395.02 toks/s][A
Processed prompts:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 401/528 [00:31<00:42,  2.96it/s, est. speed input: 1322.82 toks/s, output: 4889.52 toks/s][A
Processed prompts:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 408/528 [00:34<00:43,  2.76it/s, est. speed input: 1236.05 toks/s, output: 4657.00 toks/s][A
Processed prompts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 413/528 [00:34<00:30,  3.80it/s, est. speed input: 1241.61 toks/s, output: 4795.95 toks/s][A
Processed prompts:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 416/528 [00:37<00:49,  2.27it/s, est. speed input: 1135.86 toks/s, output: 4446.56 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 422/528 [00:49<00:46,  2.27it/s, est. speed input: 1156.28 toks/s, output: 4624.62 toks/s][A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 423/528 [01:19<04:42,  2.69s/it, est. speed input: 546.06 toks/s, output: 2218.91 toks/s] [A
Processed prompts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 424/528 [01:19<04:19,  2.50s/it, est. speed input: 545.98 toks/s, output: 2253.21 toks/s][A
Processed prompts:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 432/528 [01:20<02:09,  1.35s/it, est. speed input: 551.59 toks/s, output: 2552.77 toks/s][A
Processed prompts:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 464/528 [01:22<00:27,  2.33it/s, est. speed input: 562.60 toks/s, output: 3649.84 toks/s][A
Processed prompts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 468/528 [01:25<00:26,  2.24it/s, est. speed input: 551.49 toks/s, output: 3664.44 toks/s][A
Processed prompts:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 476/528 [01:25<00:18,  2.80it/s, est. speed input: 556.29 toks/s, output: 3921.80 toks/s][A
Processed prompts:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 483/528 [01:25<00:12,  3.58it/s, est. speed input: 570.81 toks/s, output: 4163.47 toks/s][A
Processed prompts:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 485/528 [01:26<00:12,  3.40it/s, est. speed input: 567.07 toks/s, output: 4190.95 toks/s][A
Processed prompts:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 492/528 [01:27<00:07,  4.54it/s, est. speed input: 571.34 toks/s, output: 4420.34 toks/s][A
Processed prompts:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 494/528 [01:27<00:07,  4.62it/s, est. speed input: 571.61 toks/s, output: 4471.72 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 499/528 [01:28<00:05,  5.41it/s, est. speed input: 575.48 toks/s, output: 4619.22 toks/s][A
Processed prompts:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 504/528 [01:28<00:04,  5.69it/s, est. speed input: 577.10 toks/s, output: 4752.19 toks/s][A
Processed prompts:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 507/528 [01:29<00:04,  4.87it/s, est. speed input: 577.55 toks/s, output: 4803.29 toks/s][A
Processed prompts:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 514/528 [01:30<00:02,  6.53it/s, est. speed input: 587.38 toks/s, output: 5013.50 toks/s][A
Processed prompts:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 516/528 [01:30<00:02,  5.95it/s, est. speed input: 587.22 toks/s, output: 5052.35 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 521/528 [01:31<00:00,  8.22it/s, est. speed input: 592.95 toks/s, output: 5213.17 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 523/528 [01:31<00:00,  8.21it/s, est. speed input: 594.01 toks/s, output: 5266.47 toks/s][A
Processed prompts:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 525/528 [01:36<00:01,  1.76it/s, est. speed input: 564.50 toks/s, output: 5053.53 toks/s][AProcessed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 528/528 [01:36<00:00,  5.48it/s, est. speed input: 567.08 toks/s, output: 5145.75 toks/s]
-------------------- Epoch 1
Unsolved samples: 0

Evaluate:   0%|          | 0/528 [00:00<?, ?it/s][AEvaluate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 528/528 [00:00<00:00, 11597.76it/s]
{'num_samples': 66, 'num_scores': 528, 'timeout_samples': 0, 'empty_samples': 1, 'acc': 37.9, 'total_acc': 39.58333333333333, 'pass_at_k_percent': {'1': 39.6, '8': 40.9}, 'pass_at_k_valid_counts': {'1': 66, '8': 66}}
Saved to /uge_mnt/home/caixq/project/noisy-RLVR/eval_results/noise_rlvr_1_5b_128batchsize_deepscaler_v2_think-boxed/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g2/math500/test_think-boxed_-1_seed0_t0.0_s0_e-1_part7.jsonl
[2025-12-03 20:15:16] ‚úì B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g2/math500  acc=37.9 pass_at_k={'1': 39.6, '8': 40.9}
B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [05:58<00:00, 120.66s/ds]B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300/g2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [05:58<00:00, 119.65s/ds]
[2025-12-03 20:15:16] ‚úÖ ÂÆåÊàêÔºöB_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_300Ôºàg1+g2 Áº∫Â§±Êï∞ÊçÆÈõÜÂ∑≤Ë°•ÂÖ®Ôºâ
[2025-12-03 20:15:16] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_313
INFO 12-03 20:15:16 [config.py:717] This model supports multiple tasks: {'embed', 'classify', 'reward', 'generate', 'score'}. Defaulting to 'generate'.
INFO 12-03 20:15:16 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-03 20:15:16 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-03 20:15:22 [__init__.py:239] Automatically detected platform cuda.
INFO 12-03 20:15:28 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-03 20:15:28 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f739febe500>
INFO 12-03 20:15:39 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-03 20:15:39 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-03 20:15:39 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-03 20:15:39 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-03 20:15:39 [core.py:396] EngineCore failed to start.
ERROR 12-03 20:15:39 [core.py:396] Traceback (most recent call last):
ERROR 12-03 20:15:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-03 20:15:39 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-03 20:15:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-03 20:15:39 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-03 20:15:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-03 20:15:39 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-03 20:15:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-03 20:15:39 [core.py:396]     self._init_executor()
ERROR 12-03 20:15:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-03 20:15:39 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-03 20:15:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-03 20:15:39 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-03 20:15:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-03 20:15:39 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:15:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-03 20:15:39 [core.py:396]     self.model_runner.load_model()
ERROR 12-03 20:15:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-03 20:15:39 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-03 20:15:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-03 20:15:39 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-03 20:15:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-03 20:15:39 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-03 20:15:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-03 20:15:39 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-03 20:15:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-03 20:15:39 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-03 20:15:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-03 20:15:39 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-03 20:15:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-03 20:15:39 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-03 20:15:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-03 20:15:39 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-03 20:15:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-03 20:15:39 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-03 20:15:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-03 20:15:39 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-03 20:15:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-03 20:15:39 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-03 20:15:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
ERROR 12-03 20:15:39 [core.py:396]     self.mlp = LlamaMLP(
ERROR 12-03 20:15:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
ERROR 12-03 20:15:39 [core.py:396]     self.down_proj = RowParallelLinear(
ERROR 12-03 20:15:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
ERROR 12-03 20:15:39 [core.py:396]     self.quant_method.create_weights(
ERROR 12-03 20:15:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-03 20:15:39 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-03 20:15:39 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-03 20:15:39 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:15:39 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3304113 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
    self.mlp = LlamaMLP(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
    self.down_proj = RowParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3304113 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f7653b6c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f7653b15b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f760468e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f7653f64b78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f7653f6520e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7f7653f7bb0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f7653f67329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f764bc864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f764b3a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f764b3a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x5616c17afc04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x5616c173c2a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x5616c173cbbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x5616c173cc83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x5616c17afb85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x5616c181bc3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x5616c181ef1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x5616c173dc98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x5616c187cc30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x5616c18a2407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x5616c18a2634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x5616c18a2718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x5616c18a275b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x5616c18a2972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x5616c18a8f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x5616c18a91ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x5616c18a9469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f7654a60d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f7654a60e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x5616c18142d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-03 20:15:41] ‚ö† Ê®°Âûã B_rb_manual_algo2_est_r00.10_r10.20_est0.10_0.20_Llama-3.2-3B-Instruct__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-03 20:15:41] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_100
INFO 12-03 20:15:41 [config.py:717] This model supports multiple tasks: {'embed', 'classify', 'reward', 'generate', 'score'}. Defaulting to 'generate'.
INFO 12-03 20:15:41 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-03 20:15:41 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-03 20:15:46 [__init__.py:239] Automatically detected platform cuda.
INFO 12-03 20:15:53 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_100', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_100', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_100, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-03 20:15:54 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f84db576c80>
INFO 12-03 20:16:09 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-03 20:16:09 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-03 20:16:09 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-03 20:16:09 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_100...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-03 20:16:10 [core.py:396] EngineCore failed to start.
ERROR 12-03 20:16:10 [core.py:396] Traceback (most recent call last):
ERROR 12-03 20:16:10 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-03 20:16:10 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-03 20:16:10 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-03 20:16:10 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-03 20:16:10 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-03 20:16:10 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-03 20:16:10 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-03 20:16:10 [core.py:396]     self._init_executor()
ERROR 12-03 20:16:10 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-03 20:16:10 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-03 20:16:10 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-03 20:16:10 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-03 20:16:10 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-03 20:16:10 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:16:10 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-03 20:16:10 [core.py:396]     self.model_runner.load_model()
ERROR 12-03 20:16:10 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-03 20:16:10 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-03 20:16:10 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-03 20:16:10 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-03 20:16:10 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-03 20:16:10 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-03 20:16:10 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-03 20:16:10 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-03 20:16:10 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-03 20:16:10 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-03 20:16:10 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-03 20:16:10 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-03 20:16:10 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-03 20:16:10 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-03 20:16:10 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-03 20:16:10 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-03 20:16:10 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-03 20:16:10 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-03 20:16:10 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-03 20:16:10 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-03 20:16:10 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-03 20:16:10 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-03 20:16:10 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
ERROR 12-03 20:16:10 [core.py:396]     self.mlp = LlamaMLP(
ERROR 12-03 20:16:10 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
ERROR 12-03 20:16:10 [core.py:396]     self.down_proj = RowParallelLinear(
ERROR 12-03 20:16:10 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
ERROR 12-03 20:16:10 [core.py:396]     self.quant_method.create_weights(
ERROR 12-03 20:16:10 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-03 20:16:10 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-03 20:16:10 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-03 20:16:10 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:16:10 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3304971 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
    self.mlp = LlamaMLP(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
    self.down_proj = RowParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3304971 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f878ef6c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f878ef15b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f873fe8e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f878f35fb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f878f36020e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7f878f376b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f878f362329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f87874864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f8786ba5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f8786ba64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x5583a7556c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x5583a74e32a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x5583a74e3bbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x5583a74e3c83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x5583a7556b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x5583a75c2c3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x5583a75c5f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x5583a74e4c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x5583a7623c30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x5583a7649407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x5583a7649634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x5583a7649718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x5583a764975b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x5583a7649972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x5583a764ff60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x5583a76501ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x5583a7650469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f8790112d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f8790112e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x5583a75bb2d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-03 20:16:11] ‚ö† Ê®°Âûã B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct__global_step_100 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-03 20:16:11] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_200
INFO 12-03 20:16:11 [config.py:717] This model supports multiple tasks: {'embed', 'classify', 'reward', 'generate', 'score'}. Defaulting to 'generate'.
INFO 12-03 20:16:11 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-03 20:16:11 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-03 20:16:17 [__init__.py:239] Automatically detected platform cuda.
INFO 12-03 20:16:23 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-03 20:16:23 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f6b311898d0>
INFO 12-03 20:16:49 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-03 20:16:49 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-03 20:16:49 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-03 20:16:49 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-03 20:16:49 [core.py:396] EngineCore failed to start.
ERROR 12-03 20:16:49 [core.py:396] Traceback (most recent call last):
ERROR 12-03 20:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-03 20:16:49 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-03 20:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-03 20:16:49 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-03 20:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-03 20:16:49 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-03 20:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-03 20:16:49 [core.py:396]     self._init_executor()
ERROR 12-03 20:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-03 20:16:49 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-03 20:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-03 20:16:49 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-03 20:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-03 20:16:49 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-03 20:16:49 [core.py:396]     self.model_runner.load_model()
ERROR 12-03 20:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-03 20:16:49 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-03 20:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-03 20:16:49 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-03 20:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-03 20:16:49 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-03 20:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-03 20:16:49 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-03 20:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-03 20:16:49 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-03 20:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-03 20:16:49 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-03 20:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-03 20:16:49 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-03 20:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-03 20:16:49 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-03 20:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-03 20:16:49 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-03 20:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-03 20:16:49 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-03 20:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-03 20:16:49 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-03 20:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
ERROR 12-03 20:16:49 [core.py:396]     self.mlp = LlamaMLP(
ERROR 12-03 20:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
ERROR 12-03 20:16:49 [core.py:396]     self.down_proj = RowParallelLinear(
ERROR 12-03 20:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
ERROR 12-03 20:16:49 [core.py:396]     self.quant_method.create_weights(
ERROR 12-03 20:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-03 20:16:49 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-03 20:16:49 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-03 20:16:49 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:16:49 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3305731 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
    self.mlp = LlamaMLP(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
    self.down_proj = RowParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3305731 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f6de4b6c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f6de4b15b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f6d95a8e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f6de4f45b78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f6de4f4620e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7f6de4f5cb0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f6de4f48329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f6ddd0864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f6ddc7a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f6ddc7a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x5555c68abc04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x5555c68382a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x5555c6838bbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x5555c6838c83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x5555c68abb85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x5555c6917c3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x5555c691af1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x5555c6839c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x5555c6978c30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x5555c699e407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x5555c699e634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x5555c699e718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x5555c699e75b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x5555c699e972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x5555c69a4f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x5555c69a51ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x5555c69a5469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f6de5cfad90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f6de5cfae40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x5555c69102d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-03 20:16:51] ‚ö† Ê®°Âûã B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-03 20:16:51] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_300
INFO 12-03 20:16:51 [config.py:717] This model supports multiple tasks: {'embed', 'classify', 'reward', 'generate', 'score'}. Defaulting to 'generate'.
INFO 12-03 20:16:51 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-03 20:16:51 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-03 20:16:57 [__init__.py:239] Automatically detected platform cuda.
INFO 12-03 20:17:05 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_300', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_300', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_300, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-03 20:17:05 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f5c9d6bac80>
INFO 12-03 20:17:15 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-03 20:17:15 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-03 20:17:15 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-03 20:17:16 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_300...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-03 20:17:16 [core.py:396] EngineCore failed to start.
ERROR 12-03 20:17:16 [core.py:396] Traceback (most recent call last):
ERROR 12-03 20:17:16 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-03 20:17:16 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-03 20:17:16 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-03 20:17:16 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-03 20:17:16 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-03 20:17:16 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-03 20:17:16 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-03 20:17:16 [core.py:396]     self._init_executor()
ERROR 12-03 20:17:16 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-03 20:17:16 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-03 20:17:16 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-03 20:17:16 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-03 20:17:16 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-03 20:17:16 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:17:16 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-03 20:17:16 [core.py:396]     self.model_runner.load_model()
ERROR 12-03 20:17:16 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-03 20:17:16 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-03 20:17:16 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-03 20:17:16 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-03 20:17:16 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-03 20:17:16 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-03 20:17:16 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-03 20:17:16 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-03 20:17:16 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-03 20:17:16 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-03 20:17:16 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-03 20:17:16 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-03 20:17:16 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-03 20:17:16 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-03 20:17:16 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-03 20:17:16 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-03 20:17:16 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-03 20:17:16 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-03 20:17:16 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-03 20:17:16 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-03 20:17:16 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-03 20:17:16 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-03 20:17:16 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
ERROR 12-03 20:17:16 [core.py:396]     self.mlp = LlamaMLP(
ERROR 12-03 20:17:16 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
ERROR 12-03 20:17:16 [core.py:396]     self.down_proj = RowParallelLinear(
ERROR 12-03 20:17:16 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
ERROR 12-03 20:17:16 [core.py:396]     self.quant_method.create_weights(
ERROR 12-03 20:17:16 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-03 20:17:16 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-03 20:17:16 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-03 20:17:16 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:17:16 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3306979 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
    self.mlp = LlamaMLP(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
    self.down_proj = RowParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3306979 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f5f5136c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f5f51315b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f5f01e8e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f5f51737b78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f5f5173820e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7f5f5174eb0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f5f5173a329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f5f494864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f5f48ba5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f5f48ba64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x56313c30dc04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x56313c29a2a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x56313c29abbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x56313c29ac83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x56313c30db85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x56313c379c3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x56313c37cf1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x56313c29bc98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x56313c3dac30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x56313c400407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x56313c400634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x56313c400718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x56313c40075b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x56313c400972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x56313c406f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x56313c4071ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x56313c407469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f5f52233d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f5f52233e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x56313c3722d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-03 20:17:17] ‚ö† Ê®°Âûã B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct__global_step_300 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-03 20:17:17] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_313
INFO 12-03 20:17:17 [config.py:717] This model supports multiple tasks: {'embed', 'classify', 'reward', 'generate', 'score'}. Defaulting to 'generate'.
INFO 12-03 20:17:17 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-03 20:17:17 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-03 20:17:23 [__init__.py:239] Automatically detected platform cuda.
INFO 12-03 20:17:30 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-03 20:17:30 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f7bd676a4a0>
INFO 12-03 20:17:41 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-03 20:17:41 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-03 20:17:41 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-03 20:17:41 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-03 20:17:42 [core.py:396] EngineCore failed to start.
ERROR 12-03 20:17:42 [core.py:396] Traceback (most recent call last):
ERROR 12-03 20:17:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-03 20:17:42 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-03 20:17:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-03 20:17:42 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-03 20:17:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-03 20:17:42 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-03 20:17:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-03 20:17:42 [core.py:396]     self._init_executor()
ERROR 12-03 20:17:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-03 20:17:42 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-03 20:17:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-03 20:17:42 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-03 20:17:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-03 20:17:42 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:17:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-03 20:17:42 [core.py:396]     self.model_runner.load_model()
ERROR 12-03 20:17:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-03 20:17:42 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-03 20:17:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-03 20:17:42 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-03 20:17:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-03 20:17:42 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-03 20:17:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-03 20:17:42 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-03 20:17:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-03 20:17:42 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-03 20:17:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-03 20:17:42 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-03 20:17:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-03 20:17:42 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-03 20:17:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-03 20:17:42 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-03 20:17:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-03 20:17:42 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-03 20:17:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-03 20:17:42 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-03 20:17:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-03 20:17:42 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-03 20:17:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
ERROR 12-03 20:17:42 [core.py:396]     self.mlp = LlamaMLP(
ERROR 12-03 20:17:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
ERROR 12-03 20:17:42 [core.py:396]     self.down_proj = RowParallelLinear(
ERROR 12-03 20:17:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
ERROR 12-03 20:17:42 [core.py:396]     self.quant_method.create_weights(
ERROR 12-03 20:17:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-03 20:17:42 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-03 20:17:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-03 20:17:42 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:17:42 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3307527 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
    self.mlp = LlamaMLP(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
    self.down_proj = RowParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3307527 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f7e8a16c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f7e8a115b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f7e3b08e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f7e8a539b78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f7e8a53a20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7f7e8a550b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f7e8a53c329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f7e826864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f7e81da5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f7e81da64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x565147201c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x56514718e2a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x56514718ebbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x56514718ec83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x565147201b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x56514726dc3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x565147270f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x56514718fc98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x5651472cec30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x5651472f4407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x5651472f4634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x5651472f4718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x5651472f475b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x5651472f4972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x5651472faf60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x5651472fb1ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x5651472fb469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f7e8b2ecd90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f7e8b2ece40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x5651472662d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-03 20:17:43] ‚ö† Ê®°Âûã B_rb_manual_grpo_r00.10_r10.20_Llama-3.2-3B-Instruct__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-03 20:17:43] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_100
INFO 12-03 20:17:43 [config.py:717] This model supports multiple tasks: {'embed', 'classify', 'reward', 'generate', 'score'}. Defaulting to 'generate'.
INFO 12-03 20:17:43 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-03 20:17:43 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-03 20:17:49 [__init__.py:239] Automatically detected platform cuda.
INFO 12-03 20:17:55 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_100', speculative_config=None, tokenizer='/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_100', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_100, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-03 20:17:55 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fe9005924a0>
INFO 12-03 20:18:06 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-03 20:18:06 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-03 20:18:06 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-03 20:18:06 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_100...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-03 20:18:06 [core.py:396] EngineCore failed to start.
ERROR 12-03 20:18:06 [core.py:396] Traceback (most recent call last):
ERROR 12-03 20:18:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-03 20:18:06 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-03 20:18:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-03 20:18:06 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-03 20:18:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-03 20:18:06 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-03 20:18:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-03 20:18:06 [core.py:396]     self._init_executor()
ERROR 12-03 20:18:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-03 20:18:06 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-03 20:18:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-03 20:18:06 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-03 20:18:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-03 20:18:06 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:18:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-03 20:18:06 [core.py:396]     self.model_runner.load_model()
ERROR 12-03 20:18:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-03 20:18:06 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-03 20:18:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-03 20:18:06 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-03 20:18:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-03 20:18:06 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-03 20:18:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-03 20:18:06 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-03 20:18:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-03 20:18:06 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-03 20:18:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-03 20:18:06 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-03 20:18:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-03 20:18:06 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-03 20:18:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-03 20:18:06 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-03 20:18:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-03 20:18:06 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-03 20:18:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-03 20:18:06 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-03 20:18:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-03 20:18:06 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-03 20:18:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
ERROR 12-03 20:18:06 [core.py:396]     self.mlp = LlamaMLP(
ERROR 12-03 20:18:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
ERROR 12-03 20:18:06 [core.py:396]     self.down_proj = RowParallelLinear(
ERROR 12-03 20:18:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
ERROR 12-03 20:18:06 [core.py:396]     self.quant_method.create_weights(
ERROR 12-03 20:18:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-03 20:18:06 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-03 20:18:06 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-03 20:18:06 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:18:06 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3308258 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
    self.mlp = LlamaMLP(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
    self.down_proj = RowParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3308258 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7febb3d6c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7febb3d15b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7feb64c8e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7febb416bb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7febb416c20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7febb4182b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7febb416e329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7febac2864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7febab9a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7febab9a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x5593133a7c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x5593133342a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x559313334bbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x559313334c83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x5593133a7b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x559313413c3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x559313416f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x559313335c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x559313474c30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x55931349a407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x55931349a634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x55931349a718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x55931349a75b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x55931349a972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x5593134a0f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x5593134a11ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x5593134a1469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7febb4f36d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7febb4f36e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x55931340c2d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-03 20:18:08] ‚ö† Ê®°Âûã C_llm_verifier_grpo_Llama-3.2-3B-Instruct__global_step_100 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-03 20:18:08] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_200
INFO 12-03 20:18:08 [config.py:717] This model supports multiple tasks: {'embed', 'classify', 'reward', 'generate', 'score'}. Defaulting to 'generate'.
INFO 12-03 20:18:08 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-03 20:18:08 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-03 20:18:14 [__init__.py:239] Automatically detected platform cuda.
INFO 12-03 20:18:20 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-03 20:18:20 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f73d78c86a0>
INFO 12-03 20:18:41 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-03 20:18:41 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-03 20:18:41 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-03 20:18:41 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-03 20:18:41 [core.py:396] EngineCore failed to start.
ERROR 12-03 20:18:41 [core.py:396] Traceback (most recent call last):
ERROR 12-03 20:18:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-03 20:18:41 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-03 20:18:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-03 20:18:41 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-03 20:18:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-03 20:18:41 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-03 20:18:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-03 20:18:41 [core.py:396]     self._init_executor()
ERROR 12-03 20:18:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-03 20:18:41 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-03 20:18:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-03 20:18:41 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-03 20:18:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-03 20:18:41 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:18:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-03 20:18:41 [core.py:396]     self.model_runner.load_model()
ERROR 12-03 20:18:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-03 20:18:41 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-03 20:18:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-03 20:18:41 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-03 20:18:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-03 20:18:41 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-03 20:18:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-03 20:18:41 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-03 20:18:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-03 20:18:41 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-03 20:18:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-03 20:18:41 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-03 20:18:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-03 20:18:41 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-03 20:18:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-03 20:18:41 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-03 20:18:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-03 20:18:41 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-03 20:18:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-03 20:18:41 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-03 20:18:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-03 20:18:41 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-03 20:18:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
ERROR 12-03 20:18:41 [core.py:396]     self.mlp = LlamaMLP(
ERROR 12-03 20:18:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
ERROR 12-03 20:18:41 [core.py:396]     self.down_proj = RowParallelLinear(
ERROR 12-03 20:18:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
ERROR 12-03 20:18:41 [core.py:396]     self.quant_method.create_weights(
ERROR 12-03 20:18:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-03 20:18:41 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-03 20:18:41 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-03 20:18:41 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:18:41 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3308849 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
    self.mlp = LlamaMLP(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
    self.down_proj = RowParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3308849 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f768b56c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f768b515b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f763c08e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f768b957b78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f768b95820e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7f768b96eb0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f768b95a329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f76836864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f7682da5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f7682da64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x5645f7ef0c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x5645f7e7d2a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x5645f7e7dbbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x5645f7e7dc83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x5645f7ef0b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x5645f7f5cc3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x5645f7f5ff1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x5645f7e7ec98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x5645f7fbdc30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x5645f7fe3407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x5645f7fe3634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x5645f7fe3718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x5645f7fe375b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x5645f7fe3972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x5645f7fe9f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x5645f7fea1ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x5645f7fea469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f768c453d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f768c453e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x5645f7f552d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-03 20:18:43] ‚ö† Ê®°Âûã C_llm_verifier_grpo_Llama-3.2-3B-Instruct__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-03 20:18:43] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_300
INFO 12-03 20:18:43 [config.py:717] This model supports multiple tasks: {'embed', 'classify', 'reward', 'generate', 'score'}. Defaulting to 'generate'.
INFO 12-03 20:18:43 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-03 20:18:43 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-03 20:18:48 [__init__.py:239] Automatically detected platform cuda.
INFO 12-03 20:18:54 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_300', speculative_config=None, tokenizer='/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_300', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_300, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-03 20:18:55 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7ff3d1995ea0>
INFO 12-03 20:19:05 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-03 20:19:05 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-03 20:19:05 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-03 20:19:05 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_300...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-03 20:19:05 [core.py:396] EngineCore failed to start.
ERROR 12-03 20:19:05 [core.py:396] Traceback (most recent call last):
ERROR 12-03 20:19:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-03 20:19:05 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-03 20:19:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-03 20:19:05 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-03 20:19:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-03 20:19:05 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-03 20:19:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-03 20:19:05 [core.py:396]     self._init_executor()
ERROR 12-03 20:19:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-03 20:19:05 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-03 20:19:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-03 20:19:05 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-03 20:19:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-03 20:19:05 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:19:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-03 20:19:05 [core.py:396]     self.model_runner.load_model()
ERROR 12-03 20:19:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-03 20:19:05 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-03 20:19:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-03 20:19:05 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-03 20:19:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-03 20:19:05 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-03 20:19:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-03 20:19:05 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-03 20:19:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-03 20:19:05 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-03 20:19:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-03 20:19:05 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-03 20:19:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-03 20:19:05 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-03 20:19:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-03 20:19:05 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-03 20:19:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-03 20:19:05 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-03 20:19:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-03 20:19:05 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-03 20:19:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-03 20:19:05 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-03 20:19:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
ERROR 12-03 20:19:05 [core.py:396]     self.mlp = LlamaMLP(
ERROR 12-03 20:19:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
ERROR 12-03 20:19:05 [core.py:396]     self.down_proj = RowParallelLinear(
ERROR 12-03 20:19:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
ERROR 12-03 20:19:05 [core.py:396]     self.quant_method.create_weights(
ERROR 12-03 20:19:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-03 20:19:05 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-03 20:19:05 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-03 20:19:05 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:19:05 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3309880 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
    self.mlp = LlamaMLP(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
    self.down_proj = RowParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3309880 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7ff68536c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7ff685315b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7ff63628e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7ff68575fb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7ff68576020e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7ff685776b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7ff685762329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7ff67d8864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7ff67cfa5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7ff67cfa64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x564850067c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x56484fff42a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x56484fff4bbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x56484fff4c83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x564850067b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x5648500d3c3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x5648500d6f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x56484fff5c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x564850134c30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x56485015a407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x56485015a634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x56485015a718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x56485015a75b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x56485015a972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x564850160f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x5648501611ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x564850161469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7ff686511d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7ff686511e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x5648500cc2d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-03 20:19:07] ‚ö† Ê®°Âûã C_llm_verifier_grpo_Llama-3.2-3B-Instruct__global_step_300 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-03 20:19:07] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_313
INFO 12-03 20:19:07 [config.py:717] This model supports multiple tasks: {'embed', 'classify', 'reward', 'generate', 'score'}. Defaulting to 'generate'.
INFO 12-03 20:19:07 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-03 20:19:07 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-03 20:19:13 [__init__.py:239] Automatically detected platform cuda.
INFO 12-03 20:19:19 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-03 20:19:19 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fd2f97a64a0>
INFO 12-03 20:19:29 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-03 20:19:29 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-03 20:19:29 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-03 20:19:30 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/C_llm_verifier_grpo_Llama-3.2-3B-Instruct/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-03 20:19:30 [core.py:396] EngineCore failed to start.
ERROR 12-03 20:19:30 [core.py:396] Traceback (most recent call last):
ERROR 12-03 20:19:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-03 20:19:30 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-03 20:19:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-03 20:19:30 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-03 20:19:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-03 20:19:30 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-03 20:19:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-03 20:19:30 [core.py:396]     self._init_executor()
ERROR 12-03 20:19:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-03 20:19:30 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-03 20:19:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-03 20:19:30 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-03 20:19:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-03 20:19:30 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:19:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-03 20:19:30 [core.py:396]     self.model_runner.load_model()
ERROR 12-03 20:19:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-03 20:19:30 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-03 20:19:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-03 20:19:30 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-03 20:19:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-03 20:19:30 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-03 20:19:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-03 20:19:30 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-03 20:19:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-03 20:19:30 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-03 20:19:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-03 20:19:30 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-03 20:19:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-03 20:19:30 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-03 20:19:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-03 20:19:30 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-03 20:19:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-03 20:19:30 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-03 20:19:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-03 20:19:30 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-03 20:19:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-03 20:19:30 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-03 20:19:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
ERROR 12-03 20:19:30 [core.py:396]     self.mlp = LlamaMLP(
ERROR 12-03 20:19:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
ERROR 12-03 20:19:30 [core.py:396]     self.down_proj = RowParallelLinear(
ERROR 12-03 20:19:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
ERROR 12-03 20:19:30 [core.py:396]     self.quant_method.create_weights(
ERROR 12-03 20:19:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-03 20:19:30 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-03 20:19:30 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-03 20:19:30 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:19:30 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3310271 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
    self.mlp = LlamaMLP(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
    self.down_proj = RowParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3310271 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fd5ad16c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7fd5ad115b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7fd55e08e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7fd5ad56bb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7fd5ad56c20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7fd5ad582b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7fd5ad56e329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7fd5a56864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7fd5a4da5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7fd5a4da64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x55cf0c891c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x55cf0c81e2a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x55cf0c81ebbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x55cf0c81ec83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x55cf0c891b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x55cf0c8fdc3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x55cf0c900f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x55cf0c81fc98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x55cf0c95ec30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x55cf0c984407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x55cf0c984634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x55cf0c984718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x55cf0c98475b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x55cf0c984972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x55cf0c98af60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x55cf0c98b1ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x55cf0c98b469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7fd5ae32fd90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7fd5ae32fe40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x55cf0c8f62d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-03 20:19:31] ‚ö† Ê®°Âûã C_llm_verifier_grpo_Llama-3.2-3B-Instruct__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-03 20:19:31] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_100
INFO 12-03 20:19:31 [config.py:717] This model supports multiple tasks: {'embed', 'classify', 'reward', 'generate', 'score'}. Defaulting to 'generate'.
INFO 12-03 20:19:31 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-03 20:19:31 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-03 20:19:37 [__init__.py:239] Automatically detected platform cuda.
INFO 12-03 20:19:43 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_100', speculative_config=None, tokenizer='/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_100', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_100, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-03 20:19:43 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7ff75584a4a0>
INFO 12-03 20:19:54 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-03 20:19:54 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-03 20:19:54 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-03 20:19:54 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_100...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-03 20:19:54 [core.py:396] EngineCore failed to start.
ERROR 12-03 20:19:54 [core.py:396] Traceback (most recent call last):
ERROR 12-03 20:19:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-03 20:19:54 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-03 20:19:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-03 20:19:54 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-03 20:19:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-03 20:19:54 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-03 20:19:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-03 20:19:54 [core.py:396]     self._init_executor()
ERROR 12-03 20:19:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-03 20:19:54 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-03 20:19:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-03 20:19:54 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-03 20:19:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-03 20:19:54 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:19:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-03 20:19:54 [core.py:396]     self.model_runner.load_model()
ERROR 12-03 20:19:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-03 20:19:54 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-03 20:19:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-03 20:19:54 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-03 20:19:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-03 20:19:54 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-03 20:19:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-03 20:19:54 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-03 20:19:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-03 20:19:54 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-03 20:19:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-03 20:19:54 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-03 20:19:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-03 20:19:54 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-03 20:19:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-03 20:19:54 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-03 20:19:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-03 20:19:54 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-03 20:19:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-03 20:19:54 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-03 20:19:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-03 20:19:54 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-03 20:19:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
ERROR 12-03 20:19:54 [core.py:396]     self.mlp = LlamaMLP(
ERROR 12-03 20:19:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
ERROR 12-03 20:19:54 [core.py:396]     self.down_proj = RowParallelLinear(
ERROR 12-03 20:19:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
ERROR 12-03 20:19:54 [core.py:396]     self.quant_method.create_weights(
ERROR 12-03 20:19:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-03 20:19:54 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-03 20:19:54 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-03 20:19:54 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:19:54 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3311023 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
    self.mlp = LlamaMLP(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
    self.down_proj = RowParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3311023 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7ffa0956c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7ffa09515b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7ff9ba08e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7ffa098e9b78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7ffa098ea20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7ffa09900b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7ffa098ec329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7ffa016864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7ffa00da5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7ffa00da64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x560d66dedc04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x560d66d7a2a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x560d66d7abbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x560d66d7ac83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x560d66dedb85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x560d66e59c3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x560d66e5cf1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x560d66d7bc98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x560d66ebac30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x560d66ee0407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x560d66ee0634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x560d66ee0718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x560d66ee075b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x560d66ee0972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x560d66ee6f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x560d66ee71ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x560d66ee7469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7ffa0a3e5d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7ffa0a3e5e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x560d66e522d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-03 20:19:56] ‚ö† Ê®°Âûã D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct__global_step_100 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-03 20:19:56] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_200
INFO 12-03 20:19:56 [config.py:717] This model supports multiple tasks: {'embed', 'classify', 'reward', 'generate', 'score'}. Defaulting to 'generate'.
INFO 12-03 20:19:56 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-03 20:19:56 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-03 20:20:01 [__init__.py:239] Automatically detected platform cuda.
INFO 12-03 20:20:07 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-03 20:20:08 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f90a25fc6a0>
INFO 12-03 20:20:28 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-03 20:20:28 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-03 20:20:28 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-03 20:20:28 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-03 20:20:28 [core.py:396] EngineCore failed to start.
ERROR 12-03 20:20:28 [core.py:396] Traceback (most recent call last):
ERROR 12-03 20:20:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-03 20:20:28 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-03 20:20:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-03 20:20:28 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-03 20:20:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-03 20:20:28 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-03 20:20:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-03 20:20:28 [core.py:396]     self._init_executor()
ERROR 12-03 20:20:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-03 20:20:28 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-03 20:20:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-03 20:20:28 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-03 20:20:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-03 20:20:28 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:20:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-03 20:20:28 [core.py:396]     self.model_runner.load_model()
ERROR 12-03 20:20:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-03 20:20:28 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-03 20:20:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-03 20:20:28 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-03 20:20:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-03 20:20:28 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-03 20:20:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-03 20:20:28 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-03 20:20:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-03 20:20:28 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-03 20:20:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-03 20:20:28 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-03 20:20:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-03 20:20:28 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-03 20:20:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-03 20:20:28 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-03 20:20:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-03 20:20:28 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-03 20:20:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-03 20:20:28 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-03 20:20:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-03 20:20:28 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-03 20:20:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
ERROR 12-03 20:20:28 [core.py:396]     self.mlp = LlamaMLP(
ERROR 12-03 20:20:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
ERROR 12-03 20:20:28 [core.py:396]     self.down_proj = RowParallelLinear(
ERROR 12-03 20:20:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
ERROR 12-03 20:20:28 [core.py:396]     self.quant_method.create_weights(
ERROR 12-03 20:20:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-03 20:20:28 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-03 20:20:28 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-03 20:20:28 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:20:28 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3311599 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
    self.mlp = LlamaMLP(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
    self.down_proj = RowParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3311599 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f9355d6c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f9355d15b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f9306c8e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f935616bb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f935616c20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7f9356182b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f935616e329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f934e2864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f934d9a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f934d9a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x5616bad59c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x5616bace62a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x5616bace6bbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x5616bace6c83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x5616bad59b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x5616badc5c3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x5616badc8f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x5616bace7c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x5616bae26c30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x5616bae4c407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x5616bae4c634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x5616bae4c718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x5616bae4c75b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x5616bae4c972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x5616bae52f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x5616bae531ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x5616bae53469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f9356fb6d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f9356fb6e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x5616badbe2d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-03 20:20:30] ‚ö† Ê®°Âûã D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-03 20:20:30] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_300
INFO 12-03 20:20:30 [config.py:717] This model supports multiple tasks: {'embed', 'classify', 'reward', 'generate', 'score'}. Defaulting to 'generate'.
INFO 12-03 20:20:30 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-03 20:20:30 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-03 20:20:35 [__init__.py:239] Automatically detected platform cuda.
INFO 12-03 20:20:41 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_300', speculative_config=None, tokenizer='/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_300', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_300, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-03 20:20:42 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f283b816b90>
INFO 12-03 20:20:52 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-03 20:20:52 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-03 20:20:52 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-03 20:20:52 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_300...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-03 20:20:53 [core.py:396] EngineCore failed to start.
ERROR 12-03 20:20:53 [core.py:396] Traceback (most recent call last):
ERROR 12-03 20:20:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-03 20:20:53 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-03 20:20:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-03 20:20:53 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-03 20:20:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-03 20:20:53 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-03 20:20:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-03 20:20:53 [core.py:396]     self._init_executor()
ERROR 12-03 20:20:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-03 20:20:53 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-03 20:20:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-03 20:20:53 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-03 20:20:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-03 20:20:53 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:20:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-03 20:20:53 [core.py:396]     self.model_runner.load_model()
ERROR 12-03 20:20:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-03 20:20:53 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-03 20:20:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-03 20:20:53 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-03 20:20:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-03 20:20:53 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-03 20:20:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-03 20:20:53 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-03 20:20:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-03 20:20:53 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-03 20:20:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-03 20:20:53 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-03 20:20:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-03 20:20:53 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-03 20:20:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-03 20:20:53 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-03 20:20:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-03 20:20:53 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-03 20:20:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-03 20:20:53 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-03 20:20:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-03 20:20:53 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-03 20:20:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
ERROR 12-03 20:20:53 [core.py:396]     self.mlp = LlamaMLP(
ERROR 12-03 20:20:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
ERROR 12-03 20:20:53 [core.py:396]     self.down_proj = RowParallelLinear(
ERROR 12-03 20:20:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
ERROR 12-03 20:20:53 [core.py:396]     self.quant_method.create_weights(
ERROR 12-03 20:20:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-03 20:20:53 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-03 20:20:53 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-03 20:20:53 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:20:53 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3312675 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
    self.mlp = LlamaMLP(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
    self.down_proj = RowParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3312675 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f2aef16c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f2aef115b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f2aa008e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f2aef56bb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f2aef56c20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7f2aef582b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f2aef56e329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f2ae76864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f2ae6da5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f2ae6da64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x564ecbd42c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x564ecbccf2a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x564ecbccfbbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x564ecbccfc83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x564ecbd42b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x564ecbdaec3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x564ecbdb1f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x564ecbcd0c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x564ecbe0fc30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x564ecbe35407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x564ecbe35634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x564ecbe35718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x564ecbe3575b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x564ecbe35972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x564ecbe3bf60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x564ecbe3c1ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x564ecbe3c469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f2af0371d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f2af0371e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x564ecbda72d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-03 20:20:54] ‚ö† Ê®°Âûã D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct__global_step_300 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-03 20:20:54] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_313
INFO 12-03 20:20:54 [config.py:717] This model supports multiple tasks: {'embed', 'classify', 'reward', 'generate', 'score'}. Defaulting to 'generate'.
INFO 12-03 20:20:54 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-03 20:20:54 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-03 20:21:00 [__init__.py:239] Automatically detected platform cuda.
INFO 12-03 20:21:06 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-03 20:21:06 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fadcf62e4a0>
INFO 12-03 20:21:17 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-03 20:21:17 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-03 20:21:17 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-03 20:21:17 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-03 20:21:17 [core.py:396] EngineCore failed to start.
ERROR 12-03 20:21:17 [core.py:396] Traceback (most recent call last):
ERROR 12-03 20:21:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-03 20:21:17 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-03 20:21:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-03 20:21:17 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-03 20:21:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-03 20:21:17 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-03 20:21:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-03 20:21:17 [core.py:396]     self._init_executor()
ERROR 12-03 20:21:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-03 20:21:17 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-03 20:21:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-03 20:21:17 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-03 20:21:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-03 20:21:17 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:21:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-03 20:21:17 [core.py:396]     self.model_runner.load_model()
ERROR 12-03 20:21:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-03 20:21:17 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-03 20:21:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-03 20:21:17 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-03 20:21:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-03 20:21:17 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-03 20:21:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-03 20:21:17 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-03 20:21:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-03 20:21:17 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-03 20:21:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-03 20:21:17 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-03 20:21:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-03 20:21:17 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-03 20:21:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-03 20:21:17 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-03 20:21:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-03 20:21:17 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-03 20:21:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-03 20:21:17 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-03 20:21:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-03 20:21:17 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-03 20:21:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
ERROR 12-03 20:21:17 [core.py:396]     self.mlp = LlamaMLP(
ERROR 12-03 20:21:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
ERROR 12-03 20:21:17 [core.py:396]     self.down_proj = RowParallelLinear(
ERROR 12-03 20:21:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
ERROR 12-03 20:21:17 [core.py:396]     self.quant_method.create_weights(
ERROR 12-03 20:21:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-03 20:21:17 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-03 20:21:17 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-03 20:21:17 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:21:17 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3313182 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
    self.mlp = LlamaMLP(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
    self.down_proj = RowParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3313182 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fb08336c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7fb083315b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7fb033e8e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7fb0836ddb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7fb0836de20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7fb0836f4b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7fb0836e0329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7fb07b4864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7fb07aba5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7fb07aba64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x5645f5ba1c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x5645f5b2e2a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x5645f5b2ebbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x5645f5b2ec83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x5645f5ba1b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x5645f5c0dc3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x5645f5c10f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x5645f5b2fc98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x5645f5c6ec30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x5645f5c94407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x5645f5c94634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x5645f5c94718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x5645f5c9475b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x5645f5c94972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x5645f5c9af60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x5645f5c9b1ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x5645f5c9b469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7fb0841d9d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7fb0841d9e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x5645f5c062d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-03 20:21:19] ‚ö† Ê®°Âûã D_rb_online_rho1_algo2_Llama-3.2-3B-Instruct__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-03 20:21:19] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_100
INFO 12-03 20:21:19 [config.py:717] This model supports multiple tasks: {'embed', 'classify', 'reward', 'generate', 'score'}. Defaulting to 'generate'.
INFO 12-03 20:21:19 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-03 20:21:19 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-03 20:21:24 [__init__.py:239] Automatically detected platform cuda.
INFO 12-03 20:21:31 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_100', speculative_config=None, tokenizer='/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_100', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_100, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-03 20:21:31 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f5fc62fdba0>
INFO 12-03 20:21:41 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-03 20:21:41 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-03 20:21:41 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-03 20:21:41 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_100...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-03 20:21:42 [core.py:396] EngineCore failed to start.
ERROR 12-03 20:21:42 [core.py:396] Traceback (most recent call last):
ERROR 12-03 20:21:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-03 20:21:42 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-03 20:21:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-03 20:21:42 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-03 20:21:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-03 20:21:42 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-03 20:21:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-03 20:21:42 [core.py:396]     self._init_executor()
ERROR 12-03 20:21:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-03 20:21:42 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-03 20:21:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-03 20:21:42 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-03 20:21:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-03 20:21:42 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:21:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-03 20:21:42 [core.py:396]     self.model_runner.load_model()
ERROR 12-03 20:21:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-03 20:21:42 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-03 20:21:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-03 20:21:42 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-03 20:21:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-03 20:21:42 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-03 20:21:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-03 20:21:42 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-03 20:21:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-03 20:21:42 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-03 20:21:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-03 20:21:42 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-03 20:21:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-03 20:21:42 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-03 20:21:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-03 20:21:42 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-03 20:21:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-03 20:21:42 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-03 20:21:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-03 20:21:42 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-03 20:21:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-03 20:21:42 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-03 20:21:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
ERROR 12-03 20:21:42 [core.py:396]     self.mlp = LlamaMLP(
ERROR 12-03 20:21:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
ERROR 12-03 20:21:42 [core.py:396]     self.down_proj = RowParallelLinear(
ERROR 12-03 20:21:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
ERROR 12-03 20:21:42 [core.py:396]     self.quant_method.create_weights(
ERROR 12-03 20:21:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-03 20:21:42 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-03 20:21:42 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-03 20:21:42 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:21:42 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3313910 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
    self.mlp = LlamaMLP(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
    self.down_proj = RowParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3313910 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f6279f6c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f6279f15b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f622aa8e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f627a38bb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f627a38c20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7f627a3a2b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f627a38e329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f62720864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f62717a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f62717a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x559127ed9c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x559127e662a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x559127e66bbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x559127e66c83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x559127ed9b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x559127f45c3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x559127f48f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x559127e67c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x559127fa6c30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x559127fcc407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x559127fcc634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x559127fcc718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x559127fcc75b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x559127fcc972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x559127fd2f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x559127fd31ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x559127fd3469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f627ae87d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f627ae87e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x559127f3e2d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-03 20:21:43] ‚ö† Ê®°Âûã E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct__global_step_100 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-03 20:21:43] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_200
INFO 12-03 20:21:43 [config.py:717] This model supports multiple tasks: {'embed', 'classify', 'reward', 'generate', 'score'}. Defaulting to 'generate'.
INFO 12-03 20:21:43 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-03 20:21:43 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-03 20:21:49 [__init__.py:239] Automatically detected platform cuda.
INFO 12-03 20:21:55 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_200', speculative_config=None, tokenizer='/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-03 20:21:56 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f32dae39900>
INFO 12-03 20:22:06 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-03 20:22:06 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-03 20:22:06 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-03 20:22:06 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_200...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-03 20:22:07 [core.py:396] EngineCore failed to start.
ERROR 12-03 20:22:07 [core.py:396] Traceback (most recent call last):
ERROR 12-03 20:22:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-03 20:22:07 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-03 20:22:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-03 20:22:07 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-03 20:22:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-03 20:22:07 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-03 20:22:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-03 20:22:07 [core.py:396]     self._init_executor()
ERROR 12-03 20:22:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-03 20:22:07 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-03 20:22:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-03 20:22:07 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-03 20:22:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-03 20:22:07 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:22:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-03 20:22:07 [core.py:396]     self.model_runner.load_model()
ERROR 12-03 20:22:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-03 20:22:07 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-03 20:22:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-03 20:22:07 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-03 20:22:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-03 20:22:07 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-03 20:22:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-03 20:22:07 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-03 20:22:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-03 20:22:07 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-03 20:22:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-03 20:22:07 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-03 20:22:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-03 20:22:07 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-03 20:22:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-03 20:22:07 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-03 20:22:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-03 20:22:07 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-03 20:22:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-03 20:22:07 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-03 20:22:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-03 20:22:07 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-03 20:22:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
ERROR 12-03 20:22:07 [core.py:396]     self.mlp = LlamaMLP(
ERROR 12-03 20:22:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
ERROR 12-03 20:22:07 [core.py:396]     self.down_proj = RowParallelLinear(
ERROR 12-03 20:22:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
ERROR 12-03 20:22:07 [core.py:396]     self.quant_method.create_weights(
ERROR 12-03 20:22:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-03 20:22:07 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-03 20:22:07 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-03 20:22:07 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:22:07 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3314432 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
    self.mlp = LlamaMLP(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
    self.down_proj = RowParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3314432 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f358e76c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f358e715b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f353f68e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f358eb6bb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f358eb6c20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7f358eb82b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f358eb6e329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f3586c864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f35863a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f35863a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x55aa37b69c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x55aa37af62a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x55aa37af6bbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x55aa37af6c83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x55aa37b69b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x55aa37bd5c3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x55aa37bd8f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x55aa37af7c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x55aa37c36c30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x55aa37c5c407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x55aa37c5c634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x55aa37c5c718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x55aa37c5c75b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x55aa37c5c972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x55aa37c62f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x55aa37c631ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x55aa37c63469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f358f993d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f358f993e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x55aa37bce2d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-03 20:22:08] ‚ö† Ê®°Âûã E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct__global_step_200 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-03 20:22:08] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_300
INFO 12-03 20:22:08 [config.py:717] This model supports multiple tasks: {'embed', 'classify', 'reward', 'generate', 'score'}. Defaulting to 'generate'.
INFO 12-03 20:22:08 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-03 20:22:08 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-03 20:22:14 [__init__.py:239] Automatically detected platform cuda.
INFO 12-03 20:22:20 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_300', speculative_config=None, tokenizer='/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_300', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_300, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-03 20:22:20 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f4e1004a4a0>
INFO 12-03 20:22:31 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-03 20:22:31 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-03 20:22:31 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-03 20:22:31 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_300...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-03 20:22:31 [core.py:396] EngineCore failed to start.
ERROR 12-03 20:22:31 [core.py:396] Traceback (most recent call last):
ERROR 12-03 20:22:31 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-03 20:22:31 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-03 20:22:31 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-03 20:22:31 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-03 20:22:31 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-03 20:22:31 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-03 20:22:31 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-03 20:22:31 [core.py:396]     self._init_executor()
ERROR 12-03 20:22:31 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-03 20:22:31 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-03 20:22:31 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-03 20:22:31 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-03 20:22:31 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-03 20:22:31 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:22:31 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-03 20:22:31 [core.py:396]     self.model_runner.load_model()
ERROR 12-03 20:22:31 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-03 20:22:31 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-03 20:22:31 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-03 20:22:31 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-03 20:22:31 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-03 20:22:31 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-03 20:22:31 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-03 20:22:31 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-03 20:22:31 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-03 20:22:31 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-03 20:22:31 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-03 20:22:31 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-03 20:22:31 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-03 20:22:31 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-03 20:22:31 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-03 20:22:31 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-03 20:22:31 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-03 20:22:31 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-03 20:22:31 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-03 20:22:31 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-03 20:22:31 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-03 20:22:31 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-03 20:22:31 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
ERROR 12-03 20:22:31 [core.py:396]     self.mlp = LlamaMLP(
ERROR 12-03 20:22:31 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
ERROR 12-03 20:22:31 [core.py:396]     self.down_proj = RowParallelLinear(
ERROR 12-03 20:22:31 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
ERROR 12-03 20:22:31 [core.py:396]     self.quant_method.create_weights(
ERROR 12-03 20:22:31 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-03 20:22:31 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-03 20:22:31 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-03 20:22:31 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:22:31 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3315089 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
    self.mlp = LlamaMLP(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
    self.down_proj = RowParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3315089 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f50c3b6c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f50c3b15b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f507468e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f50c3efbb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f50c3efc20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7f50c3f12b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f50c3efe329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f50bbc864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f50bb3a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f50bb3a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x55fabed88c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x55fabed152a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x55fabed15bbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x55fabed15c83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x55fabed88b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x55fabedf4c3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x55fabedf7f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x55fabed16c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x55fabee55c30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x55fabee7b407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x55fabee7b634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x55fabee7b718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x55fabee7b75b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x55fabee7b972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x55fabee81f60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x55fabee821ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x55fabee82469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f50c49f7d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f50c49f7e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x55fabeded2d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-03 20:22:33] ‚ö† Ê®°Âûã E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct__global_step_300 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
[2025-12-03 20:22:33] ‚ñ∂ Âä†ËΩΩÊ®°ÂûãÔºà‰∏ÄÊ¨°ÔºâÔºö/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_313
INFO 12-03 20:22:33 [config.py:717] This model supports multiple tasks: {'embed', 'classify', 'reward', 'generate', 'score'}. Defaulting to 'generate'.
INFO 12-03 20:22:33 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-03 20:22:33 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 12-03 20:22:38 [__init__.py:239] Automatically detected platform cuda.
INFO 12-03 20:22:44 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_313', speculative_config=None, tokenizer='/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_313', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_313, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}
WARNING 12-03 20:22:45 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f29b8c198d0>
INFO 12-03 20:22:55 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 12-03 20:22:55 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 12-03 20:22:55 [topk_topp_sampler.py:59] Using FlashInfer for top-p & top-k sampling.
INFO 12-03 20:22:55 [gpu_model_runner.py:1329] Starting to load model /data/giil/caixq/export/E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct/global_step_313...
CUDA Error: out of memory at /workspace/csrc/cumem_allocator.cpp:62
ERROR 12-03 20:22:56 [core.py:396] EngineCore failed to start.
ERROR 12-03 20:22:56 [core.py:396] Traceback (most recent call last):
ERROR 12-03 20:22:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
ERROR 12-03 20:22:56 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 12-03 20:22:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
ERROR 12-03 20:22:56 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 12-03 20:22:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
ERROR 12-03 20:22:56 [core.py:396]     self.model_executor = executor_class(vllm_config)
ERROR 12-03 20:22:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 12-03 20:22:56 [core.py:396]     self._init_executor()
ERROR 12-03 20:22:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 12-03 20:22:56 [core.py:396]     self.collective_rpc("load_model")
ERROR 12-03 20:22:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 12-03 20:22:56 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-03 20:22:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
ERROR 12-03 20:22:56 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:22:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
ERROR 12-03 20:22:56 [core.py:396]     self.model_runner.load_model()
ERROR 12-03 20:22:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
ERROR 12-03 20:22:56 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 12-03 20:22:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 12-03 20:22:56 [core.py:396]     return loader.load_model(vllm_config=vllm_config)
ERROR 12-03 20:22:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 12-03 20:22:56 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)
ERROR 12-03 20:22:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 12-03 20:22:56 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 12-03 20:22:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
ERROR 12-03 20:22:56 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 12-03 20:22:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
ERROR 12-03 20:22:56 [core.py:396]     return LlamaModel(vllm_config=vllm_config,
ERROR 12-03 20:22:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 12-03 20:22:56 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 12-03 20:22:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 12-03 20:22:56 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 12-03 20:22:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
ERROR 12-03 20:22:56 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [
ERROR 12-03 20:22:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
ERROR 12-03 20:22:56 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 12-03 20:22:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 12-03 20:22:56 [core.py:396]     lambda prefix: layer_type(config=config,
ERROR 12-03 20:22:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
ERROR 12-03 20:22:56 [core.py:396]     self.mlp = LlamaMLP(
ERROR 12-03 20:22:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
ERROR 12-03 20:22:56 [core.py:396]     self.down_proj = RowParallelLinear(
ERROR 12-03 20:22:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
ERROR 12-03 20:22:56 [core.py:396]     self.quant_method.create_weights(
ERROR 12-03 20:22:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
ERROR 12-03 20:22:56 [core.py:396]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 12-03 20:22:56 [core.py:396]   File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 12-03 20:22:56 [core.py:396]     return func(*args, **kwargs)
ERROR 12-03 20:22:56 [core.py:396] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3315596 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process EngineCore_0:
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 400, in run_engine_core
    raise e
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 387, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 329, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 64, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 52, in __init__
    self._init_executor()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("load_model")
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 162, in load_model
    self.model_runner.load_model()
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1332, in load_model
    self.model = get_model(vllm_config=self.vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
    return loader.load_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
    model = _initialize_model(vllm_config=vllm_config)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
    return model_class(vllm_config=vllm_config, prefix=prefix)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 496, in __init__
    self.model = self._init_model(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 542, in _init_model
    return LlamaModel(vllm_config=vllm_config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 151, in __init__
    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
    self.start_layer, self.end_layer, self.layers = make_layers(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 609, in make_layers
    [PPMissingLayer() for _ in range(start_layer)] + [
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 610, in <listcomp>
    maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
    lambda prefix: layer_type(config=config,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
    self.mlp = LlamaMLP(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 77, in __init__
    self.down_proj = RowParallelLinear(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 1194, in __init__
    self.quant_method.create_weights(
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 189, in create_weights
    weight = Parameter(torch.empty(sum(output_partition_sizes),
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 14.81 MiB is free. Process 3289344 has 35.91 GiB memory in use. Process 3315596 has 3.46 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, with 33.83 MiB allocated in private pools (e.g., CUDA Graphs), and 13.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Trying to free a pointer not allocated here
Exception raised from raw_delete at /pytorch/torch/csrc/cuda/CUDAPluggableAllocator.cpp:151 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f2c6c56c1b6 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x68 (0x7f2c6c515b3f in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: torch::cuda::CUDAPluggableAllocator::CUDAPluggableAllocator::raw_delete(void*) + 0x1a7 (0x7f2c1d48e667 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0x22b78 (0x7f2c6c96bb78 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2320e (0x7f2c6c96c20e in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x39b0d (0x7f2c6c982b0d in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #6: c10::cuda::MemPool::~MemPool() + 0x1b9 (0x7f2c6c96e329 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0xdf74f0 (0x7f2c64a864f0 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x516907 (0x7f2c641a5907 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x5174d1 (0x7f2c641a64d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x1acc04 (0x55b223e74c04 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #11: <unknown function> + 0x1392a2 (0x55b223e012a2 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #12: <unknown function> + 0x139bbb (0x55b223e01bbb in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #13: <unknown function> + 0x139c83 (0x55b223e01c83 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #14: <unknown function> + 0x1acb85 (0x55b223e74b85 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #15: <unknown function> + 0x218c3c (0x55b223ee0c3c in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #16: <unknown function> + 0x21bf1b (0x55b223ee3f1b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #17: <unknown function> + 0x13ac98 (0x55b223e02c98 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #18: <unknown function> + 0x279c30 (0x55b223f41c30 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #19: <unknown function> + 0x29f407 (0x55b223f67407 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #20: Py_FinalizeEx + 0x134 (0x55b223f67634 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #21: Py_Exit + 0x8 (0x55b223f67718 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #22: <unknown function> + 0x29f75b (0x55b223f6775b in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #23: PyErr_PrintEx + 0x12 (0x55b223f67972 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #24: PyRun_SimpleStringFlags + 0x50 (0x55b223f6df60 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #25: Py_RunMain + 0x26c (0x55b223f6e1ec in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #26: Py_BytesMain + 0x39 (0x55b223f6e469 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)
frame #27: <unknown function> + 0x29d90 (0x7f2c6d7afd90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #28: __libc_start_main + 0x80 (0x7f2c6d7afe40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #29: <unknown function> + 0x2112d1 (0x55b223ed92d1 in /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3)

[2025-12-03 20:22:57] ‚ö† Ê®°Âûã E_rb_rule_addon_tinyv_Llama-3.2-3B-Instruct__global_step_313 ËØÑÊµãÂ§±Ë¥•ÔºöRuntimeError('Engine core initialization failed. See root cause above.')
