+ TEMP_G1=0.6
+ TEMP_G2=0.0
+ NSAMP_G1=8
+ NSAMP_G2=8
+ export EVAL_ONE_MODEL_TIMEOUT=21600
+ EVAL_ONE_MODEL_TIMEOUT=21600
+ export PASS_AT_KS=1,8
+ PASS_AT_KS=1,8
+ export TORCH_CPP_LOG_LEVEL=ERROR
+ TORCH_CPP_LOG_LEVEL=ERROR
++ seq -s, 0 0
+ export CUDA_VISIBLE_DEVICES=0
+ CUDA_VISIBLE_DEVICES=0
+ export VLLM_WORKER_MULTIPROC_METHOD=spawn
+ VLLM_WORKER_MULTIPROC_METHOD=spawn
+ export PYTHONUNBUFFERED=1
+ PYTHONUNBUFFERED=1
+ export VLLM_USE_FLASHINFER_SAMPLER=1
+ VLLM_USE_FLASHINFER_SAMPLER=1
+ args=(--model_root "$MODEL_ROOT" --out_root "$OUT_ROOT" --prompt_type "$PROMPT_TYPE" --max_tokens_per_call "$MAX_TOKENS" --nproc "$NUM_GPUS" --base_root "$BASE_ROOT" --use_vllm --pipeline_parallel_size 1 --vllm_batch_size 0 --temperature_g1 "$TEMP_G1" --temperature_g2 "$TEMP_G2" --n_sampling_g1 "$NSAMP_G1" --n_sampling_g2 "$NSAMP_G2" --cleanup_exported)
+ '[' false = true ']'
+ echo '[INFO] Running: /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3 -u tools/run_qwen_eval_all_shared.py --model_root /data/giil/caixq/ckpts/noise_rlvr_DeepSeek-1.5B --out_root /uge_mnt/home/caixq/project/noisy-RLVR/new_eval_noise_rlvr_DeepSeek-1.5B_think-boxed --prompt_type think-boxed --max_tokens_per_call 3072 --nproc 1 --base_root /hss/giil/caixq/model --use_vllm --pipeline_parallel_size 1 --vllm_batch_size 0 --temperature_g1 0.6 --temperature_g2 0.0 --n_sampling_g1 8 --n_sampling_g2 8 --cleanup_exported'
[INFO] Running: /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3 -u tools/run_qwen_eval_all_shared.py --model_root /data/giil/caixq/ckpts/noise_rlvr_DeepSeek-1.5B --out_root /uge_mnt/home/caixq/project/noisy-RLVR/new_eval_noise_rlvr_DeepSeek-1.5B_think-boxed --prompt_type think-boxed --max_tokens_per_call 3072 --nproc 1 --base_root /hss/giil/caixq/model --use_vllm --pipeline_parallel_size 1 --vllm_batch_size 0 --temperature_g1 0.6 --temperature_g2 0.0 --n_sampling_g1 8 --n_sampling_g2 8 --cleanup_exported
+ /uge_mnt/home/caixq/miniconda3/envs/eval/bin/python3 -u tools/run_qwen_eval_all_shared.py --model_root /data/giil/caixq/ckpts/noise_rlvr_DeepSeek-1.5B --out_root /uge_mnt/home/caixq/project/noisy-RLVR/new_eval_noise_rlvr_DeepSeek-1.5B_think-boxed --prompt_type think-boxed --max_tokens_per_call 3072 --nproc 1 --base_root /hss/giil/caixq/model --use_vllm --pipeline_parallel_size 1 --vllm_batch_size 0 --temperature_g1 0.6 --temperature_g2 0.0 --n_sampling_g1 8 --n_sampling_g2 8 --cleanup_exported
Traceback (most recent call last):
  File "/uge_mnt/home/caixq/project/Qwen2.5-Eval-v3/evaluation/tools/run_qwen_eval_all_shared.py", line 20, in <module>
    from math_eval import main as eval_one_dataset
  File "/uge_mnt/home/caixq/project/Qwen2.5-Eval-v3/evaluation/math_eval.py", line 6, in <module>
    from vllm import LLM, SamplingParams
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/__init__.py", line 12, in <module>
    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/engine/arg_utils.py", line 18, in <module>
    from vllm.config import (BlockSize, CacheConfig, CacheDType, CompilationConfig,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/config.py", line 30, in <module>
    from vllm.model_executor.layers.quantization import (QUANTIZATION_METHODS,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/__init__.py", line 3, in <module>
    from vllm.model_executor.parameter import (BasevLLMParameter,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/model_executor/parameter.py", line 9, in <module>
    from vllm.distributed import get_tensor_model_parallel_rank
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/distributed/__init__.py", line 3, in <module>
    from .communication_op import *
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/distributed/communication_op.py", line 8, in <module>
    from .parallel_state import get_tp_group
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/distributed/parallel_state.py", line 149, in <module>
    from vllm.platforms import current_platform
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/platforms/__init__.py", line 11, in <module>
    from .interface import _Backend  # noqa: F401
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/platforms/interface.py", line 11, in <module>
    from vllm.inputs import ProcessorInputs, PromptType
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/inputs/__init__.py", line 8, in <module>
    from .registry import (DummyData, InputContext, InputProcessingContext,
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/vllm/inputs/registry.py", line 6, in <module>
    from transformers import BatchFeature, PretrainedConfig, ProcessorMixin
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1955, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1967, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/transformers/processing_utils.py", line 33, in <module>
    from .image_utils import (
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/transformers/image_utils.py", line 64, in <module>
    from torchvision import io as torchvision_io
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torchvision/__init__.py", line 10, in <module>
    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils  # usort:skip
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torchvision/models/__init__.py", line 2, in <module>
    from .convnext import *
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torchvision/models/convnext.py", line 8, in <module>
    from ..ops.misc import Conv2dNormActivation, Permute
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torchvision/ops/__init__.py", line 1, in <module>
    from ._register_onnx_ops import _register_custom_op
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torchvision/ops/_register_onnx_ops.py", line 5, in <module>
    from torch.onnx import symbolic_opset11 as opset11
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/onnx/__init__.py", line 67, in <module>
    from .utils import (
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/onnx/utils.py", line 25, in <module>
    from torch.onnx._internal import diagnostics, jit_utils, onnx_proto_utils, registration
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/onnx/_internal/diagnostics/__init__.py", line 1, in <module>
    from ._diagnostic import (
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/onnx/_internal/diagnostics/_diagnostic.py", line 11, in <module>
    from torch.onnx._internal.diagnostics import infra
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/onnx/_internal/diagnostics/infra/__init__.py", line 1, in <module>
    from ._infra import (
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/onnx/_internal/diagnostics/infra/_infra.py", line 11, in <module>
    from torch.onnx._internal.diagnostics.infra import formatter, sarif
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/onnx/_internal/diagnostics/infra/formatter.py", line 10, in <module>
    from torch.onnx._internal.diagnostics.infra import sarif
  File "/uge_mnt/home/caixq/miniconda3/envs/eval/lib/python3.10/site-packages/torch/onnx/_internal/diagnostics/infra/sarif/__init__.py", line 19, in <module>
    from torch.onnx._internal.diagnostics.infra.sarif._edge import Edge
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 975, in get_code
  File "<frozen importlib._bootstrap_external>", line 1074, in get_data
KeyboardInterrupt
